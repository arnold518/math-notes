# Pearson New International Edition 

Topology<br>James Munkres<br>Second Edition

## Pearson Education Limited

Edinburgh Gate

Harlow

Essex CM20 2JE

England and Associated Companies throughout the world

Visit us on the World Wide Web at: www.pearsoned.co.uk

(C) Pearson Education Limited 2014

All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the prior written permission of the publisher or a licence permitting restricted copying in the United Kingdom issued by the Copyright Licensing Agency Ltd, Saffron House, 6-10 Kirby Street, London EC1N 8TS.

All trademarks used herein are the property of their respective owners. The use of any trademark in this text does not vest in the author or publisher any trademark ownership rights in such trademarks, nor does the use of such trademarks imply any affiliation with or endorsement of this book by such owners.

## British Library Cataloguing-in-Publication Data

A catalogue record for this book is available from the British Library

P E A R S O $N \quad$ C U S T O $M$ L I B $R$ A $R \quad Y$

## Table of Contents

Chapter I. Set Theory and Logic James Munkres ..... 1
Chapter 2. Topological Spaces and Continuous Functions James Munkres ..... 73
Chapter 3. Connectedness and Compactness James Munkres ..... 145
Chapter 4. Countability and Separation Axioms James Munkres ..... 187
Chapter 5. The Tychonoff Theorem James Munkres ..... 228
Chapter 6. Metrization Theorems and Paracompactness James Munkres ..... 241
Chapter 7. Complete Metric Spaces and Function Spaces James Munkres ..... 261
Chapter 8. Baire Spaces and Dimension Theory James Munkres ..... 292
Chapter 9. The Fundamental Group James Munkres ..... 317
Chapter 10. Separation Theorems in the Plane James Munkres ..... 372
Chapter II. The Seifert-van Kampen Theorem James Munkres ..... 403
Chapter 13. Classification of Covering Spaces James Munkres ..... 443
Chapter 12. Classification of Surfaces James Munkres ..... 468
Bibliography James Munkres ..... 499

## Chapter 1

## Set Theory and Logic

We adopt, as most mathematicians do, the naive point of view regarding set theory. We shall assume that what is meant by a set of objects is intuitively clear, and we shall proceed on that basis without analyzing the concept further. Such an analysis properly belongs to the foundations of mathematics and to mathematical logic, and it is not our purpose to initiate the study of those fields.

Logicians have analyzed set theory in great detail, and they have formulated axioms for the subject. Each of their axioms expresses a property of sets that mathematicians commonly accept, and collectively the axioms provide a foundation broad enough and strong enough that the rest of mathematics can be built on them.

It is unfortunately true that careless use of set theory, relying on intuition alone, can lead to contradictions. Indeed, one of the reasons for the axiomatization of set theory was to formulate rules for dealing with sets that would avoid these contradictions. Although we shall not deal with the axioms explicitly, the rules we follow in dealing with sets derive from them. In this book, you will learn how to deal with sets in an "apprentice" fashion, by observing how we handle them and by working with them yourself. At some point of your studies, you may wish to study set theory more carefully and in greater detail; then a course in logic or foundations will be in order.

## §1 Fundamental Concepts

Here we introduce the ideas of set theory, and establish the basic terminology and notation. We also discuss some points of elementary logic that, in our experience, are apt to cause confusion.

## Basic Notation

Commonly we shall use capital letters $A, B, \ldots$ to denote sets, and lowercase letters $a, b, \ldots$ to denote the objects or elements belonging to these sets. If an object $a$ belongs to a set $A$, we express this fact by the notation

$$
a \in A .
$$

If $a$ does not belong to $A$, we express this fact by writing

$$
a \notin A \text {. }
$$

The equality symbol $=$ is used throughout this book to mean logical identity. Thus, when we write $a=b$, we mean that " $a$ " and " $b$ " are symbols for the same object. This is what one means in arithmetic, for example, when one writes $\frac{2}{4}=\frac{1}{2}$. Similarly, the equation $A=B$ states that " $A$ " and " $B$ " are symbols for the same set; that is, $A$ and $B$ consist of precisely the same objects.

If $a$ and $b$ are different objects, we write $a \neq b$; and if $A$ and $B$ are different sets, we write $A \neq B$. For example, if $A$ is the set of all nonnegative real numbers, and $B$ is the set of all positive real numbers, then $A \neq B$, because the number 0 belongs to $A$ and not to $B$.

We say that $A$ is a subset of $B$ if every element of $A$ is also an element of $B$; and we express this fact by writing

$$
A \subset B .
$$

Nothing in this definition requires $A$ to be different from $B$; in fact, if $A=B$, it is true that both $A \subset B$ and $B \subset A$. If $A \subset B$ and $A$ is different from $B$, we say that $A$ is a proper subset of $B$, and we write

$$
A \subsetneq B .
$$

The relations $\subset$ and $\subsetneq$ are called inclusion and proper inclusion, respectively. If $A \subset B$, we also write $B \supset A$, which is read " $B$ contains $A$."

How does one go about specifying a set? If the set has only a few elements, one can simply list the objects in the set, writing " $A$ is the set consisting of the elements $a$, $b$, and $c$. 'In symbols, this statement becomes

$$
A=\{a, b, c\}
$$

where braces are used to enclose the list of elements.

The usual way to specify a set, however, is to take some set $A$ of objects and some property that elements of $A$ may or may not possess, and to form the set consisting of all elements of $A$ having that property. For instance, one might take the set of real numbers and form the subset $B$ consisting of all even integers. In symbols, this statement becomes

$$
B=\{x \mid x \text { is an even integer }\} .
$$

Here the braces stand for the words "the set of," and the vertical bar stands for the words "such that." The equation is read " $B$ is the set of all $x$ such that $x$ is an even integer."

## The Union of Sets and the Meaning of "or"

Given two sets $A$ and $B$, one can form a set from them that consists of all the elements of $A$ together with all the elements of $B$. This set is called the union of $A$ and $B$ and is denoted by $A \cup B$. Formally, we define

$$
A \cup B=\{x \mid x \in A \text { or } x \in B\} .
$$

But we must pause at this point and make sure exactly what we mean by the statement " $x \in A$ or $x \in B$."

In ordinary everyday English, the word "or" is ambiguous. Sometimes the statement " $P$ or $Q$ " means " $P$ or $Q$, or both" and sometimes it means " $P$ or $Q$, but not both." Usually one decides from the context which meaning is intended. For example, suppose I spoke to two students as follows:

"Miss Smith, every student registered for this course has taken either a course in linear algebra or a course in analysis."

"Mr. Jones, either you get a grade of at least 70 on the final exam or you will flunk this course."

In the context, Miss Smith knows perfectly well that I mean "everyone has had linear algebra or analysis, or both," and Mr. Jones knows I mean "either he gets at least 70 or he flunks, but not both." Indeed, Mr. Jones would be exceedingly unhappy if both statements turned out to be true!

In mathematics, one cannot tolerate such ambiguity. One has to pick just one meaning and stick with it, or confusion will reign. Accordingly, mathematicians have agreed that they will use the word "or" in the first sense, so that the statement " $P$ or $Q$ " always means " $P$ or $Q$, or both." If one means " $P$ or $Q$, but not both," then one has to include the phrase "but not both" explicitly.

With this understanding, the equation defining $A \cup B$ is unambiguous; it states that $A \cup B$ is the set consisting of all elements $x$ that belong to $A$ or to $B$ or to both.

## The Intersection of Sets, the Empty Set, and the Meaning of "If ... Then"

Given sets $A$ and $B$, another way one can form a set is to take the common part of $A$ and $B$. This set is called the intersection of $A$ and $B$ and is denoted by $A \cap B$. Formally, we define

$$
A \cap B=\{x \mid x \in A \text { and } x \in B\} .
$$

But just as with the definition of $A \cup B$, there is a difficulty. The difficulty is not in the meaning of the word "and"; it is of a different sort. It arises when the sets $A$ and $B$ happen to have no elements in common. What meaning does the symbol $A \cap B$ have in such a case?

To take care of this eventuality, we make a special convention. We introduce a special set that we call the empty set, denoted by $\varnothing$, which we think of as "the set having no elements."

Using this convention, we express the statement that $A$ and $B$ have no elements in common by the equation

$$
A \cap B=\varnothing .
$$

We also express this fact by saying that $A$ and $B$ are disjoint.

Now some students are bothered by the notion of an "empty set." "How," they say, "can you have a set with nothing in it?" The problem is similar to that which arose many years ago when the number 0 was first introduced.

The empty set is only a convention, and mathematics could very well get along without it. But it is a very convenient convention, for it saves us a good deal of awkwardness in stating theorems and in proving them. Without this convention, for instance, one would have to prove that the two sets $A$ and $B$ do have elements in common before one could use the notation $A \cap B$. Similarly, the notation

$$
C=\{x \mid x \in A \text { and } x \text { has a certain property }\}
$$

could not be used if it happened that no element $x$ of $A$ had the given property. It is much more convenient to agree that $A \cap B$ and $C$ equal the empty set in such cases.

Since the empty set $\varnothing$ is merely a convention, we must make conventions relating it to the concepts already introduced. Because $\varnothing$ is thought of as "the set with no elements," it is clear we should make the convention that for each object $x$, the relation $x \in \varnothing$ does not hold. Similarly, the definitions of union and intersection show that for every set $A$ we should have the equations

$$
A \cup \varnothing=A \quad \text { and } \quad A \cap \varnothing=\varnothing .
$$

The inclusion relation is a bit more tricky. Given a set $A$, should we agree that $\varnothing \subset A$ ? Once more, we must be careful about the way mathematicians use the English language. The expression $\varnothing \subset A$ is a shorthand way of writing the sentence, "Every element that belongs to the empty set also belongs to the set $A$." Or to put it more
formally, "For every object $x$, if $x$ belongs to the empty set, then $x$ also belongs to the set $A$."

Is this statement true or not? Some might say "yes" and others say "no." You will never settle the question by argument, only by agreement. This is a statement of the form "If $P$, then $Q$," and in everyday English the meaning of the "if $\ldots$ then" construction is ambiguous. It always means that if $P$ is true, then $Q$ is true also. Sometimes that is all it means; other times it means something more: that if $P$ is false, $Q$ must be false. Usually one decides from the context which interpretation is correct.

The situation is similar to the ambiguity in the use of the word "or." One can reformulate the examples involving Miss Smith and Mr. Jones to illustrate the ambiguity. Suppose I said the following:

"Miss Smith, if any student registered for this course has not taken a course in linear algebra, then he has taken a course in analysis."

"Mr. Jones, if you get a grade below 70 on the final, you are going to flunk this course."

In the context, Miss Smith understands that if a student in the course has not had linear algebra, then he has taken analysis, but if he has had linear algebra, he may or may not have taken analysis as well. And Mr. Jones knows that if he gets a grade below 70, he will flunk the course, but if he gets a grade of at least 70 , he will pass.

Again, mathematics cannot tolerate ambiguity, so a choice of meanings must be made. Mathematicians have agreed always to use "if ... then" in the first sense, so that a statement of the form "If $P$, then $Q$ " means that if $P$ is true, $Q$ is true also, but if $P$ is false, $Q$ may be either true or false.

As an example, consider the following statement about real numbers:

$$
\text { If } x>0 \text {, then } x^{3} \neq 0 \text {. }
$$

It is a statement of the form, "If $P$, then $Q$," where $P$ is the phrase " $x>0$ " (called the hypothesis of the statement) and $Q$ is the phrase " $x^{3} \neq 0$ " (called the conclusion of the statement). This is a true statement, for in every case for which the hypothesis $x>0$ holds, the conclusion $x^{3} \neq 0$ holds as well.

Another true statement about real numbers is the following:

$$
\text { If } x^{2}<0 \text {, then } x=23
$$

in every case for which the hypothesis holds, the conclusion holds as well. Of course, it happens in this example that there are no cases for which the hypothesis holds. A statement of this sort is sometimes said to be vacuously true.

To return now to the empty set and inclusion, we see that the inclusion $\varnothing \subset A$ does hold for every set $A$. Writing $\varnothing \subset A$ is the same as saying, "If $x \in \varnothing$, then $x \in A$," and this statement is vacuously true.

## Contrapositive and Converse

Our discussion of the "if ... then" construction leads us to consider another point of elementary logic that sometimes causes difficulty. It concerns the relation between a statement, its contrapositive, and its converse.

Given a statement of the form "If $P$, then $Q$, ," its contrapositive is defined to be the statement "If $Q$ is not true, then $P$ is not true." For example, the contrapositive of the statement

$$
\text { If } x>0 \text {, then } x^{3} \neq 0 \text {, }
$$

is the statement

$$
\text { If } x^{3}=0 \text {, then it is not true that } x>0 \text {. }
$$

Note that both the statement and its contrapositive are true. Similarly, the statement

$$
\text { If } x^{2}<0 \text {, then } x=23 \text {, }
$$

has as its contrapositive the statement

$$
\text { If } x \neq 23 \text {, then it is not true that } x^{2}<0 \text {. }
$$

Again, both are true statements about real numbers.

These examples may make you suspect that there is some relation between a statement and its contrapositive. And indeed there is; they are two ways of saying precisely the same thing. Each is true if and only if the other is true; they are logically equivalent.

This fact is not hard to demonstrate. Let us introduce some notation first. As a shorthand for the statement "If $P$, then $Q$," we write

$$
P \Longrightarrow Q
$$

which is read " $P$ implies $Q$. " The contrapositive can then be expressed in the form

$$
(\operatorname{not} Q) \Longrightarrow(\operatorname{not} P) \text {, }
$$

where "not $Q$ " stands for the phrase " $Q$ is not true."

Now the only way in which the statement " $P \Rightarrow Q$ " can fail to be correct is if the hypothesis $P$ is true and the conclusion $Q$ is false. Otherwise it is correct. Similarly, the only way in which the statement (not $Q) \Rightarrow(\operatorname{not} P)$ can fail to be correct is if the hypothesis "not $Q$ " is true and the conclusion "not $P$ " is false. This is the same as saying that $Q$ is false and $P$ is true. And this, in turn, is precisely the situation in which $P \Rightarrow Q$ fails to be correct. Thus, we see that the two statements are either both correct or both incorrect; they are logically equivalent. Therefore, we shall accept a proof of the statement "not $Q \Rightarrow$ not $P$ " as a proof of the statement " $P \Rightarrow Q$."

There is another statement that can be formed from the statement $P \Rightarrow Q$. It is the statement

$$
Q \Longrightarrow P
$$

which is called the converse of $P \Rightarrow Q$. One must be careful to distinguish between a statement's converse and its contrapositive. Whereas a statement and its contrapositive are logically equivalent, the truth of a statement says nothing at all about the truth or falsity of its converse. For example, the true statement

$$
\text { If } x>0 \text {, then } x^{3} \neq 0 \text {, }
$$

has as its converse the statement

$$
\text { If } x^{3} \neq 0 \text {, then } x>0 \text {, }
$$

which is false. Similarly, the true statement

$$
\text { If } x^{2}<0 \text {, then } x=23
$$

has as its converse the statement

$$
\text { If } x=23 \text {, then } x^{2}<0 \text {, }
$$

which is false.

If it should happen that both the statement $P \Rightarrow Q$ and its converse $Q \Rightarrow P$ are true, we express this fact by the notation

$$
P \Longleftrightarrow Q,
$$

which is read " $P$ holds if and only if $Q$ holds."

## Negation

If one wishes to form the contrapositive of the statement $P \Rightarrow Q$, one has to know how to form the statement "not $P$," which is called the negation of $P$. In many cases, this causes no difficulty; but sometimes confusion occurs with statements involving the phrases "for every" and "for at least one." These phrases are called logical quantifiers.

To illustrate, suppose that $X$ is a set, $A$ is a subset of $X$, and $P$ is a statement about the general element of $X$. Consider the following statement:

For every $x \in A$, statement $P$ holds.

How does one form the negation of this statement? Let us translate the problem into the language of sets. Suppose that we let $B$ denote the set of all those elements $x$ of $X$ for which $P$ holds. Then statement (*) is just the statement that $A$ is a subset of $B$. What is its negation? Obviously, the statement that $A$ is not a subset of $B$; that is, the statement that there exists at least one element of $A$ that does not belong to $B$. Translating back into ordinary language, this becomes

For at least one $x \in A$, statement $P$ does not hold.

Therefore, to form the negation of statement $(*)$, one replaces the quantifier "for every" by the quantifier "for at least one," and one replaces statement $P$ by its negation.

The process works in reverse just as well; the negation of the statement

For at least one $x \in A$, statement $Q$ holds,

is the statement

For every $x \in A$, statement $Q$ does not hold.

## The Difference of Two Sets

We return now to our discussion of sets. There is one other operation on sets that is occasionally useful. It is the difference of two sets, denoted by $A-B$, and defined as the set consisting of those elements of $A$ that are not in $B$. Formally,

$$
A-B=\{x \mid x \in A \text { and } x \notin B\} .
$$

It is sometimes called the complement of $B$ relative to $A$, or the complement of $B$ in $A$.

Our three set operations are represented schematically in Figure 1.1.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-011.jpg?height=242&width=1094&top_left_y=1172&top_left_x=656)

Figure 1.1

## Rules of Set Theory

Given several sets, one may form new sets by applying the set-theoretic operations to them. As in algebra, one uses parentheses to indicate in what order the operations are to be performed. For example, $A \cup(B \cap C)$ denotes the union of the two sets $A$ and $B \cap C$, while $(A \cup B) \cap C$ denotes the intersection of the two sets $A \cup B$ and $C$. The sets thus formed are quite different, as Figure 1.2 shows.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-011.jpg?height=313&width=338&top_left_y=1842&top_left_x=794)

$A \cup(B \cap C)$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-011.jpg?height=355&width=342&top_left_y=1843&top_left_x=1261)

$(A \cup B) \cap C$

Figure 1.2

Sometimes different combinations of operations lead to the same set; when that happens, one has a rule of set theory. For instance, it is true that for any sets $A, B$, and $C$ the equation

$$
A \cap(B \cup C)=(A \cap B) \cup(A \cap C)
$$

holds. The equation is illustrated in Figure 1.3; the shaded region represents the set in question, as you can check mentally. This equation can be thought of as a "distributive law" for the operations $\cap$ and $\cup$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-012.jpg?height=333&width=383&top_left_y=774&top_left_x=835)

Figure 1.3

Other examples of set-theoretic rules include the second "distributive law,"

$$
A \cup(B \cap C)=(A \cup B) \cap(A \cup C) \text {, }
$$

and DeMorgan's laws,

$$
\begin{aligned}
& A-(B \cup C)=(A-B) \cap(A-C), \\
& A-(B \cap C)=(A-B) \cup(A-C) .
\end{aligned}
$$

We leave it to you to check these rules. One can state other rules of set theory, but these are the most important ones. DeMorgan's laws are easier to remember if you verbalize them as follows:

The complement of the union equals the intersection of the complements. The complement of the intersection equals the union of the complements.

## Collections of Sets

The objects belonging to a set may be of any sort. One can consider the set of all even integers, and the set of all blue-eyed people in Nebraska, and the set of all decks of playing cards in the world. Some of these are of limited mathematical interest, we admit! But the third example illustrates a point we have not yet mentioned: namely, that the objects belonging to a set may themselves be sets. For a deck of cards is itself a set, one consisting of pieces of pasteboard with certain standard designs printed on them. The set of all decks of cards in the world is thus a set whose elements are themselves sets (of pieces of pasteboard).

We now have another way to form new sets from old ones. Given a set $A$, we can consider sets whose elements are subsets of $A$. In particular, we can consider the set of all subsets of $A$. This set is sometimes denoted by the symbol $\mathcal{P}(A)$ and is called the power set of $A$ (for reasons to be explained later).

When we have a set whose elements are sets, we shall often refer to it as a collection of sets and denote it by a script letter such as $\mathcal{A}$ or $\mathscr{B}$. This device will help us in keeping things straight in arguments where we have to consider objects, and sets of objects, and collections of sets of objects, all at the same time. For example, we might use $\mathcal{A}$ to denote the collection of all decks of cards in the world, letting an ordinary capital letter $A$ denote a deck of cards and a lowercase letter $a$ denote a single playing card.

A certain amount of care with notation is needed at this point. We make a distinction between the object $a$, which is an element of a set $A$, and the one-element set $\{a\}$, which is a subset of $A$. To illustrate, if $A$ is the set $\{a, b, c\}$, then the statements

$$
a \in A, \quad\{a\} \subset A, \quad \text { and } \quad\{a\} \in \mathcal{P}(A)
$$

are all correct, but the statements $\{a\} \in A$ and $a \subset A$ are not.

## Arbitrary Unions and Intersections

We have already defined what we mean by the union and the intersection of two sets. There is no reason to limit ourselves to just two sets, for we can just as well form the union and intersection of arbitrarily many sets.

Given a collection $\mathcal{A}$ of sets, the union of the elements of $\mathcal{A}$ is defined by the equation

$$
\bigcup_{A \in \mathcal{A}} A=\{x \mid x \in A \text { for at least one } A \in \mathcal{A}\}
$$

The intersection of the elements of $\mathcal{A}$ is defined by the equation

$$
\bigcap_{A \in \mathcal{A}} A=\{x \mid x \in A \text { for every } A \in \mathcal{A}\}
$$

There is no problem with these definitions if one of the elements of $\mathcal{A}$ happens to be the empty set. But it is a bit tricky to decide what (if anything) these definitions mean if we allow $\mathcal{A}$ to be the empty collection. Applying the definitions literally, we see that no element $x$ satisfies the defining property for the union of the elements of $\mathcal{A}$. So it is reasonable to say that

$$
\bigcup_{A \in \mathcal{A}} A=\varnothing
$$

if $\mathcal{A}$ is empty. On the other hand, every $x$ satisfies (vacuously) the defining property for the intersection of the elements of $\mathcal{A}$. The question is, every $x$ in what set? If one has a given large set $X$ that is specified at the outset of the discussion to be one's "universe of discourse," and one considers only subsets of $X$ throughout, it is reasonable to let

$$
\bigcap_{A \in \mathcal{A}} A=X
$$

when $\mathcal{A}$ is empty. Not all mathematicians follow this convention, however. To avoid difficulty, we shall not define the intersection when $\mathcal{A}$ is empty.

## Cartesian Products

There is yet another way of forming new sets from old ones; it involves the notion of an "ordered pair" of objects. When you studied analytic geometry, the first thing you did was to convince yourself that after one has chosen an $x$-axis and a $y$-axis in the plane, every point in the plane can be made to correspond to a unique ordered pair $(x, y)$ of real numbers. (In a more sophisticated treatment of geometry, the plane is more likely to be defined as the set of all ordered pairs of real numbers!)

The notion of ordered pair carries over to general sets. Given sets $A$ and $B$, we define their cartesian product $A \times B$ to be the set of all ordered pairs $(a, b)$ for which $a$ is an element of $A$ and $b$ is an element of $B$. Formally,

$$
A \times B=\{(a, b) \mid a \in A \text { and } b \in B\}
$$

This definition assumes that the concept of "ordered pair" is already given. It can be taken as a primitive concept, as was the notion of "set"; or it can be given a definition in terms of the set operations already introduced. One definition in terms of set operations is expressed by the equation

$$
(a, b)=\{\{a\},\{a, b\}\}
$$

it defines the ordered pair $(a, b)$ as a collection of sets. If $a \neq b$, this definition says that $(a, b)$ is a collection containing two sets, one of which is a one-element set and the other a two-element set. The first coordinate of the ordered pair is defined to be the element belonging to both sets, and the second coordinate is the element belonging to only one of the sets. If $a=b$, then $(a, b)$ is a collection containing only one set $\{a\}$, since $\{a, b\}=$ $\{a, a\}=\{a\}$ in this case. Its first coordinate and second coordinate both equal the element in this single set.

I think it is fair to say that most mathematicians think of an ordered pair as a primitive concept rather than thinking of it as a collection of sets!

Let us make a comment on notation. It is an unfortunate fact that the notation $(a, b)$ is firmly established in mathematics with two entirely different meanings. One meaning, as an ordered pair of objects, we have just discussed. The other meaning is the one you are familiar with from analysis; if $a$ and $b$ are real numbers, the symbol $(a, b)$ is used to denote the interval consisting of all numbers $x$ such that $a<x<b$. Most of the time, this conflict in notation will cause no difficulty because the meaning will be clear from the context. Whenever a situation occurs where confusion is possible, we shall adopt a different notation for the ordered pair $(a, b)$, denoting it by the symbol

$$
a \times b
$$

instead.

## Exercises

1. Check the distributive laws for $\cup$ and $\cap$ and DeMorgan's laws.
2. Determine which of the following statements are true for all sets $A, B, C$, and $D$. If a double implication fails, determine whether one or the other of the possible implications holds. If an equality fails, determine whether the statement becomes true if the "equals" symbol is replaced by one or the other of the inclusion symbols $\subset$ or $\supset$.

(a) $A \subset B$ and $A \subset C \Leftrightarrow A \subset(B \cup C)$.

(b) $A \subset B$ or $A \subset C \Leftrightarrow A \subset(B \cup C)$.

(c) $A \subset B$ and $A \subset C \Leftrightarrow A \subset(B \cap C)$.

(d) $A \subset B$ or $A \subset C \Leftrightarrow A \subset(B \cap C)$.

(e) $A-(A-B)=B$.

(f) $A-(B-A)=A-B$.

(g) $A \cap(B-C)=(A \cap B)-(A \cap C)$.

(h) $A \cup(B-C)=(A \cup B)-(A \cup C)$.

(i) $(A \cap B) \cup(A-B)=A$.

(j) $A \subset C$ and $B \subset D \Rightarrow(A \times B) \subset(C \times D)$.

(k) The converse of (j).

(l) The converse of (j), assuming that $A$ and $B$ are nonempty.

(m) $(A \times B) \cup(C \times D)=(A \cup C) \times(B \cup D)$.

(n) $(A \times B) \cap(C \times D)=(A \cap C) \times(B \cap D)$.

(o) $A \times(B-C)=(A \times B)-(A \times C)$.

(p) $(A-B) \times(C-D)=(A \times C-B \times C)-A \times D$.

(q) $(A \times B)-(C \times D)=(A-C) \times(B-D)$.

3. (a) Write the contrapositive and converse of the following statement: "If $x<0$, then $x^{2}-x>0$," and determine which (if any) of the three statements are true.

(b) Do the same for the statement "If $x>0$, then $x^{2}-x>0$."

4. Let $A$ and $B$ be sets of real numbers. Write the negation of each of the following statements:

(a) For every $a \in A$, it is true that $a^{2} \in B$.

(b) For at least one $a \in A$, it is true that $a^{2} \in B$.

(c) For every $a \in A$, it is true that $a^{2} \notin B$.

(d) For at least one $a \notin A$, it is true that $a^{2} \in B$.

5. Let $\mathcal{A}$ be a nonempty collection of sets. Determine the truth of each of the following statements and of their converses:

(a) $x \in \bigcup_{A \in \mathcal{A}} A \Rightarrow x \in A$ for at least one $A \in \mathcal{A}$.

(b) $x \in \bigcup_{A \in \mathcal{A}} A \Rightarrow x \in A$ for every $A \in \mathcal{A}$.

(c) $x \in \bigcap_{A \in \mathcal{A}} A \Rightarrow x \in A$ for at least one $A \in \mathcal{A}$.

(d) $x \in \bigcap_{A \in \mathcal{A}} A \Rightarrow x \in A$ for every $A \in \mathcal{A}$.

6. Write the contrapositive of each of the statements of Exercise 5.
7. Given sets $A, B$, and $C$, express each of the following sets in terms of $A, B$, and $C$, using the symbols $\cup, \cap$, and - .

$$
\begin{aligned}
& D=\{x \mid x \in A \text { and }(x \in B \text { or } x \in C)\}, \\
& E=\{x \mid(x \in A \text { and } x \in B) \text { or } x \in C\}, \\
& F=\{x \mid x \in A \text { and }(x \in B \Rightarrow x \in C)\}
\end{aligned}
$$

8. If a set $A$ has two elements, show that $\mathcal{P}(A)$ has four elements. How many elements does $\mathcal{P}(A)$ have if $A$ has one element? Three elements? No elements? Why is $\mathcal{P}(A)$ called the power set of $A$ ?
9. Formulate and prove DeMorgan's laws for arbitrary unions and intersections.
10. Let $\mathbb{R}$ denote the set of real numbers. For each of the following subsets of $\mathbb{R} \times \mathbb{R}$, determine whether it is equal to the cartesian product of two subsets of $\mathbb{R}$.

(a) $\{(x, y) \mid x$ is an integer $\}$.

(b) $\{(x, y) \mid 0<y \leq 1\}$.

(c) $\{(x, y) \mid y>x\}$.

(d) $\{(x, y) \mid x$ is not an integer and $y$ is an integer $\}$.

(e) $\left\{(x, y) \mid x^{2}+y^{2}<1\right\}$.

## §2 Functions

The concept of function is one you have seen many times already, so it is hardly necessary to remind you how central it is to all mathematics. In this section, we give the precise mathematical definition, and we explore some of the associated concepts.

A function is usually thought of as a rule that assigns to each element of a set $A$, an element of a set $B$. In calculus, a function is often given by a simple formula such as $f(x)=3 x^{2}+2$ or perhaps by a more complicated formula such as

$$
f(x)=\sum_{k=1}^{\infty} x^{k}
$$

One often does not even mention the sets $A$ and $B$ explicitly, agreeing to take $A$ to be the set of all real numbers for which the rule makes sense and $B$ to be the set of all real numbers.

As one goes further in mathematics, however, one needs to be more precise about what a function is. Mathematicians think of functions in the way we just described, but the definition they use is more exact. First, we define the following:

Definition. A rule of assignment is a subset $r$ of the cartesian product $C \times D$ of two sets, having the property that each element of $C$ appears as the first coordinate of at most one ordered pair belonging to $r$.

Thus, a subset $r$ of $C \times D$ is a rule of assignment if

$$
\left[(c, d) \in r \text { and }\left(c, d^{\prime}\right) \in r\right] \Longrightarrow\left[d=d^{\prime}\right]
$$

We think of $r$ as a way of assigning, to the element $c$ of $C$, the element $d$ of $D$ for which $(c, d) \in r$.

Given a rule of assignment $r$, the domain of $\mathrm{r}$ is defined to be the subset of $C$ consisting of all first coordinates of elements of $r$, and the image set of $r$ is defined as the subset of $D$ consisting of all second coordinates of elements of $r$. Formally,

$$
\begin{aligned}
\text { domain } r & =\{c \mid \text { there exists } d \in D \text { such that }(c, d) \in r\}, \\
\text { image } r & =\{d \mid \text { there exists } c \in C \text { such that }(c, d) \in r\} .
\end{aligned}
$$

Note that given a rule of assignment $r$, its domain and image are entirely determined.

Now we can say what a function is.

Definition. A function $f$ is a rule of assignment $r$, together with a set $B$ that contains the image set of $r$. The domain $A$ of the rule $r$ is also called the domain of the function $f$; the image set of $r$ is also called the image set of $f$; and the set $B$ is called the range of $f .^{\dagger}$

If $f$ is a function having domain $A$ and range $B$, we express this fact by writing

$$
f: A \longrightarrow B
$$

which is read " $f$ is a function from $A$ to $B$," or " $f$ is a mapping from $A$ into $B$, " or simply " $f$ maps $A$ into $B$." One sometimes visualizes $f$ as a geometric transformation physically carrying the points of $A$ to points of $B$.

If $f: A \rightarrow B$ and if $a$ is an element of $A$, we denote by $f(a)$ the unique element of $B$ that the rule determining $f$ assigns to $a$; it is called the value of $f$ at $a$, or sometimes the image of $a$ under $f$. Formally, if $r$ is the rule of the function $f$, then $f(a)$ denotes the unique element of $B$ such that $(a, f(a)) \in r$.

Using this notation, one can go back to defining functions almost as one did before, with no lack of rigor. For instance, one can write (letting $\mathbb{R}$ denote the real numbers)

"Let $f$ be the function whose rule is $\left\{\left(x, x^{3}+1\right) \mid x \in \mathbb{R}\right\}$ and whose range is $\mathbb{R}$,"

or one can equally well write

"Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be the function such that $f(x)=x^{3}+1$. ."

Both sentences specify precisely the same function. But the sentence "Let $f$ be the function $f(x)=x^{3}+1$ " is no longer adequate for specifying a function because it specifies neither the domain nor the range of $f$.[^0]

Definition. If $f: A \rightarrow B$ and if $A_{0}$ is a subset of $A$, we define the restriction of $f$ to $A_{0}$ to be the function mapping $A_{0}$ into $B$ whose rule is

$$
\left\{(a, f(a)) \mid a \in A_{0}\right\} .
$$

It is denoted by $f \mid A_{0}$, which is read " $f$ restricted to $A_{0}$."

EXAMPLE 1. Let $\mathbb{R}$ denote the real numbers and let $\overline{\mathbb{R}}_{+}$denote the nonnegative reals. Consider the functions

$$
\begin{aligned}
& f: \mathbb{R} \longrightarrow \mathbb{R} \quad \text { defined by } \quad f(x)=x^{2} \\
& g: \overline{\mathbb{R}}_{+} \longrightarrow \mathbb{R} \quad \text { defined by } \quad g(x)=x^{2} \\
& h: \mathbb{R} \longrightarrow \overline{\mathbb{R}}_{+} \quad \text { defined by } \quad h(x)=x^{2} \\
& k: \overline{\mathbb{R}}_{+} \longrightarrow \overline{\mathbb{R}}_{+} \quad \text { defined by } \quad k(x)=x^{2} .
\end{aligned}
$$

The function $g$ is different from the function $f$ because their rules are different subsets of $\mathbb{R} \times \mathbb{R}$; it is the restriction of $f$ to the set $\overline{\mathbb{R}}_{+}$. The function $h$ is also different from $f$, even though their rules are the same set, because the range specified for $h$ is different from the range specified for $f$. The function $k$ is different from all of these. These functions are pictured in Figure 2.1.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-018.jpg?height=376&width=1122&top_left_y=1199&top_left_x=458)

Figure 2.1

Restricting the domain of a function and changing its range are two ways of forming a new function from an old one. Another way is to form the composite of two functions.

Definition. Given functions $f: A \rightarrow B$ and $g: B \rightarrow C$, we define the composite $g \circ f$ of $f$ and $g$ as the function $g \circ f: A \rightarrow C$ defined by the equation $(g \circ f)(a)=$ $g(f(a))$.

Formally, $g \circ f: A \rightarrow C$ is the function whose rule is

$$
\{(a, c) \mid \text { For some } b \in B, f(a)=b \text { and } g(b)=c\} \text {. }
$$

We often picture the composite $g \circ f$ as involving a physical movement of the point $a$ to the point $f(a)$, and then to the point $g(f(a))$, as illustrated in Figure 2.2.

Note that $g \circ f$ is defined only when the range of $f$ equals the domain of $g$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-019.jpg?height=305&width=1052&top_left_y=369&top_left_x=662)

Figure 2.2

EXAMPLE 2. The composite of the function $f: \mathbb{R} \rightarrow \mathbb{R}$ given by $f(x)=3 x^{2}+2$ and the function $g: \mathbb{R} \rightarrow \mathbb{R}$ given by $g(x)=5 x$ is the function $g \circ f: \mathbb{R} \rightarrow \mathbb{R}$ given by

$$
(g \circ f)(x)=g(f(x))=g\left(3 x^{2}+2\right)=5\left(3 x^{2}+2\right)
$$

The composite $f \circ g$ can also be formed in this case; it is the quite different function $f \circ g: \mathbb{R} \rightarrow \mathbb{R}$ given by

$$
(f \circ g)(x)=f(g(x))=f(5 x)=3(5 x)^{2}+2 .
$$

Definition. A function $f: A \rightarrow B$ is said to be injective (or one-to-one) if for each pair of distinct points of $A$, their images under $f$ are distinct. It is said to be surjective (or $f$ is said to map $A$ onto $B$ ) if every element of $B$ is the image of some element of $A$ under the function $f$. If $f$ is both injective and surjective, it is said to be bijective (or is called a one-to-one correspondence).

More formally, $f$ is injective if

$$
\left[f(a)=f\left(a^{\prime}\right)\right] \Longrightarrow\left[a=a^{\prime}\right]
$$

and $f$ is surjective if

$$
[b \in B] \Longrightarrow[b=f(a) \text { for at least one } a \in A] \text {. }
$$

Injectivity of $f$ depends only on the rule of $f$; surjectivity depends on the range of $f$ as well. You can check that the composite of two injective functions is injective, and the composite of two surjective functions is surjective; it follows that the composite of two bijective functions is bijective.

If $f$ is bijective, there exists a function from $B$ to $A$ called the inverse of $f$. It is denoted by $f^{-1}$ and is defined by letting $f^{-1}(b)$ be that unique element $a$ of $A$ for which $f(a)=b$. Given $b \in B$, the fact that $f$ is surjective implies that there exists such an element $a \in A$; the fact that $f$ is injective implies that there is only one such element $a$. It is easy to see that if $f$ is bijective, $f^{-1}$ is also bijective.

EXAMPLE 3. Consider again the functions $f, g, h$, and $k$ of Figure 2.1. The function $f: \mathbb{R} \rightarrow \mathbb{R}$ given by $f(x)=x^{2}$ is neither injective nor surjective. Its restriction $g$ to the nonnegative reals is injective but not surjective. The function $h: \mathbb{R} \rightarrow \overline{\mathbb{R}}_{+}$obtained from $f$
by changing the range is surjective but not injective. The function $k: \overline{\mathbb{R}}_{+} \rightarrow \overline{\mathbb{R}}_{+}$obtained from $f$ by restricting the domain and changing the range is both injective and surjective, so it has an inverse. Its inverse is, of course, what we usually call the square-root function.

A useful criterion for showing that a given function $f$ is bijective is the following, whose proof is left to the exercises:

Lemma 2.1. Let $f: A \rightarrow B$. If there are functions $g: B \rightarrow A$ and $h: B \rightarrow A$ such that $g(f(a))=a$ for every $a$ in $A$ and $f(h(b))=b$ for every $b$ in $B$, then $f$ is bijective and $g=h=f^{-1}$.

Definition. Let $f: A \rightarrow B$. If $A_{0}$ is a subset of $A$, we denote by $f\left(A_{0}\right)$ the set of all images of points of $A_{0}$ under the function $f$; this set is called the image of $A_{0}$ under $f$. Formally,

$$
f\left(A_{0}\right)=\left\{b \mid b=f(a) \text { for at least one } a \in A_{0}\right\}
$$

On the other hand, if $B_{0}$ is a subset of $B$, we denote by $f^{-1}\left(B_{0}\right)$ the set of all elements of $A$ whose images under $f$ lie in $B_{0}$; it is called the preimage of $B_{0}$ under $f$ (or the "counterimage," or the "inverse image," of $B_{0}$ ). Formally,

$$
f^{-1}\left(B_{0}\right)=\left\{a \mid f(a) \in B_{0}\right\}
$$

Of course, there may be no points $a$ of $A$ whose images lie in $B_{0}$; in that case, $f^{-1}\left(B_{0}\right)$ is empty.

Note that if $f: A \rightarrow B$ is bijective and $B_{0} \subset B$, we have two meanings for the notation $f^{-1}\left(B_{0}\right)$. It can be taken to denote the preimage of $B_{0}$ under the function $f$ or to denote the image of $B_{0}$ under the function $f^{-1}: B \rightarrow A$. These two meanings give precisely the same subset of $A$, however, so there is, in fact, no ambiguity.

Some care is needed if one is to use the $f$ and $f^{-1}$ notation correctly. The operation $f^{-1}$, for instance, when applied to subsets of $B$, behaves very nicely; it preserves inclusions, unions, intersections, and differences of sets. We shall use this fact frequently. But the operation $f$, when applied to subsets of $A$, preserves only inclusions and unions. See Exercises 2 and 3.

As another situation where care is needed, we note that it is not in general true that $f^{-1}\left(f\left(A_{0}\right)\right)=A_{0}$ and $f\left(f^{-1}\left(B_{0}\right)\right)=B_{0}$. (See the following example.) The relevant rules, which we leave to you to check, are the following: If $f: A \rightarrow B$ and if $A_{0} \subset A$ and $B_{0} \subset B$, then

$$
A_{0} \subset f^{-1}\left(f\left(A_{0}\right)\right) \quad \text { and } \quad f\left(f^{-1}\left(B_{0}\right)\right) \subset B_{0}
$$

The first inclusion is an equality if $f$ is injective, and the second inclusion is an equality if $f$ is surjective.

EXAMPle 4. Consider the function $f: \mathbb{R} \rightarrow \mathbb{R}$ given by $f(x)=3 x^{2}+2$ (Figure 2.3). Let $[a, b]$ denote the closed interval $a \leq x \leq b$. Then

$$
\begin{aligned}
& f^{-1}(f([0,1]))=f^{-1}([2,5])=[-1,1], \quad \text { and } \\
& f\left(f^{-1}([0,5])\right)=f([-1,1])=[2,5] .
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-021.jpg?height=852&width=710&top_left_y=648&top_left_x=844)

Figure 2.3

## Exercises

1. Let $f: A \rightarrow B$. Let $A_{0} \subset A$ and $B_{0} \subset B$.

(a) Show that $A_{0} \subset f^{-1}\left(f\left(A_{0}\right)\right)$ and that equality holds if $f$ is injective.

(b) Show that $f\left(f^{-1}\left(B_{0}\right)\right) \subset B_{0}$ and that equality holds if $f$ is surjective.

2. Let $f: A \rightarrow B$ and let $A_{i} \subset A$ and $B_{i} \subset B$ for $i=0$ and $i=1$. Show that $f^{-1}$ preserves inclusions, unions, intersections, and differences of sets:

(a) $B_{0} \subset B_{1} \Rightarrow f^{-1}\left(B_{0}\right) \subset f^{-1}\left(B_{1}\right)$.

(b) $f^{-1}\left(B_{0} \cup B_{1}\right)=f^{-1}\left(B_{0}\right) \cup f^{-1}\left(B_{1}\right)$.

(c) $f^{-1}\left(B_{0} \cap B_{1}\right)=f^{-1}\left(B_{0}\right) \cap f^{-1}\left(B_{1}\right)$.

(d) $f^{-1}\left(B_{0}-B_{1}\right)=f^{-1}\left(B_{0}\right)-f^{-1}\left(B_{1}\right)$.

Show that $f$ preserves inclusions and unions only:

(e) $A_{0} \subset A_{1} \Rightarrow f\left(A_{0}\right) \subset f\left(A_{1}\right)$.
(f) $f\left(A_{0} \cup A_{1}\right)=f\left(A_{0}\right) \cup\left(A_{1}\right)$.

(g) $f\left(A_{0} \cap A_{1}\right) \subset f\left(A_{0}\right) \cap f\left(A_{1}\right)$; show that equality holds if $f$ is injective.

(h) $f\left(A_{0}-A_{1}\right) \supset f\left(A_{0}\right)-f\left(A_{1}\right)$; show that equality holds if $f$ is injective.

3. Show that (b), (c), (f), and (g) of Exercise 2 hold for arbitrary unions and intersections.
4. Let $f: A \rightarrow B$ and $g: B \rightarrow C$.

(a) If $C_{0} \subset C$, show that $(g \circ f)^{-1}\left(C_{0}\right)=f^{-1}\left(g^{-1}\left(C_{0}\right)\right)$.

(b) If $f$ and $g$ are injective, show that $g \circ f$ is injective.

(c) If $g \circ f$ is injective, what can you say about injectivity of $f$ and $g$ ?

(d) If $f$ and $g$ are surjective, show that $g \circ f$ is surjective.

(e) If $g \circ f$ is surjective, what can you say about surjectivity of $f$ and $g$ ?

(f) Summarize your answers to (b)-(e) in the form of a theorem.

5. In general, let us denote the identity function for a set $C$ by $i_{C}$. That is, define $i_{C}: C \rightarrow C$ to be the function given by the rule $i_{C}(x)=x$ for all $x \in C$. Given $f: A \rightarrow B$, we say that a function $g: B \rightarrow A$ is a left inverse for $f$ if $g \circ f=i_{A}$; and we say that $h: B \rightarrow A$ is a right inverse for $f$ if $f \circ h=i_{B}$.

(a) Show that if $f$ has a left inverse, $f$ is injective; and if $f$ has a right inverse, $f$ is surjective.

(b) Give an example of a function that has a left inverse but no right inverse.

(c) Give an example of a function that has a right inverse but no left inverse.

(d) Can a function have more than one left inverse? More than one right inverse?

(e) Show that if $f$ has both a left inverse $g$ and a right inverse $h$, then $f$ is bijective and $g=h=f^{-1}$.

6. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be the function $f(x)=x^{3}-x$. By restricting the domain and range of $f$ appropriately, obtain from $f$ a bijective function $g$. Draw the graphs of $g$ and $g^{-1}$. (There are several possible choices for $g$.)

## §3 Relations

A concept that is, in some ways, more general than that of function is the concept of a relation. In this section, we define what mathematicians mean by a relation, and we consider two types of relations that occur with great frequency in mathematics: equivalence relations and order relations. Order relations will be used throughout the book; equivalence relations will not be used until $\$ 22$.

Definition. A relation on a set $A$ is a subset $C$ of the cartesian product $A \times A$.

If $C$ is a relation on $A$, we use the notation $x C y$ to mean the same thing as $(x, y) \in$ $C$. We read it " $x$ is in the relation $C$ to $y$."

A rule of assignment $r$ for a function $f: A \rightarrow A$ is also a subset of $A \times A$. But it is a subset of a very special kind: namely, one such that each element of $A$ appears as the first coordinate of an element of $r$ exactly once. Any subset of $A \times A$ is a relation on $A$.

EXAMPLE 1. Let $P$ denote the set of all people in the world, and define $D \subset P \times P$ by the equation

$$
D=\{(x, y) \mid x \text { is a descendant of } y\}
$$

Then $D$ is a relation on the set $P$. The statements " $x$ is in the relation $D$ to $y$ " and " $x$ is a descendant of $y$ " mean precisely the same thing, namely, that $(x, y) \in D$. Two other relations on $P$ are the following:

$$
\begin{aligned}
B & =\{(x, y) \mid x \text { has an ancestor who is also an ancestor of } y\} \\
S & =\{(x, y) \mid \text { the parents of } x \text { are the parents of } y\} .
\end{aligned}
$$

We can call $B$ the "blood relation" (pun intended), and we can call $S$ the "sibling relation." These three relations have quite different properties. The blood relationship is symmetric, for instance (if $x$ is a blood relative of $y$, then $y$ is a blood relative of $x$ ), whereas the descendant relation is not. We shall consider these relations again shortly.

## Equivalence Relations and Partitions

An equivalence relation on a set $A$ is a relation $C$ on $A$ having the following three properties:

(1) (Reflexivity) $x C x$ for every $x$ in $A$.

(2) (Symmetry) If $x C y$, then $y C x$.

(3) (Transitivity) If $x C y$ and $y C z$, then $x C z$.

EXAMPLE 2. Among the relations defined in Example 1, the descendant relation $D$ is neither reflexive nor symmetric, while the blood relation $B$ is not transitive (I am not a blood relation to my wife, although my children are!) The sibling relation $S$ is, however, an equivalence relation, as you may check.

There is no reason one must use a capital letter — or indeed a letter of any sortto denote a relation, even though it is a set. Another symbol will do just as well. One symbol that is frequently used to denote an equivalence relation is the "tilde" symbol $\sim$. Stated in this notation, the properties of an equivalence relation become

(1) $x \sim x$ for every $x$ in $A$.

(2) If $x \sim y$, then $y \sim x$.

(3) If $x \sim y$ and $y \sim z$, then $x \sim z$.

There are many other symbols that have been devised to stand for particular equivalence relations; we shall meet some of them in the pages of this book.

Given an equivalence relation $\sim$ on a set $A$ and an element $x$ of $A$, we define a certain subset $E$ of $A$, called the equivalence class determined by $x$, by the equation

$$
E=\{y \mid y \sim x\} .
$$

Note that the equivalence class $E$ determined by $x$ contains $x$, since $x \sim x$. Equivalence classes have the following property:

Lemma 3.1. Two equivalence classes $E$ and $E^{\prime}$ are either disjoint or equal.

Proof. Let $E$ be the equivalence class determined by $x$, and let $E^{\prime}$ be the equivalence class determined by $x^{\prime}$. Suppose that $E \cap E^{\prime}$ is not empty; let y be a point of $E \cap E^{\prime}$. See Figure 3.1. We show that $E=E^{\prime}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-024.jpg?height=233&width=367&top_left_y=611&top_left_x=838)

Figure 3.1

By definition, we have $y \sim x$ and $y \sim x^{\prime}$. Symmetry allows us to conclude that $x \sim y$ and $y \sim x^{\prime}$; from transitivity it follows that $x \sim x^{\prime}$. If now $w$ is any point of $E$, we have $w \sim x$ by definition; it follows from another application of transitivity that $w \sim x^{\prime}$. We conclude that $E \subset E^{\prime}$.

The symmetry of the situation allows us to conclude that $E^{\prime} \subset E$ as well, so that $E=E^{\prime}$.

Given an equivalence relation on a set $A$, let us denote by $\mathcal{E}$ the collection of all the equivalence classes determined by this relation. The preceding lemma shows that distinct elements of $\mathcal{E}$ are disjoint. Furthermore, the union of the elements of $\mathcal{E}$ equals all of $A$ because every element of $A$ belongs to an equivalence class. The collection $\mathcal{E}$ is a particular example of what is called a partition of $A$ :

Definition. A partition of a set $A$ is a collection of disjoint nonempty subsets of $A$ whose union is all of $A$.

Studying equivalence relations on a set $A$ and studying partitions of $A$ are really the same thing. Given any partition $\mathscr{D}$ of $A$, there is exactly one equivalence relation on $A$ from which it is derived.

The proof is not difficult. To show that the partition $\mathscr{D}$ comes from some equivalence relation, let us define a relation $C$ on $A$ by setting $x C y$ if $x$ and $y$ belong to the same element of $\mathcal{D}$. Symmetry of $C$ is obvious; reflexivity follows from the fact that the union of the elements of $\mathscr{D}$ equals all of $A$; transitivity follows from the fact that distinct elements of $\mathcal{D}$ are disjoint. It is simple to check that the collection of equivalence classes determined by $C$ is precisely the collection $\mathscr{D}$.

To show there is only one such equivalence relation, suppose that $C_{1}$ and $C_{2}$ are two equivalence relations on $A$ that give rise to the same collection of equivalence classes $\mathscr{D}$. Given $x \in A$, we show that $y C_{1} x$ if and only if $y C_{2} x$, from which we conclude that $C_{1}=C_{2}$. Let $E_{1}$ be the equivalence class determined by $x$ relative to the relation $C_{1}$; let $E_{2}$ be the equivalence class determined by $x$ relative to the relation $C_{2}$. Then $E_{1}$ is an element of $\mathscr{D}$, so that it must equal the unique element $D$ of $\mathscr{D}$ that
contains $x$. Similarly, $E_{2}$ must equal $D$. Now by definition. $E_{1}$ consists of all $y$ such that $y C_{1} x$; and $E_{2}$ consists of all $y$ such that $y C_{2} x$. Since $E_{1}=D=E_{2}$, our result is proved.

EXAmple 3. Define two points in the plane to be equivalent if they lie at the same distance from the origin. Reflexivity, symmetry, and transitivity hold trivially. The collection $\varepsilon$ of equivalence classes consists of all circles centered at the origin, along with the set consisting of the origin alone.

EXAMPLE 4. Define two points of the plane to be equivalent if they have the same $y$-coordinate. The collection of equivalence classes is the collection of all straight lines in the plane parallel to the $x$-axis.

EXAMPLE 5. Let $\mathcal{L}$ be the collection of all straight lines in the plane parallel to the line $y=-x$. Then $\mathcal{L}$ is a partition of the plane, since each point lies on exactly one such line. The partition $\mathcal{L}$ comes from the equivalence relation on the plane that declares the points $\left(x_{0}, y_{0}\right)$ and $\left(x_{1}, y_{1}\right)$ to be equivalent if $x_{0}+y_{0}=x_{1}+y_{1}$.

EXAMPLE 6. Let $\mathscr{L}^{\prime}$ be the collection of all straight lines in the plane. Then $\mathscr{L}^{\prime}$ is not a partition of the plane, for distinct elements of $\mathcal{L}^{\prime}$ are not necessarily disjoint; two lines may intersect without being equal.

## Order Relations

A relation $C$ on a set $A$ is called an order relation (or a simple order, or a linear order) if it has the following properties:

(1) (Comparability) For every $x$ and $y$ in $A$ for which $x \neq y$, either $x C y$ or $y C x$.

(2) (Nonreflexivity) For no $x$ in $A$ does the relation $x C x$ hold.

(3) (Transitivity) If $x C y$ and $y C z$, then $x C z$.

Note that property (1) does not by itself exclude the possibility that for some pair of elements $x$ and $y$ of $A$, both the relations $x C y$ and $y C x$ hold (since "or" means "one or the other, or both"). But properties (2) and (3) combined do exclude this possibility; for if both $x C y$ and $y C x$ held, transitivity would imply that $x C x$, contradicting nonreflexivity.

EXAMPLE 7. Consider the relation on the real line consisting of all pairs $(x, y)$ of real numbers such that $x<y$. It is an order relation, called the "usual order relation," on the real line. A less familiar order relation on the real line is the following: Define $x C y$ if $x^{2}<y^{2}$, or if $x^{2}=y^{2}$ and $x<y$. You can check that this is an order relation.

EXAMPLE 8. Consider again the relationships among people given in Example 1. The blood relation $B$ satisfies none of the properties of an order relation, and the sibling relation $S$ satisfies only (3). The descendant relation $D$ does somewhat better, for it satisfies both (2) and (3); however, comparability still fails. Relations that satisfy (2) and (3) occur often enough in mathematics to be given a special name. They are called strict partial order relations; we shall consider them later (see §11).

As the tilde, $\sim$, is the generic symbol for an equivalence relation, the "less than" symbol, $<$, is commonly used to denote an order relation. Stated in this notation, the properties of an order relation become

(1) If $x \neq y$, then either $x<y$ or $y<x$.

(2) If $x<y$, then $x \neq y$.

(3) If $x<y$ and $y<z$, then $x<z$.

We shall use the notation $x \leq y$ to stand for the statement "either $x<y$ or $x=y$ "; and we shall use the notation $y>x$ to stand for the statement " $x<y$." We write $x<y<z$ to mean " $x<y$ and $y<z$."

Definition. If $X$ is a set and $<$ is an order relation on $X$, and if $a<b$, we use the notation $(a, b)$ to denote the set

$$
\{x \mid a<x<b\}
$$

it is called an open interval in $X$. If this set is empty, we call $a$ the immediate predecessor of $b$, and we call $b$ the immediate successor of $a$.

Definition. Suppose that $A$ and $B$ are two sets with order relations $<_{A}$ and $<_{B}$ respectively. We say that $A$ and $B$ have the same order type if there is a bijective correspondence between them that preserves order; that is, if there exists a bijective function $f: A \rightarrow B$ such that

$$
a_{1}<_{A} a_{2} \Longrightarrow f\left(a_{1}\right)<_{B} f\left(a_{2}\right) .
$$

EXAMPLE 9. The interval $(-1,1)$ of real numbers has the same order type as the set $\mathbb{R}$ of real numbers itself, for the function $f:(-1,1) \rightarrow \mathbb{R}$ given by

$$
f(x)=\frac{x}{1-x^{2}}
$$

is an order-preserving bijective correspondence, as you can check. It is pictured in Figure 3.2.

EXAmple 10. The subset $A=\{0\} \cup(1,2)$ of $\mathbb{R}$ has the same order type as the subset

$$
[0,1)=\{x \mid 0 \leq x<1\}
$$

of $\mathbb{R}$. The function $f: A \rightarrow[0,1)$ defined by

$$
\begin{aligned}
& f(0)=0, \\
& f(x)=x-1 \quad \text { for } x \in(1,2)
\end{aligned}
$$

is the required order-preserving correspondence.

One interesting way of defining an order relation, which will be useful to us later in dealing with some examples, is the following:

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-027.jpg?height=710&width=652&top_left_y=361&top_left_x=862)

Figure 3.2

Definition. Suppose that $A$ and $B$ are two sets with order relations $<_{A}$ and $<_{B}$ respectively. Define an order relation $<$ on $A \times B$ by defining

$$
a_{1} \times b_{1}<a_{2} \times b_{2}
$$

if $a_{1}<_{A} a_{2}$, or if $a_{1}=a_{2}$ and $b_{1}<_{B} b_{2}$. It is called the dictionary order relation on $A \times B$.

Checking that this is an order relation involves looking at several separate cases; we leave it to you.

The reason for the choice of terminology is fairly evident. The rule defining $<$ is the same as the rule used to order the words in the dictionary. Given two words, one compares their first letters and orders the words according to the order in which their first letters appear in the alphabet. If the first letters are the same, one compares their second letters and orders accordingly. And so on.

EXAMPLE 11. Consider the dictionary order on the plane $\mathbb{R} \times \mathbb{R}$. In this order, the point $p$ is less than every point lying above it on the vertical line through $p$, and $p$ is less than every point to the right of this vertical line.

EXAMPLE 12. Consider the set $[0,1)$ of real numbers and the set $\mathbb{Z}_{+}$of positive integers, both in their usual orders; give $\mathbb{Z}_{+} \times[0,1)$ the dictionary order. This set has the same order type as the set of nonnegative reals; the function

$$
f(n \times t)=n+t-1
$$

is the required bijective order-preserving correspondence. On the other hand, the set $[0,1) \times \mathbb{Z}_{+}$in the dictionary order has quite a different order type; for example, every element of this ordered set has an immediate successor. These sets are pictured in Figure 3.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-028.jpg?height=525&width=1035&top_left_y=365&top_left_x=504)

Figure 3.3

One of the properties of the real numbers that you may have seen before is the "least upper bound property." One can define this property for an arbitrary ordered set. First, we need some preliminary definitions.

Suppose that $A$ is a set ordered by the relation $<$. Let $A_{0}$ be a subset of $A$. We say that the element $b$ is the largest element of $A_{0}$ if $b \in A_{0}$ and if $x \leq b$ for every $x \in A_{0}$. Similarly, we say that $a$ is the smallest element of $A_{0}$ if $a \in A_{0}$ and if $a \leq x$ for every $x \in A_{0}$. It is easy to see that a set has at most one largest element and at most one smallest element.

We say that the subset $A_{0}$ of $A$ is bounded above if there is an element $b$ of $A$ such that $x \leq b$ for every $x \in A_{0}$; the element $b$ is called an upper bound for $A_{0}$. If the set of all upper bounds for $A_{0}$ has a smallest element, that element is called the least upper bound, or the supremum, of $A_{0}$. It is denoted by sup $A_{0}$; it may or may not belong to $A_{0}$. If it does, it is the largest element of $A_{0}$.

Similarly, $A_{0}$ is bounded below if there is an element $a$ of $A$ such that $a \leq x$ for every $x \in A_{0}$; the element $a$ is called a lower bound for $A_{0}$. If the set of all lower bounds for $A_{0}$ has a largest element, that element is called the greatest lower bound, or the infimum, of $A_{0}$. It is denoted by inf $A_{0}$; it may or may not belong to $A_{0}$. If it does, it is the smallest element of $A_{0}$.

Now we can define the least upper bound property.

Definition. An ordered set $A$ is said to have the least upper bound property if every nonempty subset $A_{0}$ of $A$ that is bounded above has a least upper bound. Analogously, the set $A$ is said to have the greatest lower bound property if every nonempty subset $A_{0}$ of $A$ that is bounded below has a greatest lower bound.

We leave it to the exercises to show that $A$ has the least upper bound property if and only if it has the greatest lower bound property.

EXAMPlE 13. Consider the set $A=(-1,1)$ of real numbers in the usual order. Assuming the fact that the real numbers have the least upper bound property, it follows that
the set $A$ has the least upper bound property. For, given any subset of $A$ having an upper bound in $A$, it follows that its least upper bound (in the real numbers) must be in $A$. For example, the subset $\left\{-1 / 2 n \mid n \in \mathbb{Z}_{+}\right\}$of $A$, though it has no largest element, does have a least upper bound in $A$, the number 0 .

On the other hand, the set $B=(-1,0) \cup(0,1)$ does not have the least upper bound property. The subset $\left\{-1 / 2 n \mid n \in \mathbb{Z}_{+}\right\}$of $B$ is bounded above by any element of $(0,1)$, but it has no least upper bound in $B$.

## Exercises

## Equivalence Relations

1. Define two points $\left(x_{0}, y_{0}\right)$ and $\left(x_{1}, y_{1}\right)$ of the plane to be equivalent if $y_{0}-x_{0}^{2}=$ $y_{1}-x_{1}^{2}$. Check that this is an equivalence relation and describe the equivalence classes.
2. Let $C$ be a relation on a set $A$. If $A_{0} \subset A$, define the restriction of $C$ to $A_{0}$ to be the relation $C \cap\left(A_{0} \times A_{0}\right)$. Show that the restriction of an equivalence relation is an equivalence relation.
3. Here is a "proof" that every relation $C$ that is both symmetric and transitive is also reflexive: "Since $C$ is symmetric, $a C b$ implies $b C a$. Since $C$ is transitive, $a C b$ and $b C a$ together imply $a C a$, as desired." Find the flaw in this argument.
4. Let $f: A \rightarrow B$ be a surjective function. Let us define a relation on $A$ by setting $a_{0} \sim a_{1}$ if

$$
f\left(a_{0}\right)=f\left(a_{1}\right)
$$

(a) Show that this is an equivalence relation.

(b) Let $A^{*}$ be the set of equivalence classes. Show there is a bijective correspondence of $A^{*}$ with $B$.

5. Let $S$ and $S^{\prime}$ be the following subsets of the plane:

$$
\begin{aligned}
S & =\{(x, y) \mid y=x+1 \text { and } 0<x<2\} \\
S^{\prime} & =\{(x, y) \mid y-x \text { is an integer }\} .
\end{aligned}
$$

(a) Show that $S^{\prime}$ is an equivalence relation on the real line and $S^{\prime} \supset S$. Describe the equivalence classes of $S^{\prime}$.

(b) Show that given any collection of equivalence relations on a set $A$, their intersection is an equivalence relation on $A$.

(c) Describe the equivalence relation $T$ on the real line that is the intersection of all equivalence relations on the real line that contain $S$. Describe the equivalence classes of $T$.

## Order Relations

6. Define a relation on the plane by setting

$$
\left(x_{0}, y_{0}\right)<\left(x_{1}, y_{1}\right)
$$

if either $y_{0}-x_{0}^{2}<y_{1}-x_{1}^{2}$, or $y_{0}-x_{0}^{2}=y_{1}-x_{1}^{2}$ and $x_{0}<x_{1}$. Show that this is an order relation on the plane, and describe it geometrically.

7. Show that the restriction of an order relation is an order relation.
8. Check that the relation defined in Example 7 is an order relation.
9. Check that the dictionary order is an order relation.
10. (a) Show that the map $f:(-1,1) \rightarrow \mathbb{R}$ of Example 9 is order preserving.

(b) Show that the equation $g(y)=2 y /\left[1+\left(1+4 y^{2}\right)^{1 / 2}\right]$ defines a function $g: \mathbb{R} \rightarrow(-1,1)$ that is both a left and a right inverse for $f$.

11. Show that an element in an ordered set has at most one immediate successor and at most one immediate predecessor. Show that a subset of an ordered set has at most one smallest element and at most one largest element.
12. Let $\mathbb{Z}_{+}$denote the set of positive integers. Consider the following order relations on $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$:

(i) The dictionary order.

(ii) $\left(x_{0}, y_{0}\right)<\left(x_{1}, y_{1}\right)$ if either $x_{0}-y_{0}<x_{1}-y_{1}$, or $x_{0}-y_{0}=x_{1}-y_{1}$ and $y_{0}<y_{1}$.

(iii) $\left(x_{0}, y_{0}\right)<\left(x_{1}, y_{1}\right)$ if either $x_{0}+y_{0}<x_{1}+y_{1}$, or $x_{0}+y_{0}=x_{1}+y_{1}$ and $y_{0}<y_{1}$.

In these order relations, which elements have immediate predecessors? Does the set have a smallest element? Show that all three order types are different.

13. Prove the following:

Theorem. If an ordered set A has the least upper bound property, then it has the greatest lower bound property.

14. If $C$ is a relation on a set $A$, define a new relation $D$ on $A$ by letting $(b, a) \in D$ if $(a, b) \in C$.

(a) Show that $C$ is symmetric if and only if $C=D$.

(b) Show that if $C$ is an order relation, $D$ is also an order relation.

(c) Prove the converse of the theorem in Exercise 13.

15. Assume that the real line has the least upper bound property.

(a) Show that the sets

$$
\begin{aligned}
& {[0,1]=\{x \mid 0 \leq x \leq 1\}} \\
& {[0,1)=\{x \mid 0 \leq x<1\}}
\end{aligned}
$$

have the least upper bound property.

(b) Does $[0,1] \times[0,1]$ in the dictionary order have the least upper bound property? What about $[0,1] \times[0,1)$ ? What about $[0,1) \times[0,1]$ ?

## §4 The Integers and the Real Numbers

Up to now we have been discussing what might be called the logical foundations for our study of topology-the elementary concepts of set theory. Now we turn to what we might call the mathematical foundations for our study-the integers and the real number system. We have already used them in an informal way in the examples and exercises of the preceding sections. Now we wish to deal with them more formally.

One way of establishing these foundations is to construct the real number system, using only the axioms of set theory-to build them with one's bare hands, so to speak. This way of approaching the subject takes a good deal of time and effort and is of greater logical than mathematical interest.

A second way is simply to assume a set of axioms for the real numbers and work from these axioms. In the present section, we shall sketch this approach to the real numbers. Specifically, we shall give a set of axioms for the real numbers and shall indicate how the familiar properties of real numbers and the integers are derived from them. But we shall leave most of the proofs to the exercises. If you have seen all this before, our description should refresh your memory. If not, you may want to work through the exercises in detail in order to make sure of your knowledge of the mathematical foundations.

First we need a definition from set theory.

Definition. A binary operation on a set $A$ is a function $f$ mapping $A \times A$ into $A$.

When dealing with a binary operation $f$ on a set $A$, we usually use a notation different from the standard functional notation introduced in $\$ 2$. Instead of denoting the value of the function $f$ at the point $\left(a, a^{\prime}\right)$ by $f\left(a, a^{\prime}\right)$, we usually write the symbol for the function between the two coordinates of the point in question, writing the value of the function at $\left(a, a^{\prime}\right)$ as $a f a^{\prime}$. Furthermore (just as was the case with relations), it is more common to use some symbol other than a letter to denote an operation. Symbols often used are the plus symbol + , the multiplication symbols $\cdot$ and $\circ$, and the asterisk $*$; however, there are many others.

## Assumption

We assume there exists a set $\mathbb{R}$, called the set of real numbers, two binary operations + and $\cdot$ on $\mathbb{R}$, called the addition and multiplication operations, respectively, and an order relation $<$ on $\mathbb{R}$, such that the following properties hold:

## Algebraic Properties

(1) $(x+y)+z=x+(y+z)$,

$(x \cdot y) \cdot z=x \cdot(y \cdot z)$ for all $x, y, z$ in $\mathbb{R}$.

(2) $x+y=y+x$,

$x \cdot y=y \cdot x$ for all $x, y$ in $\mathbb{R}$.

(3) There exists a unique element of $\mathbb{R}$ called zero, denoted by 0 , such that $x+0=x$ for all $x \in \mathbb{R}$.

There exists a unique element of $\mathbb{R}$ called one, different from 0 and denoted by 1 , such that $x \cdot 1=x$ for all $x \in \mathbb{R}$.

(4) For each $x$ in $\mathbb{R}$, there exists a unique $y$ in $\mathbb{R}$ such that $x+y=0$.

For each $x$ in $\mathbb{R}$ different from 0 , there exists a unique $y$ in $\mathbb{R}$ such that $x \cdot y=1$.

(5) $x \cdot(y+z)=(x \cdot y)+(x \cdot z)$ for all $x, y, z \in \mathbb{R}$.

## A Mixed Algebraic and Order Property

(6) If $x>y$, then $x+z>y+z$.

If $x>y$ and $z>0$, then $x \cdot z>y \cdot z$.

## Order Properties

(7) The order relation $<$ has the least upper bound property.

(8) If $x<y$, there exists an element $z$ such that $x<z$ and $z<y$.

From properties (1)-(5) follow the familiar "laws of algebra." Given $x$, one denotes by $-x$ that number $y$ such that $x+y=0$; it is called the negative of $x$. One defines the subtraction operation by the formula $z-x=z+(-x)$. Similarly, given $x \neq 0$, one denotes by $1 / x$ that number $y$ such that $x \cdot y=1$; it is called the reciprocal of $x$. One defines the quotient $z / x$ by the formula $z / x=z \cdot(1 / x)$. The usual laws of signs, and the rules for adding and multiplying fractions, follow as theorems. These laws of algebra are listed in Exercise 1 at the end of the section. We often denote $x \cdot y$ simply by $x y$.

When one adjoins property (6) to properties (1)-(5), one can prove the usual "laws of inequalities," such as the following:

$$
\begin{aligned}
& \text { If } x>y \text { and } z<0 \text {, then } x \cdot z<y \cdot z \text {. } \\
& -1<0 \text { and } 0<1 \text {. }
\end{aligned}
$$

The laws of inequalities are listed in Exercise 2.

We define a number $x$ to be positive if $x>0$, and to be negative if $x<0$. We denote the positive reals by $\mathbb{R}_{+}$and the nonnegative reals (for reasons to be explained later) by $\overline{\mathbb{R}}_{+}$. Properties (1)-(6) are familiar properties in modern algebra. Any set with two binary operations satisfying (1)-(5) is called by algebraists a field; if the field has an order relation satisfying (6), it is called an ordered field.

Properties (7) and (8), on the other hand, are familiar properties in topology. They involve only the order relation; any set with an order relation satisfying (7) and (8) is called by topologists a linear continuum.

Now it happens that when one adjoins to the axioms for an ordered field [properties (1)-(6)] the axioms for a linear continuum [properties (7) and (8)], the resulting list contains some redundancies. Property (8), in particular, can be proved as a consequence of the others; given $x<y$ one can show that $z=(x+y) /(1+1)$ satisfies the requirements of (8). Therefore, in the standard treatment of the real numbers, properties (1)-(7) are taken as axioms, and property (8) becomes a theorem. We have
included (8) in our list merely to emphasize the fact that it and the least upper bound property are the two crucial properties of the order relation for $\mathbb{R}$. From these two properties many of the topological properties of $\mathbb{R}$ may be derived, as we shall see in Chapter 3.

Now there is nothing in this list as it stands to tell us what an integer is. We now define the integers, using only properties (1)-(6).

Definition. A subset $A$ of the real numbers is said to be inductive if it contains the number 1, and if for every $x$ in $A$, the number $x+1$ is also in $A$. Let $\mathcal{A}$ be the collection of all inductive subsets of $\mathbb{R}$. Then the set $\mathbb{Z}_{+}$of positive integers is defined by the equation

$$
\mathbb{Z}_{+}=\bigcap_{A \in \mathcal{A}} A
$$

Note that the set $\mathbb{R}_{+}$of positive real numbers is inductive, for it contains 1 and the statement $x>0$ implies the statement $x+1>0$. Therefore, $\mathbb{Z}_{+} \subset \mathbb{R}_{+}$, so the elements of $\mathbb{Z}_{+}$are indeed positive, as the choice of terminology suggests. Indeed, one sees readily that 1 is the smallest element of $\mathbb{Z}_{+}$, because the set of all real numbers $x$ for which $x \geq 1$ is inductive. lowing:

The basic properties of $\mathbb{Z}_{+}$, which follow readily from the definition, are the fol-

(1) $\mathbb{Z}_{+}$is inductive.

(2) (Principle of induction). If $A$ is an inductive set of positive integers, then $A=$ $\mathbb{Z}_{+}$.

We define the set $\mathbb{Z}$ of integers to be the set consisting of the positive integers $\mathbb{Z}_{+}$, the number 0 , and the negatives of the elements of $\mathbb{Z}_{+}$. One proves that the sum, difference, and product of two integers are integers, but the quotient is not necessarily an integer. The set $\mathbb{Q}$ of quotients of integers is called the set of rational numbers.

One proves also that, given the integer $n$, there is no integer $a$ such that $n<a<$ $n+1$.

If $n$ is a positive integer, we use the symbol $S_{n}$ to denote the set of all positive integers less than $n$; we call it a section of the positive integers. The set $S_{1}$ is empty, and $S_{n+1}$ denotes the set of positive integers between 1 and $n$, inclusive. We also use the notation

$$
\{1, \ldots, n\}=S_{n+1}
$$

for the latter set.

Now we prove two properties of the positive integers that may not be quite so familiar, but are quite useful. They may be thought of as alternative versions of the induction principle.

Theorem 4.1 (Well-ordering property). Every nonempty subset of $\mathbb{Z}_{+}$has a smallest element.

Proof. We first prove that, for each $n \in \mathbb{Z}_{+}$, the following statement holds: Every nonempty subset of $\{1, \ldots, n\}$ has a smallest element.

Let $A$ be the set of all positive integers $\mathrm{n}$ for which this statement holds. Then $A$ contains 1 , since if $n=1$, the only nonempty subset of $\{1, \ldots, n\}$ is the set $\{1\}$ itself. Then, supposing $A$ contains $n$, we show that it contains $n+1$. So let $C$ be a nonempty subset of the set $\{1, \ldots, n+1\}$. If $C$ consists of the single element $n+1$, then that element is the smallest element of $C$. Otherwise, consider the set $C \cap\{1, \ldots, n\}$, which is nonempty. Because $n \in A$, this set has a smallest element, which will automatically be the smallest element of $C$ also. Thus $A$ is inductive, so we conclude that $A=\mathbb{Z}_{+}$; hence the statement is true for all $n \in \mathbb{Z}_{+}$.

Now we prove the theorem. Suppose that $D$ is a nonempty subset of $\mathbb{Z}_{+}$. Choose an element $n$ of $D$. Then the set $A=D \cap\{1, \ldots, n\}$ is nonempty, so that $A$ has a smallest element $k$. The element $k$ is automatically the smallest element of $D$ as well.

Theorem 4.2 (Strong induction principle). Let $A$ be a set of positive integers. Suppose that for each positive integer $n$, the statement $S_{n} \subset A$ implies the statement $n \in A$. Then $A=\mathbb{Z}_{+}$.

Proof. If $A$ does not equal all of $\mathbb{Z}_{+}$, let $n$ be the smallest positive integer that is not in $A$. Then every positive integer less than $n$ is in $A$, so that $S_{n} \subset A$. Our hypothesis implies that $n \in A$, contrary to assumption.

Everything we have done up to now has used only the axioms for an ordered field, properties (1)-(6) of the real numbers. At what point do you need (7), the least upper bound axiom?

For one thing, you need the least upper bound axiom to prove that the set $\mathbb{Z}_{+}$of positive integers has no upper bound in $\mathbb{R}$. This is the Archimedean ordering property of the real line. To prove it, we assume that $\mathbb{Z}_{+}$has an upper bound and derive a contradiction. If $\mathbb{Z}_{+}$has an upper bound, it has a least upper bound $b$. There exists $n \in \mathbb{Z}_{+}$such that $n>b-1$; for otherwise, $b-1$ would be an upper bound for $\mathbb{Z}_{+}$ smaller than $b$. Then $n+1>b$, contrary to the fact that $b$ is an upper bound for $\mathbb{Z}_{+}$.

The least upper bound axiom is also used to prove a number of other things about $\mathbb{R}$. It is used for instance to show that $\mathbb{R}$ has the greatest lower bound property. It is also used to prove the existence of a unique positive square root $\sqrt{x}$ for every positive real number. This fact, in turn, can be used to demonstrate the existence of real numbers that are not rational numbers; the number $\sqrt{2}$ is an easy example.

We use the symbol 2 to denote $1+1$, the symbol 3 to denote $2+1$, and so on through the standard symbols for the positive integers. It is a fact that this procedure assigns to each positive integer a unique symbol, but we never need this fact and shall not prove it.

Proofs of these properties of the integers and real numbers, along with a few other properties we shall need later, are outlined in the exercises that follow.

## Exercises

1. Prove the following "laws of algebra" for $\mathbb{R}$, using only axioms (1)-(5):

(a) If $x+y=x$, then $y=0$.

(b) $0 \cdot x=0$. [Hint: Compute $(x+0) \cdot x$.]

(c) $-0=0$.

(d) $-(-x)=x$.

(e) $x(-y)=-(x y)=(-x) y$.

(f) $(-1) x=-x$.

(g) $x(y-z)=x y-x z$.

(h) $-(x+y)=-x-y$; $-(x-y)=-x+y$.

(i) If $x \neq 0$ and $x \cdot y=x$, then $y=1$.

(j) $x / x=1$ if $x \neq 0$.

(k) $x / 1=x$.

(l) $x \neq 0$ and $y \neq 0 \Rightarrow x y \neq 0$.

(m) $(1 / y)(1 / z)=1 /(y z)$ if $y, z \neq 0$.

(n) $(x / y)(w / z)=(x w) /(y z)$ if $y, z \neq 0$.

(o) $(x / y)+(w / z)=(x z+w y) /(y z)$ if $y, z \neq 0$.

(p) $x \neq 0 \Rightarrow 1 / x \neq 0$.

(q) $1 /(w / z)=z / w$ if $w, z \neq 0$.

(r) $(x / y) /(w / z)=(x z) /(y w)$ if $y, w, z \neq 0$.

(s) $(a x) / y=a(x / y)$ if $y \neq 0$.

(t) $(-x) / y=x /(-y)=-(x / y)$ if $y \neq 0$.

2. Prove the following "laws of inequalities" for $\mathbb{R}$, using axioms (1)-(6) along with the results of Exercise 1:

(a) $x>y$ and $w>z \Rightarrow x+w>y+z$.

(b) $x>0$ and $y>0 \Rightarrow x+y>0$ and $x \cdot y>0$.

(c) $x>0 \Leftrightarrow-x<0$.

(d) $x>y \Leftrightarrow-x<-y$.

(e) $x>y$ and $z<0 \Rightarrow x z<y z$.

(f) $x \neq 0 \Rightarrow x^{2}>0$, where $x^{2}=x \cdot x$.

(g) $-1<0<1$.

(h) $x y>0 \Leftrightarrow x$ and $y$ are both positive or both negative.

(i) $x>0 \Rightarrow 1 / x>0$.

(j) $x>y>0 \Rightarrow 1 / x<1 / y$.

(k) $x<y \Rightarrow x<(x+y) / 2<y$.

3. (a) Show that if $\mathcal{A}$ is a collection of inductive sets, then the intersection of the elements of $\mathcal{A}$ is an inductive set.

(b) Prove the basic properties (1) and (2) of $\mathbb{Z}_{+}$.

4. (a) Prove by induction that given $n \in \mathbb{Z}_{+}$, every nonempty subset of $\{1, \ldots, n\}$ has a largest element.

(b) Explain why you cannot conclude from (a) that every nonempty subset of $\mathbb{Z}_{+}$ has a largest element.

5. Prove the following properties of $\mathbb{Z}$ and $\mathbb{Z}_{+}$:

(a) $a$, $b \in \mathbb{Z}_{+} \Rightarrow a+b \in \mathbb{Z}_{+}$. [Hint: Show that given $a \in \mathbb{Z}_{+}$, the set $X=\left\{x \mid x \in \mathbb{R}\right.$ and $\left.a+x \in \mathbb{Z}_{+}\right\}$is inductive.]

(b) $a, b \in \mathbb{Z}_{+} \Rightarrow a \cdot b \in \mathbb{Z}_{+}$.

(c) Show that $a \in \mathbb{Z}_{+} \Rightarrow a-1 \in \mathbb{Z}_{+} \cup\{0\}$. [Hint: Let $X=\{x \mid x \in \mathbb{R}$ and $x-1 \in \mathbb{Z}_{+} \cup\{0\}$; show that $X$ is inductive.]

(d) $c, d \in \mathbb{Z} \Rightarrow c+d \in \mathbb{Z}$ and $c-d \in \mathbb{Z}$. [Hint: Prove it first for $d=1$.]

(e) $c, d \in \mathbb{Z} \Rightarrow c \cdot d \in \mathbb{Z}$.

6. Let $a \in \mathbb{R}$. Define inductively

$$
\begin{aligned}
a^{1} & =a, \\
a^{n+1} & =a^{n} \cdot a
\end{aligned}
$$

for $n \in \mathbb{Z}_{+}$. (See $\S 7$ for a discussion of the process of inductive definition.) Show that for $n, m \in \mathbb{Z}_{+}$and $a, b \in \mathbb{R}$,

$$
\begin{aligned}
a^{n} a^{m} & =a^{n+m} \\
\left(a^{n}\right)^{m} & =a^{n m} \\
a^{m} b^{m} & =(a b)^{m}
\end{aligned}
$$

These are called the laws of exponents. [Hint: For fixed $n$, prove the formulas by induction on $m$.]

7. Let $a \in \mathbb{R}$ and $a \neq 0$. Define $a^{0}=1$, and for $n \in \mathbb{Z}_{+}, a^{-n}=1 / a^{n}$. Show that the laws of exponents hold for $a, b \neq 0$ and $n, m \in \mathbb{Z}$.
8. (a) Show that $\mathbb{R}$ has the greatest lower bound property.

(b) Show that $\inf \left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}=0$.

(c) Show that given $a$ with $0<a<1$, inf $\left\{a^{n} \mid n \in \mathbb{Z}_{+}\right\}=0$. [Hint: Let $h=(1-a) / a$, and show that $\left.(1+h)^{n} \geq 1+n h.\right]$

9. (a) Show that every nonempty subset of $\mathbb{Z}$ that is bounded above has a largest element.

(b) If $x \notin \mathbb{Z}$, show there is exactly one $n \in \mathbb{Z}$ such that $n<x<n+1$.

(c) If $x-y>1$, show there is at least one $n \in \mathbb{Z}$ such that $y<n<x$.

(d) If $y<x$, show there is a rational number $z$ such that $y<z<x$.

10. Show that every positive number $a$ has exactly one positive square root, as follows:

(a) Show that if $x>0$ and $0 \leq h<1$, then

$$
\begin{aligned}
& (x+h)^{2} \leq x^{2}+h(2 x+1) \\
& (x-h)^{2} \geq x^{2}-h(2 x)
\end{aligned}
$$

(b) Let $x>0$. Show that if $x^{2}<a$, then $(x+h)^{2}<a$ for some $h>0$; and if $x^{2}>a$, then $(x-h)^{2}>a$ for some $h>0$.
(c) Given $a>0$, let $B$ be the set of all real numbers $x$ such that $x^{2}<a$. Show that $B$ is bounded above and contains at least one positive number. Let $b=\sup B$; show that $b^{2}=a$.

(d) Show that if $b$ and $c$ are positive and $b^{2}=c^{2}$, then $b=c$.

11. Given $m \in \mathbb{Z}$, we say that $m$ is even if $m / 2 \in \mathbb{Z}$, and $m$ is odd otherwise.

(a) Show that if $m$ is odd, $m=2 n+1$ for some $n \in \mathbb{Z}$. [Hint: Choose $n$ so that $n<m / 2<n+1$.]

(b) Show that if $p$ and $q$ are odd, so are $p \cdot q$ and $p^{n}$, for any $n \in \mathbb{Z}_{+}$.

(c) Show that if $a>0$ is rational, then $a=m / n$ for some $m, n \in \mathbb{Z}_{+}$where not both $m$ and $n$ are even. [Hint: Let $n$ be the smallest element of the set $\left\{x \mid x \in \mathbb{Z}_{+}\right.$and $\left.\left.x \cdot a \in \mathbb{Z}_{+}\right\}.\right]$

(d) Theorem. $\sqrt{2}$ is irrational.

## §5 Cartesian Products

We have already defined what we mean by the cartesian product $A \times B$ of two sets. Now we introduce more general cartesian products.

Definition. Let $\mathcal{A}$ be a nonempty collection of sets. An indexing function for $\mathcal{A}$ is a surjective function $f$ from some set $J$, called the index set, to $\mathcal{A}$. The collection $\mathcal{A}$, together with the indexing function $f$, is called an indexed family of sets. Given $\alpha \in J$, we shall denote the set $f(\alpha)$ by the symbol $A_{\alpha}$. And we shall denote the indexed family itself by the symbol

$$
\left\{A_{\alpha}\right\}_{\alpha \in J}
$$

which is read "the family of all $A_{\alpha}$, as $\alpha$ ranges over $J$." Sometimes we write merely $\left\{A_{\alpha}\right\}$, if it is clear what the index set is.

Note that although an indexing function is required to be surjective, it is not required to be injective. It is entirely possible for $A_{\alpha}$ and $A_{\beta}$ to be the same set of $\mathcal{A}$, even though $\alpha \neq \beta$.

One way in which indexing functions are used is to give a new notation for arbitrary unions and intersections of sets. Suppose that $f: J \rightarrow \mathcal{A}$ is an indexing function for $\mathcal{A}$; let $A_{\alpha}$ denote $f(\alpha)$. Then we define

$$
\bigcup_{\alpha \in J} A_{\alpha}=\left\{x \mid \text { for at least one } \alpha \in J, x \in A_{\alpha}\right\}
$$

and

$$
\bigcap_{\alpha \in J} A_{\alpha}=\left\{x \mid \text { for every } \alpha \in J, x \in A_{\alpha}\right\}
$$

These are simply new notations for previously defined concepts; one sees at once (using the surjectivity of the index function) that the first equals the union of all the elements of $\mathcal{A}$ and the second equals the intersection of all the elements of $\mathcal{A}$.

Two especially useful index sets are the set $\{1, \ldots, n\}$ of positive integers from 1 to $n$, and the set $\mathbb{Z}_{+}$of all positive integers. For these index sets, we introduce some special notation. If a collection of sets is indexed by the set $\{1, \ldots, n\}$, we denote the indexed family by the symbol $\left\{A_{1}, \ldots, A_{n}\right\}$, and we denote the union and intersection, respectively, of the members of this family by the symbols

$$
A_{1} \cup \cdots \cup A_{n} \quad \text { and } \quad A_{1} \cap \cdots \cap A_{n} \text {. }
$$

In the case where the index set is the set $\mathbb{Z}_{+}$, we denote the indexed family by the symbol $\left\{A_{1}, A_{2}, \ldots\right\}$, and the union and intersection by the respective symbols

$$
A_{1} \cup A_{2} \cup \cdots \quad \text { and } \quad A_{1} \cap A_{2} \cap \cdots \text {. }
$$

Definition. Let $m$ be a positive integer. Given a set $X$, we define an $\boldsymbol{m}$-tuple of elements of $X$ to be a function

$$
\mathbf{x}:\{1, \ldots, m\} \rightarrow X
$$

If $\mathbf{x}$ is an $m$-tuple, we often denote the value of $\mathbf{x}$ at $i$ by the symbol $x_{i}$ rather than $\mathbf{x}(i)$ and call it the $i$ th coordinate of $\mathbf{x}$. And we often denote the function $\mathbf{x}$ itself by the symbol

$$
\left(x_{1}, \ldots, x_{m}\right)
$$

Now let $\left\{A_{1}, \ldots, A_{m}\right\}$ be a family of sets indexed with the set $\{1, \ldots, m\}$. Let $X=$ $A_{1} \cup \cdots \cup A_{m}$. We define the cartesian product of this indexed family, denoted by

$$
\prod_{i=1}^{m} A_{i} \quad \text { or } \quad A_{1} \times \cdots \times A_{m}
$$

to be the set of all $m$-tuples $\left(x_{1}, \ldots, x_{m}\right)$ of elements of $X$ such that $x_{i} \in A_{i}$ for each $i$.

EXAMPLE 1. We now have two definitions for the symbol $A \times B$. One definition is, of course, the one given earlier, under which $A \times B$ denotes the set of all ordered pairs $(a, b)$ such that $a \in A$ and $b \in B$. The second definition, just given, defines $A \times B$ as the set of all functions $\mathbf{x}:\{1,2\} \rightarrow A \cup B$ such that $\mathbf{x}(1) \in A$ and $\mathbf{x}(2) \in B$. There is an obvious bijective correspondence between these two sets, under which the ordered pair $(a, b)$ corresponds to the function $\mathbf{x}$ defined by $\mathbf{x}(1)=a$ and $\mathbf{x}(2)=b$. Since we commonly denote this function $\mathbf{x}$ in "tuple notation" by the symbol $(a, b)$, the notation itself suggests the correspondence. Thus for the cartesian product of two sets, the general definition of cartesian product reduces essentially to the earlier one.

EXAMPLE 2. How does the cartesian product $A \times B \times C$ differ from the cartesian products $A \times(B \times C)$ and $(A \times B) \times C$ ? Very little. There are obvious bijective correspondences between these sets, indicated as follows:

$$
(a, b, c) \longleftrightarrow(a,(b, c)) \longleftrightarrow((a, b), c) .
$$

Definition. Given a set $X$, we define an $\omega$-tuple of elements of $X$ to be a function

$$
\mathbf{x}: \mathbb{Z}_{+} \longrightarrow X
$$

we also call such a function a sequence, or an infinite sequence, of elements of $X$. If $\mathbf{x}$ is an $\omega$-tuple, we often denote the value of $\mathbf{x}$ at $i$ by $x_{i}$ rather than $\mathbf{x}(i)$, and call it the $i$ th coordinate of $\mathbf{x}$. We denote $\mathbf{x}$ itself by the symbol

$$
\left(x_{1}, x_{2}, \ldots\right) \quad \text { or } \quad\left(x_{n}\right)_{n \in \mathbb{Z}_{+}} \text {. }
$$

Now let $\left\{A_{1}, A_{2}, \ldots\right\}$ be a family of sets, indexed with the positive integers; let $X$ be the union of the sets in this family. The cartesian product of this indexed family of sets, denoted by

$$
\prod_{i \in \mathbb{Z}_{+}} A_{i} \quad \text { or } \quad A_{1} \times A_{2} \times \cdots
$$

is defined to be the set of all $\omega$-tuples $\left(x_{1}, x_{2}, \ldots\right)$ of elements of $X$ such that $x_{i} \in A_{i}$ for each $i$.

Nothing in these definitions requires the sets $A_{i}$ to be different from one another. Indeed, they may all equal the same set $X$. In that case, the cartesian product $A_{1} \times$ $\cdots \times A_{m}$ is just the set of all $m$-tuples of elements of $X$, which we denote by $X^{m}$. Similarly, the product $A_{1} \times A_{2} \times \cdots$ is just the set of all $\omega$-tuples of elements of $X$, which we denote by $X^{\omega}$.

Later we will define the cartesian product of an arbitrary indexed family of sets.

EXAMPLE 3. If $\mathbb{R}$ is the set of real numbers, then $\mathbb{R}^{m}$ denotes the set of all $m$-tuples of real numbers; it is often called euclidean $\boldsymbol{m}$-space (although Euclid would never recognize it). Analogously, $\mathbb{R}^{\omega}$ is sometimes called "infinite-dimensional euclidean space"; it is the set of all $\omega$-tuples $\left(x_{1}, x_{2}, \ldots\right)$ of real numbers, that is, the set of all functions $\mathbf{x}: \mathbb{Z}_{+} \rightarrow \mathbb{R}$.

## Exercises

1. Show there is a bijective correspondence of $A \times B$ with $B \times A$.
2. (a) Show that if $n>1$ there is bijective correspondence of

$$
A_{1} \times \cdots \times A_{n} \quad \text { with } \quad\left(A_{1} \times \cdots \times A_{n-1}\right) \times A_{n} \text {. }
$$

(b) Given the indexed family $\left\{A_{1}, A_{2}, \ldots\right\}$, let $B_{i}=A_{2 i-1} \times A_{2 i}$ for each positive integer $i$. Show there is bijective correspondence of $A_{1} \times A_{2} \times \ldots$ with $B_{1} \times B_{2} \times \cdots$.

3. Let $A=A_{1} \times A_{2} \times \cdots$ and $B=B_{1} \times B_{2} \times \cdots$.

(a) Show that if $B_{i} \subset A_{i}$ for all $i$, then $B \subset A$. (Strictly speaking, if we are given a function mapping the index set $\mathbb{Z}_{+}$into the union of the sets $B_{i}$, we must change its range before it can be considered as a function mapping $\mathbb{Z}_{+}$ into the union of the sets $A_{i}$. We shall ignore this technicality when dealing with cartesian products).
(b) Show the converse of (a) holds if $B$ is nonempty.

(c) Show that if $A$ is nonempty, each $A_{i}$ is nonempty. Does the converse hold? (We will return to this question in the exercises of §19.)

(d) What is the relation between the set $A \cup B$ and the cartesian product of the sets $A_{i} \cup B_{i}$ ? What is the relation between the set $A \cap B$ and the cartesian product of the sets $A_{i} \cap B_{i}$ ?

4. Let $m, n \in \mathbb{Z}_{+}$. Let $X \neq \varnothing$.

(a) If $m \leq n$, find an injective map $f: X^{m} \rightarrow X^{n}$.

(b) Find a bijective map $g: X^{m} \times X^{n} \rightarrow X^{m+n}$.

(c) Find an injective map $h: X^{n} \rightarrow X^{\omega}$.

(d) Find a bijective map $k: X^{n} \times X^{\omega} \rightarrow X^{\omega}$.

(e) Find a bijective map $l: X^{\omega} \times X^{\omega} \rightarrow X^{\omega}$.

(f) If $A \subset B$, find an injective map $m: X^{A} \rightarrow X^{B}$.

5. Which of the following subsets of $\mathbb{R}^{\omega}$ can be expressed as the cartesian product of subsets of $\mathbb{R}$ ?

(a) $\left\{\mathbf{x} \mid x_{i}\right.$ is an integer for all $\left.i\right\}$.

(b) $\left\{\mathbf{x} \mid x_{i} \geq i\right.$ for all $\left.i\right\}$.

(c) $\left\{\mathbf{x} \mid x_{i}\right.$ is an integer for all $\left.i \geq 100\right\}$.

(d) $\left\{\mathbf{x} \mid x_{2}=x_{3}\right\}$.

## §6 Finite Sets

Finite sets and infinite sets, countable sets and uncountable sets, these are types of sets that you may have encountered before. Nevertheless, we shall discuss them in this section and the next, not only to make sure you understand them thoroughly, but also to elucidate some particular points of logic that will arise later on. First we consider finite sets.

Recall that if $n$ is a positive integer, we use $S_{n}$ to denote the set of positive integers less than $n$; it is called a section of the positive integers. The sets $S_{n}$ are the prototypes for what we call the finite sets.

Definition. A set is said to be finite if there is a bijective correspondence of $A$ with some section of the positive integers. That is, $A$ is finite if it is empty or if there is a bijection

$$
f: A \longrightarrow\{1, \ldots, n\}
$$

for some positive integer $n$. In the former case, we say that $A$ has cardinality 0 ; in the latter case, we say that $A$ has cardinality $\boldsymbol{n}$.

For instance, the set $\{1, \ldots, n\}$ itself has cardinality $n$, for it is in bijective correspondence with itself under the identity function.

Now note carefully: We have not yet shown that the cardinality of a finite set is uniquely determined by the set. It is of course clear that the empty set must have cardinality zero. But as far as we know, there might exist bijective correspondences of a given nonempty set $A$ with two different sets $\{1, \ldots, n\}$ and $\{1, \ldots, m\}$. The possibility may seem ridiculous, for it is like saying that it is possible for two people to count the marbles in a box and come out with two different answers, both correct. Our experience with counting in everyday life suggests that such is impossible, and in fact this is easy to prove when $n$ is a small number such as 1,2 , or 3 . But a direct proof when $n$ is 5 million would be impossibly demanding.

Even empirical demonstration would be difficult for such a large value of $n$. One might, for instance, construct an experiment by taking a freight car full of marbles and hiring 10 different people to count them independently. If one thinks of the physical problems involved, it seems likely that the counters would not all arrive at the same answer. Of course, the conclusion one could draw is that at least one person made a mistake. But that would mean assuming the correctness of the result one was trying to demonstrate empirically. An alternative explanation could be that there do exist bijective correspondences between the given set of marbles and two different sections of the positive integers.

In real life, we accept the first explanation. We simply take it on faith that our experience in counting comparatively small sets of objects demonstrates a truth that holds for arbitrarily large sets as well.

However, in mathematics (as opposed to real life), one does not have to take this statement on faith. If it is formulated in terms of the existence of bijective correspondences rather than in terms of the physical act of counting, it is capable of mathematical proof. We shall prove shortly that if $n \neq m$, there do not exist bijective functions mapping a given set $A$ onto both the sets $\{1, \ldots, n\}$ and $\{1, \ldots, m\}$.

There are a number of other "intuitively obvious" facts about finite sets that are capable of mathematical proof; we shall prove some of them in this section and leave the rest to the exercises. Here is an easy fact to start with:

Lemma 6.1. Let $n$ be a positive integer. Let $A$ be a set; let $a_{0}$ be an element of $A$. Then there exists a bijective correspondence $f$ of the set $A$ with the set $\{1, \ldots, n+1\}$ if and only if there exists a bijective correspondence $g$ of the set $A-\left\{a_{0}\right\}$ with the set $\{1, \ldots, n\}$.

Proof. There are two implications to be proved. Let us first assume that there is a bijective correspondence

$$
g: A-\left\{a_{0}\right\} \longrightarrow\{1, \ldots, n\} .
$$

We then define a function $f: A \longrightarrow\{1, \ldots, n+1\}$ by setting

$$
\begin{aligned}
f(x) & =g(x) \quad \text { for } x \in A-\left\{a_{0}\right\}, \\
f\left(a_{0}\right) & =n+1 .
\end{aligned}
$$

One checks at once that $f$ is bijective.

To prove the converse, assume there is a bijective correspondence

$$
f: A \longrightarrow\{1, \ldots, n+1\}
$$

If $f$ maps $a_{0}$ to the number $n+1$, things are especially easy; in that case, the restriction $f \mid A-\left\{a_{0}\right\}$ is the desired bijective correspondence of $A-\left\{a_{0}\right\}$ with $\{1, \ldots, n\}$. Otherwise, let $f\left(a_{0}\right)=m$, and let $a_{1}$ be the point of $A$ such that $f\left(a_{1}\right)=n+1$. Then $a_{1} \neq a_{0}$. Define a new function

$$
h: A \longrightarrow\{1, \ldots, n+1\}
$$

by setting

$$
\begin{aligned}
h\left(a_{0}\right) & =n+1, \\
h\left(a_{1}\right) & =m, \\
h(x) & =f(x) \quad \text { for } x \in A-\left\{a_{0}\right\}-\left\{a_{1}\right\} .
\end{aligned}
$$

See Figure 6.1. It is easy to check that $h$ is a bijection.

Now we are back in the easy case; the restriction $h \mid A-\left\{a_{0}\right\}$ is the desired bijection of $A-\left\{a_{0}\right\}$ with $\{1, \ldots, n\}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-042.jpg?height=319&width=1021&top_left_y=1267&top_left_x=511)

Figure 6.1

From this lemma a number of useful consequences follow:

Theorem 6.2. Let $A$ be a set; suppose that there exists a bijection $f: A \rightarrow\{1, \ldots, n\}$ for some $n \in \mathbb{Z}_{+}$. Let $B$ be a proper subset of $A$. Then there exists no bijection $g: B \rightarrow\{1, \ldots, n\}$; but (provided $B \neq \varnothing$ ) there does exist a bijection $h: B \rightarrow$ $\{1, \ldots, m\}$ for some $m<n$.

Proof. The case in which $B=\varnothing$ is trivial, for there cannot exist a bijection of the empty set $B$ with the nonempty set $\{1, \ldots, n\}$.

We prove the theorem "by induction." Let $C$ be the subset of $\mathbb{Z}_{+}$consisting of those integers $n$ for which the theorem holds. We shall show that $C$ is inductive. From this we conclude that $C=\mathbb{Z}_{+}$, so the theorem is true for all positive integers $n$.

First we show the theorem is true for $n=1$. In this case $A$ consists of a single element $\{a\}$, and its only proper subset $B$ is the empty set.

Now assume that the theorem is true for $n$; we prove it true for $n+1$. Suppose that $f: A \rightarrow\{1, \ldots, n+1\}$ is a bijection, and $B$ is a nonempty proper subset of $A$. Choose an element $a_{0}$ of $B$ and an element $a_{1}$ of $A-B$. We apply the preceding lemma to conclude there is a bijection

$$
g: A-\left\{a_{0}\right\} \longrightarrow\{1, \ldots, n\}
$$

Now $B-\left\{a_{0}\right\}$ is a proper subset of $A-\left\{a_{0}\right\}$, for $a_{1}$ belongs to $A-\left\{a_{0}\right\}$ and not to $B-\left\{a_{0}\right\}$. Because the theorem has been assumed to hold for the integer $n$, we conclude the following:

(1) There exists no bijection $h: B-\left\{a_{0}\right\} \rightarrow\{1, \ldots, n\}$.

(2) Either $B-\left\{a_{0}\right\}=\varnothing$, or there exists a bijection

$$
k: B-\left\{a_{0}\right\} \longrightarrow\{1, \ldots, p\} \quad \text { for some } p<n \text {. }
$$

The preceding lemma, combined with (1), implies that there is no bijection of $B$ with $\{1, \ldots, n+1\}$. This is the first half of what we wanted to proved. To prove the second half, note that if $B-\left\{a_{0}\right\}=\varnothing$, there is a bijection of $B$ with the set $\{1\}$; while if $B-\left\{a_{0}\right\} \neq \varnothing$, we can apply the preceding lemma, along with (2), to conclude that there is a bijection of $B$ with $\{1, \ldots, p+1\}$. In either case, there is a bijection of $B$ with $\{1, \ldots, m\}$ for some $m<n+1$, as desired. The induction principle now shows that the theorem is true for all $n \in \mathbb{Z}_{+}$.

Corollary 6.3. If $A$ is finite, there is no bijection of $A$ with a proper subset of itself.

Proof. Assume that $B$ is a proper subset of $A$ and that $f: A \rightarrow B$ is a bijection. By assumption, there is a bijection $g: A \rightarrow\{1, \ldots, n\}$ for some $n$. The composite $g \circ f^{-1}$ is then a bijection of $B$ with $\{1, \ldots, n\}$. This contradicts the preceding theorem.

Corollary 6.4. $\mathbb{Z}_{+}$is not finite.

Proof. The function $f: \mathbb{Z}_{+} \rightarrow \mathbb{Z}_{+}-\{1\}$ defined by $f(n)=n+1$ is a bijection of $\mathbb{Z}_{+}$with a proper subset of itself.

Corollary 6.5. The cardinality of a finite set $A$ is uniquely determined by $A$.

Proof. Let $m<n$. Suppose there are bijections

$$
\begin{aligned}
& f: A \longrightarrow\{1, \ldots, n\} \\
& g: A \longrightarrow\{1, \ldots, m\}
\end{aligned}
$$

Then the composite

$$
g \circ f^{-1}:\{1, \ldots, n\} \longrightarrow\{1, \ldots, m\}
$$

is a bijection of the finite set $\{1, \ldots, n\}$ with a proper subset of itself, contradicting the corollary just proved.

Corollary 6.6. If $B$ is a subset of the finite set $A$, then $B$ is finite. If $B$ is a proper subset of $A$, then the cardinality of $B$ is less than the cardinality of $A$.

Corollary 6.7. Let $B$ be a nonempty set. Then the following are equivalent:

(1) $B$ is finite.

(2) There is a surjective function from a section of the positive integers onto $B$.

(3) There is an injective function from $B$ into a section of the positive integers.

Proof. (1) $\Longrightarrow$ (2). Since $B$ is nonempty, there is, for some $n$, a bijective function $f:\{1, \ldots, n\} \rightarrow B$.

$(2) \Longrightarrow(3)$. If $f:\{1, \ldots, n\} \rightarrow B$ is surjective, define $g: B \rightarrow\{1, \ldots, n\}$ by the equation

$$
g(b)=\text { smallest element of } f^{-1}(\{b\})
$$

Because $f$ is surjective, the set $f^{-1}\{(b)\}$ is nonempty; then the well-ordering property of $\mathbb{Z}_{+}$tells us that $g(b)$ is uniquely defined. The map $g$ is injective, for if $b \neq b^{\prime}$, then the sets $f^{-1}(\{b\})$ and $f^{-1}\left(\left\{b^{\prime}\right\}\right)$ are disjoint, so their smallest elements must be different.

(3) $\Longrightarrow$ (1). If $g: B \rightarrow\{1, \ldots, n\}$ is injective, then changing the range of $g$ gives a bijection of $B$ with a subset of $\{1, \ldots, n\}$. It follows from the preceding corollary that $B$ is finite.

Corollary 6.8. Finite unions and finite cartesian products of finite sets are finite.

Proof. We first show that if $A$ and $B$ are finite, so is $A \cup B$. The result is trivial if $A$ or $B$ is empty. Otherwise, there are bijections $f:\{1, \ldots, m\} \rightarrow A$ and $g$ : $\{1, \ldots, n\} \rightarrow B$ for some choice of $m$ and $n$. Define a function $h:\{1, \ldots, m+$ $n\} \rightarrow A \cup B$ by setting $h(i)=f(i)$ for $i=1,2, \ldots, m$ and $h(i)=g(i-m)$ for $i=m+1, \ldots, m+n$. It is easy to check that $h$ is surjective, from which it follows that $A \cup B$ is finite.

Now we show by induction that finiteness of the sets $A_{1}, \ldots, A_{n}$ implies finiteness of their union. This result is trivial for $n=1$. Assuming it true for $n-1$, we note that $A_{1} \cup \cdots \cup A_{n}$ is the union of the two finite sets $A_{1} \cup \cdots \cup A_{n-1}$ and $A_{n}$, so the result of the preceding paragraph applies.

Now we show that the cartesian product of two finite sets $A$ and $B$ is finite. Given $a \in A$, the set $\{a\} \times B$ is finite, being in bijective correspondence with $B$. The set $A \times B$ is the union of these sets; since there are only finitely many of them, $A \times B$ is a finite union of finite sets and thus finite.

To prove that the product $A_{1} \times \cdots \times A_{n}$ is finite if each $A_{i}$ is finite, one proceeds by induction.

## Exercises

1. (a) Make a list of all the injective maps

$$
f:\{1,2,3\} \longrightarrow\{1,2,3,4\} .
$$

Show that none is bijective. (This constitutes a direct proof that a set $A$ of cardinality three does not have cardinality four.)

(b) How many injective maps

$$
f:\{1, \ldots, 8\} \longrightarrow\{1, \ldots, 10\}
$$

are there? (You can see why one would not wish to try to prove directly that there is no bijective correspondence between these sets.)

2. Show that if $B$ is not finite and $B \subset A$, then $A$ is not finite.
3. Let $X$ be the two-element set $\{0,1\}$. Find a bijective correspondence between $X^{\omega}$ and a proper subset of itself.
4. Let $A$ be a nonempty finite simply ordered set.

(a) Show that $A$ has a largest element. [Hint: Proceed by induction on the cardinality of $A$.]

(b) Show that $A$ has the order type of a section of the positive integers.

5. If $A \times B$ is finite, does it follow that $A$ and $B$ are finite?
6. (a) Let $A=\{1, \ldots, n\}$. Show there is a bijection of $\mathcal{P}(A)$ with the cartesian product $X^{n}$, where $X$ is the two-element set $X=\{0,1\}$.

(b) Show that if $A$ is finite, then $\mathcal{P}(A)$ is finite.

7. If $A$ and $B$ are finite, show that the set of all functions $f: A \rightarrow B$ is finite.

## \$7 Countable and Uncountable Sets

Just as sections of the positive integers are the prototypes for the finite sets, the set of all the positive integers is the prototype for what we call the countably infinite sets. In this section, we shall study such sets; we shall also construct some sets that are neither finite nor countably infinite. This study will lead us into a discussion of what we mean by the process of "inductive definition."

Definition. A set $A$ is said to be infinite if it is not finite. It is said to be countably infinite if there is a bijective correspondence

$$
f: A \longrightarrow \mathbb{Z}_{+} .
$$

EXAMPLE 1. The set $\mathbb{Z}$ of all integers is countably infinite. One checks easily that the function $f: \mathbb{Z} \rightarrow \mathbb{Z}_{+}$defined by

$$
f(n)= \begin{cases}2 n & \text { if } n>0 \\ -2 n+1 & \text { if } n \leq 0\end{cases}
$$

is a bijection.

EXAMPLE 2. The product $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$is countably infinite. If we represent the elements of the product $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$by the integer points in the first quadrant, then the left-hand portion of Figure 7.1 suggests how to "count" the points, that is, how to put them in bijective correspondence with the positive integers. A picture is not a proof, of course, but this picture suggests a proof. First, we define a bijection $f: \mathbb{Z}_{+} \times \mathbb{Z}_{+} \rightarrow A$, where $A$ is the subset of $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$consisting of pairs $(x, y)$ for which $y \leq x$, by the equation

$$
f(x, y)=(x+y-1, y) .
$$

Then we construct a bijection of $A$ with the positive integers, defining $g: A \rightarrow \mathbb{Z}_{+}$by the formula

$$
g(x, y)=\frac{1}{2}(x-1) x+y .
$$

We leave it to you to show that $f$ and $g$ are bijections.

Another proof that $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$is countably infinite will be given later.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-046.jpg?height=533&width=1115&top_left_y=1041&top_left_x=464)

Figure 7.1

Definition. A set is said to be countable if it is either finite or countably infinite. A set that is not countable is said to be uncountable.

There is a very useful criterion for showing that a set is countable. It is the following:

Theorem 7.1. Let $B$ be a nonempty set. Then the following are equivalent:

(1) $B$ is countable.

(2) There is a surjective function $f: \mathbb{Z}_{+} \rightarrow B$.

(3) There is an injective function $g: B \rightarrow \mathbb{Z}_{+}$.

Proof. (1) $\Longrightarrow(2)$. Suppose that $B$ is countable. If $B$ is countably infinite, there is a bijection $f: \mathbb{Z}_{+} \rightarrow B$ by definition, and we are through. If $B$ is finite, there is a
bijection $h:\{1, \ldots, n\} \rightarrow B$ for some $n \geq 1$. (Recall that $B \neq \varnothing$.) We can extend $h$ to a surjection $f: \mathbb{Z}_{+} \rightarrow B$ by defining

$$
f(i)= \begin{cases}h(i) & \text { for } 1 \leq i \leq n \\ h(1) & \text { for } i>n\end{cases}
$$

$(2) \Longrightarrow(3)$. Let $f: \mathbb{Z}_{+} \rightarrow B$ be a surjection. Define $g: B \rightarrow \mathbb{Z}_{+}$by the equation

$$
g(b)=\text { smallest element of } f^{-1}(\{b\})
$$

Because $f$ is surjective, $f^{-1}(\{b\})$ is nonempty; thus $g$ is well defined. The map $g$ is injective, for if $b \neq b^{\prime}$, the sets $f^{-1}(\{b\})$ and $f^{-1}\left(\left\{b^{\prime}\right\}\right)$ are disjoint, so their smallest elements are different.

(3) $\Longrightarrow$ (1). Let $g: B \rightarrow \mathbb{Z}_{+}$be an injection; we wish to prove $B$ is countable. By changing the range of $g$, we can obtain a bijection of $B$ with a subset of $\mathbb{Z}_{+}$. Thus to prove our result, it suffices to show that every subset of $\mathbb{Z}_{+}$is countable. So let $C$ be a subset of $\mathbb{Z}_{+}$.

If $C$ is finite, it is countable by definition. So what we need to prove is that every infinite subset $C$ of $\mathbb{Z}_{+}$is countably infinite. This statement is certainly plausible. For the elements of $C$ can easily be arranged in an infinite sequence; one simply takes the set $\mathbb{Z}_{+}$in its usual order and "erases" all the elements of $\mathbb{Z}_{+}$that are not in $C$ !

The plausibility of this argument may make one overlook its informality. Providing a formal proof requires a certain amount of care. We state this result as a separate lemma, which follows.

Lemma 7.2. If $C$ is an infinite subset of $\mathbb{Z}_{+}$, then $C$ is countably infinite.

Proof. We define a bijection $h: \mathbb{Z}_{+} \rightarrow C$. We proceed by induction. Define $h(1)$ to be the smallest element of $C$; it exists because every nonempty subset $C$ of $\mathbb{Z}_{+}$has a smallest element. Then assuming that $h(1), \ldots, h(n-1)$ are defined, define

$$
h(n)=\text { smallest element of }[C-h(\{1, \ldots, n-1\})] .
$$

The set $C-h(\{1, \ldots, n-1\})$ is not empty; for if it were empty, then $h:\{1, \ldots, n-$ $1\} \rightarrow C$ would be surjective, so that $C$ would be finite (by Corollary 6.7). Thus $h(n)$ is well defined. By induction, we have defined $h(n)$ for all $n \in \mathbb{Z}_{+}$.

To show that $h$ is injective is easy. Given $m<n$, note that $h(m)$ belongs to the set $h(\{1, \ldots, n-1\})$, whereas $h(n)$, by definition, does not. Hence $h(n) \neq h(m)$.

To show that $h$ is surjective, let $c$ be any element of $C$; we show that $c$ lies in the image set of $h$. First note that $h\left(\mathbb{Z}_{+}\right)$cannot be contained in the finite set $\{1, \ldots, c\}$, because $h\left(\mathbb{Z}_{+}\right)$is infinite (since $h$ is injective). Therefore, there is an $n$ in $\mathbb{Z}_{+}$, such that $h(n)>c$. Let $m$ be the smallest element of $\mathbb{Z}_{+}$, such that $h(m) \geq c$. Then for all $i<m$, we must have $h(i)<c$. Thus, $c$ does not belong to the set $h(\{1, \ldots, m-1\})$. Since $h(m)$ is defined as the smallest element of the set $C-h(\{1, \ldots, m-1\})$, we must have $h(m) \leq c$. Putting the two inequalities together, we have $h(m)=c$, as desired.

There is a point in the preceding proof where we stretched the principles of logic a bit. It occurred at the point where we said that "using the induction principle" we had defined the function $h$ for all positive integers $n$. You may have seen arguments like this used before, with no questions raised concerning their legitimacy. We have already used such an argument ourselves, in the exercises of $\S 4$, when we defined $a^{n}$.

But there is a problem here. After all, the induction principle states only that if $A$ is an inductive set of positive integers, then $A=\mathbb{Z}_{+}$. To use the principle to prove a theorem "by induction," one begins the proof with the statement "Let $A$ be the set of all positive integers $n$ for which the theorem is true," and then one goes ahead to prove that $A$ is inductive, so that $A$ must be all of $\mathbb{Z}_{+}$.

In the preceding theorem, however, we were not really proving a theorem by induction, but defining something by induction. How then should we start the proof? Can we start by saying, "Let $A$ be the set of all integers $n$ for which the function $h$ is defined"? But that's silly; the symbol $h$ has no meaning at the outset of the proof. It only takes on meaning in the course of the proof. So something more is needed.

What is needed is another principle, which we call the principle of recursive definition. In the proof of the preceding theorem, we wished to assert the following:

Given the infinite subset $C$ of $\mathbb{Z}_{+}$, there is a unique function $h: \mathbb{Z}_{+} \rightarrow C$ satisfying the formula:

$$
\begin{align*}
h(1) & =\text { smallest element of } C  \tag{*}\\
h(i) & =\text { smallest element of }[C-h(\{1, \ldots, i-1\})] \quad \text { for all } i>1 .
\end{align*}
$$

The formula $(*)$ is called a recursion formula for $h$; it defines the function $h$ in terms of itself. A definition given by such a formula is called a recursive definition.

Now one can get into logical difficulties when one tries to define something recursively. Not all recursive formulas make sense. The recursive formula

$$
h(i)=\text { smallest element of }[C-h(\{1, \ldots, i+1\})] \text {, }
$$

for example, is self-contradictory; although $h(i)$ necessarily is an element of the set $h(\{1, \ldots, i+1\})$, this formula says that it does not belong to the set. Another example is the classic paradox:

Let the barber of Seville shave every man of Seville who does not shave himself.

Who shall shave the barber?

In this statement, the barber appears twice, once in the phrase "the barber of Seville" and once as an element of the set "men of Seville"; this definition of whom the barber shall shave is a recursive one. It also happens to be self-contradictory.

Some recursive formulas do make sense, however. Specifically, one has the following principle:

Principle of recursive definition. Let $A$ be a set. Given a formula that defines $h(1)$ as a unique element of $A$, and for $i>1$ defines $h(i)$ uniquely as an element of $A$ in terms of the values of $h$ for positive integers less than $i$, this formula determines a unique function $h: \mathbb{Z}_{+} \rightarrow A$.

This principle is the one we actually used in the proof of Lemma 7.2. You can simply accept it on faith if you like. It may however be proved rigorously, using the principle of induction. We shall formulate it more precisely in the next section and indicate how it is proved. Mathematicians seldom refer to this principle specifically. They are much more likely to write a proof like our proof of Lemma 7.2 above, a proof in which they invoke the "induction principle" to define a function when what they are really using is the principle of recursive definition. We shall avoid undue pedantry in this book by following their example.

Corollary 7.3. A subset of a countable set is countable.

Proof. Suppose $A \subset B$, where $B$ is countable. There is an injection $f$ of $B$ into $\mathbb{Z}_{+}$; the restriction of $f$ to $A$ is an injection of $A$ into $\mathbb{Z}_{+}$.

Corollary 7.4. The set $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$is countably infinite.

Proof. In view of Theorem 7.1, it suffices to construct an injective map $f: \mathbb{Z}_{+} \times$ $\mathbb{Z}_{+} \rightarrow \mathbb{Z}_{+}$. We define $f$ by the equation

$$
f(n, m)=2^{n} 3^{m} .
$$

It is easy to check that $f$ is injective. For suppose that $2^{n} 3^{m}=2^{p} 3^{q}$. If $n<p$, then $3^{m}=2^{p-n} 3^{q}$, contradicting the fact that $3^{m}$ is odd for all $m$. Therefore, $n=p$. As a result, $3^{m}=3^{q}$, Then if $m<q$, it follows that $1=3^{q-m}$, another contradiction. Hence $m=q$.

EXAMPLE 3. The set $\mathbb{Q}_{+}$of positive rational numbers is countably infinite. For we can define a surjection $g: \mathbb{Z}_{+} \times \mathbb{Z}_{+} \rightarrow \mathbb{Q}_{+}$by the equation

$$
g(n, m)=m / n \text {. }
$$

Because $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$is countable, there is a surjection $f: \mathbb{Z}_{+} \rightarrow \mathbb{Z}_{+} \times \mathbb{Z}_{+}$. Then the composite $g \circ f: \mathbb{Z}_{+} \rightarrow \mathbb{Q}_{+}$is a surjection, so that $\mathbb{Q}_{+}$is countable. And, of course, $\mathbb{Q}_{+}$ is infinite because it contains $\mathbb{Z}_{+}$.

We leave it as an exercise to show the set $\mathbb{Q}$ of all rational numbers is countably infinite.

Theorem 7.5. A countable union of countable sets is countable.

Proof. Let $\left\{A_{n}\right\}_{n \in J}$ be an indexed family of countable sets, where the index set $J$ is either $\{1, \ldots, N\}$ or $\mathbb{Z}_{+}$. Assume that each set $A_{n}$ is nonempty, for convenience; this assumption does not change anything.

Because each $A_{n}$ is countable, we can choose, for each $n$, a surjective function $f_{n}: \mathbb{Z}_{+} \rightarrow A_{n}$. Similarly, we can choose a surjective function $g: \mathbb{Z}_{+} \rightarrow J$. Now define

$$
h: \mathbb{Z}_{+} \times \mathbb{Z}_{+} \rightarrow \bigcup_{n \in J} A_{n}
$$

by the equation

$$
h(k, m)=f_{g(k)}(m) .
$$

It is easy to check that $h$ is surjective. Since $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$is in bijective correspondence with $\mathbb{Z}_{+}$, the countability of the union follows from Theorem 7.1.

Theorem 7.6. A finite product of countable sets is countable.

Proof. First let us show that the product of two countable sets $A$ and $B$ is countable. The result is trivial if $A$ or $B$ is empty. Otherwise, choose surjective functions $f$ : $\mathbb{Z}_{+} \rightarrow A$ and $g: \mathbb{Z}_{+} \rightarrow B$. Then the function $h: \mathbb{Z}_{+} \times \mathbb{Z}_{+} \rightarrow A \times B$ defined by the equation $h(n, m)=(f(n), g(m))$ is surjective, so that $A \times B$ is countable.

In general, we proceed by induction. Assuming that $A_{1} \times \cdots \times A_{n-1}$ is countable if each $A_{i}$ is countable, we prove the same thing for the product $A_{1} \times \cdots \times A_{n}$. First, note that there is a bijective correspondence

$$
g: A_{1} \times \cdots \times A_{n} \longrightarrow\left(A_{1} \times \cdots \times A_{n-1}\right) \times A_{n}
$$

defined by the equation

$$
g\left(x_{1}, \ldots, x_{n}\right)=\left(\left(x_{1}, \ldots, x_{n-1}\right), x_{n}\right) .
$$

Because the set $A_{1} \times \cdots \times A_{n-1}$ is countable by the induction assumption and $A_{n}$ is countable by hypothesis, the product of these two sets is countable, as proved in the preceding paragraph. We conclude that $A_{1} \times \cdots \times A_{n}$ is countable as well.

It is very tempting to assert that countable products of countable sets should be countable; but this assertion is in fact not true:

Theorem 7.7. Let $X$ denote the two element set $\{0,1\}$. Then the set $X^{\omega}$ is uncountable.

Proof. We show that, given any function

$$
g: \mathbb{Z}_{+} \longrightarrow X^{\omega}
$$

$g$ is not surjective. For this purpose, let us denote $g(n)$ as follows :

$$
g(n)=\left(x_{n 1}, x_{n 2}, x_{n 3}, \ldots x_{n m}, \ldots\right),
$$

where each $x_{i j}$ is either 0 or 1 . Then we define an element $\mathbf{y}=\left(y_{1}, y_{2}, \ldots, y_{n}, \ldots\right)$ of $X^{\omega}$ by letting

$$
y_{n}= \begin{cases}0 & \text { if } x_{n n}=1 \\ 1 & \text { if } x_{n n}=0\end{cases}
$$

(If we write the numbers $x_{n i}$ in a rectangular array, the particular elements $x_{n n}$ appear as the diagonal entries in this array; we choose $\mathbf{y}$ so that its $n$th coordinate differs from the diagonal entry $x_{n n}$.)

Now $\mathbf{y}$ is an element of $X^{\omega}$, and $\mathbf{y}$ does not lie in the image of $g$; given $n$, the point $g(n)$ and the point $\mathbf{y}$ differ in at least one coordinate, namely, the $n$ th. Thus, $g$ is not surjective.

The cartesian product $\{0,1\}^{\omega}$ is one example of an uncountable set. Another is the set $\mathcal{P}\left(\mathbb{Z}_{+}\right)$, as the following theorem implies:

Theorem 7.8. Let $A$ be a set. There is no injective map $f: \mathcal{P}(A) \rightarrow A$, and there is no surjective map $g: A \rightarrow \mathcal{P}(A)$.

Proof. In general, if $B$ is a nonempty set, the existence of an injective map $f: B \rightarrow$ $C$ implies the existence of a surjective map $g: C \rightarrow B$; one defines $g(c)=f^{-1}(c)$ for each $c$ in the image set of $f$, and defines $g$ arbitrarily on the rest of $C$.

Therefore, it suffices to prove that given a map $g: A \rightarrow \mathcal{P}(A)$, the map $g$ is not surjective. For each $a \in A$, the image $g(a)$ of $a$ is a subset of $A$, which may or may not contain the point $a$ itself. Let $B$ be the subset of $A$ consisting of all those points $a$ such that $g(a)$ does not contain $a$;

$$
B=\{a \mid a \in A-g(a)\} .
$$

Now, $B$ may be empty, or it may be all of $A$, but that does not matter. We assert that $B$ is a subset of $A$ that does not lie in the image of $g$. For suppose that $B=g\left(a_{0}\right)$ for some $a_{0} \in A$. We ask the question: Does $a_{0}$ belong to $B$ or not? By definition of $B$,

$$
a_{0} \in B \Longleftrightarrow a_{0} \in A-g\left(a_{0}\right) \Longleftrightarrow a_{0} \in A-B .
$$

In either case, we have a contradiction.

Now we have proved the existence of uncountable sets. But we have not yet mentioned the most familiar uncountable set of all-the set of real numbers. You have probably seen the uncountability of $\mathbb{R}$ demonstrated already. If one assumes that every real number can be represented uniquely by an infinite decimal (with the proviso that a representation ending in an infinite string of 9's is forbidden), then the uncountability of the reals can be proved by a variant of the diagonal procedure used in the proof of Theorem 7.7. But this proof is in some ways not very satisfying. One reason is that the infinite decimal representation of a real number is not at all an elementary consequence of the axioms but requires a good deal of labor to prove. Another reason is that the uncountability of $\mathbb{R}$ does not, in fact, depend on the infinite decimal expansion of $\mathbb{R}$ or indeed on any of the algebraic properties of $\mathbb{R}$; it depends on only the order properties of $\mathbb{R}$. We shall demonstrate the uncountability of $\mathbb{R}$, using only its order properties, in a later chapter.

## Exercises

1. Show that $\mathbb{Q}$ is countably infinite.
2. Show that the maps $f$ and $g$ of Examples 1 and 2 are bijections.
3. Let $X$ be the two-element set $\{0,1\}$. Show there is a bijective correspondence between the set $\mathcal{P}\left(\mathbb{Z}_{+}\right)$and the cartesian product $X^{\omega}$.
4. (a) A real number $x$ is said to be algebraic (over the rationals) if it satisfies some polynomial equation of positive degree

$$
x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}=0
$$

with rational coefficients $a_{i}$. Assuming that each polynomial equation has only finitely many roots, show that the set of algebraic numbers is countable.

(b) A real number is said to be transcendental if it is not algebraic. Assuming the reals are uncountable, show that the transcendental numbers are uncountable. (It is a somewhat surprising fact that only two transcendental numbers are familiar to us: $e$ and $\pi$. Even proving these two numbers transcendental is highly nontrivial.)

5. Determine, for each of the following sets, whether or not it is countable. Justify your answers.

(a) The set $A$ of all functions $f:\{0,1\} \rightarrow \mathbb{Z}_{+}$.

(b) The set $B_{n}$ of all functions $f:\{1, \ldots, n\} \rightarrow \mathbb{Z}_{+}$.

(c) The set $C=\bigcup_{n \in \mathbb{Z}_{+}} B_{n}$.

(d) The set $D$ of all functions $f: \mathbb{Z}_{+} \rightarrow \mathbb{Z}_{+}$.

(e) The set $E$ of all functions $f: \mathbb{Z}_{+} \rightarrow\{0,1\}$.

(f) The set $F$ of all functions $f: \mathbb{Z}_{+} \rightarrow\{0,1\}$ that are "eventually zero." [We say that $f$ is eventually zero if there is a positive integer $N$ such that $f(n)=0$ for all $n \geq N$.]

(g) The set $G$ of all functions $f: \mathbb{Z}_{+} \rightarrow \mathbb{Z}_{+}$that are eventually 1 .

(h) The set $H$ of all functions $f: \mathbb{Z}_{+} \rightarrow \mathbb{Z}_{+}$that are eventually constant.

(i) The set $I$ of all two-element subsets of $\mathbb{Z}_{+}$.

(j) The set $J$ of all finite subsets of $\mathbb{Z}_{+}$.

6. We say that two sets $A$ and $B$ have the same cardinality if there is a bijection of $A$ with $B$.

(a) Show that if $B \subset A$ and if there is an injection

$$
f: A \longrightarrow B
$$

then $A$ and $B$ have the same cardinality. [Hint: Define $A_{1}=A, B_{1}=B$, and for $n>1, A_{n}=f\left(A_{n-1}\right)$ and $B_{n}=f\left(B_{n-1}\right)$. (Recursive definition again!) Note that $A_{1} \supset B_{1} \supset A_{2} \supset B_{2} \supset A_{3} \supset \cdots$. Define a bijection $h: A \rightarrow B$ by the rule

$$
h(x)= \begin{cases}f(x) & \text { if } x \in A_{n}-B_{n} \text { for some } n \\ x & \text { otherwise. }]\end{cases}
$$

(b) Theorem (Schroeder-Bernstein theorem). If there are injections $f: A \rightarrow$ $C$ and $g: C \rightarrow A$, then $A$ and $C$ have the same cardinality.

7. Show that the sets $D$ and $E$ of Exercise 5 have the same cardinality.
8. Let $X$ denote the two-element set $\{0,1\}$; let $\mathscr{B}$ be the set of countable subsets of $X^{\omega}$. Show that $X^{\omega}$ and $\mathscr{B}$ have the same cardinality.
9. (a) The formula

$(*)$

$$
\begin{aligned}
& h(1)=1 \\
& h(2)=2 \\
& h(n)=[h(n+1)]^{2}-[h(n-1)]^{2} \quad \text { for } n \geq 2
\end{aligned}
$$

is not one to which the principle of recursive definition applies. Show that nevertheless there does exist a function $h: \mathbb{Z}_{+} \rightarrow \mathbb{R}$ satisfying this formula. [Hint: Reformulate $(*)$ so that the principle will apply and require $h$ to be positive.]

(b) Show that the formula (*) of part (a) does not determine $h$ uniquely. [Hint: If $h$ is a positive function satisfying $(*)$, let $f(i)=h(i)$ for $i \neq 3$, and let $f(3)=-h(3)$.]

(c) Show that there is no function $h: \mathbb{Z}_{+} \rightarrow \mathbb{R}$ satisfying the formula

$$
\begin{aligned}
& h(1)=1 \\
& h(2)=2 \\
& h(n)=[h(n+1)]^{2}+[h(n-1)]^{2} \quad \text { for } n \geq 2
\end{aligned}
$$

## *\$8 The Principle of Recursive Definition

Before considering the general form of the principle of recursive definition, let us first prove it in a specific case, that of Lemma 7.2. That should make the underlying idea of the proof much clearer when we consider the general case.

So, given the infinite subset $C$ of $\mathbb{Z}_{+}$, let us consider the following recursion formula for a function $h: \mathbb{Z}_{+} \rightarrow C$ :

$$
\begin{align*}
h(1) & =\text { smallest element of } C \\
h(i) & =\text { smallest element of }[C-h(\{1, \ldots, i-1\})] \quad \text { for } i>1 \tag{*}
\end{align*}
$$

We shall prove that there exists a unique function $h: \mathbb{Z}_{+} \rightarrow C$ satisfying this recursion formula.

The first step is to prove that there exist functions defined on sections $\{1, \ldots, n\}$ of $\mathbb{Z}_{+}$that satisfy $(*)$ :

Lemma 8.1. Given $n \in \mathbb{Z}_{+}$, there exists a function

$$
f:\{1, \ldots, n\} \rightarrow C
$$

that satisfies (*) for all $i$ in its domain.

Proof. The point of this lemma is that it is a statement that depends on $n$; therefore, it is capable of being proved by induction. Let $A$ be the set of all $n$ for which the lemma holds. We show that $A$ is inductive. It then follows that $A=\mathbb{Z}_{+}$.

The lemma is true for $n=1$, since the function $f:\{1\} \rightarrow C$ defined by the equation

$$
f(1)=\text { smallest element of } C
$$

satisfies $(*)$.

Supposing the lemma to be true for $n-1$, we prove it true for $n$. By hypothesis, there is a function $f^{\prime}:\{1, \ldots, n-1\} \rightarrow C$ satisfying (*) for all $i$ in its domain. Define $f:\{1, \ldots, n\} \rightarrow C$ by the equations

$$
\begin{aligned}
& f(i)=f^{\prime}(i) \quad \text { for } i \in\{1, \ldots, n-1\}, \\
& f(n)=\text { smallest element of }\left[C-f^{\prime}(\{1, \ldots, n-1\})\right] .
\end{aligned}
$$

Since $C$ is infinite, $f^{\prime}$ is not surjective; hence the set $C-f^{\prime}(\{1, \ldots, n-1\})$ is not empty, and $f(n)$ is well defined. Note that this definition is an acceptable one; it does not define $f$ in terms of itself but in terms of the given function $f^{\prime}$.

It is easy to check that $f$ satisfies $(*)$ for all $i$ in its domain. The function $f$ satisfies (*) for $i \leq n-1$ because it equals $f^{\prime}$ there. And $f$ satisfies (*) for $i=n$ because, by definition,

$$
f(n)=\text { smallest element of }\left[C-f^{\prime}(\{1, \ldots, n-1\})\right]
$$

and $f^{\prime}(\{1, \ldots, n-1\})=f(\{1, \ldots, n-1\})$.

Lemma 8.2. Suppose that $f:\{1, \ldots, n\} \rightarrow C$ and $g:\{1, \ldots, m\} \rightarrow C$ both satisfy $(*)$ for all $i$ in their respective domains. Then $f(i)=g(i)$ for all $i$ in both domains.

Proof. Suppose not. Let $i$ be the smallest integer for which $f(i) \neq g(i)$. The integer $i$ is not 1 , because

$$
f(1)=\text { smallest element of } C=g(1),
$$

by (*). Now for all $j<i$, we have $f(j)=g(j)$. Because $f$ and $g$ satisfy $(*)$,

$$
\begin{aligned}
& f(i)=\text { smallest element of }[C-f(\{1, \ldots, i-1\})], \\
& g(i)=\text { smallest element of }[C-g(\{1, \ldots, i-1\})] .
\end{aligned}
$$

Since $f(\{1, \ldots, i-1\})=g(\{1, \ldots, i-1\})$, we have $f(i)=g(i)$, contrary to the choice of $i$.

Theorem 8.3. There exists a unique function $h: \mathbb{Z}_{+} \rightarrow C$ satisfying (*) for all $i \in \mathbb{Z}_{+}$.

Proof. By Lemma 8.1, there exists for each $n$ a function that maps $\{1, \ldots, n\}$ into $C$ and satisfies (*) for all $i$ in its domain. Given $n$, Lemma 8.2 shows that this function is unique; two such functions having the same domain must be equal. Let $f_{n}$ : $\{1, \ldots, n\} \rightarrow C$ denote this unique function.

Now comes the crucial step. We define a function $h: \mathbb{Z}_{+} \rightarrow C$ by defining its rule to be the union $U$ of the rules of the functions $f_{n}$. The rule for $f_{n}$ is a subset of $\{1, \ldots, n\} \times C$; therefore, $U$ is a subset of $\mathbb{Z}_{+} \times C$. We must show that $U$ is the rule for a function $h: \mathbb{Z}_{+} \rightarrow C$.

That is, we must show that each element $i$ of $\mathbb{Z}_{+}$appears as the first coordinate of exactly one element of $U$. This is easy. The integer $i$ lies in the domain of $f_{n}$ if and only if $n>i$. Therefore, the set of elements of $U$ of which $i$ is the first coordinate is precisely the set of all pairs of the form $\left(i, f_{n}(i)\right)$, for $n \geq i$. Now Lemma 8.2 tells us that $f_{n}(i)=f_{m}(i)$ if $n, m \geq i$. Therefore, all these elements of $U$ are equal; that is, there is only one element of $U$ that has $i$ as its first coordinate.

To show that $h$ satisfies $(*)$ is also easy; it is a consequence of the following facts:

$$
\begin{aligned}
& h(i)=f_{n}(i) \quad \text { for } i \leq n, \\
& f_{n} \text { satisfies }(*) \text { for all } i \text { in its domain. }
\end{aligned}
$$

The proof of uniqueness is a copy of the proof of Lemma 8.2.

Now we formulate the general principle of recursive definition. There are no new ideas involved in its proof, so we leave it as an exercise.

Theorem 8.4 (Principle of recursive definition). Let $A$ be a set; let $a_{0}$ be an element of $A$. Suppose $\rho$ is a function that assigns, to each function $f$ mapping a nonempty section of the positive integers into $A$, an element of $A$. Then there exists a unique function

$$
h: \mathbb{Z}_{+} \rightarrow A
$$

such that

$$
\begin{align*}
h(1) & =a_{0} \\
h(i) & =\rho(h \mid\{1, \ldots, i-1\}) \quad \text { for } i>1 \tag{*}
\end{align*}
$$

The formula $(*)$ is called a recursion formula for $h$. It specifies $h(1)$, and it expresses the value of $h$ at $i>1$ in terms of the values of $h$ for positive integers less than $i$.

EXAMPLE 1. Let us show that Theorem 8.3 is a special case of this theorem. Given the infinite subset $C$ of $\mathbb{Z}_{+}$, let $a_{0}$ be the smallest element of $C$, and define $\rho$ by the equation

$$
\rho(f)=\text { smallest element of }[C-\text { (image set of } f \text { ) }] \text {. }
$$

Because $C$ is infinite and $f$ is a function mapping a finite set into $C$, the image set of $f$ is not all of $C$; therefore, $\rho$ is well defined. By Theorem 8.4 there exists a function $h: \mathbb{Z}_{+} \rightarrow$ $C$ such that $h(1)=a_{0}$, and for $i>1$,

$$
\begin{aligned}
h(i) & =\rho(h \mid\{1, \ldots, i-1\}) \\
& =\text { smallest element of }[C-(\text { image set of } h \mid\{1, \ldots, i-1\})] \\
& =\text { smallest element of }[C-h(\{1 \ldots, i-1\})]
\end{aligned}
$$

as desired.

EXAMPLE 2. Given $a \in \mathbb{R}$, we "defined" $a^{n}$, in the exercises of $\S 4$, by the recursion formula

$$
\begin{aligned}
& a^{1}=a, \\
& a^{n}=a^{n-1} \cdot a .
\end{aligned}
$$

We wish to apply Theorem 8.4 to define a function $h: \mathbb{Z}_{+} \rightarrow \mathbb{R}$ rigorously such that $h(n)=a^{n}$. To apply this theorem, let $a_{0}$ denote the element $a$ of $\mathbb{R}$, and define $\rho$ by the equation $\rho(f)=f(m) \cdot a$, where $f:\{1, \ldots, m\} \rightarrow \mathbb{R}$. Then there exists a unique function $h: \mathbb{Z}_{+} \rightarrow \mathbb{R}$ such that

$$
\begin{aligned}
h(1) & =a_{0} \\
h(i) & =\rho(h \mid\{1, \ldots, i-1\}) \quad \text { for } i>1 .
\end{aligned}
$$

This means that $h(1)=a$, and $h(i)=h(i-1) \cdot a$ for $i>1$. If we denote $h(i)$ by $a^{i}$, we have

$$
\begin{aligned}
& a^{1}=a, \\
& a^{i}=a^{i-1} \cdot a,
\end{aligned}
$$

as desired.

## Exercises

1. Let $\left(b_{1}, b_{2}, \ldots\right)$ be an infinite sequence of real numbers. The sum $\sum_{k=1}^{n} b_{k}$ is defined by induction as follows :

$$
\begin{array}{ll}
\sum_{k=1}^{n} b_{k}=b_{1} & \text { for } n=1 \\
\sum_{k=1}^{n} b_{k}=\left(\sum_{k=1}^{n-1} b_{k}\right)+b_{n} & \text { for } n>1
\end{array}
$$

Let $A$ be the set of real numbers; choose $\rho$ so that Theorem 8.4 applies to define this sum rigorously. We sometimes denote the sum $\sum_{k=1}^{n} b_{k}$ by the symbol $b_{1}+b_{2}+\cdots+b_{n}$.

2. Let $\left(b_{1}, b_{2}, \ldots\right)$ be an infinite sequence of real numbers. We define the product $\prod_{k=1}^{n} b_{k}$ by the equations

$$
\begin{aligned}
& \prod_{k=1}^{1} b_{k}=b_{1} \\
& \prod_{k=1}^{n} b_{k}=\left(\prod_{k=1}^{n-1} b_{k}\right) \cdot b_{n} \quad \text { for } n>1 .
\end{aligned}
$$

Use Theorem 8.4 to define this product rigorously. We sometimes denote the product $\prod_{k=1}^{n} b_{k}$ by the symbol $b_{1} b_{2} \cdots b_{n}$.

3. Obtain the definitions of $a^{n}$ and $n$ ! for $n \in \mathbb{Z}_{+}$as special cases of Exercise 2 .
4. The Fibonacci numbers of number theory are defined recursively by the formula

$$
\begin{aligned}
& \lambda_{1}=\lambda_{2}=1, \\
& \lambda_{n}=\lambda_{n-1}+\lambda_{n-2} \quad \text { for } n>2
\end{aligned}
$$

Define them rigorously by use of Theorem 8.4.

5. Show that there is a unique function $h: \mathbb{Z}_{+} \rightarrow \mathbb{R}_{+}$satisfying the formula

$$
\begin{aligned}
& h(1)=3 \\
& h(i)=[h(i-1)+1]^{1 / 2} \quad \text { for } i>1
\end{aligned}
$$

6. (a) Show that there is no function $h: \mathbb{Z}_{+} \rightarrow \mathbb{R}_{+}$satisfying the formula

$$
\begin{aligned}
& h(1)=3 \\
& h(i)=[h(i-1)-1]^{1 / 2} \quad \text { for } i>1
\end{aligned}
$$

Explain why this example does not violate the principle of recursive definition.

(b) Consider the recursion formula

$$
\begin{aligned}
& h(1)=3 \\
& h(i)=\left\{\begin{array}{ll}
{[h(i-1)-1]^{1 / 2}} & \text { if } h(i-1)>1 \\
5 & \text { if } h(i-1) \leq 1
\end{array}\right\} \quad \text { for } i>1
\end{aligned}
$$

Show that there exists a unique function $h: \mathbb{Z}_{+} \rightarrow \mathbb{R}_{+}$satisfying this formula.

## 7. Prove Theorem 8.4.

8. Verify the following version of the principle of recursive definition: Let $A$ be a set. Let $\rho$ be a function assigning, to every function $f$ mapping a section $S_{n}$ of $\mathbb{Z}_{+}$into $A$, an element $\rho(f)$ of $A$. Then there is a unique function $h: \mathbb{Z}_{+} \rightarrow A$ such that $h(n)=\rho\left(h \mid S_{n}\right)$ for each $n \in \mathbb{Z}_{+}$.

## §9 Infinite Sets and the Axiom of Choice

We have already obtained several criteria for a set to be infinite. We know, for instance, that a set $A$ is infinite if it has a countably infinite subset, or if there is a bijection of $A$ with a proper subset of itself. It turns out that either of these properties is sufficient to characterize infinite sets. This we shall now prove. The proof will lead us into a discussion of a point of logic we have not yet mentioned - the axiom of choice.

Theorem 9.1. Let $A$ be a set. The following statements about $A$ are equivalent:

(1) There exists an injective function $f: \mathbb{Z}_{+} \rightarrow A$.

(2) There exists a bijection of $A$ with a proper subset of itself.

(3) $A$ is infinite.

Proof. We prove the implications $(1) \Rightarrow(2) \Rightarrow(3) \Rightarrow(1)$. To prove that (1) $\Rightarrow$ (2), we assume there is an injective function $f: \mathbb{Z}_{+} \rightarrow A$. Let the image set $f\left(\mathbb{Z}_{+}\right)$be denoted by $B$; and let $f(n)$ be denoted by $a_{n}$. Because $f$ is injective, $a_{n} \neq a_{m}$ if $n \neq m$. Define

$$
g: A \longrightarrow A-\left\{a_{1}\right\}
$$

by the equations

$$
\begin{aligned}
g\left(a_{n}\right) & =a_{n+1} & & \text { for } a_{n} \in B, \\
g(x) & =x & & \text { for } x \in A-B .
\end{aligned}
$$

The map $g$ is indicated schematically in Figure 9.1; one checks easily that it is a bijection.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-058.jpg?height=250&width=991&top_left_y=1571&top_left_x=526)

Figure 9.1

The implication $(2) \Rightarrow(3)$ is just the contrapositive of Corollary 6.3 , so it has already been proved. To prove that $(3) \Rightarrow(1)$, we assume that $A$ is infinite and construct "by induction" an injective function $f: \mathbb{Z}_{+} \rightarrow A$.

First, since the set $A$ is not empty, we can choose a point $a_{1}$ of $A$; define $f(1)$ to be the point so chosen.

Then, assuming that we have defined $f(1), \ldots, f(n-1)$, we wish to define $f(n)$. The set $A-f(\{1, \ldots, n-1\})$ is not empty; for if it were empty, the map $f:\{1, \ldots, n-$ $1\} \rightarrow A$ would be a surjection and $A$ would be finite. Hence, we can choose an
element of the set $A-f(\{1, \ldots, n-1\})$ and define $f(n)$ to be this element. "Using the induction principle", we have defined $f$ for all $n \in \mathbb{Z}_{+}$.

It is easy to see that $f$ is injective. For suppose that $m<n$. Then $f(m)$ belongs to the set $f(\{1, \ldots, n-1\})$, whereas $f(n)$, by definition, does not. Therefore, $f(n) \neq$ $f(m)$.

Let us try to reformulate this "induction" proof more carefully, so as to make explicit our use of the principle of recursive definition.

Given the infinite set $A$, we attempt to define $f: \mathbb{Z}_{+} \rightarrow A$ recursively by the formula

$$
\begin{align*}
& f(1)=a_{1}, \\
& f(i)=\text { an arbitrary element of }[A-f(\{1, \ldots, i-1\})] \quad \text { for } i>1 . \tag{*}
\end{align*}
$$

But this is not an acceptable recursion formula at all! For it does not define $f(i)$ uniquely in terms of $f \mid\{1, \ldots, i-1\}$.

In this respect this formula differs notably from the recursion formula we considered in proving Lemma 7.2. There we had an infinite subset $C$ of $\mathbb{Z}_{+}$, and we defined $h$ by the formula

$$
\begin{aligned}
h(1) & =\text { smallest element of } C \\
h(i) & =\text { smallest element of }[C-h(\{1, \ldots, i-1\})] \quad \text { for } i>1
\end{aligned}
$$

This formula does define $h(i)$ uniquely in terms of $h \mid\{1, \ldots, i-1\}$.

Another way of seeing that $(*)$ is not an acceptable recursion formula is to note that if it were, the principle of recursive definition would imply that there is a unique function $f: \mathbb{Z}_{+} \rightarrow A$ satisfying (*). But by no stretch of the imagination does (*) specify $f$ uniquely. In fact, this "definition" of $f$ involves infinitely many arbitrary choices.

What we are saying is that the proof we have given for Theorem 9.1 is not actually a proof. Indeed, on the basis of the properties of set theory we have discussed up to now, it is not possible to prove this theorem. Something more is needed.

Previously, we described certain definite allowable methods for specifying sets:

(1) Defining a set by listing its elements, or by taking a given set $A$ and specifying a subset $B$ of it by giving a property that the elements of $B$ are to satisfy.

(2) Taking unions or intersections of the elements of a given collection of sets, or taking the difference of two sets.

(3) Taking the set of all subsets of a given set.

(4) Taking cartesian products of sets.

Now the rule for the function $f$ is really a set: a subset of $\mathbb{Z}_{+} \times A$. Therefore, to prove the existence of the function $f$, we must construct the appropriate subset of $\mathbb{Z}_{+} \times A$, using the allowed methods for forming sets. The methods already given simply are not adequate for this purpose. We need a new way of asserting the existence of a set. So, we add to the list of allowed methods of forming sets the following:

Axiom of choice. Given a collection $\mathcal{A}$ of disjoint nonempty sets, there exists a set $C$ consisting of exactly one element from each element of $\mathcal{A}$; that is, a set $C$ such that $C$ is contained in the union of the elements of $\mathcal{A}$, and for each $A \in \mathcal{A}$, the set $C \cap A$ contains a single element.

The set $C$ can be thought of as having been obtained by choosing one element from each of the sets in $\mathcal{A}$.

The axiom of choice certainly seems an innocent-enough assertion. And, in fact, most mathematicians today accept it as part of the set theory on which they base their mathematics. But in years past a good deal of controversy raged around this particular assertion concerning set theory, for there are theorems one can prove with its aid that some mathematicians were reluctant to accept. One such is the well-ordering theorem, which we shall discuss shortly. For the present we shall simply use the choice axiom to clear up the difficulty we mentioned in the preceding proof. First, we prove an easy consequence of the axiom of choice:

Lemma 9.2 (Existence of a choice function). Given a collection $\mathscr{B}$ of nonempty sets (not necessarily disjoint), there exists a function

$$
c: \mathscr{B} \longrightarrow \bigcup_{B \in \mathcal{B}} B
$$

such that $c(B)$ is an element of $B$, for each $B \in \mathscr{B}$.

The function $c$ is called a choice function for the collection $\mathscr{B}$.

The difference between this lemma and the axiom of choice is that in this lemma the sets of the collection $\mathscr{B}$ are not required to be disjoint. For example, one can allow $\mathcal{B}$ to be the collection of all nonempty subsets of a given set.

Proof of the lemma. Given an element $B$ of $\mathcal{B}$, we define a set $B^{\prime}$ as follows:

$$
B^{\prime}=\{(B, x) \mid x \in B\}
$$

That is, $B^{\prime}$ is the collection of all ordered pairs, where the first coordinate of the ordered pair is the set $B$, and the second coordinate is an element of $B$. The set $B^{\prime}$ is a subset of the cartesian product

$$
\mathcal{B} \times \bigcup_{B \in \mathscr{B}} B
$$

Because $B$ contains at least one element $x$, the set $B^{\prime}$ contains at least the element $(B, x)$, so it is nonempty.

Now we claim that if $B_{1}$ and $B_{2}$ are two different sets in $\mathscr{B}$, then the corresponding sets $B_{1}^{\prime}$ and $B_{2}^{\prime}$ are disjoint. For the typical element of $B_{1}^{\prime}$ is a pair of the form $\left(B_{1}, x_{1}\right)$ and the typical element of $B_{2}^{\prime}$ is a pair of the form $\left(B_{2}, x_{2}\right)$. No two such elements can be equal, for their first coordinates are different. Now let us form the collection

$$
\mathcal{C}=\left\{B^{\prime} \mid B \in \mathscr{B}\right\}
$$

it is a collection of disjoint nonempty subsets of

$$
\mathcal{B} \times \bigcup_{B \in \mathscr{B}} B
$$

By the choice axiom, there exists a set $c$ consisting of exactly one element from each element of $\mathcal{C}$. Our claim is that $c$ is the rule for the desired choice function.

In the first place, $c$ is a subset of

$$
\mathcal{B} \times \bigcup_{B \in \mathscr{B}} B
$$

In the second place, $c$ contains exactly one element from each set $B^{\prime}$; therefore, for each $B \in \mathcal{B}$, the set $c$ contains exactly one ordered pair $(B, x)$ whose first coordinate is $B$. Thus $c$ is indeed the rule for a function from the collection $\mathscr{B}$ to the set $\bigcup_{B \in \mathcal{B}} B$. Finally, if $(B, x) \in c$, then $x$ belongs to $B$, so that $c(B) \in B$, as desired.

A second proof of Theorem 9.1. Using this lemma, one can make the proof of Theorem 9.1 more precise. Given the infinite set $A$, we wish to construct an injective function $f: \mathbb{Z}_{+} \rightarrow A$. Let us form the collection $\mathscr{B}$ of all nonempty subsets of $A$. The lemma just proved asserts the existence of a choice function for $\mathscr{B}$; that is, a function

$$
c: \mathcal{B} \longrightarrow \bigcup_{B \in \mathcal{B}} B=A
$$

such that $c(B) \in B$ for each $B \in \mathcal{B}$. Let us now define a function $f: \mathbb{Z}_{+} \rightarrow A$ by the recursion formula

$$
\begin{align*}
f(1) & =c(A) \\
f(i) & =c(A-f(\{1, \ldots, i-1\})) \quad \text { for } i>1 \tag{*}
\end{align*}
$$

Because $A$ is infinite, the set $A-f(\{1, \ldots, i-1\})$ is nonempty; therefore, the right side of this equation makes sense. Since this formula defines $f(i)$ uniquely in terms of $f \mid\{1, \ldots, i-1\}$, the principle of recursive definition applies. We conclude that there exists a unique function $f: \mathbb{Z}_{+} \rightarrow A$ satisfying $(*)$ for all $i \in \mathbb{Z}_{+}$. Injectivity of $f$ follows as before.

Having emphasized that in order to construct a proof of Theorem 9.1 that is logically correct, one must make specific use of a choice function, we now backtrack and admit that in practice most mathematicians do no such thing. They go on with no qualms giving proofs like our first version, proofs that involve an infinite number of arbitrary choices. They know that they are really using the choice axiom; and they know that if it were necessary, they could put their proofs into a logically more satisfactory form by introducing a choice function specifically. But usually they do not bother.

And neither will we. You will find few further specific uses of a choice function in this book; we shall introduce a choice function only when the proof would become
confusing without it. But there will be many proofs in which we make an infinite number of arbitrary choices, and in each such case we will actually be using the choice axiom implicitly.

Now we must confess that in an earlier section of this book there is a proof in which we constructed a certain function by making an infinite number of arbitrary choices. And we slipped that proof in without even mentioning the choice axiom. Our apologies for the deception. We leave it to you to ferret out which proof it was!

Let us make one final comment on the choice axiom. There are two forms of this axiom. One can be called the finite axiom of choice; it asserts that given a finite collection $\mathcal{A}$ of disjoint nonempty sets, there exists a set $C$ consisting of exactly one element from each element of $\mathcal{A}$. One needs this weak form of the choice axiom all the time; we have used it freely in the preceding sections with no comment. No mathematician has any qualms about the finite choice axiom; it is part of everyone's set theory. Said differently, no one has qualms about a proof that involves only finitely many arbitrary choices.

The stronger form of the axiom of choice, the one that applies to an arbitrary collection $\mathcal{A}$ of nonempty sets, is the one that is properly called "the axiom of choice." When a mathematician writes, "This proof depends on the choice axiom," it is invariably this stronger form of the axiom that is meant.

## Exercises

1. Define an injective map $f: \mathbb{Z}_{+} \rightarrow X^{\omega}$, where $X$ is the two-element set $\{0,1\}$, without using the choice axiom.
2. Find if possible a choice function for each of the following collections, without using the choice axiom:

(a) The collection $\mathcal{A}$ of nonempty subsets of $\mathbb{Z}_{+}$.

(b) The collection $\mathscr{B}$ of nonempty subsets of $\mathbb{Z}$.

(c) The collection $C$ of nonempty subsets of the rational numbers $\mathbb{Q}$.

(d) The collection $\mathscr{D}$ of nonempty subsets of $X^{\omega}$, where $X=\{0,1\}$.

3. Suppose that $A$ is a set and $\left\{f_{n}\right\}_{n \in \mathbb{Z}_{+}}$is a given indexed family of injective functions

$$
f_{n}:\{1, \ldots, n\} \longrightarrow A
$$

Show that $A$ is infinite. Can you define an injective function $f: \mathbb{Z}_{+} \rightarrow A$ without using the choice axiom?

4. There was a theorem in $\S 7$ whose proof involved an infinite number of arbitrary choices. Which one was it? Rewrite the proof so as to make explicit the use of the choice axiom. (Several of the earlier exercises have used the choice axiom also.)
5. (a) Use the choice axiom to show that if $f: A \rightarrow B$ is surjective, then $f$ has a right inverse $h: B \rightarrow A$.

(b) Show that if $f: A \rightarrow B$ is injective and $A$ is not empty, then $f$ has a left inverse. Is the axiom of choice needed?

6. Most of the famous paradoxes of naive set theory are associated in some way or other with the concept of the "set of all sets." None of the rules we have given for forming sets allows us to consider such a set. And for good reason-the concept itself is self-contradictory. For suppose that $\mathcal{A}$ denotes the "set of all sets."

(a) Show that $\mathcal{P}(\mathcal{A}) \subset \mathcal{A}$; derive a contradiction.

(b) (Russell's paradox.) Let $\mathcal{B}$ be the subset of $\mathcal{A}$ consisting of all sets that are not elements of themselves;

$$
\mathscr{B}=\{A \mid A \in \mathcal{A} \text { and } A \notin A\}
$$

(Of course, there may be no set $A$ such that $A \in A$; if such is the case, then $\mathscr{B}=\mathcal{A}$.) Is $\mathscr{B}$ an element of itself or not?

7. Let $A$ and $B$ be two nonempty sets. If there is an injection of $B$ into $A$, but no injection of $A$ into $B$, we say that $A$ has greater cardinality than $B$.

(a) Conclude from Theorem 9.1 that every uncountable set has greater cardinality than $\mathbb{Z}_{+}$.

(b) Show that if $A$ has greater cardinality than $B$, and $B$ has greater cardinality than $C$, then $A$ has greater cardinality than $C$.

(c) Find a sequence $A_{1}, A_{2}, \ldots$ of infinite sets, such that for each $n \in \mathbb{Z}_{+}$, the set $A_{n+1}$ has greater cardinality than $A_{n}$.

(d) Find a set that for every $n$ has cardinality greater than $A_{n}$.

*8. Show that $\mathcal{P}\left(\mathbb{Z}_{+}\right)$and $\mathbb{R}$ have the same cardinality. [Hint: You may use the fact that every real number has a decimal expansion, which is unique if expansions that end in an infinite string of 9's are forbidden.]

A famous conjecture of set theory, called the continuum hypothesis, asserts that there exists no set having greater cardinality than $\mathbb{Z}_{+}$and lesser cardinality than $\mathbb{R}$. The generalized continuum hypothesis asserts that, given the infinite set $A$, there is no set having greater cardinality than $A$ and lesser cardinality than $\mathcal{P}(A)$. Surprisingly enough, both of these assertions have been shown to be independent of the usual axioms for set theory. For a readable expository account, see $[\mathrm{Sm}]$.

## $\$ 10$ Well-Ordered Sets

One of the useful properties of the set $\mathbb{Z}_{+}$of positive integers is the fact that each of its nonempty subsets has a smallest element. Generalizing this property leads to the concept of a well-ordered set.

Definition. A set $A$ with an order relation $<$ is said to be well-ordered if every nonempty subset of $A$ has a smallest element.

EXAmple 1. Consider the set $\{1,2\} \times \mathbb{Z}_{+}$in the dictionary ordering. Schematically, it can be represented as one infinite sequence followed by another infinite sequence:

$$
a_{1}, a_{2}, a_{3}, \ldots ; b_{1}, b_{2}, b_{3}, \ldots
$$

with the understanding that each element is less than every element to the right of it. It is not difficult to see that every nonempty subset $C$ of this ordered set has a smallest element: If $C$ contains any one of the elements $a_{n}$, we simply take the smallest element of the intersection of $C$ with the sequence $a_{1}, a_{2}, \ldots$; while if $C$ contains no $a_{n}$, then it is a subset of the sequence $b_{1}, b_{2}, \ldots$ and as such has a smallest element.

EXAMPLE 2. Consider the set $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$in the dictionary order. Schematically, it can be represented as an infinite sequence of infinite sequences. We show that it is well-ordered. Let $X$ be a nonempty subset of $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$. Let $A$ be the subset of $\mathbb{Z}_{+}$consisting of all first coordinates of elements of $X$. Now $A$ has a smallest element; call it $a_{0}$. Then the collection

$$
\left\{b \mid a_{0} \times b \in X\right\}
$$

is a nonempty subset of $\mathbb{Z}_{+}$; let $b_{0}$ be its smallest element. By definition of the dictionary order, $a_{0} \times b_{0}$ is the smallest element of $X$. See Figure 10.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-064.jpg?height=600&width=891&top_left_y=1221&top_left_x=576)

Figure 10.1

EXAMPLE 3. The set of integers is not well-ordered in the usual order; the subset consisting of the negative integers has no smallest element. Nor is the set of real numbers in the interval $0 \leq x \leq 1$ well-ordered; the subset consisting of those $x$ for which $0<x<1$ has no smallest element (although it has a greatest lower bound, of course).

There are several ways of constructing well-ordered sets. Two of them are the following:

(1) If $A$ is a well-ordered set, then any subset of $A$ is well-ordered in the restricted order relation.

(2) If $A$ and $B$ are well-ordered sets, then $A \times B$ is well-ordered in the dictionary order.

The proof of (1) is trivial; the proof of (2) follows the pattern given in Example 2.

It follows that the set $\mathbb{Z}_{+} \times\left(\mathbb{Z}_{+} \times \mathbb{Z}_{+}\right)$is well-ordered in the dictionary order; it can be represented as an infinite sequence of infinite sequences of infinite sequences. Similarly, $\left(\mathbb{Z}_{+}\right)^{4}$ is well-ordered in the dictionary order. And so on. But if you try to generalize to an infinite product of $\mathbb{Z}_{+}$with itself, you will run into trouble. We shall examine this situation shortly.

Now, given a set $A$ without an order relation, it is natural to ask whether there exists an order relation for $A$ that makes it into a well-ordered set. If $A$ is finite, any bijection

$$
f: A \longrightarrow\{1, \ldots, n\}
$$

can be used to define an order relation on $A$; under this relation, $A$ has the same order type as the ordered set $\{1, \ldots, n\}$. In fact, every order relation on a finite set can be obtained in this way:

Theorem 10.1. Every nonempty finite ordered set has the order type of a section $\{1, \ldots, n\}$ of $\mathbb{Z}_{+}$, so it is well-ordered.

Proof. This was given as an exercise in $\S 6$; we prove it here. First, we show that every finite ordered set $A$ has a largest element. If $A$ has one element, this is trivial. Supposing it true for sets having $n-1$ elements, let $A$ have $n$ elements and let $a_{0} \in A$. Then $A-\left\{a_{0}\right\}$ has a largest element $a_{1}$, and the larger of $\left\{a_{0}, a_{1}\right\}$ is the largest element of $A$.

Second, we show there is an order-preserving bijection of $A$ with $\{1, \ldots, n\}$ for some $n$. If $A$ has one element, this fact is trivial. Suppose that it is true for sets having $n-1$ elements. Let $b$ be the largest element of $A$. By hypothesis, there is an order-preserving bijection

$$
f^{\prime}: A-\{b\} \longrightarrow\{1, \ldots, n-1\} .
$$

Define an order-preserving bijection $f: A \rightarrow\{1, \ldots, n\}$ by setting

$$
\begin{aligned}
& f(x)=f^{\prime}(x) \quad \text { for } x \neq b \\
& f(b)=n .
\end{aligned}
$$

Thus, a finite ordered set has only one possible order type. For an infinite set, things are quite different. The well-ordered sets

$$
\begin{aligned}
& \mathbb{Z}_{+}, \\
& \{1, \ldots, n\} \times \mathbb{Z}_{+}, \\
& \mathbb{Z}_{+} \times \mathbb{Z}_{+}, \\
& \mathbb{Z}_{+} \times\left(\mathbb{Z}_{+} \times \mathbb{Z}_{+}\right)
\end{aligned}
$$

are all countably infinite, but they all have different order types, as you can check.

All the examples we have given of well-ordered sets are orderings of countable sets. It is natural to ask whether one can find a well-ordered uncountable set.

The obvious uncountable set to try is the countably infinite product

$$
X=\mathbb{Z}_{+} \times \mathbb{Z}_{+} \times \cdots=\left(\mathbb{Z}_{+}\right)^{\omega}
$$

of $\mathbb{Z}_{+}$with itself. One can generalize the dictionary order to this set in a natural way, by defining

$$
\left(a_{1}, a_{2}, \ldots\right)<\left(b_{1}, b_{2}, \ldots\right)
$$

if for some $n \geq 1$,

$$
a_{i}=b_{i}, \quad \text { for } i<n \text { and } a_{n}<b_{n} .
$$

This is, in fact, an order relation on the set $X$; but unfortunately it is not a well-ordering. Consider the set $A$ of all elements $\mathbf{x}$ of $X$ of the form

$$
\mathbf{x}=(1, \ldots, 1,2,1,1, \ldots)
$$

where exactly one coordinate of $\mathbf{x}$ equals 2 , and the others are all equal to 1 . The set $A$ clearly has no smallest element.

Thus, the dictionary order at least does not give a well-ordering of the set $\left(\mathbb{Z}_{+}\right)^{\omega}$. Is there some other order relation on this set that is a well-ordering? No one has ever constructed a specific well-ordering of $\left(\mathbb{Z}_{+}\right)^{\omega}$. Nevertheless, there is a famous theorem that says such a well-ordering exists:

Theorem (Well-ordering theorem). If $A$ is a set, there exists an order relation on $A$ that is a well-ordering.

This theorem was proved by Zermelo in 1904, and it startled the mathematical world. There was considerable debate as to the correctness of the proof; the lack of any constructive procedure for well-ordering an arbitrary uncountable set led many to be skeptical. When the proof was analyzed closely, the only point at which it was found that there might be some question was a construction involving an infinite number of arbitrary choices, that is, a construction involving-the choice axiom.

Some mathematicians rejected the choice axiom as a result, and for many years a legitimate question about a new theorem was: Does its proof involve the choice axiom or not? A theorem was considered to be on somewhat shaky ground if one had to use the choice axiom in its proof. Present-day mathematicians, by and large, do not have such qualms. They accept the axiom of choice as a reasonable assumption about set theory, and they accept the well-ordering theorem along with it.

The proof that the choice axiom implies the well-ordering theorem is rather long (although not exceedingly difficult) and primarily of interest to logicians; we shall omit it. If you are interested, a proof is outlined in the supplementary exercises at the end
of the chapter. Instead, we shall simply assume the well-ordering theorem whenever we need it. Consider it to be an additional axiom of set theory if you like!

We shall in fact need the full strength of this assumption only occasionally. Most of the time, all we need is the following weaker result:

Corollary. There exists an uncountable well-ordered set.

We now use this result to construct a particular well-ordered set that will prove to be very useful.

Definition. Let $X$ be a well-ordered set. Given $\alpha \in X$, let $S_{\alpha}$ denote the set

$$
S_{\alpha}=\{x \mid x \in X \text { and } x<\alpha\}
$$

It is called the section of $X$ by $\alpha$.

Lemma 10.2. There exists a well-ordered set $A$ having a largest element $\Omega$, such that the section $S_{\Omega}$ of $A$ by $\Omega$ is uncountable but every other section of $A$ is countable.

Proof. We begin with an uncountable well-ordered set $B$. Let $C$ be the well-ordered set $\{1,2\} \times B$ in the dictionary order; then some section of $C$ is uncountable. (Indeed, the section of $C$ by any element of the form $2 \times b$ is uncountable.) Let $\Omega$ be the smallest element of $C$ for which the section of $C$ by $\Omega$ is uncountable. Then let $A$ consist of this section along with the element $\Omega$.

Note that $S_{\Omega}$ is an uncountable well-ordered set every section of which is countable. Its order type is in fact uniquely determined by this condition. We shall call it a minimal uncountable well-ordered set. Furthermore, we shall denote the well-ordered set $A=S_{\Omega} \cup\{\Omega\}$ by the symbol $\bar{S}_{\Omega}$ (for reasons to be seen later).

The most useful property of the set $S_{\Omega}$ for our purposes is expressed in the following theorem:

Theorem 10.3. If $A$ is a countable subset of $S_{\Omega}$, then $A$ has an upper bound in $S_{\Omega}$.

Proof. Let $A$ be a countable subset of $S_{\Omega}$. For each $a \in A$, the section $S_{a}$ is countable. Therefore, the union $B=\bigcup_{a \in A} S_{a}$ is also countable. Since $S_{\Omega}$ is uncountable, the set $B$ is not all of $S_{\Omega}$; let $x$ be a point of $S_{\Omega}$ that is not in $B$. Then $x$ is an upper bound for $A$. For if $x<a$ for some $a$ in $A$, then $x$ belongs to $S_{a}$ and hence to $B$, contrary to choice.

## Exercises

1. Show that every well-ordered set has the least upper bound property.
2. (a) Show that in a well-ordered set, every element except the largest (if one exists) has an immediate successor.

(b) Find a set in which every element has an immediate successor that is not well-ordered.

3. Both $\{1,2\} \times \mathbb{Z}_{+}$and $\mathbb{Z}_{+} \times\{1,2\}$ are well-ordered in the dictionary order. Do they have the same order type?
4. (a) Let $\mathbb{Z}_{-}$denote the set of negative integers in the usual order. Show that a simply ordered set $A$ fails to be well-ordered if and only if it contains a subset having the same order type as $\mathbb{Z}_{-}$.

(b) Show that if $A$ is simply ordered and every countable subset of $A$ is wellordered, then $A$ is well-ordered.

5. Show the well-ordering theorem implies the choice axiom.
6. Let $S_{\Omega}$ be the minimal uncountable well-ordered set.

(a) Show that $S_{\Omega}$ has no largest element.

(b) Show that for every $\alpha \in S_{\Omega}$, the subset $\{x \mid \alpha<x\}$ is uncountable.

(c) Let $X_{0}$ be the subset of $S_{\Omega}$ consisting of all elements $x$ such that $x$ has no immediate predecessor. Show that $X_{0}$ is uncountable.

7. Let $J$ be a well-ordered set. A subset $J_{0}$ of $J$ is said to be inductive if for every $\alpha \in J$,

$$
\left(S_{\alpha} \subset J_{0}\right) \Longrightarrow \alpha \in J_{0}
$$

Theorem (The principle of transfinite induction). If $J$ is a well-ordered set and $J_{0}$ is an inductive subset of $J$, then $J_{0}=J$.

8. (a) Let $A_{1}$ and $A_{2}$ be disjoint sets, well-ordered by $<_{1}$ and $<_{2}$, respectively. Define an order relation on $A_{1} \cup A_{2}$ by letting $a<b$ either if $a, b \in A_{1}$ and $a<_{1} b$, or if $a, b \in A_{2}$ and $a<_{2} b$, or if $a \in A_{1}$ and $b \in A_{2}$. Show that this is a well-ordering.

(b) Generalize (a) to an arbitrary family of disjoint well-ordered sets, indexed by a well-ordered set.

9. Consider the subset $A$ of $\left(\mathbb{Z}_{+}\right)^{\omega}$ consisting of all infinite sequences of positive integers $\mathbf{x}=\left(x_{1}, x_{2}, \ldots\right)$ that end in an infinite string of 1's. Give $A$ the following order: $\mathbf{x}<\mathbf{y}$ if $x_{n}<y_{n}$ and $x_{i}=y_{i}$ for $i>n$. We call this the "antidictionary order" on $A$.

(a) Show that for every $n$, there is a section of $A$ that has the same order type as $\left(\mathbb{Z}_{+}\right)^{n}$ in the dictionary order.

(b) Show $A$ is well-ordered.

10. Theorem. Let $J$ and $C$ be well-ordered sets; assume that there is no surjective function mapping a section of $J$ onto $C$. Then there exists a unique function $h: J \rightarrow C$ satisfying the equation

$$
\begin{equation*}
h(x)=\operatorname{smallest}\left[C-h\left(S_{x}\right)\right] \tag{*}
\end{equation*}
$$

for each $x \in J$, where $S_{x}$ is the section of $J$ by $x$.

Proof.

(a) If $h$ and $k$ map sections of $J$, or all of $J$, into $C$ and satisfy (*) for all $x$ in their respective domains, show that $h(x)=k(x)$ for all $x$ in both domains.

(b) If there exists a function $h: S_{\alpha} \rightarrow C$ satisfying (*), show that there exists a function $k: S_{\alpha} \cup\{\alpha\} \rightarrow C$ satisfying (*).

(c) If $K \subset J$ and for all $\alpha \in K$ there exists a function $h_{\alpha}: S_{\alpha} \rightarrow C$ satisfying $(*)$, show that there exists a function

$$
k: \bigcup_{\alpha \in K} S_{\alpha} \longrightarrow C
$$

satisfying $(*)$.

(d) Show by transfinite induction that for every $\beta \in J$, there exists a function $h_{\beta}: S_{\beta} \rightarrow C$ satisfying (*). [Hint: If $\beta$ has an immediate predecessor $\alpha$, then $S_{\beta}=S_{\alpha} \cup\{\alpha\}$. If not, $S_{\beta}$ is the union of all $S_{\alpha}$ with $\alpha<\beta$.]

(e) Prove the theorem.

11. Let $A$ and $B$ be two sets. Using the well-ordering theorem, prove that either they have the same cardinality, or one has cardinality greater than the other. [Hint: If there is no surjection $f: A \rightarrow B$, apply the preceding exercise.]

## *\$11 The Maximum Principle ${ }^{\dagger}$

We have already indicated that the axiom of choice leads to the deep theorem that every set can be well-ordered. The axiom of choice has other consequences that are even more important in mathematics. Collectively referred to as "maximum principles," they come in many versions. Formulated independently by a number of mathematicians, including F. Hausdorff, K. Kuratowski, S. Bochner, and M. Zorn, during the years 1914-1935, they were typically proved as consequences of the well-ordering theorem. Later, it was realized that they were in fact equivalent to the well-ordering theorem. We consider several of them here.

First, we make a definition. Given a set $A$, a relation $\prec$ on $A$ is called a strict partial order on $A$ if it has the following two properties:

(1) (Nonreflexivity) The relation $a \prec a$ never holds.

(2) (Transitivity) If $a \prec b$ and $b \prec c$, then $a \prec c$.

These are just the second and third of the properties of a simple order (see §3); the comparability property is the one that is omitted. In other words, a strict partial order behaves just like a simple order except that it need not be true that for every pair of distinct points $x$ and $y$ in the set, either $x \prec y$ or $y \prec x$.

If $\prec$ is a strict partial order on a set $A$, it can easily happen that some subset $B$ of $A$ is simply ordered by the relation; all that is needed is for every pair of elements of $B$ to be comparable under $\prec$.[^1]

Now we can state the following principle, which was first formulated by Hausdorff in 1914.

Theorem (The maximum principle). Let $A$ be a set; let $\prec$ be a strict partial order on $A$. Then there exists a maximal simply ordered subset $B$ of $A$.

Said differently, there exists a subset $B$ of $A$ such that $B$ is simply ordered by $\prec$ and such that no subset of $A$ that properly contains $B$ is simply ordered by $\prec$.

EXAMPLE 1. If $\mathcal{A}$ is any collection of sets, the relation "is a proper subset of" is a strict partial order on $\mathcal{A}$. Suppose that $\mathcal{A}$ is the collection of all circular regions (interiors of circles) in the plane. One maximal simply ordered subcollection of $\mathcal{A}$ consists of all circular regions with centers at the origin. Another maximal simply ordered subcollection consists of all circular regions bounded by circles tangent from the right to the $y$-axis at the origin. See Figure 11.1.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-070.jpg?height=474&width=1144&top_left_y=1012&top_left_x=441)

Figure 11.1

EXAmple 2. If $\left(x_{0}, y_{0}\right)$ and $\left(x_{1}, y_{1}\right)$ are two points of the plane $\mathbb{R}^{2}$, define

$$
\left(x_{0}, y_{0}\right) \prec\left(x_{1}, y_{1}\right)
$$

if $y_{0}=y_{1}$ and $x_{0}<x_{1}$. This is a partial ordering of $\mathbb{R}^{2}$ under which two points are comparable only if they lie on the same horizontal line. The maximal simply ordered sets are the horizontal lines in $\mathbb{R}^{2}$.

One can give an intuitive "proof" of the maximum principle that is rather appealing. It involves a step-by-step procedure, which one can describe in physical terms as follows. Suppose we take a box, and put into it some of the elements of $A$ according to the following plan: First we pick an arbitrary element of $A$ and put it in the box. Then we pick another element of $A$. If it is comparable with the element in the box, we put it in the box too; otherwise, we throw it away. At the general step, we will have a collection of elements in the box and a collection of elements that have been tossed away. Take one of the remaining elements of $A$. If it is comparable with everything in the box, toss it in the box, too; otherwise, throw it away. Similarly continue. After
you have checked all the elements of $A$, the elements you have in the box will be comparable with one another, and thus they will form a simply ordered set. Every element not in the box will be noncomparable with at least one element in the box, for that was why it was tossed away. Hence, the simply ordered set in the box is maximal, for no larger subset of $A$ can satisfy the comparability condition.

Now of course the weak point in the preceding "proof" comes when we said, "After you have checked all the elements of $A$." How do you know you ever "get through" checking all the elements of $A$ ? If $A$ should happen to be countable, it is not hard to make this intuitive proof into a real proof. Let us take the countably infinite case; the finite case is even easier. Index the elements of $A$ bijectively with the positive integers, so that $A=\left\{a_{1}, a_{2} \ldots\right\}$. This indexing gives a way of deciding what order to test the elements of $A$ in, and how to know when one has tested them all.

Now we define a function $h: \mathbb{Z}_{+} \rightarrow\{0,1\}$, by letting it assign the value 0 to $i$ if we "put $a_{i}$ in the box," and the value 1 if we "throw $a_{i}$ away." This means that $h(1)=0$, and for $i>1$, we have $h(i)=0$ if and only if $a_{i}$ is comparable with every element of the set

$$
\left\{a_{j} \mid j<i \text { and } h(j)=0\right\} .
$$

By the principle of recursive definition, this formula determines a unique function $h: \mathbb{Z}_{+} \rightarrow\{0,1\}$. It is easy to check that the set of those $a_{j}$ for which $h(j)=0$ is a maximal simply ordered subset of $A$.

If $A$ is not countable, a variant of this procedure will work, if we allow ourselves to use the well-ordering theorem. Instead of indexing the elements of $A$ with the set $\mathbb{Z}_{+}$, we index them (in a bijective fashion) with the elements of some well-ordered set $J$, so that $A=\left\{a_{\alpha} \mid \alpha \in J\right\}$. For this we need the well-ordering theorem, so that we know there is a bijection between $A$ and some well-ordered set $J$. Then we can proceed as in the previous paragraph, letting $\alpha$ replace $i$ in the argument. Strictly speaking, you need to generalize the principle of recursive definition to well-ordered sets as well, but that is not particularly difficult. (See the Supplementary Exercises.)

Thus, the well-ordering theorem implies the maximum principle.

Although the maximum principle of Hausdorff was the first to be formulated and is probably the simplest to understand, there is another such principle that is nowadays the one most frequently quoted. It is popularly called "Zorn's Lemma," although Kuratowski (1922) and Bochner (1922) preceded Zorn (1935) in enunciating and proving versions of it. For a history and discussion of the tangled history of these ideas, see [C] or $[\mathrm{Mo}]$. To state this principle, we need some terminology.

Definition. Let $A$ be a set and let $\prec$ be a strict partial order on $A$. If $B$ is a subset of $A$, an upper bound on $B$ is an element $c$ of $A$ such that for every $b$ in $B$, either $b=c$ or $b \prec c$. A maximal element of $A$ is an element $m$ of $A$ such that for no element $a$ of $A$ does the relation $m \prec a$ hold.

Zorn's Lemma. Let $A$ be a set that is strictly partially ordered. If every simply ordered subset of $A$ has an upper bound in $A$, then $A$ has a maximal element.

Zorn's lemma is an easy consequence of the maximum principle: Given $A$, the maximum principle implies that $A$ has a maximal simply ordered subset $B$. The hypothesis of Zorn's lemma tells us that $B$ has an upper bound $c$ in $A$. The element $c$ is then automatically a maximal element of $A$. For if $c \prec d$ for some element $d$ of $A$, then the set $B \cup\{d\}$, which properly contains $B$, is simply ordered because $b \prec d$ for every $b \in B$. This fact contradicts maximality of $B$.

It is also true that the maximum principle is an easy consequence of Zorn's lemma. See Exercises 5-7.

One final remark. We have defined what we mean by a strict partial order on a set, but we have not said what a partial order itself is. Let $\prec$ be a strict partial order on a set $A$. Suppose that we define $a \preceq b$ if either $a \prec b$ or $a=b$. Then the relation $\preceq$ is called a partial order on $A$. For example, the inclusion relation $\subset$ on a collection of sets is a partial order, whereas proper inclusion is a strict partial order.

Many authors prefer to deal with partial orderings rather than strict partial orderings; the maximum principle and Zorn's lemma are often expressed in these terms. Which formulation is used is simply a matter of taste and convenience.

## Exercises

1. If $a$ and $b$ are real numbers, define $a \prec b$ if $b-a$ is positive and rational. Show this is a strict partial order on $\mathbb{R}$. What are the maximal simply ordered subsets?
2. (a) Let $\prec$ be a strict partial order on the set $A$. Define a relation on $A$ by letting $a \preceq b$ if either $a \prec b$ or $a=b$. Show that this relation has the following properties, which are called the partial order axioms:

(i) $a \preceq a$ for all $a \in A$.

(ii) $a \preceq b$ and $b \preceq a \Longrightarrow a=b$.

(iii) $a \preceq b$ and $b \preceq c \Longrightarrow a \preceq c$.

(b) Let $P$ be a relation on $A$ that satisfies properties (i)-(iii). Define a relation $S$ on $A$ by letting $a S b$ if $a P b$ and $a \neq b$. Show that $S$ is a strict partial order on $A$.

3. Let $A$ be a set with a strict partial order $\prec$; let $x \in A$. Suppose that we wish to find a maximal simply ordered subset $B$ of $A$ that contains $x$. One plausible way of attempting to define $B$ is to let $B$ equal the set of all those elements of $A$ that are comparable with $x$;

$$
B=\{y \mid y \in A \text { and either } x \prec y \text { or } y \prec x\}
$$

But this will not always work. In which of Examples 1 and 2 will this procedure succeed and in which will it not?

4. Given two points $\left(x_{0}, y_{0}\right)$ and $\left(x_{1}, y_{1}\right)$ of $\mathbb{R}^{2}$, define

$$
\left(x_{0}, y_{0}\right) \prec\left(x_{1}, y_{1}\right)
$$

if $x_{0}<x_{1}$ and $y_{0} \leq y_{1}$. Show that the curves $y=x^{3}$ and $y=2$ are maximal simply ordered subsets of $\mathbb{R}^{2}$, and the curve $y=x^{2}$ is not. Find all maximal simply ordered subsets.

5. Show that Zorn's lemma implies the following:

Lemma (Kuratowski). Let $\mathcal{A}$ be a collection of sets. Suppose that for every subcollection $\mathcal{B}$ of $\mathcal{A}$ that is simply ordered by proper inclusion, the union of the elements of $\mathscr{B}$ belongs to $\mathcal{A}$. Then $\mathcal{A}$ has an element that is properly contained in no other element of $\mathcal{A}$.

6. A collection $\mathcal{A}$ of subsets of a set $X$ is said to be of finite type provided that a subset $B$ of $X$ belongs to $\mathcal{A}$ if and only if every finite subset of $B$ belongs to $\mathcal{A}$. Show that the Kuratowski lemma implies the following:

Lemma (Tukey, 1940). Let $\mathcal{A}$ be a collection of sets. If $\mathcal{A}$ is of finite type, then $\mathcal{A}$ has an element that is properly contained in no other element of $\mathcal{A}$.

7. Show that the Tukey lemma implies the Hausdorff maximum principle. [Hint: If $\prec$ is a strict partial order on $A$, let $\mathcal{A}$ be the collection of all subsets of $A$ that are simply ordered by $\prec$. Show that $\mathcal{A}$ is of finite type.]
8. A typical use of Zorn's lemma in algebra is the proof that every vector space has a basis. Recall that if $A$ is a subset of the vector space $V$, we say a vector belongs to the span of $A$ if it equals a finite linear combination of elements of $A$. The set $A$ is independent if the only finite linear combination of elements of $A$ that equals the zero vector is the trivial one having all coefficients zero. If $A$ is independent and if every vector in $V$ belongs to the span of $A$, then $A$ is a basis for $V$.

(a) If $A$ is independent and $v \in V$ does not belong to the span of $A$, show $A \cup\{v\}$ is independent.

(b) Show the collection of all independent sets in $V$ has a maximal element.

(c) Show that $V$ has a basis.

## *Supplementary Exercises: Well-Ordering

In the following exercises, we ask you to prove the equivalence of the choice axiom, the well-ordering theorem, and the maximum principle. We comment that of these exercises, only Exercise 7 uses the choice axiom.

1. Theorem (General principle of recursive definition). Let $J$ be a well-ordered set; let $C$ be a set. Let $\mathcal{F}$ be the set of all functions mapping sections of $J$ into $C$. Given a function $\rho: \mathcal{F} \rightarrow C$, there exists a unique function $h: J \rightarrow C$ such that $h(\alpha)=\rho\left(h \mid S_{\alpha}\right)$ for each $\alpha \in J$.

[Hint: Follow the pattern outlined in Exercise 10 of $\S 10$.

2. (a) Let $J$ and $E$ be well-ordered sets; let $h: J \rightarrow E$. Show the following two statements are equivalent:

(i) $h$ is order preserving and its image is $E$ or a section of $E$.
(ii) $h(\alpha)=$ smallest $\left[E-h\left(S_{\alpha}\right)\right]$ for all $\alpha$.

[Hint: Show that each of these conditions implies that $h\left(S_{\alpha}\right)$ is a section of $E$; conclude that it must be the section by $h(\alpha)$.]

(b) If $E$ is a well-ordered set, show that no section of $E$ has the order type of $E$, nor do two different sections of $E$ have the same order type. [Hint: Given $J$, there is at most one order-preserving map of $J$ into $E$ whose image is $E$ or a section of $E$.]

3. Let $J$ and $E$ be well-ordered sets; suppose there is an order-preserving map $k: J \rightarrow E$. Using Exercises 1 and 2, show that $J$ has the order type of $E$ or a section of $E$. [Hint: Choose $e_{0} \in E$. Define $h: J \rightarrow E$ by the recursion formula

$$
h(\alpha)=\operatorname{smallest}\left[E-h\left(S_{\alpha}\right)\right] \quad \text { if } \quad h\left(S_{\alpha}\right) \neq E \text {, }
$$

and $h(\alpha)=e_{0}$ otherwise. Show that $h(\alpha) \leq k(\alpha)$ for all $\alpha$; conclude that $h\left(S_{\alpha}\right) \neq E$ for all $\alpha$.]

4. Use Exercises 1-3 to prove the following:

(a) If $A$ and $B$ are well-ordered sets, then exactly one of the following three conditions holds: $A$ and $B$ have the same order type, or $A$ has the order type of a section of $B$, or $B$ has the order type of a section of $A$. [Hint: Form a well-ordered set containing both $A$ and $B$, as in Exercise 8 of $\S 10$; then apply the preceding exercise.]

(b) Suppose that $A$ and $B$ are well-ordered sets that are uncountable, such that every section of $A$ and of $B$ is countable. Show $A$ and $B$ have the same order type.

5. Let $X$ be a set; let $\mathcal{A}$ be the collection of all pairs $(A,<)$, where $A$ is a subset of $X$ and $<$ is a well-ordering of $A$. Define

$$
(A,<) \prec\left(A^{\prime},<^{\prime}\right)
$$

if $(A,<)$ equals a section of $\left(A^{\prime},<^{\prime}\right)$.

(a) Show that $\prec$ is a strict partial order on $\mathcal{A}$.

(b) Let $\mathscr{B}$ be a subcollection of $\mathcal{A}$ that is simply ordered by $\prec$. Define $B^{\prime}$ to be the union of the sets $B$, for all $(B,<) \in \mathcal{B}$; and define $<^{\prime}$ to be the union of the relations $<$, for all $(B,<) \in \mathscr{B}$. Show that $\left(B^{\prime},<^{\prime}\right)$ is a well-ordered set.

6. Use Exercises 1 and 5 to prove the following:

Theorem. The maximum principle is equivalent to the well-ordering theorem.

7. Use Exercises $1-5$ to prove the following:

Theorem. The choice axiom is equivalent to the well-ordering theorem.

Proof. Let $X$ be a set; let $c$ be a fixed choice function for the nonempty subsets of $X$. If $T$ is a subset of $X$ and $<$ is a relation on $T$, we say that $(T,<)$ is a tower in $X$ if $<$ is a well-ordering of $T$ and if for each $x \in T$,

$$
x=c\left(X-S_{x}(T)\right),
$$

where $S_{x}(T)$ is the section of $T$ by $x$.

(a) Let $\left(T_{1},<_{1}\right)$ and $\left(T_{2},<_{2}\right)$ be two towers in $X$. Show that either these two ordered sets are the same, or one equals a section of the other. [Hint: Switching indices if necessary, we can assume that $h: T_{1} \rightarrow T_{2}$ is order preserving and $h\left(T_{1}\right)$ equals either $T_{2}$ or a section of $T_{2}$. Use Exercise 2 to show that $h(x)=x$ for all $x$.]

(b) If $(T,<)$ is a tower in $X$ and $T \neq X$, show there is a tower in $X$ of which $(T,<)$ is a section.

(c) Let $\left\{\left(T_{k},<_{k}\right) \mid k \in K\right\}$ be the collection of all towers in $X$. Let

$$
T=\bigcup_{k \in K} T_{k} \quad \text { and } \quad<=\bigcup_{k \in K}\left(<_{k}\right)
$$

Show that $(T,<)$ is a tower in $X$. Conclude that $T=X$.

8. Using Exercises 1-4, construct an uncountable well-ordered set, as follows. Let $\mathcal{A}$ be the collection of all pairs $(A,<)$, where $A$ is a subset of $\mathbb{Z}_{+}$and $<$is a wellordering of $A$. (We allow $A$ to be empty.) Define $(A,<) \sim\left(A^{\prime},<^{\prime}\right)$ if $(A,<)$ and $\left(A^{\prime},<^{\prime}\right)$ have the same order type. It is trivial to show this is an equivalence relation. Let $[(A,<)]$ denote the equivalence class of $(A,<)$; let $E$ denote the collection of these equivalence classes. Define

$$
[(A,<)] \ll\left[\left(A^{\prime},<^{\prime}\right)\right]
$$

if $(A,<)$ has the order type of a section of $\left(A^{\prime},<^{\prime}\right)$.

(a) Show that the relation $\ll$ is well defined and is a simple order on $E$. Note that the equivalence class $[(\varnothing, \varnothing)]$ is the smallest element of $E$.

(b) Show that if $\alpha=[(A,<)]$ is an element of $E$, then $(A,<)$ has the same order type as the section $S_{\alpha}(E)$ of $E$ by $\alpha$. [Hint: Define a map $f: A \rightarrow E$ by setting $f(x)=\left[\left(S_{x}(A)\right.\right.$, restriction of $\left.\left.<\right)\right]$ for each $x \in A$. $]$

(c) Conclude that $E$ is well-ordered by $\ll$.

(d) Show that $E$ is uncountable. [Hint: If $h: E \rightarrow \mathbb{Z}_{+}$is a bijection, then $h$ gives rise to a well-ordering of $\mathbb{Z}_{+}$.]

This same argument, with $\mathbb{Z}_{+}$replaced by an arbitrary well-ordered set $X$, proves (without use of the choice axiom) the existence of a well-ordered set $E$ whose cardinality is greater than that of $X$.

This exercise shows that one can construct an uncountable well-ordered set, and hence the minimal uncountable well-ordered set, by an explicit construction that does not use the choice axiom. However, this result is less interesting than it might appear. The crucial property of $S_{\Omega}$, the one we use repeatedly, is the fact that every countable subset of $S_{\Omega}$ has an upper bound in $S_{\Omega}$. That fact depends, in turn, on the fact that a countable union of countable sets is countable. And the proof of that result (if you examine it carefully) involves an infinite number of arbitrary choices-that is, it depends on the choice axiom.

Said differently, without the choice axiom we may be able to construct the minimal uncountable well-ordered set, but we can't use it for anything!

## Chapter 2

## Topological Spaces and Continuous Functions

The concept of topological space grew out of the study of the real line and euclidean space and the study of continuous functions on these spaces. In this chapter, we define what a topological space is, and we study a number of ways of constructing a topology on a set so as to make it into a topological space. We also consider some of the elementary concepts associated with topological spaces. Open and closed sets, limit points, and continuous functions are introduced as natural generalizations of the corresponding ideas for the real line and euclidean space.

## §12 Topological Spaces

The definition of a topological space that is now standard was a long time in being formulated. Various mathematicians-Fréchet, Hausdorff, and others-proposed different definitions over a period of years during the first decades of the twentieth century, but it took quite a while before mathematicians settled on the one that seemed most suitable. They wanted, of course, a definition that was as broad as possible, so that it would include as special cases all the various examples that were useful in mathematics-euclidean space, infinite-dimensional euclidean space, and function spaces among them-but they also wanted the definition to be narrow enough that the standard theorems about these familiar spaces would hold for topological spaces in
general. This is always the problem when one is trying to formulate a new mathematical concept, to decide how general its definition should be. The definition finally settled on may seem a bit abstract, but as you work through the various ways of constructing topological spaces, you will get a better feeling for what the concept means.

Definition. A topology on a set $X$ is a collection $\mathcal{T}$ of subsets of $X$ having the following properties:

(1) $\varnothing$ and $X$ are in $\mathcal{T}$.

(2) The union of the elements of any subcollection of $\mathcal{T}$ is in $\mathcal{T}$.

(3) The intersection of the elements of any finite subcollection of $\mathcal{T}$ is in $\mathcal{T}$.

A set $X$ for which a topology $\mathcal{T}$ has been specified is called a topological space.

Properly speaking, a topological space is an ordered pair $(X, \mathcal{T})$ consisting of a set $X$ and a topology $\mathcal{T}$ on $X$, but we often omit specific mention of $\mathcal{T}$ if no confusion will arise.

If $X$ is a topological space with topology $\mathcal{T}$, we say that a subset $U$ of $X$ is an open set of $X$ if $U$ belongs to the collection $\mathcal{T}$. Using this terminology, one can say that a topological space is a set $X$ together with a collection of subsets of $X$, called open sets, such that $\varnothing$ and $X$ are both open, and such that arbitrary unions and finite intersections of open sets are open.

EXAMPLE 1. Let $X$ be a three-element set, $X=\{a, b, c\}$. There are many possible topologies on $X$, some of which are indicated schematically in Figure 12.1. The diagram in the upper right-hand corner indicates the topology in which the open sets are $X, \varnothing$, $\{a, b\},\{b\}$, and $\{b, c\}$. The topology in the upper left-hand corner contains only $X$ and $\varnothing$, while the topology in the lower right-hand corner contains every subset of $X$. You can get other topologies on $X$ by permuting $a, b$, and $c$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-077.jpg?height=538&width=942&top_left_y=1528&top_left_x=751)

Figure 12.1

From this example, you can see that even a three-element set has many different topologies. But not every collection of subsets of $X$ is a topology on $X$. Neither of the collections indicated in Figure 12.2 is a topology, for instance.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-078.jpg?height=178&width=720&top_left_y=360&top_left_x=661)

Figure 12.2

EXAMPLE 2. If $X$ is any set, the collection of all subsets of $X$ is a topology on $X$; it is called the discrete topology. The collection consisting of $X$ and $\varnothing$ only is also a topology on $X$; we shall call it the indiscrete topology, or the trivial topology.

EXAMPLE 3. Let $X$ be a set; let $\mathcal{T}_{f}$ be the collection of all subsets $U$ of $X$ such that $X-U$ either is finite or is all of $X$. Then $\mathcal{T}_{f}$ is a topology on $X$, called the finite complement topology. Both $X$ and $\varnothing$ are in $\mathcal{T}_{f}$, since $X-X$ is finite and $X-\varnothing$ is all of $X$. If $\left\{U_{\alpha}\right\}$ is an indexed family of nonempty elements of $\mathcal{T}_{f}$, to show that $\bigcup U_{\alpha}$ is in $\mathcal{T}_{f}$, we compute

$$
X-\bigcup U_{\alpha}=\bigcap\left(X-U_{\alpha}\right)
$$

The latter set is finite because each set $X-U_{\alpha}$ is finite. If $U_{1}, \ldots, U_{n}$ are nonempty elements of $\mathcal{T}_{f}$, to show that $\bigcap U_{i}$ is in $\mathcal{T}_{f}$, we compute

$$
X-\bigcap_{i=1}^{n} U_{i}=\bigcup_{i=1}^{n}\left(X-U_{i}\right)
$$

The latter set is a finite union of finite sets and, therefore, finite.

EXAmple 4. Let $X$ be a set; let $\mathcal{T}_{c}$ be the collection of all subsets $U$ of $X$ such that $X-U$ either is countable or is all of $X$. Then $\mathcal{T}_{c}$ is a topology on $X$, as you can check.

Definition. Suppose that $\mathcal{T}$ and $\mathcal{T}^{\prime}$ are two topologies on a given set $X$. If $\mathcal{T}^{\prime} \supset \mathcal{T}$, we say that $\mathcal{T}^{\prime}$ is finer than $\mathcal{T}$; if $\mathcal{T}^{\prime}$ properly contains $\mathcal{T}$, we say that $\mathcal{T}^{\prime}$ is strictly finer than $\mathcal{T}$. We also say that $\mathcal{T}$ is coarser than $\mathcal{T}^{\prime}$, or strictly coarser, in these two respective situations. We say $\mathcal{T}$ is comparable with $\mathcal{T}^{\prime}$ if either $\mathcal{T}^{\prime} \supset \mathcal{T}$ or $\mathcal{T} \supset \mathcal{T}^{\prime}$.

This terminology is suggested by thinking of a topological space as being something like a truckload full of gravel- the pebbles and all unions of collections of pebbles being the open sets. If now we smash the pebbles into smaller ones, the collection of open sets has been enlarged, and the topology, like the gravel, is said to have been made finer by the operation.

Two topologies on $X$ need not be comparable, of course. In Figure 12.1 preceding, the topology in the upper right-hand corner is strictly finer than each of the three topologies in the first column and strictly coarser than each of the other topologies in the third column. But it is not comparable with any of the topologies in the second column.

Other terminology is sometimes used for this concept. If $\mathcal{T}^{\prime} \supset \mathcal{T}$, some mathematicians would say that $\mathcal{T}^{\prime}$ is larger than $\mathcal{T}$, and $\mathcal{T}$ is smaller than $\mathcal{T}^{\prime}$. This is certainly acceptable terminology, if not as vivid as the words "finer" and "coarser."

Many mathematicians use the words "weaker" and "stronger" in this context. Unfortunately, some of them (particularly analysts) are apt to say that $\mathcal{T}^{\prime}$ is stronger than $\mathcal{T}$ if $\mathcal{T}^{\prime} \supset \mathcal{T}$, while others (particularly topologists) are apt to say that $\mathcal{T}^{\prime}$ is weaker than $\mathcal{T}$ in the same situation! If you run across the terms "strong topology" or "weak topology" in some book, you will have to decide from the context which inclusion is meant. We shall not use these terms in this book.

## §13 Basis for a Topology

For each of the examples in the preceding section, we were able to specify the topology by describing the entire collection $\mathcal{T}$ of open sets. Usually this is too difficult. In most cases, one specifies instead a smaller collection of subsets of $X$ and defines the topology in terms of that.

Definition. If $X$ is a set, a basis for a topology on $X$ is a collection $\mathcal{B}$ of subsets of $X$ (called basis elements) such that

(1) For each $x \in X$, there is at least one basis element $B$ containing $x$.

(2) If $x$ belongs to the intersection of two basis elements $B_{1}$ and $B_{2}$, then there is a basis element $B_{3}$ containing $x$ such that $B_{3} \subset B_{1} \cap B_{2}$.

If $\mathscr{B}$ satisfies these two conditions, then we define the topology $\mathcal{T}$ generated by $\mathscr{B}$ as follows: $A$ subset $U$ of $X$ is said to be open in $X$ (that is, to be an element of $\mathcal{T}$ ) if for each $x \in U$, there is a basis element $B \in \mathscr{B}$ such that $x \in B$ and $B \subset U$. Note that each basis element is itself an element of $\mathcal{T}$.

We will check shortly that the collection $\mathcal{T}$ is indeed a topology on $X$. But first let us consider some examples.

EXAMPLE 1. Let $\mathscr{B}$ be the collection of all circular regions (interiors of circles) in the plane. Then $\mathcal{B}$ satisfies both conditions for a basis. The second condition is illustrated in Figure 13.1. In the topology generated by $\mathcal{B}$, a subset $U$ of the plane is open if every $x$ in $U$ lies in some circular region contained in $U$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-079.jpg?height=377&width=469&top_left_y=1821&top_left_x=681)

Figure 13.1

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-079.jpg?height=378&width=385&top_left_y=1837&top_left_x=1284)

Figure 13.2

EXAMPLE 2. Let $\mathscr{B}^{\prime}$ be the collection of all rectangular regions (interiors of rectangles) in the plane, where the rectangles have sides parallel to the coordinate axes. Then $\mathscr{B}^{\prime}$ satisfies both conditions for a basis. The second condition is illustrated in Figure 13.2; in this case, the condition is trivial, because the intersection of any two basis elements is itself a basis element (or empty). As we shall see later, the basis $\mathscr{B}^{\prime}$ generates the same topology on the plane as the basis $\mathscr{B}$ given in the preceding example.

EXAMPLE 3. If $X$ is any set, the collection of all one-point subsets of $X$ is a basis for the discrete topology on $X$.

Let us check now that the collection $\mathcal{T}$ generated by the basis $\mathcal{B}$ is, in fact, a topology on $X$. If $U$ is the empty set, it satisfies the defining condition of openness vacuously. Likewise, $X$ is in $\mathcal{T}$, since for each $x \in X$ there is some basis element $B$ containing $x$ and contained in $X$. Now let us take an indexed family $\left\{U_{\alpha}\right\}_{\alpha \in J}$, of elements of $\mathcal{T}$ and show that

$$
U=\bigcup_{\alpha \in J} U_{\alpha}
$$

belongs to $\mathcal{T}$. Given $x \in U$, there is an index $\alpha$ such that $x \in U_{\alpha}$. Since $U_{\alpha}$ is open, there is a basis element $B$ such that $x \in B \subset U_{\alpha}$. Then $x \in B$ and $B \subset U$, so that $U$ is open, by definition.

Now let us take two elements $U_{1}$ and $U_{2}$ of $\mathcal{T}$ and show that $U_{1} \cap U_{2}$ belongs to $\mathcal{T}$. Given $x \in U_{1} \cap U_{2}$, choose a basis element $B_{1}$ containing $x$ such that $B_{1} \subset U_{1}$; choose also a basis element $B_{2}$ containing $x$ such that $B_{2} \subset U_{2}$. The second condition for a basis enables us to choose a basis element $B_{3}$ containing $x$ such that $B_{3} \subset B_{1} \cap B_{2}$. See Figure 13.3. Then $x \in B_{3}$ and $B_{3} \subset U_{1} \cap U_{2}$, so $U_{1} \cap U_{2}$ belongs to $\mathcal{T}$, by definition.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-080.jpg?height=544&width=979&top_left_y=1482&top_left_x=532)

Figure 13.3

Finally, we show by induction that any finite intersection $U_{1} \cap \cdots \cap U_{n}$ of elements of $\mathcal{T}$ is in $\mathcal{T}$. This fact is trivial for $n=1$; we suppose it true for $n-1$ and prove it for $n$. Now

$$
\left(U_{1} \cap \cdots \cap U_{n}\right)=\left(U_{1} \cap \cdots \cap U_{n-1}\right) \cap U_{n} .
$$

By hypothesis, $U_{1} \cap \cdots \cap U_{n-1}$ belongs to $\mathcal{T}$; by the result just proved, the intersection of $U_{1} \cap \cdots \cap U_{n-1}$ and $U_{n}$ also belongs to $\mathcal{T}$.

Thus we have checked that collection of open sets generated by a basis $\mathcal{B}$ is, in fact, a topology.

Another way of describing the topology generated by a basis is given in the following lemma:

Lemma 13.1. Let $X$ be a set; let $\mathscr{B}$ be a basis for a topology $\mathcal{T}$ on $X$. Then $\mathcal{T}$ equals the collection of all unions of elements of $\mathscr{B}$.

Proof. Given a collection of elements of $\mathscr{B}$, they are also elements of $\mathcal{T}$. Because $\mathcal{T}$ is a topology, their union is in $\mathcal{T}$. Conversely, given $U \in \mathcal{T}$, choose for each $x \in U$ an element $B_{x}$ of $\mathscr{B}$ such that $x \in B_{x} \subset U$. Then $U=\bigcup_{x \in U} B_{x}$, so $U$ equals a union of elements of $\mathscr{B}$.

This lemma states that every open set $U$ in $X$ can be expressed as a union of basis elements. This expression for $U$ is not, however, unique. Thus the use of the term "basis" in topology differs drastically from its use in linear algebra, where the equation expressing a given vector as a linear combination of basis vectors $i s$ unique.

We have described in two different ways how to go from a basis to the topology it generates. Sometimes we need to go in the reverse direction, from a topology to a basis generating it. Here is one way of obtaining a basis for a given topology; we shall use it frequently.

Lemma 13.2. Let $X$ be a topological space. Suppose that $C$ is a collection of open sets of $X$ such that for each open set $U$ of $X$ and each $x$ in $U$, there is an element $C$ of $\mathcal{C}$ such that $x \in C \subset U$. Then $\mathcal{C}$ is a basis for the topology of $X$.

Proof. We must show that $\mathcal{C}$ is a basis. The first condition for a basis is easy: Given $x \in X$, since $X$ is itself an open set, there is by hypothesis an element $C$ of $\mathcal{C}$ such that $x \in C \subset X$. To check the second condition, let $x$ belong to $C_{1} \cap C_{2}$, where $C_{1}$ and $C_{2}$ are elements of $C$. Since $C_{1}$ and $C_{2}$ are open, so is $C_{1} \cap C_{2}$. Therefore, there exists by hypothesis an element $C_{3}$ in $C$ such that $x \in C_{3} \subset C_{1} \cap C_{2}$.

Let $\mathcal{T}$ be the collection of open sets of $X$; we must show that the topology $\mathcal{T}^{\prime}$ generated by $\mathcal{C}$ equals the topology $\mathcal{T}$. First, note that if $U$ belongs to $\mathcal{T}$ and if $x \in U$, then there is by hypothesis an element $C$ of $\mathcal{C}$ such that $x \in C \subset U$. It follows that $U$ belongs to the topology $\mathcal{T}^{\prime}$, by definition. Conversely, if $W$ belongs to the topology $\mathcal{T}^{\prime}$, then $W$ equals a union of elements of $\mathcal{C}$, by the preceding lemma. Since each element of $\mathcal{C}$ belongs to $\mathcal{T}$ and $\mathcal{T}$ is a topology, $W$ also belongs to $\mathcal{T}$.

When topologies are given by bases, it is useful to have a criterion in terms of the bases for determining whether one topology is finer than another. One such criterion is the following:

Lemma 13.3. Let $\mathscr{B}$ and $\mathscr{B}^{\prime}$ be bases for the topologies $\mathcal{T}$ and $\mathcal{T}^{\prime}$, respectively, on $X$. Then the following are equivalent:

(1) $\mathcal{T}^{\prime}$ is finer than $\mathcal{T}$.

(2) For each $x \in X$ and each basis element $B \in \mathscr{B}$ containing $x$, there is a basis element $B^{\prime} \in \mathcal{B}^{\prime}$ such that $x \in B^{\prime} \subset B$.

Proof. (2) $\Rightarrow$ (1). Given an element $U$ of $\mathcal{T}$, we wish to show that $U \in \mathcal{T}^{\prime}$. Let $x \in U$. Since $\mathscr{B}$ generates $\mathcal{T}$, there is an element $B \in \mathscr{B}$ such that $x \in B \subset U$. Condition (2) tells us there exists an element $B^{\prime} \in \mathscr{B}^{\prime}$ such that $x \in B^{\prime} \subset B$. Then $x \in B^{\prime} \subset U$, so $U \in \mathcal{T}$, by definition.

$(1) \Rightarrow(2)$. We are given $x \in X$ and $B \in \mathcal{B}$, with $x \in B$. Now $B$ belongs to $\mathcal{T}$ by definition and $\mathcal{T} \subset \mathcal{T}^{\prime}$ by condition (1); therefore, $B \in \mathcal{T}^{\prime}$. Since $\mathcal{T}^{\prime}$ is generated by $\mathscr{B}^{\prime}$, there is an element $B^{\prime} \in \mathscr{B}^{\prime}$ such that $x \in B^{\prime} \subset B$.

Some students find this condition hard to remember. "Which way does the inclusion $g o$ ?" they ask. It may be easier to remember if you recall the analogy between a topological space and a truckload full of gravel. Think of the pebbles as the basis elements of the topology; after the pebbles are smashed to dust, the dust particles are the basis elements of the new topology. The new topology is finer than the old one, and each dust particle was contained inside a pebble, as the criterion states.

EXAMPLE 4. One can now see that the collection $\mathscr{B}$ of all circular regions in the plane generates the same topology as the collection $\mathscr{B}^{\prime}$ of all rectangular regions; Figure 13.4 illustrates the proof. We shall treat this example more formally when we study metric spaces.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-082.jpg?height=308&width=828&top_left_y=1439&top_left_x=600)

Figure 13.4

We now define three topologies on the real line $\mathbb{R}$, all of which are of interest.

Definition. If $\mathscr{B}$ is the collection of all open intervals in the real line,

$$
(a, b)=\{x \mid a<x<b\}
$$

the topology generated by $\mathscr{B}$ is called the standard topology on the real line. Whenever we consider $\mathbb{R}$, we shall suppose it is given this topology unless we specifically state otherwise. If $\mathscr{B}^{\prime}$ is the collection of all half-open intervals of the form

$$
[a, b)=\{x \mid a \leq x<b\}
$$

where $a<b$, the topology generated by $\mathscr{B}^{\prime}$ is called the lower limit topology on $\mathbb{R}$. When $\mathbb{R}$ is given the lower limit topology, we denote it by $\mathbb{R}_{\ell}$. Finally let $K$ denote the set of all numbers of the form $1 / n$, for $n \in \mathbb{Z}_{+}$, and let $\mathscr{B}^{\prime \prime}$ be the collection of all open intervals $(a, b)$, along with all sets of the form $(a, b)-K$. The topology generated by $\mathscr{B}^{\prime \prime}$ will be called the $\boldsymbol{K}$-topology on $\mathbb{R}$. When $\mathbb{R}$ is given this topology, we denote it by $\mathbb{R}_{K}$.

It is easy to see that all three of these collections are bases; in each case, the intersection of two basis elements is either another basis element or is empty. The relation between these topologies is the following:

Lemma 13.4. The topologies of $\mathbb{R}_{\ell}$ and $\mathbb{R}_{K}$ are strictly finer than the standard topology on $\mathbb{R}$, but are not comparable with one another.

Proof. Let $\mathcal{T}, \mathcal{T}^{\prime}$, and $\mathcal{T}^{\prime \prime}$ be the topologies of $\mathbb{R}, \mathbb{R}_{\ell}$, and $\mathbb{R}_{K}$, respectively. Given a basis element $(a, b)$ for $\mathcal{T}$ and a point $x$ of $(a, b)$, the basis element $[x, b)$ for $\mathcal{T}^{\prime}$ contains $x$ and lies in $(a, b)$. On the other hand, given the basis element $[x, d)$ for $\mathcal{T}^{\prime}$, there is no open interval $(a, b)$ that contains $x$ and lies in $[x, d)$. Thus $\mathcal{T}^{\prime}$ is strictly finer than $\mathcal{T}$.

A similar argument applies to $\mathbb{R}_{K}$. Given a basis element $(a, b)$ for $\mathcal{T}$ and a point $x$ of $(a, b)$, this same interval is a basis element for $\mathcal{T}^{\prime \prime}$ that contains $x$. On the other hand, given the basis element $B=(-1,1)-K$ for $\mathcal{T}^{\prime \prime}$ and the point 0 of $B$, there is no open interval that contains 0 and lies in $B$.

We leave it to you to show that the topologies of $\mathbb{R}_{\ell}$ and $\mathbb{R}_{K}$ are not comparable.

A question may occur to you at this point. Since the topology generated by a basis $\mathcal{B}$ may be described as the collection of arbitrary unions of elements of $\mathcal{B}$, what happens if you start with a given collection of sets and take finite intersections of them as well as arbitrary unions? This question leads to the notion of a subbasis for a topology.

Definition. A subbasis $S$ for a topology on $X$ is a collection of subsets of $X$ whose union equals $X$. The topology generated by the subbasis $S$ is defined to be the collection $\mathcal{T}$ of all unions of finite intersections of elements of $S$.

We must of course check that $\mathcal{T}$ is a topology. For this purpose it will suffice to show that the collection $\mathcal{B}$ of all finite intersections of elements of $\mathcal{S}$ is a basis, for then the collection $\mathcal{T}$ of all unions of elements of $\mathscr{B}$ is a topology, by Lemma 13.1. Given $x \in X$, it belongs to an element of $\mathcal{S}$ and hence to an element of $\mathscr{B}$; this is the first condition for a basis. To check the second condition, let

$$
B_{1}=S_{1} \cap \cdots \cap S_{m} \quad \text { and } \quad B_{2}=S_{1}^{\prime} \cap \cdots \cap S_{n}^{\prime}
$$

be two elements of $\mathscr{B}$. Their intersection

$$
B_{1} \cap B_{2}=\left(S_{1} \cap \cdots \cap S_{m}\right) \cap\left(S_{1}^{\prime} \cap \cdots \cap S_{n}^{\prime}\right)
$$

is also a finite intersection of elements of $\mathcal{S}$, so it belongs to $\mathcal{B}$.

## Exercises

1. Let $X$ be a topological space; let $A$ be a subset of $X$. Suppose that for each $x \in A$ there is an open set $U$ containing $x$ such that $U \subset A$. Show that $A$ is open in $X$.
2. Consider the nine topologies on the set $X=\{a, b, c\}$ indicated in Example 1 of $\S 12$. Compare them; that is, for each pair of topologies, determine whether they are comparable, and if so, which is the finer.
3. Show that the collection $\mathcal{T}_{c}$ given in Example 4 of $\S 12$ is a topology on the set $X$. Is the collection

$$
\mathcal{T}_{\infty}=\{U \mid X-U \text { is infinite or empty or all of } X\}
$$

a topology on $X$ ?

4. (a) If $\left\{\mathcal{T}_{\alpha}\right\}$ is a family of topologies on $X$, show that $\bigcap \mathcal{T}_{\alpha}$ is a topology on $X$. Is $\bigcup \mathcal{T}_{\alpha}$ a topology on $X$ ?

(b) Let $\left\{\mathcal{T}_{\alpha}\right\}$ be a family of topologies on $X$. Show that there is a unique smallest topology on $X$ containing all the collections $\mathcal{T}_{\alpha}$, and a unique largest topology contained in all $\mathcal{T}_{\alpha}$.

(c) If $X=\{a, b, c\}$, let

$$
\mathcal{T}_{1}=\{\varnothing, X,\{a\},\{a, b\}\} \quad \text { and } \quad \mathcal{T}_{2}=\{\varnothing, X,\{a\},\{b, c\}\} .
$$

Find the smallest topology containing $\mathcal{T}_{1}$ and $\mathcal{T}_{2}$, and the largest topology contained in $\mathcal{T}_{1}$ and $\mathcal{T}_{2}$.

5. Show that if $\mathcal{A}$ is a basis for a topology on $X$, then the topology generated by $\mathcal{A}$ equals the intersection of all topologies on $X$ that contain $\mathcal{A}$. Prove the same if $\mathcal{A}$ is a subbasis.
6. Show that the topologies of $\mathbb{R}_{\ell}$ and $\mathbb{R}_{K}$ are not comparable.
7. Consider the following topologies on $\mathbb{R}$ :

$$
\begin{aligned}
& \mathcal{T}_{1}=\text { the standard topology, } \\
& \mathcal{T}_{2}=\text { the topology of } \mathbb{R}_{K}, \\
& \mathcal{T}_{3}=\text { the finite complement topology, } \\
& \mathcal{T}_{4}=\text { the upper limit topology, having all sets }(a, b] \text { as basis, } \\
& \mathcal{T}_{5}=\text { the topology having all sets }(-\infty, a)=\{x \mid x<a\} \text { as basis. }
\end{aligned}
$$

Determine, for each of these topologies, which of the others it contains.

8. (a) Apply Lemma 13.2 to show that the countable collection

$$
\mathscr{B}=\{(a, b) \mid a<b, a \text { and } b \text { rational }\}
$$

is a basis that generates the standard topology on $\mathbb{R}$.

(b) Show that the collection

$$
\mathcal{C}=\{[a, b) \mid a<b, a \text { and } b \text { rational }\}
$$

is a basis that generates a topology different from the lower limit topology on $\mathbb{R}$.

## §14 The Order Topology

If $X$ is a simply ordered set, there is a standard topology for $X$, defined using the order relation. It is called the order topology; in this section, we consider it and study some of its properties.

Suppose that $X$ is a set having a simple order relation $<$. Given elements $a$ and $b$ of $X$ such that $a<b$, there are four subsets of $X$ that are called the intervals determined by $a$ and $b$. They are the following :

$$
\begin{aligned}
& (a, b)=\{x \mid a<x<b\}, \\
& (a, b]=\{x \mid a<x \leq b\}, \\
& {[a, b)=\{x \mid a \leq x<b\},} \\
& {[a, b]=\{x \mid a \leq x \leq b\} .}
\end{aligned}
$$

The notation used here is familiar to you already in the case where $X$ is the real line, but these are intervals in an arbitrary ordered set. A set of the first type is called an open interval in $X$, a set of the last type is called a closed interval in $X$, and sets of the second and third types are called half-open intervals. The use of the term "open" in this connection suggests that open intervals in $X$ should turn out to be open sets when we put a topology on $X$. And so they will.

Definition. Let $X$ be a set with a simple order relation; assume $X$ has more than one element. Let $\mathscr{B}$ be the collection of all sets of the following types:

(1) All open intervals $(a, b)$ in $X$.

(2) All intervals of the form $\left[a_{0}, b\right.$ ), where $a_{0}$ is the smallest element (if any) of $X$.

(3) All intervals of the form $\left(a, b_{0}\right]$, where $b_{0}$ is the largest element (if any) of $X$. The collection $\mathscr{B}$ is a basis for a topology on $X$, which is called the order topology.

If $X$ has no smallest element, there are no sets of type (2), and if $X$ has no largest element, there are no sets of type (3).

One has to check that $\mathscr{B}$ satisfies the requirements for a basis. First, note that every element $x$ of $X$ lies in at least one element of $\mathscr{B}$ : The smallest element (if any) lies in all sets of type (2), the largest element (if any) lies in all sets of type (3), and every other element lies in a set of type (1). Second, note that the intersection of any two sets of the preceding types is again a set of one of these types, or is empty. Several cases need to be checked; we leave it to you.

EXAMPLE 1. The standard topology on $\mathbb{R}$, as defined in the preceding section, is just the order topology derived from the usual order on $\mathbb{R}$.

EXAMPLE 2. Consider the set $\mathbb{R} \times \mathbb{R}$ in the dictionary order; we shall denote the general element of $\mathbb{R} \times \mathbb{R}$ by $x \times y$, to avoid difficulty with notation. The set $\mathbb{R} \times \mathbb{R}$ has neither a largest nor a smallest element, so the order topology on $\mathbb{R} \times \mathbb{R}$ has as basis the collection of all open intervals of the form $(a \times b, c \times d)$ for $a<c$, and for $a=c$ and $b<d$. These two types of intervals are indicated in Figure 14.1. The subcollection consisting of only intervals of the second type is also a basis for the order topology on $\mathbb{R} \times \mathbb{R}$, as you can check.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-086.jpg?height=480&width=1022&top_left_y=787&top_left_x=506)

Figure 14.1

EXAMPLE 3. The positive integers $\mathbb{Z}_{+}$form an ordered set with a smallest element. The order topology on $\mathbb{Z}_{+}$is the discrete topology, for every one-point set is open: If $n>1$, then the one-point set $\{n\}=(n-1, n+1)$ is a basis element; and if $n=1$, the one-point set $\{1\}=[1,2)$ is a basis element.

EXAMPle 4. The set $X=\{1,2\} \times \mathbb{Z}_{+}$in the dictionary order is another example of an ordered set with a smallest element. Denoting $1 \times n$ by $a_{n}$ and $2 \times n$ by $b_{n}$, we can represent $X$ by

$$
a_{1}, a_{2}, \ldots ; b_{1}, b_{2}, \ldots
$$

The order topology on $X$ is not the discrete topology. Most one-point sets are open, but there is an exception-the one-point set $\left\{b_{1}\right\}$. Any open set containing $b_{1}$ must contain a basis element about $b_{1}$ (by definition), and any basis element containing $b_{1}$ contains points of the $a_{i}$ sequence.

Definition. If $X$ is an ordered set, and $a$ is an element of $X$, there are four subsets of $X$ that are called the rays determined by $a$. They are the following:

$$
\begin{aligned}
& (a,+\infty)=\{x \mid x>a\}, \\
& (-\infty, a)=\{x \mid x<a\}, \\
& {[a,+\infty)=\{x \mid x \geq a\},} \\
& (-\infty, a]=\{x \mid x \leq a\} .
\end{aligned}
$$

Sets of the first two types are called open rays, and sets of the last two types are called closed rays.

The use of the term "open" suggests that open rays in $X$ are open sets in the order topology. And so they are. Consider, for example, the ray $(a,+\infty)$. If $X$ has a largest element $b_{0}$, then $(a,+\infty)$ equals the basis element $\left(a, b_{0}\right]$. If $X$ has no largest element, then $(a,+\infty)$ equals the union of all basis elements of the form $(a, x)$, for $x>a$. In either case, $(a,+\infty)$ is open. A similar argument applies to the ray $(-\infty, a)$.

The open rays, in fact, form a subbasis for the order topology on $X$, as we now show. Because the open rays are open in the order topology, the topology they generate is contained in the order topology. On the other hand, every basis element for the order topology equals a finite intersection of open rays; the interval $(a, b)$ equals the intersection of $(-\infty, b)$ and $(a,+\infty)$, while $\left[a_{0}, b\right)$ and $\left(a, b_{0}\right]$, if they exist, are themselves open rays. Hence the topology generated by the open rays contains the order topology.

## §15 The Product Topology on $X \times Y$

If $X$ and $Y$ are topological spaces, there is a standard way of defining a topology on the cartesian product $X \times Y$. We consider this topology now and study some of its properties.

Definition. Let $X$ and $Y$ be topological spaces. The product topology on $X \times Y$ is the topology having as basis the collection $\mathcal{B}$ of all sets of the form $U \times V$, where $U$ is an open subset of $X$ and $V$ is an open subset of $Y$.

Let us check that $\mathscr{B}$ is a basis. The first condition is trivial, since $X \times Y$ is itself a basis element. The second condition is almost as easy, since the intersection of any two basis elements $U_{1} \times V_{1}$ and $U_{2} \times V_{2}$ is another basis element. For

$$
\left(U_{1} \times V_{1}\right) \cap\left(U_{2} \times V_{2}\right)=\left(U_{1} \cap U_{2}\right) \times\left(V_{1} \cap V_{2}\right)
$$

and the latter set is a basis element because $U_{1} \cap U_{2}$ and $V_{1} \cap V_{2}$ are open in $X$ and $Y$, respectively. See Figure 15.1.

Note that the collection $\mathscr{B}$ is not a topology on $X \times Y$. The union of the two rectangles pictured in Figure 15.1, for instance, is not a product of two sets, so it cannot belong to $\mathcal{B}$; however, it is open in $X \times Y$.

Each time we introduce a new concept, we shall try to relate it to the concepts that have been previously introduced. In the present case, we ask: What can one say if the topologies on $X$ and $Y$ are given by bases? The answer is as follows:

Theorem 15.1. If $\mathcal{B}$ is a basis for the topology of $X$ and $\mathcal{C}$ is a basis for the topology of $Y$, then the collection

$$
\mathscr{D}=\{B \times C \mid B \in \mathscr{B} \text { and } C \in \mathcal{C}\}
$$

is a basis for the topology of $X \times Y$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-088.jpg?height=461&width=857&top_left_y=361&top_left_x=593)

Figure 15.1

Proof. We apply Lemma 13.2. Given an open set $W$ of $X \times Y$ and a point $x \times y$ of $W$, by definition of the product topology there is a basis element $U \times V$ such that $x \times y \in U \times V \subset W$. Because $\mathcal{B}$ and $\mathcal{C}$ are bases for $X$ and $Y$, respectively, we can choose an element $B$ of $\mathscr{B}$ such that $x \in B \subset U$, and an element $C$ of $\mathcal{C}$ such that $y \in C \subset V$. Then $x \times y \in B \times C \subset W$. Thus the collection $D$ meets the criterion of Lemma 13.2, so $\mathscr{D}$ is a basis for $X \times Y$.

EXAMPLE 1. We have a standard topology on $\mathbb{R}$ : the order topology. The product of this topology with itself is called the standard topology on $\mathbb{R} \times \mathbb{R}=\mathbb{R}^{2}$. It has as basis the collection of all products of open sets of $\mathbb{R}$, but the theorem just proved tells us that the much smaller collection of all products $(a, b) \times(c, d)$ of open intervals in $\mathbb{R}$ will also serve as a basis for the topology of $\mathbb{R}^{2}$. Each such set can be pictured as the interior of a rectangle in $\mathbb{R}^{2}$. Thus the standard topology on $\mathbb{R}^{2}$ is just the one we considered in Example 2 of $\S 13$.

It is sometimes useful to express the product topology in terms of a subbasis. To do this, we first define certain functions called projections.

Definition. Let $\pi_{1}: X \times Y \rightarrow X$ be defined by the equation

$$
\pi_{1}(x, y)=x
$$

let $\pi_{2}: X \times Y \rightarrow Y$ be defined by the equation

$$
\pi_{2}(x, y)=y .
$$

The maps $\pi_{1}$ and $\pi_{2}$ are called the projections of $X \times Y$ onto its first and second factors, respectively.

We use the word "onto" because $\pi_{1}$ and $\pi_{2}$ are surjective (unless one of the spaces $X$ or $Y$ happens to be empty, in which case $X \times Y$ is empty and our whole discussion is empty as well!).

If $U$ is an open subset of $X$, then the set $\pi_{1}^{-1}(U)$ is precisely the set $U \times Y$, which is open in $X \times Y$. Similarly, if $V$ is open in $Y$, then

$$
\pi_{2}^{-1}(V)=X \times V
$$

which is also open in $X \times Y$. The intersection of these two sets is the set $U \times V$, as indicated in Figure 15.2. This fact leads to the following theorem:

Theorem 15.2. The collection

$$
S=\left\{\pi_{1}^{-1}(U) \mid U \text { open in } X\right\} \cup\left\{\pi_{2}^{-1}(V) \mid V \text { open in } Y\right\}
$$

is a subbasis for the product topology on $X \times Y$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-089.jpg?height=602&width=894&top_left_y=770&top_left_x=749)

Figure 15.2

Proof. Let $\mathcal{T}$ denote the product topology on $X \times Y$; let $\mathcal{T}^{\prime}$ be the topology generated by $\mathcal{S}$. Because every element of $\mathcal{S}$ belongs to $\mathcal{T}$, so do arbitrary unions of finite intersections of elements of $\mathcal{S}$. Thus $\mathcal{T}^{\prime} \subset \mathcal{T}$. On the other hand, every basis element $U \times V$ for the topology $\mathcal{T}$ is a finite intersection of elements of $\mathcal{S}$, since

$$
U \times V=\pi_{1}^{-1}(U) \cap \pi_{2}^{-1}(V) .
$$

Therefore, $U \times V$ belongs to $\mathcal{T}^{\prime}$, so that $\mathcal{T} \subset \mathcal{T}^{\prime}$ as well.

## $\$ 16$ The Subspace Topology

Definition. Let $X$ be a topological space with topology $\mathcal{T}$. If $Y$ is a subset of $X$, the collection

$$
\mathcal{T}_{Y}=\{Y \cap U \mid U \in \mathcal{T}\}
$$

is a topology on $Y$, called the subspace topology. With this topology, $Y$ is called a subspace of $X$; its open sets consist of all intersections of open sets of $X$ with $Y$.

It is easy to see that $\mathcal{T}_{Y}$ is a topology. It contains $\varnothing$ and $Y$ because

$$
\varnothing=Y \cap \varnothing \quad \text { and } \quad Y=Y \cap X
$$

where $\varnothing$ and $X$ are elements of $\mathcal{T}$. The fact that it is closed under finite intersections and arbitrary unions follows from the equations

$$
\begin{aligned}
\left(U_{1} \cap Y\right) \cap \cdots \cap\left(U_{n} \cap Y\right) & =\left(U_{1} \cap \cdots \cap U_{n}\right) \cap Y \\
\bigcup_{\alpha \in J}\left(U_{\alpha} \cap Y\right) & =\left(\bigcup_{\alpha \in J} U_{\alpha}\right) \cap Y .
\end{aligned}
$$

Lemma 16.1. If $\mathscr{B}$ is a basis for the topology of $X$ then the collection

$$
\mathscr{B}_{Y}=\{B \cap Y \mid B \in \mathscr{B}\}
$$

is a basis for the subspace topology on $Y$.

Proof. Given $U$ open in $X$ and given $y \in U \cap Y$, we can choose an element $B$ of $\mathscr{B}$ such that $y \in B \subset U$. Then $y \in B \cap Y \subset U \cap Y$. It follows from Lemma 13.2 that $\mathscr{B}_{Y}$ is a basis for the subspace topology on $Y$.

When dealing with a space $X$ and a subspace $Y$, one needs to be careful when one uses the term "open set". Does one mean an element of the topology of $Y$ or an element of the topology of $X$ ? We make the following definition: If $Y$ is a subspace of $X$, we say that a set $U$ is open in $Y$ (or open relative to $Y$ ) if it belongs to the topology of $Y$; this implies in particular that it is a subset of $Y$. We say that $U$ is open in $X$ if it belongs to the topology of $X$.

There is a special situation in which every set open in $Y$ is also open in $X$ :

Lemma 16.2. Let $Y$ be a subspace of $X$. If $U$ is open in $Y$ and $Y$ is open in $X$, then $U$ is open in $X$.

Proof. Since $U$ is open in $Y, U=Y \cap V$ for some set $V$ open in $X$. Since $Y$ and $V$ are both open in $X$, so is $Y \cap V$.

Now let us explore the relation between the subspace topology and the order and product topologies. For product topologies, the result is what one might expect; for order topologies, it is not.

Theorem 16.3. If $A$ is a subspace of $X$ and $B$ is a subspace of $Y$, then the product topology on $A \times B$ is the same as the topology $A \times B$ inherits as a subspace of $X \times Y$.

Proof. The set $U \times V$ is the general basis element for $X \times Y$, where $U$ is open in $X$ and $V$ is open in $Y$. Therefore, $(U \times V) \cap(A \times B)$ is the general basis element for the subspace topology on $A \times B$. Now

$$
(U \times V) \cap(A \times B)=(U \cap A) \times(V \cap B)
$$

Since $U \cap A$ and $V \cap B$ are the general open sets for the subspace topologies on $A$ and $B$, respectively, the set $(U \cap A) \times(V \cap B)$ is the general basis element for the product topology on $A \times B$.

The conclusion we draw is that the bases for the subspace topology on $A \times B$ and for the product topology on $A \times B$ are the same. Hence the topologies are the same.

Now let $X$ be an ordered set in the order topology, and let $Y$ be a subset of $X$. The order relation on $X$, when restricted to $Y$, makes $Y$ into an ordered set. However, the resulting order topology on $Y$ need not be the same as the topology that $Y$ inherits as a subspace of $X$. We give one example where the subspace and order topologies on $Y$ agree, and two examples where they do not.

EXAMPLE 1. Consider the subset $Y=[0,1]$ of the real line $\mathbb{R}$, in the subspace topology. The subspace topology has as basis all sets of the form $(a, b) \cap Y$, where $(a, b)$ is an open interval in $\mathbb{R}$. Such a set is of one of the following types:

$$
(a, b) \cap Y= \begin{cases}(a, b) & \text { if } a \text { and } b \text { are in } Y, \\ {[0, b)} & \text { if only } b \text { is in } Y, \\ (a, 1] & \text { if only } a \text { is in } Y, \\ Y \text { or } \varnothing & \text { if neither } a \text { nor } b \text { is in } Y .\end{cases}
$$

By definition, each of these sets is open in $Y$. But sets of the second and third types are not open in the larger space $\mathbb{R}$.

Note that these sets form a basis for the order topology on $Y$. Thus, we see that in the case of the set $Y=[0,1]$, its subspace topology (as a subspace of $\mathbb{R}$ ) and its order topology are the same.

EXAMPLE 2. Let $Y$ be the subset $[0,1) \cup\{2\}$ of $\mathbb{R}$. In the subspace topology on $Y$ the one-point set $\{2\}$ is open, because it is the intersection of the open set $\left(\frac{3}{2}, \frac{5}{2}\right)$ with $Y$. But in the order topology on $Y$, the set $\{2\}$ is not open. Any basis element for the order topology on $Y$ that contains 2 is of the form

$$
\{x \mid x \in Y \text { and } a<x \leq 2\}
$$

for some $a \in Y$; such a set necessarily contains points of $Y$ less than 2 .

EXAmple 3. Let $I=[0,1]$. The dictionary order on $I \times I$ is just the restriction to $I \times I$ of the dictionary order on the plane $\mathbb{R} \times \mathbb{R}$. However, the dictionary order topology on $I \times I$ is not the same as the subspace topology on $I \times I$ obtained from the dictionary order topology on $\mathbb{R} \times \mathbb{R}$ ! For example, the set $\{1 / 2\} \times(1 / 2,1]$ is open in $I \times I$ in the subspace topology, but not in the order topology, as you can check. See Figure 16.1.

The set $I \times I$ in the dictionary order topology will be called the ordered square, and denoted by $I_{o}^{2}$.

The anomaly illustrated in Examples 2 and 3 does not occur for intervals or rays in an ordered set $X$. This we now prove.

Given an ordered set $X$, let us say that a subset $Y$ of $X$ is convex in $X$ if for each pair of points $a<b$ of $Y$, the entire interval $(a, b)$ of points of $X$ lies in $Y$. Note that intervals and rays in $X$ are convex in $X$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-092.jpg?height=508&width=408&top_left_y=357&top_left_x=507)

Subspace

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-092.jpg?height=402&width=399&top_left_y=465&top_left_x=1130)

Order

Figure 16.1

Theorem 16.4. Let $X$ be an ordered set in the order topology; let $Y$ be a subset of $X$ that is convex in $X$. Then the order topology on $Y$ is the same as the topology $Y$ inherits as a subspace of $X$.

Proof. Consider the ray $(a,+\infty)$ in $X$. What is its intersection with $Y$ ? If $a \in Y$, then

$$
(a,+\infty) \cap Y=\{x \mid x \in Y \text { and } x>a\}
$$

this is an open ray of the ordered set $Y$. If $a \notin Y$, then $a$ is either a lower bound on $Y$

or an upper bound on $Y$, since $Y$ is convex. In the former case, the set $(a,+\infty) \cap Y$ equals all of $Y$; in the latter case, it is empty.

A similar remark shows that the intersection of the ray $(-\infty, a)$ with $Y$ is either an open ray of $Y$, or $Y$ itself, or empty. Since the sets $(a,+\infty) \cap Y$ and $(-\infty, a) \cap Y$ form a subbasis for the subspace topology on $Y$, and since each is open in the order topology, the order topology contains the subspace topology.

To prove the reverse, note that any open ray of $Y$ equals the intersection of an open ray of $X$ with $Y$, so it is open in the subspace topology on $Y$. Since the open rays of $Y$ are a subbasis for the order topology on $Y$, this topology is contained in the subspace topology.

To avoid ambiguity, let us agree that whenever $X$ is an ordered set in the order topology and $Y$ is a subset of $X$, we shall assume that $Y$ is given the subspace topology unless we specifically state otherwise. If $Y$ is convex in $X$, this is the same as the order topology on $Y$; otherwise, it may not be.

## Exercises

1. Show that if $Y$ is a subspace of $X$, and $A$ is a subset of $Y$, then the topology $A$
inherits as a subspace of $Y$ is the same as the topology it inherits as a subspace of $X$.
2. If $\mathcal{T}$ and $\mathcal{T}^{\prime}$ are topologies on $X$ and $\mathcal{T}^{\prime}$ is strictly finer than $\mathcal{T}$, what can you say about the corresponding subspace topologies on the subset $Y$ of $X$ ?
3. Consider the set $Y=[-1,1]$ as a subspace of $\mathbb{R}$. Which of the following sets are open in $Y$ ? Which are open in $\mathbb{R}$ ?

$$
\begin{aligned}
A & =\left\{\left.x\left|\frac{1}{2}<\right| x \right\rvert\,<1\right\} \\
B & =\left\{\left.x\left|\frac{1}{2}<\right| x \right\rvert\, \leq 1\right\}, \\
C & =\left\{\left.x\left|\frac{1}{2} \leq\right| x \right\rvert\,<1\right\}, \\
D & =\left\{\left.x\left|\frac{1}{2} \leq\right| x \right\rvert\, \leq 1\right\}, \\
E & =\left\{x|0<| x \mid<1 \text { and } 1 / x \notin \mathbb{Z}_{+}\right\} .
\end{aligned}
$$

4. A map $f: X \rightarrow Y$ is said to be an open map if for every open set $U$ of $X$, the set $f(U)$ is open in $Y$. Show that $\pi_{1}: X \times Y \rightarrow X$ and $\pi_{2}: X \times Y \rightarrow Y$ are open maps.
5. Let $X$ and $X^{\prime}$ denote a single set in the topologies $\mathcal{T}$ and $\mathcal{T}^{\prime}$, respectively; let $Y$ and $Y^{\prime}$ denote a single set in the topologies $U$ and $\mathcal{U}^{\prime}$, respectively. Assume these sets are nonempty.

(a) Show that if $\mathcal{T}^{\prime} \supset \mathcal{T}$ and $\mathcal{U}^{\prime} \supset \mathcal{U}$, then the product topology on $X^{\prime} \times Y^{\prime}$ is finer than the product topology on $X \times Y$.

(b) Does the converse of (a) hold? Justify your answer.

6. Show that the countable collection

$$
\{(a, b) \times(c, d) \mid a<b \text { and } c<d, \text { and } a, b, c, d \text { are rational }\}
$$

is a basis for $\mathbb{R}^{2}$.

7. Let $X$ be an ordered set. If $Y$ is a proper subset of $X$ that is convex in $X$, does it follow that $Y$ is an interval or a ray in $X$ ?
8. If $L$ is a straight line in the plane, describe the topology $L$ inherits as a subspace of $\mathbb{R}_{\ell} \times \mathbb{R}$ and as a subspace of $\mathbb{R}_{\ell} \times \mathbb{R}_{\ell}$. In each case it is a familiar topology.
9. Show that the dictionary order topology on the set $\mathbb{R} \times \mathbb{R}$ is the same as the product topology $\mathbb{R}_{d} \times \mathbb{R}$, where $\mathbb{R}_{d}$ denotes $\mathbb{R}$ in the discrete topology. Compare this topology with the standard topology on $\mathbb{R}^{2}$.
10. Let $I=[0,1]$. Compare the product topology on $I \times I$, the dictionary order topology on $I \times I$, and the topology $I \times I$ inherits as a subspace of $\mathbb{R} \times \mathbb{R}$ in the dictionary order topology.

## §17 Closed Sets and Limit Points

Now that we have a few examples at hand, we can introduce some of the basic concepts associated with topological spaces. In this section, we treat the notions of closed set,
closure of a set, and limit point. These lead naturally to consideration of a certain axiom for topological spaces called the Hausdorff axiom.

## Closed Sets

A subset $A$ of a topological space $X$ is said to be closed if the set $X-A$ is open.

EXAmPLE 1. The subset $[a, b]$ of $\mathbb{R}$ is closed because its complement

$$
\mathbb{R}-[a, b]=(-\infty, a) \cup(b,+\infty),
$$

is open. Similarly, $[a,+\infty)$ is closed, because its complement $(-\infty, a)$ is open. These facts justify our use of the terms "closed interval" and "closed ray." The subset $[a, b)$ of $\mathbb{R}$ is neither open nor closed.

EXAMPlE 2. In the plane $\mathbb{R}^{2}$, the set

$$
\{x \times y \mid x \geq 0 \text { and } y \geq 0\}
$$

is closed, because its complement is the union of the two sets

$$
(-\infty, 0) \times \mathbb{R} \quad \text { and } \quad \mathbb{R} \times(-\infty, 0)
$$

each of which is a product of open sets of $\mathbb{R}$ and is, therefore, open in $\mathbb{R}^{2}$.

EXAMPLE 3. In the finite complement topology on a set $X$, the closed sets consist of $X$ itself and all finite subsets of $X$.

EXAmple 4. In the discrete topology on the set $X$, every set is open; it follows that every set is closed as well.

EXAMPLE 5. Consider the following subset of the real line:

$$
Y=[0,1] \cup(2,3),
$$

in the subspace topology. In this space, the set $[0,1]$ is open, since it is the intersection of the open set $\left(-\frac{1}{2}, \frac{3}{2}\right)$ of $\mathbb{R}$ with $Y$. Similarly, $(2,3)$ is open as a subset of $Y$; it is even open as a subset of $\mathbb{R}$. Since $[0,1]$ and $(2,3)$ are complements in $Y$ of each other, we conclude that both $[0,1]$ and $(2,3)$ are closed as subsets of $Y$.

These examples suggest that an answer to the mathematician's riddle: "How is a set different from a door?" should be: "A door must be either open or closed, and cannot be both, while a set can be open, or closed, or both, or neither!"

The collection of closed subsets of a space $X$ has properties similar to those satisfied by the collection of open subsets of $X$ :

Theorem 17.1. Let $X$ be a topological space. Then the following conditions hold:

(1) $\varnothing$ and $X$ are closed.

(2) Arbitrary intersections of closed sets are closed.

(3) Finite unions of closed sets are closed.

Proof. (1) $\varnothing$ and $X$ are closed because they are the complements of the open sets $X$ and $\varnothing$, respectively.

(2) Given a collection of closed sets $\left\{A_{\alpha}\right\}_{\alpha \in J}$, we apply DeMorgan's law,

$$
X-\bigcap_{\alpha \in J} A_{\alpha}=\bigcup_{\alpha \in J}\left(X-A_{\alpha}\right)
$$

Since the sets $X-A_{\alpha}$ are open by definition, the right side of this equation represents an arbitrary union of open sets, and is thus open. Therefore, $\bigcap A_{\alpha}$ is closed.

(3) Similarly, if $A_{i}$ is closed for $i=1, \ldots, n$, consider the equation

$$
X-\bigcup_{i=1}^{n} A_{i}=\bigcap_{i=1}^{n}\left(X-A_{i}\right)
$$

The set on the right side of this equation is a finite intersection of open sets and is therefore open. Hence $\bigcup A_{i}$ is closed.

Instead of using open sets, one could just as well specify a topology on a space by giving a collection of sets (to be called "closed sets") satisfying the three properties of this theorem. One could then define open sets as the complements of closed sets and proceed just as before. This procedure has no particular advantage over the one we have adopted, and most mathematicians prefer to use open sets to define topologies.

Now when dealing with subspaces, one needs to be careful in using the term "closed set." If $Y$ is a subspace of $X$, we say that a set $A$ is closed in $Y$ if $A$ is a subset of $Y$ and if $A$ is closed in the subspace topology of $Y$ (that is, if $Y-A$ is open in $Y$ ). We have the following theorem:

Theorem 17.2. Let $Y$ be a subspace of $X$. Then a set $A$ is closed in $Y$ if and only if it equals the intersection of a closed set of $X$ with $Y$.

Proof. Assume that $A=C \cap Y$, where $C$ is closed in $X$. (See Figure 17.1.) Then $X-C$ is open in $X$, so that $(X-C) \cap Y$ is open in $Y$, by definition of the subspace topology. But $(X-C) \cap Y=Y-A$. Hence $Y-A$ is open in $Y$, so that $A$ is closed in $Y$. Conversely, assume that $A$ is closed in $Y$. (See Figure 17.2.) Then $Y-A$ is open in $Y$, so that by definition it equals the intersection of an open set $U$ of $X$ with $Y$. The set $X-U$ is closed in $X$, and $A=Y \cap(X-U)$, so that $A$ equals the intersection of a closed set of $X$ with $Y$, as desired.

A set $A$ that is closed in the subspace $Y$ may or may not be closed in the larger space $X$. As was the case with open sets, there is a criterion for $A$ to be closed in $X$; we leave the proof to you:

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-096.jpg?height=358&width=474&top_left_y=371&top_left_x=479)

Figure 17.1

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-096.jpg?height=355&width=549&top_left_y=372&top_left_x=1030)

Figure 17.2

Theorem 17.3. Let $Y$ be a subspace of $X$. If $A$ is closed in $Y$ and $Y$ is closed in $X$, then $A$ is closed in $X$.

## Closure and Interior of a Set

Given a subset $A$ of a topological space $X$, the interior of $A$ is defined as the union of all open sets contained in $A$, and the closure of $A$ is defined as the intersection of all closed sets containing $A$.

The interior of $A$ is denoted by $\operatorname{Int} A$ and the closure of $A$ is denoted by $\mathrm{Cl} A$ or by $\bar{A}$. Obviously Int $A$ is an open set and $\bar{A}$ is a closed set; furthermore,

$$
\text { Int } A \subset A \subset \bar{A} \text {. }
$$

If $A$ is open, $A=\operatorname{Int} A$; while if $A$ is closed, $A=\bar{A}$.

We shall not make much use of the interior of a set, but the closure of a set will be quite important.

When dealing with a topological space $X$ and a subspace $Y$, one needs to exercise care in taking closures of sets. If $A$ is a subset of $Y$, the closure of $A$ in $Y$ and the closure of $A$ in $X$ will in general be different. In such a situation, we reserve the notation $\bar{A}$ to stand for the closure of $A$ in $X$. The closure of $A$ in $Y$ can be expressed in terms of $\bar{A}$, as the following theorem shows:

Theorem 17.4. Let $Y$ be a subspace of $X$; let $A$ be a subset of $Y$; let $\bar{A}$ denote the closure of $A$ in $X$. Then the closure of $A$ in $Y$ equals $\bar{A} \cap Y$.

Proof. Let $B$ denote the closure of $A$ in $Y$. The set $\bar{A}$ is closed in $X$, so $\bar{A} \cap Y$ is closed in $Y$ by Theorem 17.2. Since $\bar{A} \cap Y$ contains $A$, and since by definition $B$ equals the intersection of all closed subsets of $Y$ containing $A$, we must have $B \subset(\bar{A} \cap Y)$.

On the other hand, we know that $B$ is closed in $Y$. Hence by Theorem 17.2, $B=C \cap Y$ for some set $C$ closed in $X$. Then $C$ is a closed set of $X$ containing $A$; because $\bar{A}$ is the intersection of all such closed sets, we conclude that $\bar{A} \subset C$. Then $(\bar{A} \cap Y) \subset(C \cap Y)=B$.

The definition of the closure of a set does not give us a convenient way for actually finding the closures of specific sets, since the collection of all closed sets in $X$, like the collection of all open sets, is usually much too big to work with. Another way of describing the closure of a set, useful because it involves only a basis for the topology of $X$, is given in the following theorem.

First let us introduce some convenient terminology. We shall say that a set $A$ intersects a set $B$ if the intersection $A \cap B$ is not empty.

Theorem 17.5. Let $A$ be a subset of the topological space $X$.

(a) Then $x \in \bar{A}$ if and only if every open set $U$ containing $x$ intersects $A$.

(b) Supposing the topology of $X$ is given by a basis, then $x \in \bar{A}$ if and only if every basis element $B$ containing $x$ intersects $A$.

Proof. Consider the statement in (a). It is a statement of the form $P \Leftrightarrow Q$. Let us transform each implication to its contrapositive, thereby obtaining the logically equivalent statement (not $P) \Leftrightarrow($ not $Q$ ). Written out, it is the following:

$x \notin \bar{A} \Longleftrightarrow$ there exists an open set $U$ containing $x$ that does not intersect $A$.

In this form, our theorem is easy to prove. If $x$ is not in $\bar{A}$, the set $U=X-\bar{A}$ is an open set containing $x$ that does not intersect $A$, as desired. Conversely, if there exists an open set $U$ containing $x$ which does not intersect $A$, then $X-U$ is a closed set containing $A$. By definition of the closure $\bar{A}$, the set $X-U$ must contain $\bar{A}$; therefore, $x$ cannot be in $\bar{A}$.

Statement (b) follows readily. If every open set containing $x$ intersects $A$, so does every basis element $B$ containing $x$, because $B$ is an open set. Conversely, if every basis element containing $x$ intersects $A$, so does every open set $U$ containing $x$, because $U$ contains a basis element that contains $x$.

Mathematicians often use some special terminology here. They shorten the statement " $U$ is an open set containing $x$ " to the phrase

## " $U$ is a neighborhood of $x$."

Using this terminology, one can write the first half of the preceding theorem as follows:

If $A$ is a subset of the topological space $X$, then $x \in \bar{A}$ if and only if every neighborhood of $x$ intersects $A$.

EXAMPle 6. Let $X$ be the real line $\mathbb{R}$. If $A=(0,1]$, then $\bar{A}=[0,1]$, for every neighborhood of 0 intersects $A$, while every point outside $[0,1]$ has a neighborhood disjoint from $A$. Similar arguments apply to the following subsets of $X$ :

If $B=\left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}$, then $\bar{B}=\{0\} \cup B$. If $C=\{0\} \cup(1,2)$, then $\bar{C}=\{0\} \cup[1,2]$. If $\mathbb{Q}$ is the set of rational numbers, then $\overline{\mathbb{Q}}=\mathbb{R}$. If $\mathbb{Z}_{+}$is the set of positive integers, then $\overline{\mathbb{Z}}_{+}=\mathbb{Z}_{+}$. If $\mathbb{R}_{+}$is the set of positive reals, then the closure of $\mathbb{R}_{+}$is the set $\mathbb{R}_{+} \cup\{0\}$. (This is the reason we introduced the notation $\overline{\mathbb{R}}_{+}$for the set $\mathbb{R}_{+} \cup\{0\}$, back in $\S 2$.)

EXAMPLE 7. Consider the subspace $Y=(0,1]$ of the real line $\mathbb{R}$. The set $A=\left(0, \frac{1}{2}\right)$ is a subset of $Y$; its closure in $\mathbb{R}$ is the set $\left[0, \frac{1}{2}\right]$, and its closure in $Y$ is the set $\left[0, \frac{1}{2}\right] \cap Y=$ $\left(0, \frac{1}{2}\right]$.

Some mathematicians use the term "neighborhood" differently. They say that $A$ is a neighborhood of $x$ if $A$ merely contains an open set containing $x$. We shall not follow this practice.

## Limit Points

There is yet another way of describing the closure of a set, a way that involves the important concept of limit point, which we consider now.

If $A$ is a subset of the topological space $X$ and if $x$ is a point of $X$, we say that $x$ is a limit point (or "cluster point," or "point of accumulation") of $A$ if every neighborhood of $x$ intersects $A$ in some point other than $x$ itself. Said differently, $x$ is a limit point of $A$ if it belongs to the closure of $A-\{x\}$. The point $x$ may lie in $A$ or not; for this definition it does not matter.

EXAMPLE 8. Consider the real line $\mathbb{R}$. If $A=(0,1]$, then the point 0 is a limit point of $A$ and so is the point $\frac{1}{2}$. In fact, every point of the interval $[0,1]$ is a limit point of $A$, but no other point of $\mathbb{R}$ is a limit point of $A$.

If $B=\left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}$, then 0 is the only limit point of $B$. Every other point $x$ of $\mathbb{R}$ has a neighborhood that either does not intersect $B$ at all, or it intersects $B$ only in the point $x$ itself. If $C=\{0\} \cup(1,2)$, then the limit points of $C$ are the points of the interval [1,2]. If $\mathbb{Q}$ is the set of rational numbers, every point of $\mathbb{R}$ is a limit point of $\mathbb{Q}$. If $\mathbb{Z}_{+}$is the set of positive integers, no point of $\mathbb{R}$ is a limit point of $\mathbb{Z}_{+}$. If $\mathbb{R}_{+}$is the set of positive reals, then every point of $\{0\} \cup \mathbb{R}_{+}$is a limit point of $\mathbb{R}_{+}$.

Comparison of Examples 6 and 8 suggests a relationship between the closure of a set and the limit points of a set. That relationship is given in the following theorem:

Theorem 17.6. Let $A$ be a subset of the topological space $X$; let $A^{\prime}$ be the set of all limit points of $A$. Then

$$
\bar{A}=A \cup A^{\prime} .
$$

Proof. If $x$ is in $A^{\prime}$, every neighborhood of $x$ intersects $A$ (in a point different from $x$ ). Therefore, by Theorem $17.5, x$ belongs to $\bar{A}$. Hence $A^{\prime} \subset \bar{A}$. Since by definition $A \subset \bar{A}$, it follows that $A \cup A^{\prime} \subset \bar{A}$.

To demonstrate the reverse inclusion, we let $x$ be a point of $\bar{A}$ and show that $x \in A \cup A^{\prime}$. If $x$ happens to lie in $A$, it is trivial that $x \in A \cup A^{\prime}$; suppose that $x$ does not lie in $A$. Since $x \in \bar{A}$, we know that every neighborhood $U$ of $x$ intersects $A$; because $x \notin A$, the set $U$ must intersect $A$ in a point different from $x$. Then $x \in A^{\prime}$, so that $x \in A \cup A^{\prime}$, as desired.

Corollary 17.7. A subset of a topological space is closed if and only if it contains all its limit points.

Proof. The set $A$ is closed if and only if $A=\bar{A}$, and the latter holds if and only if $A^{\prime} \subset A$.

## Hausdorff Spaces

One's experience with open and closed sets and limit points in the real line and the plane can be misleading when one considers more general topological spaces. For example, in the spaces $\mathbb{R}$ and $\mathbb{R}^{2}$, each one-point set $\left\{x_{0}\right\}$ closed. This fact is easily proved; every point different from $x_{0}$ has a neighborhood not intersecting $\left\{x_{0}\right\}$, so that $\left\{x_{0}\right\}$ is its own closure. But this fact is not true for arbitrary topological spaces. Consider the topology on the three-point set $\{a, b, c\}$ indicated in Figure 17.3. In this space, the one-point set $\{b\}$ is not closed, for its complement is not open.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-099.jpg?height=174&width=310&top_left_y=1051&top_left_x=1044)

Figure 17.3

Similarly, one's experience with the properties of convergent sequences in $\mathbb{R}$ and $\mathbb{R}^{2}$ can be misleading when one deals with more general topological spaces. In an arbitrary topological space, one says that a sequence $x_{1}, x_{2}, \ldots$ of points of the space $X$ converges to the point $x$ of $X$ provided that, corresponding to each neighborhood $U$ of $x$, there is a positive integer $N$ such that $x_{n} \in U$ for all $n \geq N$. In $\mathbb{R}$ and $\mathbb{R}^{2}$, a sequence cannot converge to more than one point, but in an arbitrary space, it can. In the space indicated in Figure 17.3, for example, the sequence defined by setting $x_{n}=b$ for all $n$ converges not only to the point $b$, but also to the point $a$ and to the point $c$ !

Topologies in which one-point sets are not closed, or in which sequences can converge to more than one point, are considered by many mathematicians to be somewhat strange. They are not really very interesting, for they seldom occur in other branches of mathematics. And the theorems that one can prove about topological spaces are rather limited if such examples are allowed. Therefore, one often imposes an additional condition that will rule out examples like this one, bringing the class of spaces under consideration closer to those to which one's geometric intuition applies. The condition was suggested by the mathematician Felix Hausdorff, so mathematicians have come to call it by his name.

Definition. A topological space $X$ is called a Hausdorff space if for each pair $x_{1}, x_{2}$ of distinct points of $X$, there exist neighborhoods $U_{1}$, and $U_{2}$ of $x_{1}$ and $x_{2}$, respectively, that are disjoint.

Theorem 17.8. Every finite point set in a Hausdorff space $X$ is closed.

Proof. It suffices to show that every one-point set $\left\{x_{0}\right\}$ is closed. If $x$ is a point of $X$ different from $x_{0}$, then $x$ and $x_{0}$ have disjoint neighborhoods $U$ and $V$, respectively. Since $U$ does not intersect $\left\{x_{0}\right\}$, the point $x$ cannot belong to the closure of the set $\left\{x_{0}\right\}$. As a result, the closure of the set $\left\{x_{0}\right\}$ is $\left\{x_{0}\right\}$ itself, so that it is closed.

The condition that finite point sets be closed is in fact weaker than the Hausdorff condition. For example, the real line $\mathbb{R}$ in the finite complement topology is not a Hausdorff space, but it is a space in which finite point sets are closed. The condition that finite point sets be closed has been given a name of its own: it is called the $\boldsymbol{T}_{\mathbf{1}} \boldsymbol{a x}$ iom. (We shall explain the reason for this strange terminology in Chapter 4.) The $T_{1}$ axiom will appear in this book in a few exercises, and in just one theorem, which is the following:

Theorem 17.9. Let $X$ be a space satisfying the $T_{1}$ axiom; let $A$ be a subset of $X$. Then the point $x$ is a limit point of $A$ if and only if every neighborhood of $x$ contains infinitely many points of $A$.

Proof. If every neighborhood of $x$ intersects $A$ in infinitely many points, it certainly intersects $A$ in some point other than $x$ itself, so that $x$ is a limit point of $A$.

Conversely, suppose that $x$ is a limit point of $A$, and suppose some neighborhood $U$ of $x$ intersects $A$ in only finitely many points. Then $U$ also intersects $A-\{x\}$ in finitely many points; let $\left\{x_{1}, \ldots, x_{m}\right\}$ be the points of $U \cap(A-\{x\})$. The set $X-\left\{x_{1}, \ldots, x_{m}\right\}$ is an open set of $X$, since the finite point set $\left\{x_{1}, \ldots, x_{m}\right\}$ is closed; then

$$
U \cap\left(X-\left\{x_{1}, \ldots, x_{m}\right\}\right)
$$

is a neighborhood of $x$ that intersects the set $A-\{x\}$ not at all. This contradicts the assumption that $x$ is a limit point of $A$.

One reason for our lack of interest in the $T_{1}$ axiom is the fact that many of the interesting theorems of topology require not just that axiom, but the full strength of the Hausdorff axiom. Furthermore, most of the spaces that are important to mathematicians are Hausdorff spaces. The following two theorems give some substance to these remarks.

Theorem 17.10. If $X$ is a Hausdorff space, then a sequence of points of $X$ converges to at most one point of $X$.

Proof. Suppose that $x_{n}$ is a sequence of points of $X$ that converges to $x$. If $y \neq x$, let $U$ and $V$ be disjoint neighborhoods of $x$ and $y$, respectively. Since $U$ contains $x_{n}$ for all but finitely many values of $n$, the set $V$ cannot. Therefore, $x_{n}$ cannot converge to $y$.

If the sequence $x_{n}$ of points of the Hausdorff space $X$ converges to the point $x$ of $X$, we often write $x_{n} \rightarrow x$, and we say that $x$ is the limit of the sequence $x_{n}$.

The proof of the following result is left to the exercises.

Theorem 17.11. Every simply ordered set is a Hausdorff space in the order topology. The product of two Hausdorff spaces is a Hausdorff space. A subspace of a Hausdorff space is a Hausdorff space.

The Hausdorff condition is generally considered to be a very mild extra condition to impose on a topological space. Indeed, in a first course in topology some mathematicians go so far as to impose this condition at the outset, refusing to consider spaces that are not Hausdorff spaces. We shall not go this far, but we shall certainly assume the Hausdorff condition whenever it is needed in a proof without having any qualms about limiting seriously the range of applications of the results.

The Hausdorff condition is one of a number of extra conditions one can impose on a topological space. Each time one imposes such a condition, one can prove stronger theorems, but one limits the class of spaces to which the theorems apply. Much of the research that has been done in topology since its beginnings has centered on the problem of finding conditions that will be strong enough to enable one to prove interesting theorems about spaces satisfying those conditions, and yet not so strong that they limit severely the range of applications of the results.

We shall study a number of such conditions in the next two chapters. The Hausdorff condition and the $T_{1}$ axiom are but two of a collection of conditions similar to one another that are called collectively the separation axioms. Other conditions include the countability axioms, and various compactness and connectedness conditions. Some of these are quite stringent requirements, as you will see.

## Exercises

1. Let $C$ be a collection of subsets of the set $X$. Suppose that $\varnothing$ and $X$ are in $\mathcal{C}$, and that finite unions and arbitrary intersections of elements of $\mathcal{C}$ are in $\mathcal{C}$. Show that the collection

$$
\mathcal{T}=\{X-C \mid C \in \mathcal{C}\}
$$

is a topology on $X$.

2. Show that if $A$ is closed in $Y$ and $Y$ is closed in $X$, then $A$ is closed in $X$.
3. Show that if $A$ is closed in $X$ and $B$ is closed in $Y$, then $A \times B$ is closed in $X \times Y$.
4. Show that if $U$ is open in $X$ and $A$ is closed in $X$, then $U-A$ is open in $X$, and $A-U$ is closed in $X$.
5. Let $X$ be an ordered set in the order topology. Show that $\overline{(a, b)} \subset[a, b]$. Under what conditions does equality hold?
6. Let $A, B$, and $A_{\alpha}$ denote subsets of a space $X$. Prove the following:

(a) If $A \subset B$, then $\bar{A} \subset \bar{B}$.

(b) $\overline{A \cup B}=\bar{A} \cup \bar{B}$.

(c) $\overline{\bigcup A_{\alpha}} \supset \bigcup \bar{A}_{\alpha}$; give an example where equality fails.

7. Criticize the following "proof" that $\overline{\bigcup A_{\alpha}} \subset \bigcup \bar{A}_{\alpha}$ : if $\left\{A_{\alpha}\right\}$ is a collection of sets in $X$ and if $x \in \overline{\bigcup A_{\alpha}}$, then every neighborhood $U$ of $x$ intersects $\bigcup A_{\alpha}$. Thus $U$ must intersect some $A_{\alpha}$, so that $x$ must belong to the closure of some $A_{\alpha}$. Therefore, $x \in \bigcup \bar{A}_{\alpha}$.
8. Let $A, B$, and $A_{\alpha}$ denote subsets of a space $X$. Determine whether the following equations hold; if an equality fails, determine whether one of the inclusions $\supset$ or $\subset$ holds.

(a) $\overline{A \cap B}=\bar{A} \cap \bar{B}$.

(b) $\overline{\bigcap A_{\alpha}}=\bigcap \bar{A}_{\alpha}$.

(c) $\overline{A-B}=\bar{A}-\bar{B}$.

9. Let $A \subset X$ and $B \subset Y$. Show that in the space $X \times Y$,

$$
\overline{A \times B}=\bar{A} \times \bar{B}
$$

10. Show that every order topology is Hausdorff.
11. Show that the product of two Hausdorff spaces is Hausdorff.
12. Show that a subspace of a Hausdorff space is Hausdorff.
13. Show that $X$ is Hausdorff if and only if the diagonal $\Delta=\{x \times x \mid x \in X\}$ is closed in $X \times X$.
14. In the finite complement topology on $\mathbb{R}$, to what point or points does the sequence $x_{n}=1 / n$ converge?
15. Show the $T_{1}$ axiom is equivalent to the condition that for each pair of points of $X$, each has a neighborhood not containing the other.
16. Consider the five topologies on $\mathbb{R}$ given in Exercise 7 of $\S 13$.

(a) Determine the closure of the set $K=\left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}$under each of these topologies.

(b) Which of these topologies satisfy the Hausdorff axiom? the $T_{1}$ axiom?

17. Consider the lower limit topology on $\mathbb{R}$ and the topology given by the basis $\mathcal{C}$ of Exercise 8 of $\S 13$. Determine the closures of the intervals $A=(0, \sqrt{2})$ and $B=(\sqrt{2}, 3)$ in these two topologies.
18. Determine the closures of the following subsets of the ordered square:

$$
\begin{aligned}
& A=\left\{(1 / n) \times 0 \mid n \in \mathbb{Z}_{+}\right\}, \\
& B=\left\{\left.(1-1 / n) \times \frac{1}{2} \right\rvert\, n \in \mathbb{Z}_{+}\right\}, \\
& C=\{x \times 0 \mid 0<x<1\}, \\
& D=\left\{\left.x \times \frac{1}{2} \right\rvert\, 0<x<1\right\}, \\
& E=\left\{\left.\frac{1}{2} \times y \right\rvert\, 0<y<1\right\} .
\end{aligned}
$$

19. If $A \subset X$, we define the boundary of $A$ by the equation

$$
\operatorname{Bd} A=\bar{A} \cap(\overline{X-A})
$$

(a) Show that $\operatorname{Int} A$ and $\operatorname{Bd} A$ are disjoint, and $\bar{A}=\operatorname{Int} A \cup \operatorname{Bd} A$.

(b) Show that $\operatorname{Bd} A=\varnothing \Leftrightarrow A$ is both open and closed.

(c) Show that $U$ is open $\Leftrightarrow \operatorname{Bd} U=\bar{U}-U$.

(d) If $U$ is open, is it true that $U=\operatorname{Int}(\bar{U})$ ? Justify your answer.

20. Find the boundary and the interior of each of the following subsets of $\mathbb{R}^{2}$ :

(a) $A=\{x \times y \mid y=0\}$

(b) $B=\{x \times y \mid x>0$ and $y \neq 0\}$

(c) $C=A \cup B$

(d) $D=\{x \times y \mid x$ is rational $\}$

(e) $E=\left\{x \times y \mid 0<x^{2}-y^{2} \leq 1\right\}$

(f) $F=\{x \times y \mid x \neq 0$ and $y \leq 1 / x\}$

*21. (Kuratowski) Consider the collection of all subsets $A$ of the topological space $X$. The operations of closure $A \rightarrow \bar{A}$ and complementation $A \rightarrow X-A$ are functions from this collection to itself.

(a) Show that starting with a given set $A$, one can form no more than 14 distinct sets by applying these two operations successively.

(b) Find a subset $A$ of $\mathbb{R}$ (in its usual topology) for which the maximum of 14 is obtained.

## $\S 18$ Continuous Functions

The concept of continuous function is basic to much of mathematics. Continuous functions on the real line appear in the first pages of any calculus book, and continuous functions in the plane and in space follow not far behind. More general kinds of continuous functions arise as one goes further in mathematics. In this section, we shall formulate a definition of continuity that will include all these as special cases, and we shall study various properties of continuous functions. Many of these properties are direct generalizations of things you learned about continuous functions in calculus and analysis.

## Continuity of a Function

Let $X$ and $Y$ be topological spaces. A function $f: X \rightarrow Y$ is said to be continuous if for each open subset $V$ of $Y$, the set $f^{-1}(V)$ is an open subset of $X$.

Recall that $f^{-1}(V)$ is the set of all points $x$ of $X$ for which $f(x) \in V$; it is empty if $V$ does not intersect the image set $f(X)$ of $f$.

Continuity of a function depends not only upon the function $f$ itself, but also on the topologies specified for its domain and range. If we wish to emphasize this fact, we can say that $f$ is continuous relative to specific topologies on $X$ and $Y$.

Let us note that if the topology of the range space $Y$ is given by a basis $\mathcal{B}$, then to prove continuity of $f$ it suffices to show that the inverse image of every basis element is open: The arbitrary open set $V$ of $Y$ can be written as a union of basis elements

$$
V=\bigcup_{\alpha \in J} B_{\alpha}
$$

Then

$$
f^{-1}(V)=\bigcup_{\alpha \in J} f^{-1}\left(B_{\alpha}\right)
$$

so that $f^{-1}(V)$ is open if each set $f^{-1}\left(B_{\alpha}\right)$ is open.

If the topology on $Y$ is given by a subbasis $\mathcal{S}$, to prove continuity of $f$ it will even suffice to show that the inverse image of each subbasis element is open: The arbitrary basis element $B$ for $Y$ can be written as a finite intersection $S_{1} \cap \cdots \cap S_{n}$ of subbasis elements; it follows from the equation

$$
f^{-1}(B)=f^{-1}\left(S_{1}\right) \cap \cdots \cap f^{-1}\left(S_{n}\right)
$$

that the inverse image of every basis element is open.

EXAMPLE 1. Let us consider a function like those studied in analysis, a "real-valued function of a real variable,"

$$
f: \mathbb{R} \longrightarrow \mathbb{R}
$$

In analysis, one defines continuity of $f$ via the " $\epsilon-\delta$ definition," a bugaboo over the years for every student of mathematics. As one would expect, the $\epsilon-\delta$ definition and ours are equivalent. To prove that our definition implies the $\epsilon-\delta$ definition, for instance, we proceed as follows:

Given $x_{0}$ in $\mathbb{R}$, and given $\epsilon>0$, the interval $V=\left(f\left(x_{0}\right)-\epsilon, f\left(x_{0}\right)+\epsilon\right)$ is an open set of the range space $\mathbb{R}$. Therefore, $f^{-1}(V)$ is an open set in the domain space $\mathbb{R}$. Because $f^{-1}(V)$ contains the point $x_{0}$, it contains some basis element $(a, b)$ about $x_{0}$. We choose $\delta$ to be the smaller of the two numbers $x_{0}-a$ and $b-x_{0}$. Then if $\left|x-x_{0}\right|<\delta$, the point $x$ must be in $(a, b)$, so that $f(x) \in V$, and $\left|f(x)-f\left(x_{0}\right)\right|<\epsilon$, as desired.

Proving that the $\epsilon-\delta$ definition implies our definition is no harder; we leave it to you. We shall return to this example when we study metric spaces.

EXAMPLE 2. In calculus one considers the property of continuity for many kinds of functions. For example, one studies functions of the following types:

$$
\begin{array}{ll}
f: \mathbb{R} \longrightarrow \mathbb{R}^{2} & \text { (curves in the plane) } \\
f: \mathbb{R} \longrightarrow \mathbb{R}^{3} & \text { (curves in space) } \\
f: \mathbb{R}^{2} \longrightarrow \mathbb{R} & \text { (functions } f(x, y) \text { of two real variables) } \\
f: \mathbb{R}^{3} \longrightarrow \mathbb{R} & \text { (functions } f(x, y, z) \text { of three real variables) } \\
f: \mathbb{R}^{2} \longrightarrow \mathbb{R}^{2} & \text { (vector fields } \mathbf{v}(x, y) \text { in the plane). }
\end{array}
$$

Each of them has a notion of continuity defined for it. Our general definition of continuity includes all these as special cases; this fact will be a consequence of general theorems we shall prove concerning continuous functions on product spaces and on metric spaces.

EXAMPLE 3. Let $\mathbb{R}$ denote the set of real numbers in its usual topology, and let $\mathbb{R}_{\ell}$ denote the same set in the lower limit topology. Let

$$
f: \mathbb{R} \longrightarrow \mathbb{R}_{\ell}
$$

be the identity function; $f(x)=x$ for every real number $x$. Then $f$ is not a continuous function; the inverse image of the open set $[a, b)$ of $\mathbb{R}_{\ell}$ equals itself, which is not open in $\mathbb{R}$. On the other hand, the identity function

$$
g: \mathbb{R}_{\ell} \longrightarrow \mathbb{R}
$$

is continuous, because the inverse image of $(a, b)$ is itself, which is open in $\mathbb{R}_{\ell}$.

In analysis, one studies several different but equivalent ways of formulating the definition of continuity. Some of these generalize to arbitrary spaces, and they are considered in the theorems that follow. The familiar " $\epsilon-\delta$ " definition and the "convergent sequence definition" do not generalize to arbitrary spaces; they will be treated when we study metric spaces.

Theorem 18.1. Let $X$ and $Y$ be topological spaces; let $f: X \rightarrow Y$. Then the following are equivalent:

(1) $f$ is continuous.

(2) For every subset $A$ of $X$, one has $f(\bar{A}) \subset \overline{f(A)}$.

(3) For every closed set $B$ of $Y$, the set $f^{-1}(B)$ is closed in $X$.

(4) For each $x \in X$ and each neighborhood $V$ of $f(x)$, there is a neighborhood $U$ of $x$ such that $f(U) \subset V$.

If the condition in (4) holds for the point $x$ of $X$, we say that $f$ is continuous at the point $x$.

Proof. We show that $(1) \Rightarrow(2) \Rightarrow(3) \Rightarrow$ (1) and that (1) $\Rightarrow(4) \Rightarrow$ (1).

$(1) \Rightarrow(2)$. Assume that $f$ is continuous. Let $A$ be a subset of $X$. We show that if $x \in \bar{A}$, then $f(x) \in \overline{f(A)}$. Let $V$ be a neighborhood of $f(x)$. Then $f^{-1}(V)$ is an open set of $X$ containing $x$; it must intersect $A$ in some point $y$. Then $V$ intersects $f(A)$ in the point $f(y)$, so that $f(x) \in \overline{f(A)}$, as desired.

(2) $\Rightarrow$ (3). Let $B$ be closed in $Y$ and let $A=f^{-1}(B)$. We wish to prove that $A$ is closed in $X$; we show that $\bar{A}=A$. By elementary set theory, we have $f(A)=$ $f\left(f^{-1}(B)\right) \subset B$. Therefore, if $x \in \bar{A}$,

$$
f(x) \in f(\bar{A}) \subset \overline{f(A)} \subset \bar{B}=B,
$$

so that $x \in f^{-1}(B)=A$. Thus $\bar{A} \subset A$, so that $\bar{A}=A$, as desired.

(3) $\Rightarrow$ (1). Let $V$ be an open set of $Y$. Set $B=Y-V$. Then

$$
f^{-1}(B)=f^{-1}(Y)-f^{-1}(V)=X-f^{-1}(V) .
$$

Now $B$ is a closed set of $Y$. Then $f^{-1}(B)$ is closed in $X$ by hypothesis, so that $f^{-1}(V)$ is open in $X$, as desired.

(1) $\Rightarrow$ (4). Let $x \in X$ and let $V$ be a neighborhood of $f(x)$. Then the set $U=f^{-1}(V)$ is a neighborhood of $x$ such that $f(U) \subset V$.

(4) $\Rightarrow$ (1). Let $V$ be an open set of $Y$; let $x$ be a point of $f^{-1}(V)$. Then $f(x) \in V$, so that by hypothesis there is a neighborhood $U_{x}$ of $x$ such that $f\left(U_{x}\right) \subset V$. Then $U_{x} \subset f^{-1}(V)$. It follows that $f^{-1}(V)$ can be written as the union of the open sets $U_{x}$, so that it is open.

## Homeomorphisms

Let $X$ and $Y$ be topological spaces; let $f: X \rightarrow Y$ be a bijection. If both the function $f$ and the inverse function

$$
f^{-1}: Y \rightarrow X
$$

are continuous, then $f$ is called a homeomorphism.

The condition that $f^{-1}$ be continuous says that for each open set $U$ of $X$, the inverse image of $U$ under the map $f^{-1}: Y \rightarrow X$ is open in $Y$. But the inverse image of $U$ under the map $f^{-1}$ is the same as the image of $U$ under the map $f$. See Figure 18.1. So another way to define a homeomorphism is to say that it is a bijective correspondence $f: X \rightarrow Y$ such that $f(U)$ is open if and only if $U$ is open.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-106.jpg?height=252&width=1020&top_left_y=1234&top_left_x=511)

Figure 18.1

This remark shows that a homeomorphism $f: X \rightarrow Y$ gives us a bijective correspondence not only between $X$ and $Y$ but between the collections of open sets of $X$ and of $Y$. As a result, any property of $X$ that is entirely expressed in terms of the topology of $X$ (that is, in terms of the open sets of $X$ ) yields, via the correspondence $f$, the corresponding property for the space $Y$. Such a property of $X$ is called a topological property of $X$.

You may have studied in modern algebra the notion of an isomorphism between algebraic objects such as groups or rings. An isomorphism is a bijective correspondence that preserves the algebraic structure involved. The analogous concept in topology is that of homeomorphism; it is a bijective correspondence that preserves the topological structure involved.

Now suppose that $f: X \rightarrow Y$ is an injective continuous map, where $X$ and $Y$ are topological spaces. Let $Z$ be the image set $f(X)$, considered as a subspace of $Y$; then the function $f^{\prime}: X \rightarrow Z$ obtained by restricting the range of $f$ is bijective. If $f^{\prime}$ happens to be a homeomorphism of $X$ with $Z$, we say that the map $f: X \rightarrow Y$ is a topological imbedding, or simply an imbedding, of $X$ in $Y$.

EXAMPLE 4. The function $f: \mathbb{R} \rightarrow \mathbb{R}$ given by $f(x)=3 x+1$ is a homeomorphism. See Figure 18.2. If we define $g: \mathbb{R} \rightarrow \mathbb{R}$ by the equation

$$
g(y)=\frac{1}{3}(y-1)
$$

then one can check easily that $f(g(y))=y$ and $g(f(x))=x$ for all real numbers $x$ and $y$. It follows that $f$ is bijective and that $g=f^{-1}$; the continuity of $f$ and $g$ is a familiar result from calculus.

EXAMPle 5. The function $F:(-1,1) \rightarrow \mathbb{R}$ defined by

$$
F(x)=\frac{x}{1-x^{2}}
$$

is a homeomorphism. See Figure 18.3. We have already noted in Example 9 of $\S 3$ that $F$ is a bijective order-preserving correspondence; its inverse is the function $G$ defined by

$$
G(y)=\frac{2 y}{1+\left(1+4 y^{2}\right)^{1 / 2}} .
$$

The fact that $F$ is a homeomorphism can be proved in two ways. One way is to note that because $F$ is order preserving and bijective, $F$ carries a basis element for the order topology in $(-1,1)$ onto a basis element for the order topology in $\mathbb{R}$ and vice versa. As a result, $F$ is automatically a homeomorphism of $(-1,1)$ with $\mathbb{R}$ (both in the order topology). Since the order topology on $(-1,1)$ and the usual (subspace) topology agree, $F$ is a homeomorphism of $(-1,1)$ with $\mathbb{R}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-107.jpg?height=422&width=497&top_left_y=1402&top_left_x=640)

Figure 18.2

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-107.jpg?height=428&width=561&top_left_y=1396&top_left_x=1196)

Figure 18.3

A second way to show $F$ a homeomorphism is to use the continuity of the algebraic functions and the square-root function to show that both $F$ and $G$ are continuous. These are familiar facts from calculus.

EXAMPLE 6. A bijective function $f: X \rightarrow Y$ can be continuous without being a homeomorphism. One such function is the identity map $g: \mathbb{R}_{\ell} \rightarrow \mathbb{R}$ considered in Example 3. Another is the following: Let $S^{1}$ denote the unit circle,

$$
S^{1}=\left\{x \times y \mid x^{2}+y^{2}=1\right\}
$$

considered as a subspace of the plane $\mathbb{R}^{2}$, and let

$$
F:[0,1) \longrightarrow S^{1}
$$

be the map defined by $f(t)=(\cos 2 \pi t, \sin 2 \pi t)$. The fact that $f$ is bijective and continuous follows from familiar properties of the trigonometric functions. But the function $f^{-1}$ is not continuous. The image under $f$ of the open set $U=\left[0, \frac{1}{4}\right)$ of the domain, for instance, is not open in $S^{1}$, for the point $p=f(0)$ lies in no open set $V$ of $\mathbb{R}^{2}$ such that $V \cap S^{1} \subset f(U)$. See Figure 18.4.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-108.jpg?height=355&width=936&top_left_y=777&top_left_x=548)

Figure 18.4

EXAMPLE 7. Consider the function

$$
g:[0,1) \longrightarrow \mathbb{R}^{2}
$$

obtained from the function $f$ of the preceding example by expanding the range. The map $g$ is an example of a continuous injective map that is not an imbedding.

## Constructing Continuous Functions

How does one go about constructing continuous functions from one topological space to another? There are a number of methods used in analysis, of which some generalize to arbitrary topological spaces and others do not. We study first some constructions that do hold for general topological spaces, deferring consideration of the others until later.

Theorem 18.2 (Rules for constructing continuous functions). Let $X, Y$, and $Z$ be topological spaces.

(a) (Constant function) If $f: X \rightarrow Y$ maps all of $X$ into the single point $y_{0}$ of $Y$, then $f$ is continuous.

(b) (Inclusion) If $A$ is a subspace of $X$, the inclusion function $j: A \rightarrow X$ is continuous.

(c) (Composites) If $f: X \rightarrow Y$ and $g: Y \rightarrow Z$ are continuous, then the map $g \circ f: X \rightarrow Z$ is continuous.
(d) (Restricting the domain) If $f: X \rightarrow Y$ is continuous, and if $A$ is a subspace of $X$, then the restricted function $f \mid A: A \rightarrow Y$ is continuous.

(e) (Restricting or expanding the range) Let $f: X \rightarrow Y$ be continuous. If $Z$ is a subspace of $Y$ containing the image set $f(X)$, then the function $g: X \rightarrow Z$ obtained by restricting the range of $f$ is continuous. If $Z$ is a space having $Y$ as a subspace, then the function $h: X \rightarrow Z$ obtained by expanding the range of $f$ is continuous.

(f) (Local formulation of continuity) The map $f: X \rightarrow Y$ is continuous if $X$ can be written as the union of open sets $U_{\alpha}$ such that $f \mid U_{\alpha}$ is continuous for each $\alpha$.

Proof. (a) Let $f(x)=y_{0}$ for every $x$ in $X$. Let $V$ be open in $Y$. The set $f^{-1}(V)$ equals $X$ or $\varnothing$, depending on whether $V$ contains $y_{0}$ or not. In either case, it is open.

(b) If $U$ is open in $X$, then $j^{-1}(U)=U \cap A$, which is open in $A$ by definition of the subspace topology. But

(c) If $U$ is open in $Z$, then $g^{-1}(U)$ is open in $Y$ and $f^{-1}\left(g^{-1}(U)\right)$ is open in $X$.

$$
f^{-1}\left(g^{-1}(U)\right)=(g \circ f)^{-1}(U),
$$

by elementary set theory.

(d) The function $f \mid A$ equals the composite of the inclusion map $j: A \rightarrow X$ and the map $f: X \rightarrow Y$, both of which are continuous.

(e) Let $f: X \rightarrow Y$ be continuous. If $f(X) \subset Z \subset Y$, we show that the function $g: X \rightarrow Z$ obtained from $f$ is continuous. Let $B$ be open in $Z$. Then $B=Z \cap U$ for some open set $U$ of $Y$. Because $Z$ contains the entire image set $f(X)$,

$$
f^{-1}(U)=g^{-1}(B)
$$

by elementary set theory. Since $f^{-1}(U)$ is open, so is $g^{-1}(B)$.

To show $h: X \rightarrow Z$ is continuous if $Z$ has $Y$ as a subspace, note that $h$ is the composite of the map $f: X \rightarrow Y$ and the inclusion map $j: Y \rightarrow Z$.

(f) By hypothesis, we can write $X$ as a union of open sets $U_{\alpha}$, such that $f \mid U_{\alpha}$, is continuous for each $\alpha$. Let $V$ be an open set in $Y$. Then

$$
f^{-1}(V) \cap U_{\alpha}=\left(f \mid U_{\alpha}\right)^{-1}(V),
$$

because both expressions represent the set of those points $x$ lying in $U_{\alpha}$ for which $f(x) \in V$. Since $f \mid U$ is continuous, this set is open in $U_{\alpha}$, and hence open in $X$. But

$$
f^{-1}(V)=\bigcup_{\alpha}\left(f^{-1}(V) \cap U_{\alpha}\right),
$$

so that $f^{-1}(V)$ is also open in $X$.

Theorem 18.3 (The pasting lemma). Let $X=A \cup B$, where $A$ and $B$ are closed in $X$. Let $f: A \rightarrow Y$ and $g: B \rightarrow Y$ be continuous. If $f(x)=g(x)$ for every $x \in A \cap B$, then $f$ and $g$ combine to give a continuous function $h: X \rightarrow Y$, defined by setting $h(x)=f(x)$ if $x \in A$, and $h(x)=g(x)$ if $x \in B$.

Proof. Let $C$ be a closed subset of $Y$. Now

$$
h^{-1}(C)=f^{-1}(C) \cup g^{-1}(C)
$$

by elementary set theory. Since $f$ is continuous, $f^{-1}(C)$ is closed in $A$ and, therefore, closed in $X$. Similarly, $g^{-1}(C)$ is closed in $B$ and therefore closed in $X$. Their union $h^{-1}(C)$ is thus closed in $X$.

This theorem also holds if $A$ and $B$ are open sets in $X$; this is just a special case of the "local formulation of continuity" rule given in preceding theorem.

EXAMPLE 8. Let us define a function $h: \mathbb{R} \rightarrow \mathbb{R}$ by setting

$$
h(x)= \begin{cases}x & \text { for } x \leq 0 \\ x / 2 & \text { for } x \geq 0\end{cases}
$$

Each of the "pieces" of this definition is a continuous function, and they agree on the overlapping part of their domains, which is the one-point set $\{0\}$. Since their domains are closed in $\mathbb{R}$, the function $h$ is continuous. One needs the "pieces" of the function to agree on the overlapping part of their domains in order to have a function at all. The equations

$$
k(x)= \begin{cases}x-2 & \text { for } x \leq 0 \\ x+2 & \text { for } x \geq 0\end{cases}
$$

for instance, do not define a function. On the other hand, one needs some limitations on the sets $A$ and $B$ to guarantee continuity. The equations

$$
l(x)= \begin{cases}x-2 & \text { for } x<0 \\ x+2 & \text { for } x \geq 0\end{cases}
$$

for instance, do define a function $l$ mapping $\mathbb{R}$ into $\mathbb{R}$, and both of the pieces are continuous. But $l$ is not continuous; the inverse image of the open set $(1,3)$, for instance, is the nonopen set $[0,1)$. See Figure 18.5 .
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-110.jpg?height=322&width=1066&top_left_y=1837&top_left_x=486)

Figure 18.5

Theorem 18.4 (Maps into products). Let $f: A \rightarrow X \times Y$ be given by the equation

$$
f(a)=\left(f_{1}(a), f_{2}(a)\right) .
$$

Then $f$ is continuous if and only if the functions

$$
f_{1}: A \longrightarrow X \quad \text { and } \quad f_{2}: A \longrightarrow Y
$$

are continuous.

The maps $f_{1}$ and $f_{2}$ are called the coordinate functions of $f$.

Proof. Let $\pi_{1}: X \times Y \rightarrow X$ and $\pi_{2}: X \times Y \rightarrow Y$ be projections onto the first and second factors, respectively. These maps are continuous. For $\pi_{1}^{-1}(U)=U \times Y$ and $\pi_{2}^{-1}(V)=X \times V$, and these sets are open if $U$ and $V$ are open. Note that for each $a \in A$,

$$
f_{1}(a)=\pi_{1}(f(a)) \quad \text { and } \quad f_{2}(a)=\pi_{2}(f(a)) \text {. }
$$

If the function $f$ is continuous, then $f_{1}$ and $f_{2}$ are composites of continuous functions and therefore continuous. Conversely, suppose that $f_{1}$ and $f_{2}$ are continuous. We show that for each basis element $U \times V$ for the topology of $X \times Y$, its inverse image $f^{-1}(U \times V)$ is open. A point $a$ is in $f^{-1}(U \times V)$ if and only if $f(a) \in U \times V$, that is, if and only if $f_{1}(a) \in U$ and $f_{2}(a) \in V$. Therefore,

$$
f^{-1}(U \times V)=f_{1}^{-1}(U) \cap f_{2}^{-1}(V)
$$

Since both of the sets $f_{1}^{-1}(U)$ and $f_{2}^{-1}(V)$ are open, so is their intersection.

There is no useful criterion for the continuity of a map $f: A \times B \rightarrow X$ whose domain is a product space. One might conjecture that $f$ is continuous if it is continuous "in each variable separately," but this conjecture is not true. (See Exercise 12.)

EXAMPLE 9. In calculus, a parametrized curve in the plane is defined to be a continuous map $f:[a, b] \rightarrow \mathbb{R}^{2}$. It is often expressed in the form $f(t)=(x(t), y(t))$; and one frequently uses the fact that $f$ is a continuous function of $t$ if both $x$ and $y$ are. Similarly, a vector field in the plane

$$
\begin{aligned}
\mathbf{v}(x, y) & =P(x, y) \mathbf{i}+Q(x, y) \mathbf{j} \\
& =(P(x, y), Q(x, y))
\end{aligned}
$$

is said to be continuous if both $P$ and $Q$ are continuous functions, or equivalently, if $\mathbf{v}$ is continuous as a map of $\mathbb{R}^{2}$ into $\mathbb{R}^{2}$. Both of these statements are simply special cases of the preceding theorem.

One way of forming continuous functions that is used a great deal in analysis is to take sums, differences, products, or quotients of continuous real-valued functions. It is a standard theorem that if $f, g: X \rightarrow \mathbb{R}$ are continuous, then $f+g, f-g$, and $f \cdot g$ are continuous, and $f / g$ is continuous if $g(x) \neq 0$ for all $x$. We shall consider this theorem in $\S 21$.

Yet another method for constructing continuous functions that is familiar from analysis is to take the limit of an infinite sequence of functions. There is a theorem to the effect that if a sequence of continuous real-valued functions of a real variable converges uniformly to a limit function, then the limit function is necessarily continuous. This theorem is called the Uniform Limit Theorem. It is used, for instance, to demonstrate the continuity of the trigonometric functions, when one defines these functions rigorously using the infinite series definitions of the sine and cosine. This theorem generalizes to a theorem about maps of an arbitrary topological space $X$ into a metric space $Y$. We shall prove it in $\S 21$.

## Exercises

1. Prove that for functions $f: \mathbb{R} \rightarrow \mathbb{R}$, the $\epsilon-\delta$ definition of continuity implies the open set definition.
2. Suppose that $f: X \rightarrow Y$ is continuous. If $x$ is a limit point of the subset $A$ of $X$, is it necessarily true that $f(x)$ is a limit point of $f(A)$ ?
3. Let $X$ and $X^{\prime}$ denote a single set in the two topologies $\mathcal{T}$ and $\mathcal{T}^{\prime}$, respectively. Let $i: X^{\prime} \rightarrow X$ be the identity function.

(a) Show that $i$ is continuous $\Leftrightarrow \mathcal{T}^{\prime}$ is finer than $\mathcal{T}$.

(b) Show that $i$ is a homeomorphism $\Leftrightarrow \mathcal{T}^{\prime}=\mathcal{T}$.

4. Given $x_{0} \in X$ and $y_{0} \in Y$, show that the maps $f: X \rightarrow X \times Y$ and $g: Y \rightarrow$ $X \times Y$ defined by

$$
f(x)=x \times y_{0} \quad \text { and } \quad g(y)=x_{0} \times y
$$

are imbeddings.

5. Show that the subspace $(a, b)$ of $\mathbb{R}$ is homeomorphic with $(0,1)$ and the subspace $[a, b]$ of $\mathbb{R}$ is homeomorphic with $[0,1]$.
6. Find a function $f: \mathbb{R} \rightarrow \mathbb{R}$ that is continuous at precisely one point.
7. (a) Suppose that $f: \mathbb{R} \rightarrow \mathbb{R}$ is "continuous from the right," that is,

$$
\lim _{x \rightarrow a^{+}} f(x)=f(a)
$$

for each $a \in \mathbb{R}$. Show that $f$ is continuous when considered as a function from $\mathbb{R}_{\ell}$ to $\mathbb{R}$.

(b) Can you conjecture what functions $f: \mathbb{R} \rightarrow \mathbb{R}$ are continuous when considered as maps from $\mathbb{R}$ to $\mathbb{R}_{\ell}$ ? As maps from $\mathbb{R}_{\ell}$ to $\mathbb{R}_{\ell}$ ? We shall return to this question in Chapter 3.

8. Let $Y$ be an ordered set in the order topology. Let $f, g: X \rightarrow Y$ be continuous.

(a) Show that the set $\{x \mid f(x) \leq g(x)\}$ is closed in $X$.
(b) Let $h: X \rightarrow Y$ be the function

$$
h(x)=\min \{f(x), g(x)\} .
$$

Show that $h$ is continuous. [Hint: Use the pasting lemma.]

9. Let $\left\{A_{\alpha}\right\}$ be a collection of subsets of $X$; let $X=\bigcup_{\alpha} A_{\alpha}$. Let $f: X \rightarrow Y$; suppose that $f \mid A_{\alpha}$, is continuous for each $\alpha$.

(a) Show that if the collection $\left\{A_{\alpha}\right\}$ is finite and each set $A_{\alpha}$ is closed, then $f$ is continuous.

(b) Find an example where the collection $\left\{A_{\alpha}\right\}$ is countable and each $A_{\alpha}$ is closed, but $f$ is not continuous.

(c) An indexed family of sets $\left\{A_{\alpha}\right\}$ is said to be locally finite if each point $x$ of $X$ has a neighborhood that intersects $A_{\alpha}$ for only finitely many values of $\alpha$. Show that if the family $\left\{A_{\alpha}\right\}$ is locally finite and each $A_{\alpha}$ is closed, then $f$ is continuous.

10. Let $f: A \rightarrow B$ and $g: C \rightarrow D$ be continuous functions. Let us define a map $f \times g: A \times C \rightarrow B \times D$ by the equation

$$
(f \times g)(a \times c)=f(a) \times g(c) .
$$

Show that $f \times g$ is continuous.

11. Let $F: X \times Y \rightarrow Z$. We say that $F$ is continuous in each variable separately if for each $y_{0}$ in $Y$, the map $h: X \rightarrow Z$ defined by $h(x)=F\left(x \times y_{0}\right)$ is continuous, and for each $x_{0}$ in $X$, the map $k: Y \rightarrow Z$ defined by $k(y)=F\left(x_{0} \times y\right)$ is continuous. Show that if $F$ is continuous, then $F$ is continuous in each variable separately.
12. Let $F: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ be defined by the equation

$$
F(x \times y)= \begin{cases}x y /\left(x^{2}+y^{2}\right) & \text { if } x \times y \neq 0 \times 0 \\ 0 & \text { if } x \times y=0 \times 0\end{cases}
$$

(a) Show that $F$ is continuous in each variable separately.

(b) Compute the function $g: \mathbb{R} \rightarrow \mathbb{R}$ defined by $g(x)=F(x \times x)$.

(c) Show that $F$ is not continuous.

13. Let $A \subset X$; let $f: A \rightarrow Y$ be continuous; let $Y$ be Hausdorff. Show that if $f$ may be extended to a continuous function $g: \bar{A} \rightarrow Y$, then $g$ is uniquely determined by $f$.

## §19 The Product Topology

We now return, for the remainder of the chapter, to the consideration of various methods for imposing topologies on sets.

Previously, we defined a topology on the product $X \times Y$ of two topological spaces. In the present section, we generalize this definition to more general cartesian products.

So let us consider the cartesian products

$$
X_{1} \times \cdots \times X_{n} \quad \text { and } \quad X_{1} \times X_{2} \times \cdots
$$

where each $X_{i}$ is a topological space. There are two possible ways to proceed. One way is to take as basis all sets of the form $U_{1} \times \cdots \times U_{n}$ in the first case, and of the form $U_{1} \times U_{2} \times \cdots$ in the second case, where $U_{i}$ is an open set of $X_{i}$ for each $i$. This procedure does indeed define a topology on the cartesian product; we shall call it the box topology.

Another way to proceed is to generalize the subbasis formulation of the definition, given in $\S 15$. In this case, we take as a subbasis all sets of the form $\pi_{i}^{-1}\left(U_{i}\right)$, where $i$ is any index and $U_{i}$ is an open set of $X_{i}$. We shall call this topology the product topology.

How do these topologies differ? Consider the typical basis element $B$ for the second topology. It is a finite intersection of subbasis elements $\pi_{i}^{-1}\left(U_{i}\right)$, say for $i=$ $i_{1}, \ldots, i_{k}$. Then a point $\mathbf{x}$ belongs to $B$ if and only if $\pi_{i}(\mathbf{x})$ belongs to $U_{i}$ for $i=$ $i_{1}, \ldots, i_{k}$; there is no restriction on $\pi_{i}(x)$ for other values of $i$.

It follows that these two topologies agree for the finite cartesian product and differ for the infinite product. What is not clear is why we seem to prefer the second topology. This is the question we shall explore in this section.

Before proceeding, however, we shall introduce a more general notion of cartesian product. So far, we have defined the cartesian product of an indexed family of sets only in the cases where the index set was the set $\{1, \ldots, n\}$ or the set $\mathbb{Z}_{+}$. Now we consider the case where the index set is completely arbitrary.

Definition. Let $J$ be an index set. Given a set $X$, we define a $J$-tuple of elements of $X$ to be a function $\mathbf{x}: J \rightarrow X$. If $\alpha$ is an element of $J$, we often denote the value of $\mathbf{x}$ at $\alpha$ by $x_{\alpha}$ rather than $\mathbf{x}(\alpha)$; we call it the $\alpha$ th coordinate of $\mathbf{x}$. And we often denote the function $\mathbf{x}$ itself by the symbol

$$
\left(x_{\alpha}\right)_{\alpha \in J} \text {, }
$$

which is as close as we can come to a "tuple notation" for an arbitrary index set $J$. We denote the set of all $J$-tuples of elements of $X$ by $X^{J}$.

Definition. Let $\left\{A_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of sets; let $X=\bigcup_{\alpha \in J} A_{\alpha}$. The cartesian product of this indexed family, denoted by

$$
\prod_{\alpha \in J} A_{\alpha}
$$

is defined to be the set of all $J$-tuples $\left(x_{\alpha}\right)_{\alpha \in J}$ of elements of $X$ such that $x_{\alpha} \in A_{\alpha}$ for each $\alpha \in J$. That is, it is the set of all functions

$$
\mathbf{x}: J \rightarrow \bigcup_{\alpha \in J} A_{\alpha}
$$

such that $\mathbf{x}(\alpha) \in A_{\alpha}$ for each $\alpha \in J$.

Occasionally we denote the product simply by $\prod A_{\alpha}$, and its general element by $\left(x_{\alpha}\right)$, if the index set is understood.

If all the sets $A_{\alpha}$ are equal to one set $X$, then the cartesian product $\prod_{\alpha \in J} A_{\alpha}$ is just the set $X^{J}$ of all $J$-tuples of elements of $X$. We sometimes use "tuple notation" for the elements of $X^{J}$, and sometimes we use functional notation, depending on which is more convenient.

Definition. Let $\left\{X_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of topological spaces. Let us take as a basis for a topology on the product space

$$
\prod_{\alpha \in J} X_{\alpha}
$$

the collection of all sets of the form

$$
\prod_{\alpha \in J} U_{\alpha}
$$

where $U_{\alpha}$ is open in $X_{\alpha}$, for each $\alpha \in J$. The topology generated by this basis is called the box topology.

This collection satisfies the first condition for a basis because $\prod X_{\alpha}$ is itself a basis element; and it satisfies the second condition because the intersection of any two basis elements is another basis element:

$$
\left(\prod_{\alpha \in J} U_{\alpha}\right) \cap\left(\prod_{\alpha \in J} V_{\alpha}\right)=\prod_{\alpha \in J}\left(U_{\alpha} \cap V_{\alpha}\right)
$$

Now we generalize the subbasis formulation of the definition. Let

$$
\pi_{\beta}: \prod_{\alpha \in J} X_{\alpha} \rightarrow X_{\beta}
$$

be the function assigning to each element of the product space its $\beta$ th coordinate,

$$
\pi_{\beta}\left(\left(x_{\alpha}\right)_{\alpha \in J}\right)=x_{\beta}
$$

it is called the projection mapping associated with the index $\beta$.

Definition. Let $S_{\beta}$ denote the collection

$$
\mathcal{S}_{\beta}=\left\{\pi_{\beta}^{-1}\left(U_{\beta}\right) \mid U_{\beta} \text { open in } X_{\beta}\right\}
$$

and let $S$ denote the union of these collections,

$$
\mathcal{S}=\bigcup_{\beta \in J} s_{\beta}
$$

The topology generated by the subbasis $S$ is called the product topology. In this topology $\prod_{\alpha \in J} X_{\alpha}$ is called a product space.

To compare these topologies, we consider the basis $\mathscr{B}$ that $S$ generates. The collection $\mathscr{B}$ consists of all finite intersections of elements of $\mathcal{S}$. If we intersect elements belonging to the same one of the sets $S_{\beta}$, we do not get anything new, because

$$
\pi_{\beta}^{-1}\left(U_{\beta}\right) \cap \pi_{\beta}^{-1}\left(V_{\beta}\right)=\pi_{\beta}^{-1}\left(U_{\beta} \cap V_{\beta}\right) ;
$$

the intersection of two elements of $S_{\beta}$, or of finitely many such elements, is again an element of $S_{\beta}$. We get something new only when we intersect elements from different sets $S_{\beta}$. The typical element of the basis $\mathcal{B}$ can thus be described as follows: Let $\beta_{1}$, $\ldots, \beta_{n}$ be a finite set of distinct indices from the index set $J$, and let $U_{\beta_{i}}$ be an open set in $X_{\beta_{i}}$ for $i=1, \ldots, n$. Then

$$
B=\pi_{\beta_{1}}^{-1}\left(U_{\beta_{1}}\right) \cap \pi_{\beta_{2}}^{-1}\left(U_{\beta_{2}}\right) \cap \cdots \cap \pi_{\beta_{n}}^{-1}\left(U_{\beta_{n}}\right)
$$

is the typical element of $\mathcal{B}$.

Now a point $\mathbf{x}=\left(x_{\alpha}\right)$ is in $B$ if and only if its $\beta_{1}$ th coordinate is in $U_{\beta_{1}}$, its $\beta_{2}$ th coordinate is in $U_{\beta_{2}}$, and so on. There is no restriction whatever on the $\alpha$ th coordinate of $\mathbf{x}$ if $\alpha$ is not one of the indices $\beta_{1}, \ldots, \beta_{n}$. As a result, we can write $B$ as the product

$$
B=\prod_{\alpha \in J} U_{\alpha}
$$

where $U_{\alpha}$ denotes the entire space $X_{\alpha}$ if $\alpha \neq \beta_{1}, \ldots, \beta_{n}$.

All this is summarized in the following theorem:

Theorem 19.1 (Comparison of the box and product topologies). The box topology on $\prod X_{\alpha}$ has as basis all sets of the form $\prod U_{\alpha}$, where $U_{\alpha}$ is open in $X_{\alpha}$ for each $\alpha$. The product topology on $\prod X_{\alpha}$ has as basis all sets of the form $\prod U_{\alpha}$, where $U_{\alpha}$ is open in $X_{\alpha}$ for each $\alpha$ and $U_{\alpha}$ equals $X_{\alpha}$ except for finitely many values of $\alpha$.

Two things are immediately clear. First, for finite products $\prod_{\alpha=1}^{n} X_{\alpha}$ the two topologies are precisely the same. Second, the box topology is in general finer than the product topology.

What is not so clear is why we prefer the product topology to the box topology. The answer will appear as we continue our study of topology. We shall find that a number of important theorems about finite products will also hold for arbitrary products if we use the product topology, but not if we use the box topology. As a result, the product topology is extremely important in mathematics. The box topology is not so important; we shall use it primarily for constructing counterexamples. Therefore, we make the following convention:

Whenever we consider the product $\prod X_{\alpha}$, we shall assume it is given the product topology unless we specifically state otherwise.

Some of the theorems we proved for the product $X \times Y$ hold for the product $\prod X_{\alpha}$ no matter which topology we use. We list them here; most of the proofs are left to the exercises.

Theorem 19.2. Suppose the topology on each space $X_{\alpha}$ is given by a basis $\mathscr{B}_{\alpha}$. The collection of all sets of the form

$$
\prod_{\alpha \in J} B_{\alpha}
$$

where $B_{\alpha} \in \mathscr{B}_{\alpha}$ for each $\alpha$, will serve as a basis for the box topology on $\prod_{\alpha \in J} X_{\alpha}$.

The collection of all sets of the same form, where $B_{\alpha} \in \mathcal{B}_{\alpha}$ for finitely many indices $\alpha$ and $B_{\alpha}=X_{\alpha}$ for all the remaining indices, will serve as a basis for the product topology $\prod_{\alpha \in J} X_{\alpha}$.

EXAMPLE 1. Consider euclidean $n$-space $\mathbb{R}^{n}$. A basis for $\mathbb{R}$ consists of all open intervals in $\mathbb{R}$; hence a basis for the topology of $\mathbb{R}^{n}$ consists of all products of the form

$$
\left(a_{1}, b_{1}\right) \times\left(a_{2}, b_{2}\right) \times \cdots \times\left(a_{n}, b_{n}\right) .
$$

Since $\mathbb{R}^{n}$ is a finite product, the box and product topologies agree. Whenever we consider $\mathbb{R}^{n}$, we will assume that it is given this topology, unless we specifically state otherwise.

Theorem 19.3. Let $A_{\alpha}$ be a subspace of $X_{\alpha}$, for each $\alpha \in J$. Then $\prod A_{\alpha}$ is a subspace of $\prod X_{\alpha}$ if both products are given the box topology, or if both products are given the product topology.

Theorem 19.4. If each space $X_{\alpha}$ is Hausdorff space, then $\prod X_{\alpha}$ is a Hausdorff space in both the box and product topologies.

Theorem 19.5. Let $\left\{X_{\alpha}\right\}$ be an indexed family of spaces; let $A_{\alpha} \subset X_{\alpha}$ for each $\alpha$. If $\prod X_{\alpha}$ is given either the product or the box topology, then

$$
\prod \bar{A}_{\alpha}=\overline{\prod A_{\alpha}} .
$$

Proof. Let $\mathbf{x}=\left(x_{\alpha}\right)$ be a point of $\prod \bar{A}_{\alpha}$; we show that $\mathbf{x} \in \overline{\prod A_{\alpha}}$. Let $U=\prod U_{\alpha}$ be a basis element for either the box or product topology that contains $\mathbf{x}$. Since $x_{\alpha} \in \bar{A}_{\alpha}$, we can choose a point $y_{\alpha} \in U_{\alpha} \cap A_{\alpha}$ for each $\alpha$. Then $\mathbf{y}=\left(y_{\alpha}\right)$ belongs to both $U$ and $\prod A_{\alpha}$. Since $U$ is arbitrary, it follows that $\mathbf{x}$ belongs to the closure of $\prod A_{\alpha}$.

Conversely, suppose $\mathbf{x}=\left(x_{\alpha}\right)$ lies in the closure of $\prod A_{\alpha}$, in either topology. We show that for any given index $\beta$, we have $x_{\beta} \in \bar{A}_{\beta}$. Let $V_{\beta}$ be an arbitrary open set of $X_{\beta}$ containing $x_{\beta}$. Since $\pi_{\beta}^{-1}\left(V_{\beta}\right)$ is open in $\prod X_{\alpha}$ in either topology, it contains a point $\mathbf{y}=\left(y_{\alpha}\right)$ of $\prod A_{\alpha}$. Then $y_{\beta}$ belongs to $V_{\beta} \cap A_{\beta}$. It follows that $x_{\beta} \in \bar{A}_{\beta}$.

So far, no reason has appeared for preferring the product to the box topology. It is when we try to generalize our previous theorem about continuity of maps into product spaces that a difference first arises. Here is a theorem that does not hold if $\prod X_{\alpha}$ is given the box topology:

Theorem 19.6. Let $f: A \rightarrow \prod_{\alpha \in J} X_{\alpha}$ be given by the equation

$$
f(a)=\left(f_{\alpha}(a)\right)_{\alpha \in J}
$$

where $f_{\alpha}: A \rightarrow X_{\alpha}$ for each $\alpha$. Let $\prod X_{\alpha}$ have the product topology. Then the function $f$ is continuous if and only if each function $f_{\alpha}$ is continuous.

Proof. Let $\pi_{\beta}$ be the projection of the product onto its $\beta$ th factor. The function $\pi_{\beta}$ is continuous, for if $U_{\beta}$ is open in $X_{\beta}$, the set $\pi_{\beta}^{-1}\left(U_{\beta}\right)$ is a subbasis element for the product topology on $X_{\alpha}$. Now suppose that $f: A \rightarrow \prod X_{\alpha}$ is continuous. The function $f_{\beta}$ equals the composite $\pi_{\beta} \circ f$; being the composite of two continuous functions, it is continuous.

Conversely, suppose that each coordinate function $f_{\alpha}$ is continuous. To prove that $f$ is continuous, it suffices to prove that the inverse image under $f$ of each subbasis element is open in $A$; we remarked on this fact when we defined continuous functions. A typical subbasis element for the product topology on $\prod X_{\alpha}$ is a set of the form $\pi_{\beta}^{-1}\left(U_{\beta}\right)$, where $\beta$ is some index and $U_{\beta}$ is open in $X_{\beta}$. Now

$$
f^{-1}\left(\pi_{\beta}^{-1}\left(U_{\beta}\right)\right)=f_{\beta}^{-1}\left(U_{\beta}\right)
$$

because $f_{\beta}=\pi_{\beta} \circ f$. Since $f_{\beta}$ is continuous, this set is open in $A$, as desired.

Why does this theorem fail if we use the box topology? Probably the most convincing thing to do is to look at an example.

EXAMPLE 2. Consider $\mathbb{R}^{\omega}$, the countably infinite product of $\mathbb{R}$ with itself. Recall that

$$
\mathbb{R}^{\omega}=\prod_{n \in \mathbb{Z}_{+}} X_{n}
$$

where $X_{n}=\mathbb{R}$ for each $n$. Let us define a function $f: \mathbb{R} \rightarrow \mathbb{R}^{\omega}$ by the equation

$$
f(t)=(t, t, t, \ldots)
$$

the $n$th coordinate function of $f$ is the function $f_{n}(t)=t$. Each of the coordinate functions $f_{n}: \mathbb{R} \rightarrow \mathbb{R}$ is continuous; therefore, the function $f$ is continuous if $\mathbb{R}^{\omega}$ is given the product topology. But $f$ is not continuous if $\mathbb{R}^{\omega}$ is given the box topology. Consider, for example, the basis element

$$
B=(-1,1) \times\left(-\frac{1}{2}, \frac{1}{2}\right) \times\left(-\frac{1}{3}, \frac{1}{3}\right) \times \cdots
$$

for the box topology. We assert that $f^{-1}(B)$ is not open in $\mathbb{R}$. If $f^{-1}(B)$ were open in $\mathbb{R}$, it would contain some interval $(-\delta, \delta)$ about the point 0 . This would mean that $f((-\delta, \delta)) \subset B$, so that, applying $\pi_{n}$ to both sides of the inclusion,

$$
f_{n}((-\delta, \delta))=(-\delta, \delta) \subset(-1 / n, 1 / n)
$$

for all $n$, a contradiction.

## Exercises

1. Prove Theorem 19.2.
2. Prove Theorem 19.3.
3. Prove Theorem 19.4.
4. Show that $\left(X_{1} \times \cdots \times X_{n-1}\right) \times X_{n}$ is homeomorphic with $X_{1} \times \cdots \times X_{n}$.
5. One of the implications stated in Theorem 19.6 holds for the box topology. Which one?
6. Let $\mathbf{x}_{1}, \mathbf{x}_{2}, \ldots$ be a sequence of the points of the product space $\prod X_{\alpha}$. Show that this sequence converges to the point $\mathbf{x}$ if and only if the sequence $\pi_{\alpha}\left(\mathbf{x}_{1}\right), \pi_{\alpha}\left(\mathbf{x}_{2}\right)$, ... converges to $\pi_{\alpha}(\mathbf{x})$ for each $\alpha$. Is this fact true if one uses the box topology instead of the product topology?
7. Let $\mathbb{R}^{\infty}$ be the subset of $\mathbb{R}^{\omega}$ consisting of all sequences that are "eventually zero," that is, all sequences $\left(x_{1}, x_{2}, \ldots\right)$ such that $x_{i} \neq 0$ for only finitely many values of $i$. What is the closure of $\mathbb{R}^{\infty}$ in $\mathbb{R}^{\omega}$ in the box and product topologies? Justify your answer.
8. Given sequences $\left(a_{1}, a_{2}, \ldots\right)$ and $\left(b_{1}, b_{2}, \ldots\right)$ of real numbers with $a_{i}>0$ for all $i$, define $h: \mathbb{R}^{\omega} \rightarrow \mathbb{R}^{\omega}$ by the equation

$$
h\left(\left(x_{1}, x_{2}, \ldots\right)\right)=\left(a_{1} x_{1}+b_{1}, a_{2} x_{2}+b_{2}, \ldots\right) .
$$

Show that if $\mathbb{R}^{\omega}$ is given the product topology, $h$ is a homeomorphism of $\mathbb{R}^{\omega}$ with itself. What happens if $\mathbb{R}^{\omega}$ is given the box topology?

9. Show that the choice axiom is equivalent to the statement that for any indexed family $\left\{A_{\alpha}\right\}_{\alpha \in J}$ of nonempty sets, with $J \neq 0$, the cartesian product

$$
\prod_{\alpha \in J} A_{\alpha}
$$

is not empty.

10. Let $A$ be a set; let $\left\{X_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of spaces; and let $\left\{f_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of functions $f_{\alpha}: A \rightarrow X_{\alpha}$.

(a) Show there is a unique coarsest topology $\mathcal{T}$ on $A$ relative to which each of the functions $f_{\alpha}$ is continuous.

(b) Let

$$
S_{\beta}=\left\{f_{\beta}^{-1}\left(U_{\beta}\right) \mid U_{\beta} \text { is open in } X_{\beta}\right\} \text {, }
$$

and let $\mathcal{S}=\bigcup \mathcal{S}_{\beta}$. Show that $\mathcal{S}$ is a subbasis for $\mathcal{T}$.

(c) Show that a map $g: Y \rightarrow A$ is continuous relative to $\mathcal{T}$ if and only if each map $f_{\alpha} \circ g$ is continuous.

(d) Let $f: A \rightarrow \prod X_{\alpha}$ be defined by the equation

$$
f(a)=\left(f_{\alpha}(a)\right)_{\alpha \in J}
$$

let $Z$ denote the subspace $f(A)$ of the product space $\prod X_{\alpha}$. Show that the image under $f$ of each element of $\mathcal{T}$ is an open set of $Z$.

## §20 The Metric Topology

One of the most important and frequently used ways of imposing a topology on a set is to define the topology in terms of a metric on the set. Topologies given in this way lie at the heart of modern analysis, for example. In this section, we shall define the metric topology and shall give a number of examples. In the next section, we shall consider some of the properties that metric topologies satisfy.

Definition. A metric on a set $X$ is a function

$$
d: X \times X \longrightarrow R
$$

having the following properties:

(1) $d(x, y) \geq 0$ for all $x, y \in X$; equality holds if and only if $x=y$.

(2) $d(x, y)=d(y, x)$ for all $x, y \in X$.

(3) (Triangle inequality) $d(x, y)+d(y, z) \geq d(x, z)$, for all $x, y, z \in X$.

Given a metric $d$ on $X$, the number $d(x, y)$ is often called the distance between $x$ and $y$ in the metric $d$. Given $\epsilon>0$, consider the set

$$
B_{d}(x, \epsilon)=\{y \mid d(x, y)<\epsilon\}
$$

of all points $y$ whose distance from $x$ is less than $\epsilon$. It is called the $\epsilon$-ball centered at $\boldsymbol{x}$. Sometimes we omit the metric $d$ from the notation and write this ball simply as $B(x, \epsilon)$, when no confusion will arise.

Definition. If $d$ is a metric on the set $X$, then the collection of all $\epsilon$-balls $B_{d}(x, \epsilon)$, for $x \in X$ and $\epsilon>0$, is a basis for a topology on $X$, called the metric topology induced by $d$.

The first condition for a basis is trivial, since $x \in B(x, \epsilon)$ for any $\epsilon>0$. Before checking the second condition for a basis, we show that if $y$ is a point of the basis element $B(x, \epsilon)$, then there is a basis element $B(y, \delta)$ centered at $y$ that is contained in $B(x, \epsilon)$. Define $\delta$ to be the positive number $\epsilon-d(x, y)$. Then $B(y, \delta) \subset B(x, \epsilon)$, for if $z \in B(y, \delta)$, then $d(y, z)<\epsilon-d(x, y)$, from which we conclude that

$$
d(x, z) \leq d(x, y)+d(y, z)<\epsilon .
$$

See Figure 20.1.

Now to check the second condition for a basis, let $B_{1}$ and $B_{2}$ be two basis elements and let $y \in B_{1} \cap B_{2}$. We have just shown that we can choose positive numbers $\delta_{1}$ and $\delta_{2}$ so that $B\left(y, \delta_{1}\right) \subset B_{1}$ and $B\left(y, \delta_{2}\right) \subset B_{2}$. Letting $\delta$ be the smaller of $\delta_{1}$ and $\delta_{2}$, we conclude that $B(y, \delta) \subset B_{1} \cap B_{2}$.

Using what we have just proved, we can rephrase the definition of the metric topology as follows:

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-121.jpg?height=450&width=446&top_left_y=366&top_left_x=976)

Figure 20.1

A set $U$ is open in the metric topology induced by $d$ if and only iffor each $y \in U$, there is a $\delta>0$ such that $B_{d}(y, \delta) \subset U$.

Clearly this condition implies that $U$ is open. Conversely, if $U$ is open, it contains a basis element $B=B_{d}(x, \epsilon)$ containing $y$, and $B$ in turn contains a basis element $B_{d}(y, \delta)$ centered at $y$.

EXAMPLE 1. Given a set $X$, define

$$
\begin{array}{ll}
d(x, y)=1 & \text { if } x \neq y \\
d(x, y)=0 & \text { if } x=y
\end{array}
$$

It is trivial to check that $d$ is a metric. The topology it induces is the discrete topology; the basis element $B(x, 1)$, for example, consists of the point $x$ alone.

EXAMPLE 2. The standard metric on the real numbers $\mathbb{R}$ is defined by the equation

$$
d(x, y)=|x-y| .
$$

It is easy to check that $d$ is a metric. The topology it induces is the same as the order topology: Each basis element $(a, b)$ for the order topology is a basis element for the metric topology; indeed,

$$
(a, b)=B(x, \epsilon),
$$

where $x=(a+b) / 2$ and $\epsilon=(b-a) / 2$. And conversely, each $\epsilon$-ball $B(x, \epsilon)$ equals an open interval: the interval $(x-\epsilon, x+\epsilon)$.

Definition. If $X$ is a topological space, $X$ is said to be metrizable if there exists a metric $d$ on the set $X$ that induces the topology of $X$. A metric space is a metrizable space $X$ together with a specific metric $d$ that gives the topology of $X$.

Many of the spaces important for mathematics are metrizable, but some are not. Metrizability is always a highly desirable attribute for a space to possess, for the existence of a metric gives one a valuable tool for proving theorems about the space.

It is, therefore, a problem of fundamental importance in topology to find conditions on a topological space that will guarantee it is metrizable. One of our goals in Chapter 4 will be to find such conditions; they are expressed there in the famous theorem called Urysohn's metrization theorem. Further metrization theorems appear in Chapter 6. In the present section we shall content ourselves with proving merely that $\mathbb{R}^{n}$ and $\mathbb{R}^{\omega}$ are metrizable.

Although the metrizability problem is an important problem in topology, the study of metric spaces as such does not properly belong to topology as much as it does to analysis. Metrizability of a space depends only on the topology of the space in question, but properties that involve a specific metric for $X$ in general do not. For instance, one can make the following definition in a metric space:

Definition. Let $X$ be a metric space with metric $d$. A subset $A$ of $X$ is said to be bounded if there is some number $M$ such that

$$
d\left(a_{1}, a_{2}\right) \leq M
$$

for every pair $a_{1}, a_{2}$ of points of $A$. If $A$ is bounded and nonempty, the diameter of $A$ is defined to be the number

$$
\operatorname{diam} A=\sup \left\{d\left(a_{1}, a_{2}\right) \mid a_{1}, a_{2} \in A\right\}
$$

Boundedness of a set is not a topological property, for it depends on the particular metric $d$ that is used for $X$. For instance, if $X$ is a metric space with metric $d$, then there exists a metric $\bar{d}$ that gives the topology of $X$, relative to which every subset of $X$ is bounded. It is defined as follows:

Theorem 20.1. Let $X$ be a metric space with metric $d$. Define $\bar{d}: X \times X \rightarrow \mathbb{R}$ by the equation

$$
\bar{d}(x, y)=\min \{d(x, y), 1\} .
$$

Then $\bar{d}$ is a metric that induces the same topology as $d$.

The metric $\bar{d}$ is called the standard bounded metric corresponding to $d$.

Proof. Checking the first two conditions for a metric is trivial. Let us check the triangle inequality:

$$
\bar{d}(x, z) \leq \bar{d}(x, y)+\bar{d}(y, z) .
$$

Now if either $d(x, y) \geq 1$ or $d(y, z) \geq 1$, then the right side of this inequality is at least 1 ; since the left side is (by definition) at most 1 , the inequality holds. It remains to consider the case in which $d(x, y)<1$ and $d(y, z)<1$. In this case, we have

$$
d(x, z) \leq d(x, y)+d(y, z)=\bar{d}(x, y)+\bar{d}(y, z) .
$$

Since $\bar{d}(x, z) \leq d(x, z)$ by definition, the triangle inequality holds for $\bar{d}$.

Now we note that in any metric space, the collection of $\epsilon$-balls with $\epsilon<1$ forms a basis for the metric topology, for every basis element containing $x$ contains such an $\epsilon$-ball centered at $x$. It follows that $d$ and $\bar{d}$ induce the same topology on $X$, because the collections of $\epsilon$-balls with $\epsilon<1$ under these two metrics are the same collection.

Now we consider some familiar spaces and show they are metrizable.

Definition. Given $\mathbf{x}=\left(x_{1}, \ldots, x_{n}\right)$ in $\mathbb{R}^{n}$, we define the norm of $\mathbf{x}$ by the equation

$$
\|x\|=\left(x_{1}^{2}+\cdots+x_{n}^{2}\right)^{1 / 2}
$$

and we define the euclidean metric $d$ on $\mathbb{R}^{n}$ by the equation

$$
d(\mathbf{x}, \mathbf{y})=\|\mathbf{x}-\mathbf{y}\|=\left[\left(x_{1}-y_{1}\right)^{2}+\cdots+\left(x_{n}-y_{n}\right)^{2}\right]^{1 / 2} .
$$

We define the square metric $\rho$ by the equation

$$
\rho(\mathbf{x}, \mathbf{y})=\max \left\{\left|x_{1}-y_{1}\right|, \ldots,\left|x_{n}-y_{n}\right|\right\} .
$$

The proof that $d$ is a metric requires some work; it is probably already familiar to you. If not, a proof is outlined in the exercises. We shall seldom have occasion to use this metric on $\mathbb{R}^{n}$.

To show that $\rho$ is a metric is easier. Only the triangle inequality is nontrivial. From the triangle inequality for $\mathbb{R}$ it follows that for each positive integer $i$,

$$
\left|x_{i}-z_{i}\right| \leq\left|x_{i}-y_{i}\right|+\left|y_{i}-z_{i}\right| \text {. }
$$

Then by definition of $\rho$,

$$
\left|x_{i}-z_{i}\right| \leq \rho(\mathbf{x}, \mathbf{y})+\rho(\mathbf{y}, \mathbf{z}) \text {. }
$$

As a result

$$
\rho(\mathbf{x}, \mathbf{z})=\max \left\{\left|x_{i}-z_{i}\right|\right\} \leq \rho(\mathbf{x}, \mathbf{y})+\rho(\mathbf{y}, \mathbf{z}),
$$

as desired.

On the real line $\mathbb{R}=\mathbb{R}^{1}$, these two metrics coincide with the standard metric for $\mathbb{R}$. In the plane $\mathbb{R}^{2}$, the basis elements under $d$ can be pictured as circular regions, while the basis elements under $\rho$ can be pictured as square regions.

We now show that each of these metrics induces the usual topology on $\mathbb{R}^{n}$. We need the following lemma:

Lemma 20.2. Let $d$ and $d^{\prime}$ be two metrics on the set $X$; let $\mathcal{T}$ and $\mathcal{T}^{\prime}$ be the topologies they induce, respectively. Then $\mathcal{T}^{\prime}$ is finer than $\mathcal{T}$ if and only if for each $x$ in $X$ and each $\epsilon>0$, there exists a $\delta>0$ such that

$$
B_{d^{\prime}}(x, \delta) \subset B_{d}(x, \epsilon) .
$$

Proof. Suppose that $\mathcal{T}^{\prime}$ is finer than $\mathcal{T}$. Given the basis element $B_{d}(x, \epsilon)$ for $\mathcal{T}$, there is by Lemma 13.3 a basis element $B^{\prime}$ for the topology $\mathcal{T}^{\prime}$ such that $x \in B^{\prime} \subset B_{d}(x, \epsilon)$. Within $B^{\prime}$ we can find a ball $B_{d^{\prime}}(x, \delta)$ centered at $x$.

Conversely, suppose the $\delta-\epsilon$ condition holds. Given a basis element $B$ for $\mathcal{T}$ containing $x$, we can find within $B$ a ball $B_{d}(x, \epsilon)$ centered at $x$. By the given condition, there is a $\delta$ such that $B_{d^{\prime}}(x, \delta) \subset B_{d}(x, \epsilon)$. Then Lemma 13.3 applies to show $\mathcal{T}^{\prime}$ is finer than $\mathcal{T}$.

Theorem 20.3. The topologies on $\mathbb{R}^{n}$ induced by the euclidean metric $d$ and the square metric $\rho$ are the same as the product topology on $\mathbb{R}^{n}$.

Proof. Let $\mathbf{x}=\left(x_{1}, \ldots, x_{n}\right)$ and $\mathbf{y}=\left(y_{1}, \ldots, y_{n}\right)$ be two points of $\mathbb{R}^{n}$. It is simple algebra to check that

$$
\rho(\mathbf{x}, \mathbf{y}) \leq d(\mathbf{x}, \mathbf{y}) \leq \sqrt{n} \rho(\mathbf{x}, \mathbf{y})
$$

The first inequality shows that

$$
B_{d}(\mathbf{x}, \epsilon) \subset B_{\rho}(\mathbf{x}, \epsilon)
$$

for all $\mathbf{x}$ and $\epsilon$, since if $d(\mathbf{x}, \mathbf{y})<\epsilon$, then $\rho(\mathbf{x}, \mathbf{y})<\epsilon$ also. Similarly, the second inequality shows that

$$
B_{\rho}(\mathbf{x}, \epsilon / \sqrt{n}) \subset B_{d}(\mathbf{x}, \epsilon)
$$

for all $\mathbf{x}$ and $\epsilon$. It follows from the preceding lemma that the two metric topologies are the same.

Now we show that the product topology is the same as that given by the metric $\rho$. First, let

$$
B=\left(a_{1}, b_{1}\right) \times \cdots \times\left(a_{n}, b_{n}\right)
$$

be a basis element for the product topology, and let $\mathbf{x}=\left(x_{1}, \ldots, x_{n}\right)$ be an element of $B$. For each $i$, there is an $\epsilon_{i}$ such that

$$
\left(x_{i}-\epsilon_{i}, x_{i}+\epsilon_{i}\right) \subset\left(a_{i}, b_{i}\right)
$$

choose $\epsilon=\min \left\{\epsilon_{1}, \ldots, \epsilon_{n}\right\}$. Then $B_{\rho}(\mathbf{x}, \epsilon) \subset B$, as you can readily check. As a result, the $\rho$-topology is finer than the product topology.

Conversely, let $B_{\rho}(\mathbf{x}, \epsilon)$ be a basis element for the $\rho$-topology. Given the element $\mathbf{y} \in B_{\rho}(\mathbf{x}, \epsilon)$, we need to find a basis element $B$ for the product topology such that

$$
\mathbf{y} \in B \subset B_{\rho}(\mathbf{x}, \epsilon)
$$

But this is trivial, for

$$
B_{\rho}(\mathbf{x}, \epsilon)=\left(x_{1}-\epsilon, x_{1}+\epsilon\right) \times \cdots \times\left(x_{n}-\epsilon, x_{n}+\epsilon\right)
$$

is itself a basis element for the product topology.

Now we consider the infinite cartesian product $\mathbb{R}^{\omega}$. It is natural to try to generalize the metrics $d$ and $\rho$ to this space. For instance, one can attempt to define a metric $d$ on $\mathbb{R}^{\omega}$ by the equation

$$
d(x, y)=\left[\sum_{i=1}^{\infty}\left(x_{i}-y_{i}\right)^{2}\right]^{1 / 2}
$$

But this equation does not always make sense, for the series in question need not converge. (This equation does define a metric on a certain important subset of $\mathbb{R}^{\omega}$, however; see the exercises.)

Similarly, one can attempt to generalize the square metric $\rho$ to $\mathbb{R}^{\omega}$ by defining

$$
\rho(x, y)=\sup \left\{\left|x_{n}-y_{n}\right|\right\}
$$

Again, this formula does not always make sense. If however we replace the usual metric $d(x, y)=|x-y|$ on $\mathbb{R}$ by its bounded counterpart $\bar{d}(x, y)=\min \{|x-y|, 1\}$, then this definition does make sense; it gives a metric on $\mathbb{R}^{\omega}$ called the uniform metric.

The uniform metric can be defined more generally on the cartesian product $\mathbb{R}^{J}$ for arbitrary $J$, as follows:

Definition. Given an index set $J$, and given points $\mathbf{x}=\left(x_{\alpha}\right)_{\alpha \in J}$ and $\mathbf{y}=\left(y_{\alpha}\right)_{\alpha \in J}$ of $\mathbb{R}^{J}$, let us define a metric $\bar{\rho}$ on $\mathbb{R}^{J}$ by the equation

$$
\bar{\rho}(\mathbf{x}, \mathbf{y})=\sup \left\{\bar{d}\left(x_{\alpha}, y_{\alpha}\right) \mid \alpha \in J\right\}
$$

where $\bar{d}$ is the standard bounded metric on $\mathbb{R}$. It is easy to check that $\bar{\rho}$ is indeed a metric; it is called the uniform metric on $\mathbb{R}^{J}$, and the topology it induces is called the uniform topology.

The relation between this topology and the product and box topologies is the following:

Theorem 20.4. The uniform topology on $\mathbb{R}^{J}$ is finer than the product topology and coarser than the box topology; these three topologies are all different if $J$ is infinite.

Proof. Suppose that we are given a point $\mathbf{x}=\left(x_{\alpha}\right)_{\alpha \in J}$ and a product topology basis element $\prod U_{\alpha}$ about $\mathbf{x}$. Let $\alpha_{1}, \ldots, \alpha_{n}$ be the indices for which $U_{\alpha} \neq \mathbb{R}$. Then for each $i$, choose $\epsilon_{i}>0$ so that the $\epsilon_{i}$-ball centered at $x_{\alpha_{i}}$ in the $\bar{d}$ metric is contained in $U_{\alpha_{i}}$; this we can do because $U_{\alpha_{i}}$ is open in $\mathbb{R}$. Let $\epsilon=\min \left\{\epsilon_{1}, \ldots, \epsilon_{n}\right\}$; then the $\epsilon$-ball centered at $\mathbf{x}$ in the $\bar{\rho}$ metric is contained in $\prod U_{\alpha}$. For if $\mathbf{z}$ is a point of $\mathbb{R}^{J}$ such that $\bar{\rho}(\mathbf{x}, \mathbf{z})<\epsilon$, then $\bar{d}\left(x_{\alpha}, z_{\alpha}\right)<\epsilon$ for all $\alpha$, so that $\mathbf{z} \in \prod U_{\alpha}$. It follows that the uniform topology is finer than the product topology.

On the other hand, let $B$ be the $\epsilon$-ball centered at $\mathbf{x}$ in the $\bar{\rho}$ metric. Then the box neighborhood

$$
U=\prod\left(x_{\alpha}-\frac{1}{2} \epsilon, x_{\alpha}+\frac{1}{2} \epsilon\right)
$$

of $\mathbf{x}$ is contained in $B$. For if $\mathbf{y} \in U$, then $\bar{d}\left(x_{\alpha}, y_{\alpha}\right)<\frac{1}{2} \epsilon$ for all $\alpha$, so that $\bar{\rho}(\mathbf{x}, \mathbf{y}) \leq$ $\frac{1}{2} \epsilon$.

Showing these three topologies are different if $J$ is infinite is a task we leave to the exercises.

In the case where $J$ is infinite, we still have not determined whether $\mathbb{R}^{J}$ is metrizable in either the box or the product topology. It turns out that the only one of these cases where $\mathbb{R}^{J}$ is metrizable is the case where $J$ is countable and $\mathbb{R}^{J}$ has the product topology. As we shall see.

Theorem 20.5. Let $\bar{d}(a, b)=\min \{|a-b|, 1\}$ be the standard bounded metric on $\mathbb{R}$. If $\mathbf{x}$ and $\mathbf{y}$ are two points of $\mathbb{R}^{\omega}$, define

$$
D(\mathbf{x}, \mathbf{y})=\sup \left\{\frac{\bar{d}\left(x_{i}, y_{i}\right)}{i}\right\}
$$

Then $D$ is a metric that induces the product topology on $\mathbb{R}^{\omega}$.

Proof. The properties of a metric are satisfied trivially except for the triangle inequality, which is proved by noting that for all $i$,

$$
\frac{\bar{d}\left(x_{i}, z_{i}\right)}{i} \leq \frac{\bar{d}\left(x_{i}, y_{i}\right)}{i}+\frac{\bar{d}\left(y_{i}, z_{i}\right)}{i} \leq D(\mathbf{x}, \mathbf{y})+D(\mathbf{y}, \mathbf{z})
$$

so that

$$
\sup \left\{\frac{\bar{d}\left(x_{i}, z_{i}\right)}{i}\right\} \leq D(\mathbf{x}, \mathbf{y})+D(\mathbf{y}, \mathbf{z})
$$

The fact that $D$ gives the product topology requires a little more work. First, let $U$ be open in the metric topology and let $\mathbf{x} \in U$; we find an open set $V$ in the product topology such that $\mathbf{x} \in V \subset U$. Choose an $\epsilon$-ball $B_{D}(\mathbf{x}, \epsilon)$ lying in $U$. Then choose $N$ large enough that $1 / N<\epsilon$. Finally, let $V$ be the basis element for the product topology

$$
V=\left(x_{1}-\epsilon, x_{1}+\epsilon\right) \times \cdots \times\left(x_{N}-\epsilon, x_{N}+\epsilon\right) \times \mathbb{R} \times \mathbb{R} \times \cdots
$$

We assert that $V \subset B_{D}(\mathbf{x}, \epsilon)$ : Given any $\mathbf{y}$ in $\mathbb{R}^{\omega}$,

$$
\frac{\bar{d}\left(x_{i}, y_{i}\right)}{i} \leq \frac{1}{N} \quad \text { for } i \geq N
$$

Therefore,

$$
D(\mathbf{x}, \mathbf{y}) \leq \max \left\{\frac{\bar{d}\left(x_{1}, y_{1}\right)}{1}, \cdots, \frac{\bar{d}\left(x_{N}, y_{N}\right)}{N}, \frac{1}{N}\right\}
$$

If $\mathbf{y}$ is in $V$, this expression is less than $\epsilon$, so that $V \subset B_{D}(\mathbf{x}, \epsilon)$, as desired.

Conversely, consider a basis element

$$
U=\prod_{i \in \mathbb{Z}_{+}} U_{i}
$$

for the product topology, where $U_{i}$ is open in $\mathbb{R}$ for $i=\alpha_{1}, \ldots, \alpha_{n}$ and $U_{i}=\mathbb{R}$ for all other indices $i$. Given $\mathbf{x} \in U$, we find an open set $V$ of the metric topology such that $\mathbf{x} \in V \subset U$. Choose an interval $\left(x_{i}-\epsilon_{i}, x_{i}+\epsilon_{i}\right)$ in $\mathbb{R}$ centered about $x_{i}$ and lying in $U_{i}$ for $i=\alpha_{1}, \ldots, \alpha_{n}$; choose each $\epsilon_{i} \leq 1$. Then define

$$
\epsilon=\min \left\{\epsilon_{i} / i \mid i=\alpha_{1}, \ldots, \alpha_{n}\right\} .
$$

We assert that

$$
\mathbf{x} \in B_{D}(\mathbf{x}, \epsilon) \subset U
$$

Let $\mathbf{y}$ be a point of $B_{D}(\mathbf{x}, \epsilon)$. Then for all $i$,

$$
\frac{\bar{d}\left(x_{i}, y_{i}\right)}{i} \leq D(\mathbf{x}, \mathbf{y})<\epsilon
$$

Now if $i=\alpha_{1}, \ldots, \alpha_{n}$, then $\epsilon \leq \epsilon_{i} / i$, so that $\bar{d}\left(x_{i}, y_{i}\right)<\epsilon_{i} \leq 1$; it follows that $\left|x_{i}-y_{i}\right|<\epsilon_{i}$. Therefore, $\mathbf{y} \in \prod U_{i}$, as desired.

## Exercises

1. (a) In $\mathbb{R}^{n}$, define

$$
d^{\prime}(\mathbf{x}, \mathbf{y})=\left|x_{1}-y_{1}\right|+\cdots+\left|x_{n}-y_{n}\right| .
$$

Show that $d^{\prime}$ is a metric that induces the usual topology of $\mathbb{R}^{n}$. Sketch the basis elements under $d^{\prime}$ when $n=2$.

(b) More generally, given $p \geq 1$, define

$$
d^{\prime}(\mathbf{x}, \mathbf{y})=\left[\sum_{i=1}^{n}\left|x_{i}-y_{i}\right|^{p}\right]^{1 / p}
$$

for $\mathbf{x}, \mathbf{y} \in \mathbb{R}^{n}$. Assume that $d^{\prime}$ is a metric. Show that it induces the usual topology on $\mathbb{R}^{n}$.

2. Show that $\mathbb{R} \times \mathbb{R}$ in the dictionary order topology is metrizable.
3. Let $X$ be a metric space with metric $d$.

(a) Show that $d: X \times X \rightarrow \mathbb{R}$ is continuous.

(b) Let $X^{\prime}$ denote a space having the same underlying set as $X$. Show that if $d: X^{\prime} \times X^{\prime} \rightarrow \mathbb{R}$ is continuous, then the topology of $X^{\prime}$ is finer than the topology of $X$.

One can summarize the result of this exercise as follows: If $X$ has a metric $d$, then the topology induced by $d$ is the coarsest topology relative to which the function $d$ is continuous.

4. Consider the product, uniform, and box topologies on $\mathbb{R}^{\omega}$.

(a) In which topologies are the following functions from $\mathbb{R}$ to $\mathbb{R}^{\omega}$ continuous?

$$
\begin{aligned}
& f(t)=(t, 2 t, 3 t, \ldots), \\
& g(t)=(t, t, t, \ldots), \\
& h(t)=\left(t, \frac{1}{2} t, \frac{1}{3} t, \ldots\right) .
\end{aligned}
$$

(b) In which topologies do the following sequences converge?

$$
\begin{aligned}
& \mathbf{w}_{1}=(1,1,1,1, \ldots), \quad \mathbf{x}_{1}=(1,1,1,1, \ldots), \\
& \mathbf{w}_{2}=(0,2,2,2, \ldots), \quad \mathbf{x}_{2}=\left(0, \frac{1}{2}, \frac{1}{2}, \frac{1}{2}, \ldots\right) \\
& \mathbf{w}_{3}=(0,0,3,3, \ldots), \quad \mathbf{x}_{3}=\left(0,0, \frac{1}{3}, \frac{1}{3} \ldots\right), \\
& \ldots \quad \quad \ldots \\
& \mathbf{y}_{1}=(1,0,0,0, \ldots), \quad \mathbf{z}_{1}=(1,1,0,0, \ldots) \\
& \mathbf{y}_{2}=\left(\frac{1}{2}, \frac{1}{2}, 0,0, \ldots\right), \quad \mathbf{z}_{2}=\left(\frac{1}{2}, \frac{1}{2}, 0,0, \ldots\right), \\
& \mathbf{y}_{3}=\left(\frac{1}{3}, \frac{1}{3}, \frac{1}{3}, 0, \ldots\right), \quad \mathbf{z}_{3}=\left(\frac{1}{3}, \frac{1}{3}, 0,0, \ldots\right), \\
& \text {.. } \quad \ldots
\end{aligned}
$$

5. Let $\mathbb{R}^{\infty}$ be the subset of $\mathbb{R}^{\omega}$ consisting of all sequences that are eventually zero. What is the closure of $\mathbb{R}^{\infty}$ in $\mathbb{R}^{\omega}$ in the uniform topology? Justify your answer.
6. Let $\bar{\rho}$ be the uniform metric on $\mathbb{R}^{\omega}$. Given $\mathbf{x}=\left(x_{1}, x_{2}, \ldots\right) \in \mathbb{R}^{\omega}$ and given $0<\epsilon<1$, let

$$
U(\mathbf{x}, \epsilon)=\left(x_{1}-\epsilon, x_{1}+\epsilon\right) \times \cdots \times\left(x_{n}-\epsilon, x_{n}+\epsilon\right) \times \cdots .
$$

(a) Show that $U(\mathbf{x}, \epsilon)$ is not equal to the $\epsilon$-ball $B_{\bar{\rho}}(\mathbf{x}, \epsilon)$.

(b) Show that $U(\mathbf{x}, \epsilon)$ is not even open in the uniform topology.

(c) Show that

$$
B_{\bar{\rho}}(\mathbf{x}, \epsilon)=\bigcup_{\delta<\epsilon} U(\mathbf{x}, \delta)
$$

7. Consider the map $h: \mathbb{R}^{\omega} \rightarrow \mathbb{R}^{\omega}$ defined in Exercise 8 of $\S 19$; give $\mathbb{R}^{\omega}$ the uniform topology. Under what conditions on the numbers $a_{i}$ and $b_{i}$ is $h$ continuous? a homeomorphism?
8. Let $X$ be the subset of $\mathbb{R}^{\omega}$ consisting of all sequences $\mathbf{x}$ such that $\sum x_{i}^{2}$ converges. Then the formula

$$
d(\mathbf{x}, \mathbf{y})=\left[\sum_{i=1}^{\infty}\left(x_{i}-y_{i}\right)^{2}\right]^{1 / 2}
$$

defines a metric on $X$. (See Exercise 10.) On $X$ we have the three topologies it inherits from the box, uniform, and product topologies on $\mathbb{R}^{\omega}$. We have also the topology given by the metric $d$, which we call the $\ell^{2}$-topology. (Read "little ell two.")

(a) Show that on $X$, we have the inclusions

$$
\text { box topology } \supset \ell^{2} \text {-topology } \supset \text { uniform topology. }
$$

(b) The set $\mathbb{R}^{\infty}$ of all sequences that are eventually zero is contained in $X$. Show that the four topologies that $\mathbb{R}^{\infty}$ inherits as a subspace of $X$ are all distinct.

(c) The set

$$
H=\prod_{n \in \mathbb{Z}_{+}}[0,1 / n]
$$

is contained in $X$; it is called the Hilbert cube. Compare the four topologies that $H$ inherits as a subspace of $X$.

9. Show that the euclidean metric $d$ on $\mathbb{R}^{n}$ is a metric, as follows: If $\mathbf{x}, \mathbf{y} \in \mathbb{R}^{n}$ and $c \in \mathbb{R}$, define

$$
\begin{aligned}
\mathbf{x}+\mathbf{y} & =\left(x_{1}+y_{1}, \ldots, x_{n}+y_{n}\right), \\
c \mathbf{x} & =\left(c x_{1}, \ldots, c x_{n}\right), \\
\mathbf{x} \cdot \mathbf{y} & =x_{1} y_{1}+\cdots+x_{n} y_{n} .
\end{aligned}
$$

(a) Show that $\mathbf{x} \cdot(\mathbf{y}+\mathbf{z})=(\mathbf{x} \cdot \mathbf{y})+(\mathbf{x} \cdot \mathbf{z})$.

(b) Show that $|\mathbf{x} \cdot \mathbf{y}| \leq\|\mathbf{x}\|\|\mathbf{y}\|$. [Hint: If $\mathbf{x}, \mathbf{y} \neq 0$, let $a=1 /\|\mathbf{x}\|$ and $b=1 /\|\mathbf{y}\|$, and use the fact that $\|a \mathbf{x} \pm b \mathbf{y}\| \geq 0$.]

(c) Show that $\|\mathbf{x}+\mathbf{y}\| \leq\|\mathbf{x}\|+\|\mathbf{y}\|$. [Hint: Compute $(\mathbf{x}+\mathbf{y}) \cdot(\mathbf{x}+\mathbf{y})$ and apply (b).]

(d) Verify that $d$ is a metric.

10. Let $X$ denote the subset of $\mathbb{R}^{\omega}$ consisting of all sequences $\left(x_{1}, x_{2}, \ldots\right)$ such that $\sum x_{i}^{2}$ converges. (You may assume the standard facts about infinite series. In case they are not familiar to you, we shall give them in Exercise 11 of the next section.)

(a) Show that if $\mathbf{x}, \mathbf{y} \in X$, then $\sum\left|x_{i} y_{i}\right|$ converges. [Hint: Use (b) of Exercise 9 to show that the partial sums are bounded.]

(b) Let $c \in \mathbb{R}$. Show that if $\mathbf{x}, \mathbf{y} \in X$, then so are $\mathbf{x}+\mathbf{y}$ and $c \mathbf{x}$.

(c) Show that

$$
d(\mathbf{x}, \mathbf{y})=\left[\sum_{i=1}^{\infty}\left(x_{i}-y_{i}\right)^{2}\right]^{1 / 2}
$$

is a well-defined metric on $X$.

*11. Show that if $d$ is a metric for $X$, then

$$
d^{\prime}(x, y)=d(x, y) /(1+d(x, y))
$$

is a bounded metric that gives the topology of $X$. [Hint: If $f(x)=x /(1+x)$ for $x>0$, use the mean-value theorem to show that $f(a+b)-f(b) \leq f(a)$.]

## §21 The Metric Topology (continued)

In this section, we discuss the relation of the metric topology to the concepts we have previously introduced.

Subspaces of metric spaces behave the way one would wish them to; if $A$ is a subspace of the topological space $X$ and $d$ is a metric for $X$, then the restriction of $d$ to $A \times A$ is a metric for the topology of $A$. This we leave to you to check.

About order topologies there is nothing to be said; some are metrizable (for instance, $\mathbb{Z}_{+}$and $\mathbb{R}$ ), and others are not, as we shall see.

The Hausdorff axiom is satisfied by every metric topology. If $x$ and $y$ are distinct points of the metric space $(X, d)$, we let $\epsilon=\frac{1}{2} d(x, y)$; then the triangle inequality implies that $B_{d}(x, \epsilon)$ and $B_{d}(y, \epsilon)$ are disjoint.

The product topology we have already considered in special cases; we have proved that the products $\mathbb{R}^{n}$ and $\mathbb{R}^{\omega}$ are metrizable. It is true in general that countable products of metrizable spaces are metrizable; the proof follows a pattern similar to the proof for $\mathbb{R}^{\omega}$, so we leave it to the exercises.

About continuous functions there is a good deal to be said. Consideration of this topic will occupy the remainder of the section.

When we study continuous functions on metric spaces, we are about as close to the study of calculus and analysis as we shall come in this book. There are two things we want to do at this point.

First, we want to show that the familiar " $\epsilon-\delta$ definition" of continuity carries over to general metric spaces, and so does the "convergent sequence definition" of continuity.

Second, we want to consider two additional methods for constructing continuous functions, besides those discussed in $\S 18$. One is the process of taking sums, differences, products, and quotients of continuous real-valued functions. The other is the process of taking limits of uniformly convergent sequences of continuous functions.

Theorem 21.1. Let $f: X \rightarrow Y$; let $X$ and $Y$ be metrizable with metrics $d_{X}$ and $d_{Y}$, respectively. Then continuity of $f$ is equivalent to the requirement that given $x \in X$ and given $\epsilon>0$, there exists $\delta>0$ such that

$$
d_{X}(x, y) \Longrightarrow d_{Y}(f(x), f(y))<\epsilon
$$

Proof. Suppose that $f$ is continuous. Given $x$ and $\epsilon$, consider the set

$$
f^{-1}(B(f(x), \epsilon)),
$$

which is open in $X$ and contains the point $x$. It contains some $\delta$-ball $B(x, \delta)$ centered at $x$. If $y$ is in this $\delta$-ball, then $f(y)$ is in the $\epsilon$-ball centered at $f(x)$, as desired.

Conversely, suppose that the $\epsilon-\delta$ condition is satisfied. Let $V$ be open in $Y$; we show that $f^{-1}(V)$ is open in $X$. Let $x$ be a point of the set $f^{-1}(V)$. Since $f(x) \in$ $V$, there is an $\epsilon$-ball $B(f(x), \epsilon)$ centered at $f(x)$ and contained in $V$. By the $\epsilon$ $\delta$ condition, there is a $\delta$-ball $B(x, \delta)$ centered at $x$ such that $f(B(x, \delta)) \subset B(f(x), \epsilon)$. Then $B(x, \delta)$ is a neighborhood of $x$ contained in $f^{-1}(V)$, so that $f^{-1}(V)$ is open, as desired.

Now we turn to the convergent sequence definition of continuity. We begin by considering the relation between convergent sequences and closures of sets. It is certainly believable, from one's experience in analysis, that if $x$ lies in the closure of a subset $A$ of the space $X$, then there should exist a sequence of points of $A$ converging to $x$. This is not true in general, but it is true for metrizable spaces.

Lemma 21.2 (The sequence lemma). Let $X$ be a topological space; let $A \subset X$. If there is a sequence of points of $A$ converging to $x$, then $x \in \bar{A}$; the converse holds if $X$ is metrizable.

Proof. Suppose that $x_{n} \rightarrow x$, where $x_{n} \in A$. Then every neighborhood $U$ of $x$ contains a point of $A$, so $x \in \bar{A}$ by Theorem 17.5. Conversely, suppose that $X$ is metrizable and $x \in \bar{A}$. Let $d$ be a metric for the topology of $X$. For each positive integer $n$, take the neighborhood $B_{d}(x, 1 / n)$ of radius $1 / n$ of $x$, and choose $x_{n}$ to be a point of its intersection with $A$. We assert that the sequence $x_{n}$ converges to $x$ : Any open set $U$ containing $x$ contains an $\epsilon$-ball $B_{d}(x, \epsilon)$ centered at $x$; if we choose $N$ so that $1 / N<\epsilon$, then $U$ contains $x_{i}$ for all $i \geq N$.

Theorem 21.3. Let $f: X \rightarrow Y$. If the function $f$ is continuous, then for every convergent sequence $x_{n} \rightarrow x$ in $X$, the sequence $f\left(x_{n}\right)$ converges to $f(x)$. The converse holds if $X$ is metrizable.

Proof. Assume that $f$ is continuous. Given $x_{n} \rightarrow x$, we wish to show that $f\left(x_{n}\right) \rightarrow$ $f(x)$. Let $V$ be a neighborhood of $f(x)$. Then $f^{-1}(V)$ is a neighborhood of $x$, and so there is an $N$ such that $x_{n} \in f^{-1}(V)$ for $n \geq N$. Then $f\left(x_{n}\right) \in V$ for $n \geq N$.

To prove the converse, assume that the convergent sequence condition is satisfied. Let $A$ be a subset of $X$; we show that $f(\bar{A}) \subset \overline{f(A)}$. If $x \in \bar{A}$, then there is a sequence $x_{n}$ of points of $A$ converging to $x$ (by the preceding lemma). By assumption, the sequence $f\left(x_{n}\right)$ converges to $f(x)$. Since $f\left(x_{n}\right) \in f(A)$, the preceding lemma implies that $f(x) \in \overline{f(A)}$. (Note that metrizability of $Y$ is not needed.) Hence $f(\bar{A}) \subset$ $\overline{f(A)}$, as desired.

Incidentally, in proving Lemma 21.2 and Theorem 21.3 we did not use the full strength of the hypothesis that the space $X$ is metrizable. All we really needed was the countable collection $B_{d}(x, 1 / n)$ of balls about $x$. This fact leads us to make a new definition.

A space $X$ is said to have a countable basis at the point $x$ if there is a countable collection $\left\{U_{n}\right\}_{n \in \mathbb{Z}_{+}}$of neighborhoods of $x$ such that any neighborhood $U$ of $x$ contains at
least one of the sets $U_{n}$. A space $X$ that has a countable basis at each of its points is said to satisfy the first countability axiom.

If $X$ has a countable basis $\left\{U_{n}\right\}$ at $x$, then the proof of Lemma 21.2 goes through; one simply replaces the ball $B_{d}(x, 1 / n)$ throughout by the set

$$
B_{n}=U_{1} \cap U_{2} \cap \cdots \cap U_{n} .
$$

The proof of Theorem 21.3 goes through unchanged.

A metrizable space always satisfies the first countability axiom, but the converse is not true, as we shall see. Like the Hausdorff axiom, the first countability axiom is a requirement that we sometimes impose on a topological space in order to prove stronger theorems about the space. We shall study it in more detail in Chapter 4.

Now we consider additional methods for constructing continuous functions. We need the following lemma:

Lemma 21.4. The addition, subtraction, and multiplication operations are continuous functions from $\mathbb{R} \times \mathbb{R}$ into $\mathbb{R}$; and the quotient operation is a continuous function from $\mathbb{R} \times(\mathbb{R}-\{0\})$ into $\mathbb{R}$.

You have probably seen this lemma proved before; it is a standard " $\epsilon-\delta$ argument." If not, a proof is outlined in Exercise 12 below; you should have no trouble filling in the details.

Theorem 21.5. If $X$ is a topological space, and if $f, g: X \rightarrow \mathbb{R}$ are continuous functions, then $f+g, f-g$, and $f \cdot g$ are continuous. If $g(x) \neq 0$ for all $x$, then $f / g$ is continuous.

Proof. The map $h: X \rightarrow \mathbb{R} \times \mathbb{R}$ defined by

$$
h(x)=f(x) \times g(x)
$$

is continuous, by Theorem 18.4. The function $f+g$ equals the composite of $h$ and the addition operation

$$
+: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}
$$

therefore $f+g$ is continuous. Similar arguments apply to $f-g, f \cdot g$, and $f / g$.

Finally, we come to the notion of uniform convergence.

Definition. Let $f_{n}: X \rightarrow Y$ be a sequence of functions from the set $X$ to the metric space $Y$. Let $d$ be the metric for $Y$. We say that the sequence $\left(f_{n}\right)$ converges uniformly to the function $f: X \rightarrow Y$ if given $\epsilon>0$, there exists an integer $N$ such that

$$
d\left(f_{n}(x), f(x)\right)<\epsilon
$$

for all $n>N$ and all $x$ in $X$.

Uniformity of convergence depends not only on the topology of $Y$ but also on its metric. We have the following theorem about uniformly convergent sequences:

Theorem 21.6 (Uniform limit theorem). Let $f_{n}: X \rightarrow Y$ be a sequence of continuous functions from the topological space $X$ to the metric space $Y$. If $\left(f_{n}\right)$ converges uniformly to $f$, then $f$ is continuous.

Proof. Let $V$ be open in $Y$; let $x_{0}$ be a point of $f^{-1}(V)$. We wish to find a neighborhood $U$ of $x_{0}$ such that $f(U) \subset V$.

Let $y_{0}=f\left(x_{0}\right)$. First choose $\epsilon$ so that the $\epsilon$-ball $B\left(y_{0}, \epsilon\right)$ is contained in $V$. Then, using uniform convergence, choose $N$ so that for all $n \geq N$ and all $x \in X$,

$$
d\left(f_{n}(x), f(x)\right)<\epsilon / 3
$$

Finally, using continuity of $f_{N}$, choose a neighborhood $U$ of $x_{0}$ such that $f_{N}$ carries $U$ into the $\epsilon / 3$ ball in $Y$ centered at $f_{N}\left(x_{0}\right)$.

We claim that $f$ carries $U$ into $B\left(y_{0}, \epsilon\right)$ and hence into $V$, as desired. For this purpose, note that if $x \in U$, then

$$
\begin{aligned}
d\left(f(x), f_{N}(x)\right)<\epsilon / 3 & \text { (by choice of } N \text { ), } \\
d\left(f_{N}(x), f_{N}\left(x_{0}\right)\right)<\epsilon / 3 & \text { (by choice of } U), \\
d\left(f_{N}\left(x_{0}\right), f\left(x_{0}\right)\right)<\epsilon / 3 & \text { (by choice of } N \text { ). }
\end{aligned}
$$

Adding and using the triangle inequality, we see that $d\left(f(x), f\left(x_{0}\right)\right)<\epsilon$, as desired.

Let us remark that the notion of uniform convergence is related to the definition of the uniform metric, which we gave in the preceding section. Consider, for example, the space $\mathbb{R}^{X}$ of all functions $f: X \rightarrow \mathbb{R}$, in the uniform metric $\bar{\rho}$. It is not difficult to see that a sequence of functions $f_{n}: X \rightarrow \mathbb{R}$ converges uniformly to $f$ if and only if the sequence $\left(f_{n}\right)$ converges to $f$ when they are considered as elements of the metric space $\left(\mathbb{R}^{X}, \bar{\rho}\right)$. We leave the proof to the exercises.

We conclude the section with some examples of spaces that are not metrizable.

EXAMPLE 1. $\mathbb{R}^{\omega}$ in the box topology is not metrizable.

We shall show that the sequence lemma does not hold for $\mathbb{R}^{\omega}$. Let $A$ be the subset of $\mathbb{R}^{\omega}$ consisting of those points all of whose coordinates are positive:

$$
A=\left\{\left(x_{1}, x_{2}, \ldots\right) \mid x_{i}>0 \text { for all } i \in \mathbb{Z}_{+}\right\}
$$

Let $\mathbf{0}$ be the "origin" in $\mathbb{R}^{\omega}$, that is, the point $(0,0, \ldots)$ each of whose coordinates is zero. In the box topology, $\mathbf{0}$ belongs to $\bar{A}$; for if

$$
B=\left(a_{1}, b_{1}\right) \times\left(a_{2}, b_{2}\right) \times \cdots
$$

is any basis element containing $\mathbf{0}$, then $B$ intersects $A$. For instance, the point

$$
\left(\frac{1}{2} b_{1}, \frac{1}{2} b_{2} \ldots\right)
$$

belongs to $B \cap A$.

But we assert that there is no sequence of points of $A$ converging to $\mathbf{0}$. For let $\left(\mathbf{a}_{n}\right)$ be a sequence of points of $A$, where

$$
\mathbf{a}_{n}=\left(x_{1 n}, x_{2 n}, \ldots, x_{i n}, \ldots\right) .
$$

Every coordinate $x_{i n}$ is positive, so we can construct a basis element $B^{\prime}$ for the box topology on $\mathbb{R}$ by setting

$$
B^{\prime}=\left(-x_{11}, x_{11}\right) \times\left(-x_{22}, x_{22}\right) \times \cdots .
$$

Then $B^{\prime}$ contains the origin $\mathbf{0}$, but it contains no member of the sequence $\left(\mathbf{a}_{n}\right)$; the point $\mathbf{a}_{n}$ cannot belong to $B^{\prime}$ because its $n$th coordinate $x_{n n}$ does not belong to the interval $\left(-x_{n n}, x_{n n}\right)$. Hence the sequence $\left(\mathbf{a}_{n}\right)$ cannot converge to $\mathbf{0}$ in the box topology.

EXAMPLE 2. An uncountable product of $\mathbb{R}$ with itself is not metrizable.

Let $J$ be an uncountable index set; we show that $\mathbb{R}^{J}$ does not satisfy the sequence lemma (in the product topology).

Let $A$ be the subset of $\mathbb{R}^{J}$ consisting of all points $\left(x_{\alpha}\right)$ such that $x_{\alpha}=1$ for all but finitely many values of $\alpha$. Let $\mathbf{0}$ be the "origin" in $\mathbb{R}^{J}$, the point each of whose coordinates is 0 .

We assert that $\mathbf{0}$ belongs to the closure of $A$. Let $\prod U_{\alpha}$ be a basis element containing $\mathbf{0}$. Then $U_{\alpha} \neq \mathbb{R}$ for only finitely many values of $\alpha$, say for $\alpha=\alpha_{1}, \ldots, \alpha_{n}$. Let $\left(x_{\alpha}\right)$ be the point of $A$ defined by letting $x_{\alpha}=0$ for $\alpha=\alpha_{1}, \ldots, \alpha_{n}$ and $x_{\alpha}=1$ for all other values of $\alpha$; then $\left(x_{\alpha}\right) \in A \cap \prod U_{\alpha}$, as desired.

But there is no sequence of points of $A$ converging to $\mathbf{0}$. For let $\mathbf{a}_{n}$ be a sequence of points of $A$. Given $n$, let $J_{n}$ denote the subset of $J$ consisting of those indices $\alpha$ for which the $\alpha$ th coordinate of $\mathbf{a}_{n}$ is different from 1. The union of all the sets $J_{n}$ is a countable union of finite sets and therefore countable. Because $J$ itself is uncountable, there is an index in $J$, say $\beta$, that does not lie in any of the sets $J_{n}$. This means that for each of the points $\mathbf{a}_{n}$, its $\beta$ th coordinate equals 1 .

Now let $U_{\beta}$ be the open interval $(-1,1)$ in $\mathbb{R}$, and let $U$ be the open set $\pi_{\beta}^{-1}\left(U_{\beta}\right)$ in $\mathbb{R}^{J}$. The set $U$ is a neighborhood of $\mathbf{0}$ that contains none of the points $\mathbf{a}_{n}$; therefore, the sequence $\mathbf{a}_{n}$ cannot converge to $\mathbf{0}$.

## Exercises

1. Let $A \subset X$. If $d$ is a metric for the topology of $X$, show that $d \mid A \times A$ is a metric for the subspace topology on $A$.
2. Let $X$ and $Y$ be metric spaces with metrics $d_{X}$ and $d_{Y}$, respectively. Let $f$ : $X \rightarrow Y$ have the property that for every pair of points $x_{1}, x_{2}$ of $X$,

$$
d_{Y}\left(f\left(x_{1}\right), f\left(x_{2}\right)\right)=d_{X}\left(x_{1}, x_{2}\right) .
$$

Show that $f$ is an imbedding. It is called an isometric imbedding of $X$ in $Y$.

3. Let $X_{n}$ be a metric space with metric $d_{n}$, for $n \in \mathbb{Z}_{+}$.

(a) Show that

$$
\rho(x, y)=\max \left\{d_{1}\left(x_{1}, y_{1}\right), \ldots, d_{n}\left(x_{n}, y_{n}\right)\right\}
$$

is a metric for the product space $X_{1} \times \cdots \times X_{n}$.
(b) Let $\bar{d}_{i}=\min \left\{d_{i}, 1\right\}$. Show that

$$
D(x, y)=\sup \left\{\bar{d}_{i}\left(x_{i}, y_{i}\right) / i\right\}
$$

is a metric for the product space $\prod X_{i}$.

4. Show that $\mathbb{R}_{\ell}$ and the ordered square satisfy the first countability axiom. (This result does not, of course, imply that they are metrizable.)
5. Theorem. Let $x_{n} \rightarrow x$ and $y_{n} \rightarrow y$ in the space $\mathbb{R}$. Then

$$
\begin{aligned}
x_{n}+y_{n} & \rightarrow x+y, \\
x_{n}-y_{n} & \rightarrow x-y, \\
x_{n} y_{n} & \rightarrow x y,
\end{aligned}
$$

and provided that each $y_{n} \neq 0$ and $y \neq 0$,

$$
x_{n} / y_{n} \rightarrow x / y .
$$

[Hint: Apply Lemma 21.4; recall from the exercises of $\S 19$ that if $x_{n} \rightarrow x$ and $y_{n} \rightarrow y$, then $x_{n} \times y_{n} \rightarrow x \times y$.]

6. Define $f_{n}:[0,1] \rightarrow \mathbb{R}$ by the equation $f_{n}(x)=x^{n}$. Show that the sequence ( $\left.f_{n}(x)\right)$ converges for each $x \in[0,1]$, but that the sequence $\left(f_{n}\right)$ does not converge uniformly.
7. Let $X$ be a set, and let $f_{n}: X \rightarrow \mathbb{R}$ be a sequence of functions. Let $\bar{\rho}$ be the uniform metric on the space $\mathbb{R}^{X}$. Show that the sequence $\left(f_{n}\right)$ converges uniformly to the function $f: X \rightarrow \mathbb{R}$ if and only if the sequence $\left(f_{n}\right)$ converges to $f$ as elements of the metric space $\left(\mathbb{R}^{X}, \bar{\rho}\right)$.
8. Let $X$ be a topological space and let $Y$ be a metric space. Let $f_{n}: X \rightarrow Y$ be a sequence of continuous functions. Let $x_{n}$ be a sequence of points of $X$ converging to $x$. Show that if the sequence $\left(f_{n}\right)$ converges uniformly to $f$, then $\left(f_{n}\left(x_{n}\right)\right)$ converges to $f(x)$.
9. Let $f_{n}: \mathbb{R} \rightarrow \mathbb{R}$ be the function

$$
f_{n}(x)=\frac{1}{n^{3}[x-(1 / n)]^{2}+1} .
$$

See Figure 21.1. Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be the zero function.

(a) Show that $f_{n}(x) \rightarrow f(x)$ for each $x \in \mathbb{R}$.

(b) Show that $f_{n}$ does not converge uniformly to $f$. (This shows that the converse of Theorem 21.6 does not hold; the limit function $f$ may be continuous even though the convergence is not uniform.)

10. Using the closed set formulation of continuity (Theorem 18.1), show that the following are closed subsets of $\mathbb{R}^{2}$ :

$$
\begin{aligned}
A & =\{x \times y \mid x y=1\}, \\
S^{1} & =\left\{x \times y \mid x^{2}+y^{2}=1\right\}, \\
B^{2} & =\left\{x \times y \mid x^{2}+y^{2} \leq 1\right\} .
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-136.jpg?height=456&width=813&top_left_y=366&top_left_x=615)

Figure 21.1

The set $B^{2}$ is called the (closed) unit ball in $\mathbb{R}^{2}$.

11. Prove the following standard facts about infinite series:

(a) Show that if $\left(s_{n}\right)$ is a bounded sequence of real numbers and $s_{n} \leq s_{n+1}$ for each $n$, then $\left(s_{n}\right)$ converges.

(b) Let $\left(a_{n}\right)$ be a sequence of real numbers; define

$$
s_{n}=\sum_{i=1}^{n} a_{i}
$$

If $s_{n} \rightarrow s$, we say that the infinite series

$$
\sum_{i=1}^{\infty} a_{i}
$$

converges to $s$ also. Show that if $\sum a_{i}$ converges to $s$ and $\sum b_{i}$ converges to $t$, then $\sum\left(c a_{i}+b_{i}\right)$ converges to $c s+t$.

(c) Prove the comparison test for infinite series: If $\left|a_{i}\right| \leq b_{i}$ for each $i$, and if the series $\sum b_{i}$ converges, then the series $\sum a_{i}$ converges. [Hint: Show that the series $\sum\left|a_{i}\right|$ and $\sum c_{i}$ converge, where $c_{i}=\left|a_{i}\right|+a_{i}$.]

(d) Given a sequence of functions $f_{n}: X \rightarrow \mathbb{R}$, let

$$
s_{n}(x)=\sum_{i=1}^{n} f_{i}(x)
$$

Prove the Weierstrass M-test for uniform convergence: If $\left|f_{i}(x)\right| \leq M_{i}$ for all $x \in X$ and all $i$, and if the series $\sum M_{i}$ converges, then the sequence $\left(s_{n}\right)$ converges uniformly to a function $s$. [Hint: Let $r_{n}=\sum_{i=n+1}^{\infty} M_{i}$. Show that if $k>n$, then $\left|s_{k}(x)-s_{n}(x)\right| \leq r_{n}$; conclude that $\left|s(x)-s_{n}(x)\right| \leq r_{n}$.]

12. Prove continuity of the algebraic operations on $\mathbb{R}$, as follows: Use the metric $d(a, b)=|a-b|$ on $\mathbb{R}$ and the metric on $\mathbb{R}^{2}$ given by the equation

$$
\rho\left((x, y),\left(x_{0}, y_{0}\right)\right)=\max \left\{\left|x-x_{0}\right|,\left|y-y_{0}\right|\right\} .
$$

(a) Show that addition is continuous. [Hint: Given $\epsilon$, let $\delta=\epsilon / 2$ and note that

$$
\left.d\left(x+y, x_{0}+y_{0}\right) \leq\left|x-x_{0}\right|+\left|y-y_{0}\right| .\right]
$$

(b) Show that multiplication is continuous. [Hint: Given $\left(x_{0}, y_{0}\right)$ and $0<\epsilon<$ 1 , let

$$
3 \delta=\epsilon /\left(\left|x_{0}\right|+\left|y_{0}\right|+1\right)
$$

and note that

$$
\left.d\left(x y, x_{0} y_{0}\right) \leq\left|x_{0}\right|\left|y-y_{0}\right|+\left|y_{0}\right|\left|x-x_{0}\right|+\left|x-x_{0}\right|\left|y-y_{0}\right| .\right]
$$

(c) Show that the operation of taking reciprocals is a continuous map from $\mathbb{R}-\{0\}$ to $\mathbb{R}$. [Hint: Show the inverse image of the interval $(a, b)$ is open. Consider five cases, according as $a$ and $b$ are positive, negative, or zero.]

(d) Show that the subtraction and quotient operations are continuous.

## *\$22 The Quotient Topology ${ }^{\dagger}$

Unlike the topologies we have already considered in this chapter, the quotient topology is not a natural generalization of something you have already studied in analysis. Nevertheless, it is easy enough to motivate. One motivation comes from geometry, where one often has occasion to use "cut-and-paste" techniques to construct such geometric objects as surfaces. The torus (surface of a doughnut), for example, can be constructed by taking a rectangle and "pasting" its edges together appropriately, as in Figure 22.1. And the sphere (surface of a ball) can be constructed by taking a disc and collapsing its entire boundary to a single point; see Figure 22.2. Formalizing these constructions involves the concept of quotient topology.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-137.jpg?height=208&width=1160&top_left_y=1836&top_left_x=616)

Figure 22.1[^2]

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-138.jpg?height=327&width=805&top_left_y=361&top_left_x=619)

Figure 22.2

Definition. Let $X$ and $Y$ be topological spaces; let $p: X \rightarrow Y$ be a surjective map. The map $p$ is said to be a quotient map provided a subset $U$ of $Y$ is open in $Y$ if and only if $p^{-1}(U)$ is open in $X$.

This condition is stronger than continuity; some mathematicians call it "strong continuity." An equivalent condition is to require that a subset $A$ of $Y$ be closed in $Y$ if and only if $p^{-1}(A)$ is closed in $X$. Equivalence of the two conditions follows from equation

$$
f^{-1}(Y-B)=X-f^{-1}(B) .
$$

Another way of describing a quotient map is as follows: We say that a subset $C$ of $X$ is saturated (with respect to the surjective map $p: X \rightarrow Y$ ) if $C$ contains every set $p^{-1}(\{y\})$ that it intersects. Thus $C$ is saturated if it equals the complete inverse image of a subset of $Y$. To say that $p$ is a quotient map is equivalent to saying that $p$ is continuous and $p$ maps saturated open sets of $X$ to open sets of $Y$ (or saturated closed sets of $X$ to closed sets of $Y$ ).

Two special kinds of quotient maps are the open maps and the closed maps. Recall that a map $f: X \rightarrow Y$ is said to be an open map if for each open set $U$ of $X$, the set $f(U)$ is open in $Y$. It is said to be aclosed map if for each closed set $A$ of $X$, the set $f(A)$ is closed in $Y$. It follows immediately from the definition that if $p: X \rightarrow Y$ is a surjective continuous map that is either open or closed, then $p$ is a quotient map. There are quotient maps that are neither open or closed. (See Exercise 3.)

EXAmple 1. Let $X$ be the subspace $[0,1] \cup[2,3]$ of $\mathbb{R}$, and let $Y$ be the subspace [0,2] of $\mathbb{R}$. The map $p: X \rightarrow Y$ defined by

$$
p(x)= \begin{cases}x & \text { for } x \in[0,1] \\ x-1 & \text { for } x \in[2,3]\end{cases}
$$

is readily seen to be surjective, continuous, and closed. Therefore it is a quotient map. It is not, however, an open map; the image of the open set [0,1] of $X$ is not open in $Y$.

Note that if $A$ is the subspace $[0,1) \cup[2,3]$ of $X$, then the map $q: A \rightarrow Y$ obtained by restricting $p$ is continuous and surjective, but it is not a quotient map. For the set $[2,3]$ is open in $A$ and is saturated with respect to $q$, but its image is not open in $Y$.

EXAMPLE 2. Let $\pi_{1}: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ be projection onto the first coordinate; then $\pi_{1}$ is continuous and surjective. Furthermore, $\pi_{1}$ is an open map. For if $U \times V$ is a nonempty basis element for $\mathbb{R} \times \mathbb{R}$, then $\pi_{1}(U \times V)=U$ is open in $\mathbb{R}$; it follows that $\pi_{1}$ carries open sets of $\mathbb{R} \times \mathbb{R}$ to open sets of $\mathbb{R}$. However, $\pi_{1}$ is not a closed map. The subset

$$
C=\{x \times y \mid x y=1\}
$$

of $\mathbb{R} \times \mathbb{R}$ is closed, but $\pi_{1}(C)=\mathbb{R}-\{0\}$, which is not closed in $\mathbb{R}$.

Note that if $A$ is the subspace of $\mathbb{R} \times \mathbb{R}$ that is the union of $C$ and the origin $\{\boldsymbol{0}\}$, then the map $q: A \rightarrow \mathbb{R}$ obtained by restricting $\pi_{1}$ is continuous and surjective, but it is not a quotient map. For the one-point set $\{\boldsymbol{0}\}$ is open in $A$ and is saturated with respect to $q$, but its image is not open in $\mathbb{R}$.

Now we show how the notion of quotient map can be used to construct a topology on a set.

Definition. If $X$ is a space and $A$ is a set and if $p: X \rightarrow A$ is a surjective map, then there exists exactly one topology $\mathcal{T}$ on $A$ relative to which $p$ is a quotient map; it is called the quotient topology induced by $p$.

The topology $\mathcal{T}$ is of course defined by letting it consist of those subsets $U$ of $A$ such that $p^{-1}(U)$ is open in $X$. It is easy to check that $\mathcal{T}$ is a topology. The sets $\varnothing$ and $A$ are open because $p^{-1}(\varnothing)=\varnothing$ and $p^{-1}(A)=X$. The other two conditions follow from the equations

$$
\begin{aligned}
p^{-1}\left(\bigcup_{\alpha \in J} U_{\alpha}\right) & =\bigcup_{\alpha \in J} p^{-1}\left(U_{\alpha}\right) \\
p^{-1}\left(\bigcap_{i=1}^{n} U_{i}\right) & =\bigcap_{i=1}^{n} p^{-1}\left(U_{i}\right)
\end{aligned}
$$

EXAMPLE 3. Let $p$ be the map of the real line $\mathbb{R}$ onto the three-point set $A=\{a, b, c\}$ defined by

$$
p(x)= \begin{cases}a & \text { if } x>0 \\ b & \text { if } x<0 \\ c & \text { if } x=0\end{cases}
$$

You can check that the quotient topology on $A$ induced by $p$ is the one indicated in Figure 22.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-139.jpg?height=225&width=584&top_left_y=1850&top_left_x=929)

Figure 22.3

There is a special situation in which the quotient topology occurs particularly frequently. It is the following:

Definition. Let $X$ be a topological space, and let $X^{*}$ be a partition of $X$ into disjoint subsets whose union is $X$. Let $p: X \rightarrow X^{*}$ be the surjective map that carries each point of $X$ to the element of $X^{*}$ containing it. In the quotient topology induced by $p$, the space $X^{*}$ is called a quotient space of $X$.

Given $X^{*}$, there is an equivalence relation on $X$ of which the elements of $X^{*}$ are the equivalence classes. One can think of $X^{*}$ as having been obtained by "identifying" each pair of equivalent points. For this reason, the quotient space $X^{*}$ is often called an identification space, or a decomposition space, of the space $X$.

We can describe the topology of $X^{*}$ in another way. A subset $U$ of $X^{*}$ is a collection of equivalence classes, and the set $p^{-1}(U)$ is just the union of the equivalence classes belonging to $U$. Thus the typical open set of $X^{*}$ is a collection of equivalence classes whose union is an open set of $X$.

EXAMPLE 4. Let $X$ be the closed unit ball

$$
\left\{x \times y \mid x^{2}+y^{2} \leq 1\right\}
$$

in $\mathbb{R}^{2}$, and let $X^{*}$ be the partition of $X$ consisting of all the one-point sets $\{x \times y\}$ for which $x^{2}+y^{2}<1$, along with the set $\left.S^{1}=\{x \times y\} \mid x^{2}+y^{2}=1\right\}$. Typical saturated open sets in $X$ are pictured by the shaded regions in Figure 22.4. One can show that $X^{*}$ is homeomorphic with the subspace of $\mathbb{R}^{3}$ called the unit 2 -sphere, defined by

$$
S^{2}=\left\{(x, y, z) \mid x^{2}+y^{2}+z^{2}=1\right\} .
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-140.jpg?height=355&width=763&top_left_y=1341&top_left_x=634)

Figure 22.4

EXAMPle 5. Let $X$ be the rectangle $[0,1] \times[0,1]$. Define a partition $X^{*}$ of $X$ as follows: It consists of all the one-point sets $\{x \times y\}$ where $0<x<1$ and $0<y<1$, the following types of two-point sets:

$$
\begin{aligned}
& \{x \times 0, x \times 1\} \quad \text { where } 0<x<1 \\
& \{0 \times y, 1 \times y\} \quad \text { where } 0<y<1
\end{aligned}
$$

and the four-point set

$$
\{0 \times 0,0 \times 1,1 \times 0,1 \times 1\} .
$$

Typical saturated open sets in $X$ are pictured by the shaded regions in Figure 22.5; each is an open set of $X$ that equals a union of elements of $X^{*}$.

The image of each of these sets under $p$ is an open set of $X^{*}$, as indicated in Figure 22.6. This description of $X^{*}$ is just the mathematical way of saying what we expressed in pictures when we pasted the edges of a rectangle together to form a torus.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-141.jpg?height=326&width=1140&top_left_y=558&top_left_x=620)

Figure 22.5

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-141.jpg?height=461&width=711&top_left_y=1024&top_left_x=841)

Figure 22.6

Now we explore the relationship between the notions of quotient map and quotient space and the concepts introduced previously. It is interesting to note that this relationship is not as simple as one might wish.

We have already noted that subspaces do not behave well; if $p: X \rightarrow Y$ is a quotient map and $A$ is a subspace of $X$, then the map $q: A \rightarrow p(A)$ obtained by restricting $p$ need not be a quotient map. One has, however, the following theorem:

Theorem 22.1. Let $p: X \rightarrow Y$ be a quotient map; let $A$ be a subspace of $X$ that is saturated with respect to $p$; let $q: A \rightarrow p(A)$ be the map obtained by restricting $p$.

(1) If $A$ is either open or closed in $X$, then $q$ is a quotient map.

(2) If $p$ is either an open map or a closed map, then $q$ is a quotient map.

Proof. Step 1. We verify first the following two equations:

$$
\begin{aligned}
q^{-1}(V) & =p^{-1}(V) & & \text { if } V \subset p(A) ; \\
p(U \cap A) & =p(U) \cap p(A) & & \text { if } U \subset X .
\end{aligned}
$$

To check the first equation, we note that since $V \subset p(A)$ and $A$ is saturated, $p^{-1}(V)$ is contained in $A$. It follows that both $p^{-1}(V)$ and $q^{-1}(V)$ equal all points of $A$ that are mapped by $p$ into $V$. To check the second equation, we note that for any two subsets $U$ and $A$ of $X$, we have the inclusion

$$
p(U \cap A) \subset p(U) \cap p(A) .
$$

To prove the reverse inclusion, suppose $y=p(u)=p(a)$, for $u \in U$ and $a \in A$. Since $A$ is saturated, $A$ contains the set $p^{-1}(p(a))$, so that in particular $A$ contains $u$. Then $y=p(u)$, where $u \in U \cap A$.

Step 2. Now suppose $A$ is open or $p$ is open. Given the subset $V$ of $p(A)$, we assume that $q^{-1}(V)$ is open in $A$ and show that $V$ is open in $p(A)$.

Suppose first that $A$ is open. Since $q^{-1}(V)$ is open in $A$ and $A$ is open in $X$, the set $q^{-1}(V)$ is open in $X$. Since $q^{-1}(V)=p^{-1}(V)$, the latter set is open in $X$, so that $V$ is open in $Y$ because $p$ is a quotient map. In particular, $V$ is open in $p(A)$.

Now suppose $p$ is open. Since $q^{-1}(V)=p^{-1}(V)$ and $q^{-1}(V)$ is open in $A$, we have $p^{-1}(V)=U \cap A$ for some set $U$ open in $X$. Now $p\left(p^{-1}(V)\right)=V$ because $p$ is surjective; then

$$
V=p\left(p^{-1}(V)\right)=p(U \cap A)=p(U) \cap p(A)
$$

The set $p(U)$ is open in $Y$ because $p$ is an open map; hence $V$ is open in $p(A)$.

Step 3. The proof when $A$ or $p$ is closed is obtained by replacing the word "open" by the word "closed" throughout Step 2.

Now we consider other concepts introduced previously. Composites of maps behave nicely; it is easy to check that the composite of two quotient maps is a quotient map; this fact follows from the equation

$$
p^{-1}\left(q^{-1}(U)\right)=(q \circ p)^{-1}(U)
$$

On the other hand, products of maps do not behave well; the cartesian product of two quotient maps need not be a quotient map. See Example 7 following. One needs further conditions on either the maps or the spaces in order for this statement to be true. One such, a condition on the spaces, is called local compactness; we shall study it later. Another, a condition on the maps, is the condition that both the maps $p$ and $q$ be open maps. In that case, it is easy to see that $p \times q$ is also an open map, so it is a quotient map.

Finally, the Hausdorff condition does not behave well; even if $X$ is Hausdorff, there is no reason that the quotient space $X^{*}$ needs to be Hausdorff. There is a simple condition for $X^{*}$ to satisfy the $T_{1}$ axiom; one simply requires that each element of the partition $X^{*}$ be a closed subset of $X$. Conditions that will ensure $X^{*}$ is Hausdorff are harder to find. This is one of the more delicate questions concerning quotient spaces; we shall return to it several times later in the book.

Perhaps the most important result in the study of quotient spaces has to do with the problem of constructing continuous functions on a quotient space. We consider that
problem now. When we studied product spaces, we had a criterion for determining whether a map $f: Z \rightarrow \prod X_{\alpha}$ into a product space was continuous. Its counterpart in the theory of quotient spaces is a criterion for determining when a map $f: X^{*} \rightarrow Z$ out of a quotient space is continuous. One has the following theorem:

Theorem 22.2. Let $p: X \rightarrow Y$ be a quotient map. Let $Z$ be a space and let $g: X \rightarrow Z$ be a map that is constant on each set $p^{-1}(\{y\})$, for $y \in Y$. Then $g$ induces a map $f: Y \rightarrow Z$ such that $f \circ p=g$. The induced map $f$ is continuous if and only if $g$ is continuous; $f$ is a quotient map if and only if $g$ is a quotient map.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-143.jpg?height=197&width=186&top_left_y=801&top_left_x=1106)

Proof. For each $y \in Y$, the set $g\left(p^{-1}(\{y\})\right)$ is a one-point set in $Z$ (since $g$ is constant on $\left.p^{-1}(\{y\})\right)$. If we let $f(y)$ denote this point, then we have defined a map $f: Y \rightarrow Z$ such that for each $x \in X, f(p(x))=g(x)$. If $f$ is continuous, then $g=f \circ p$ is continuous. Conversely, suppose $g$ is continuous. Given an open set $V$ of $Z, g^{-1}(V)$ is open in $X$. But $g^{-1}(V)=p^{-1}\left(f^{-1}(V)\right)$; because $p$ is a quotient map, it follows that $f^{-1}(V)$ is open in $Y$. Hence $f$ is continuous.

If $f$ is a quotient map, then $g$ is the composite of two quotient maps and is thus a quotient map. Conversely, suppose that $g$ is a quotient map. Since $g$ is surjective, so is $f$. Let $V$ be a subset of $Z$; we show that $V$ is open in $Z$ if $f^{-1}(V)$ is open in $Y$. Now the set $p^{-1}\left(f^{-1}(V)\right)$ is open in $X$ because $p$ is continuous. Since this set equals $g^{-1}(V)$, the latter is open in $X$. Then because $g$ is a quotient map, $V$ is open in $Z$.

Corollary 22.3. Let $g: X \rightarrow Z$ be a surjective continuous map. Let $X^{*}$ be the following collection of subsets of $X$ :

$$
X^{*}=\left\{g^{-1}(\{z\}) \mid z \in Z\right\} .
$$

Give $X^{*}$ the quotient topology.

(a) The map $g$ induces a bijective continuous map $f: X^{*} \rightarrow Z$, which is a homeomorphism if and only if $g$ is a quotient map.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-143.jpg?height=194&width=186&top_left_y=1910&top_left_x=1145)

(b) If $Z$ is Hausdorff, so is $X^{*}$.

Proof. By the preceding theorem, $g$ induces a continuous map $f: X^{*} \rightarrow Z$; it is clear that $f$ is bijective. Suppose that $f$ is a homeomorphism. Then both $f$ and the
projection map $p: X \rightarrow X^{*}$ are quotient maps, so that their composite $q$ is a quotient map. Conversely, suppose that $g$ is a quotient map. Then it follows from the preceding theorem that $f$ is a quotient map. Being bijective, $f$ is thus a homeomorphism.

Suppose $Z$ is Hausdorff. Given distinct points of $X^{*}$, their images under $f$ are distinct and thus possess disjoint neighborhoods $U$ and $V$. Then $f^{-1}(U)$ and $f^{-1}(V)$ are disjoint neighborhoods of the two given points of $X^{*}$.

EXAMPLE 6. Let $X$ be the subspace of $\mathbb{R}^{2}$ that is the union of the line segments $[0,1] \times$ $\{n\}$, for $n \in \mathbb{Z}_{+}$, and let $Z$ be the subspace of $\mathbb{R}^{2}$ consisting of all points of the form $x \times(x / n)$ for $x \in[0,1]$ and $n \in \mathbb{Z}_{+}$. Then $X$ is the union of countably many disjoint line segments, and $Z$ is the union of countably many line segments having an end point in common. See Figure 22.7 .

Define a map $g: X \rightarrow Z$ by the equation $g(x \times n)=x \times(x / n)$; then $g$ is surjective and continuous. The quotient space $X^{*}$ whose elements are the sets $g^{-1}(\{z\})$ is simply the space obtained from $X$ by identifying the subset $\{0\} \times \mathbb{Z}_{+}$to a point. The map $g$ induces a bijective continuous map $f: X^{*} \rightarrow Z$. But $f$ is not a homeomorphism.

To verify this fact, it suffices to show that $g$ is not a quotient map. Consider the sequence of points $x_{n}=(1 / n) \times n$ of $X$. The set $A=\left\{x_{n}\right\}$ is a closed subset of $X$ because it has no limit points. Also, it is saturated with respect to $g$. On the other hand, the set $g(A)$ is not closed in $Z$, for it consists of the points $z_{n}=(1 / n) \times\left(1 / n^{2}\right)$; this set has the origin as a limit point.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-144.jpg?height=334&width=968&top_left_y=1262&top_left_x=530)

Figure 22.7

EXAMPLE 7. The product of two quotient maps need not be a quotient map.

We give an example that involves non-Hausdorff spaces in the exercises. Here is another involving spaces that are nicer.

Let $X=\mathbb{R}$ and let $X^{*}$ be the quotient space obtained from $X$ by identifying the subset $\mathbb{Z}_{+}$to a point $b$; let $p: X \rightarrow X^{*}$ be the quotient map. Let $\mathbb{Q}$ be the subspace of $\mathbb{R}$ consisting of the rational numbers; let $i: \mathbb{Q} \rightarrow \mathbb{Q}$ be the identity map. We show that

$$
p \times i: X \times \mathbb{Q} \rightarrow X^{*} \times \mathbb{Q}
$$

is not a quotient map.

For each $n$, let $c_{n}=\sqrt{2} / n$, and consider the straight lines in $\mathbb{R}^{2}$ with slopes 1 and -1 , respectively, through the point $n \times c_{n}$. Let $U_{n}$ consist of all points of $X \times \mathbb{Q}$ that lie above both of these lines or beneath both of them, and also between the vertical lines $x=n-1 / 4$ and $x=n+1 / 4$. Then $U_{n}$ is open in $X \times \mathbb{Q}$; it contains the set $\{n\} \times \mathbb{Q}$ because $c_{n}$ is not rational. See Figure 22.8.

Let $U$ be the union of the sets $U_{n}$; then $U$ is open in $X \times \mathbb{Q}$. It is saturated with respect to $p \times i$ because it contains the entire set $\mathbb{Z}_{+} \times\{q\}$ for each $q \in \mathbb{Q}$. We assume that $U^{\prime}=(p \times i)(U)$ is open in $X^{*} \times \mathbb{Q}$ and derive a contradiction.

Because $U$ contains, in particular, the set $\mathbb{Z}_{+} \times 0$, the set $U^{\prime}$ contains the point $b \times 0$. Hence $U^{\prime}$ contains an open set of the form $W \times I_{\delta}$, where $W$ is a neighborhood of $b$ in $X^{*}$ and $I_{\delta}$ consists of all rational numbers $y$ with $|y|<\delta$. Then

$$
p^{-1}(W) \times I_{\delta} \subset U .
$$

Choose $n$ large enough that $c_{n}<\delta$. Then since $p^{-1}(W)$ is open in $X$ and contains $\mathbb{Z}_{+}$, we can choose $\epsilon<1 / 4$ so that the interval $(n-\epsilon, n+\epsilon)$ is contained in $p^{-1}(W)$. Then $U$ contains the subset $V=(n-\epsilon, n+\epsilon) \times I_{\delta}$ of $X \times \mathbb{Q}$. But the figure makes clear that there are many points $x \times y$ of $V$ that do not lie in $U$ ! (One such is the point $x \times y$, where $x=n+\frac{1}{2} \epsilon$ and $y$ is a rational number with $\left|y-c_{n}\right|<\frac{1}{2} \epsilon$.)

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-145.jpg?height=846&width=1296&top_left_y=926&top_left_x=551)

Figure 22.8

## Exercises

1. Check the details of Example 3.
2. (a) Let $p: X \rightarrow Y$ be a continuous map. Show that if there is a continuous map $f: Y \rightarrow X$ such that $p \circ f$ equals the identity map of $Y$, then $p$ is a quotient map.

(b) If $A \subset X$, a retraction of $X$ onto $A$ is a continuous map $r: X \rightarrow A$ such that $r(a)=a$ for each $a \in A$. Show that a retraction is a quotient map.

3. Let $\pi_{1}: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ be projection on the first coordinate. Let $A$ be the subspace of $\mathbb{R} \times \mathbb{R}$ consisting of all points $x \times y$ for which either $x \geq 0$ or $y=0$ (or both); let $q: A \rightarrow \mathbb{R}$ be obtained by restricting $\pi_{1}$. Show that $q$ is a quotient map that is neither open nor closed.
4. (a) Define an equivalence relation on the plane $X=\mathbb{R}^{2}$ as follows:

$$
x_{0} \times y_{0} \sim x_{1} \times y_{1} \quad \text { if } x_{0}+y_{0}^{2}=x_{1}+y_{1}^{2} .
$$

Let $X^{*}$ be the corresponding quotient space. It is homeomorphic to a familiar space; what is it? [Hint: Set $g(x \times y)=x+y^{2}$.]

(b) Repeat (a) for the equivalence relation

$$
x_{0} \times y_{0} \sim x_{1} \times y_{1} \quad \text { if } x_{0}^{2}+y_{0}^{2}=x_{1}^{2}+y_{1}^{2} \text {. }
$$

5. Let $p: X \rightarrow Y$ be an open map. Show that if $A$ is open in $X$, then the map $q: A \rightarrow p(A)$ obtained by restricting $p$ is an open map.
6. Recall that $\mathbb{R}_{K}$ denotes the real line in the $K$-topology. (See $\S 13$.) Let $Y$ be the quotient space obtained from $\mathbb{R}_{K}$ by collapsing the set $K$ to a point; let $p: \mathbb{R}_{K} \rightarrow Y$ be the quotient map.

(a) Show that $Y$ satisfies the $T_{1}$ axiom, but is not Hausdorff.

(b) Show that $p \times p: \mathbb{R}_{K} \times \mathbb{R}_{K} \rightarrow Y \times Y$ is not a quotient map. [Hint: The diagonal is not closed in $Y \times Y$, but its inverse image is closed in $\mathbb{R}_{K} \times \mathbb{R}_{K}$.]

## *Supplementary Exercises: Topological Groups

In these exercises we consider topological groups and some of their properties. The quotient topology gets its name from the special case that arises when one forms the quotient of a topological group by a subgroup.

A topological group $G$ is a group that is also a topological space satisfying the $T_{1}$ axiom, such that the map of $G \times G$ into $G$ sending $x \times y$ into $x \cdot y$, and the map of $G$ into $G$ sending $x$ into $x^{-1}$, are continuous maps. Throughout the following exercises, let $G$ denote a topological group.

1. Let $H$ denote a group that is also a topological space satisfying the $T_{1}$ axiom. Show that $H$ is a topological group if and only if the map of $H \times H$ into $H$ sending $x \times y$ into $x \cdot y^{-1}$ is continuous.
2. Show that the following are topological groups:

(a) $(\mathbb{Z},+)$

(b) $(\mathbb{R},+)$

(c) $\left(\mathbb{R}_{+}, \cdot\right)$

(d) $\left(S^{1}, \cdot\right)$, where we take $S^{1}$ to be the space of all complex numbers $z$ for which $|z|=1$.
(e) The general linear group GL( $n$ ), under the operation of matrix multiplication. $(\operatorname{GL}(n)$ is the set of all nonsingular $n$ by $n$ matrices, topologized by considering it as a subset of euclidean space of dimension $n^{2}$ in the obvious way.)

3. Let $H$ be a subspace of $G$. Show that if $H$ is also a subgroup of $G$, then both $H$ and $\bar{H}$ are topological groups.
4. Let $\alpha$ be an element of $G$. Show that the maps $f_{\alpha}, g_{\alpha}: G \rightarrow G$ defined by

$$
f_{\alpha}(x)=\alpha \cdot x \quad \text { and } \quad g_{\alpha}(x)=x \cdot \alpha
$$

are homeomorphisms of $G$. Conclude that $G$ is a homogeneous space. (This means that for every pair $x, y$ of points of $G$, there exists a homeomorphism of $G$ onto itself that carries $x$ to $y$.)

5. Let $H$ be a subgroup of $G$. If $x \in G$, define $x H=\{x \cdot h \mid h \in H\}$; this set is called a left coset of $H$ in $G$. Let $G / H$ denote the collection of left cosets of $H$ in $G$; it is a partition of $G$. Give $G / H$ the quotient topology.

(a) Show that if $\alpha \in G$, the map $f_{\alpha}$ of the preceding exercise induces a homeomorphism of $G / H$ carrying $x H$ to $(\alpha \cdot x) H$. Conclude that $G / H$ is a homogeneous space.

(b) Show that if $H$ is a closed set in the topology of $G$, then one-point sets are closed in $G / H$.

(c) Show that the quotient map $p: G \rightarrow G / H$ is open.

(d) Show that if $H$ is closed in the topology of $G$ and is a normal subgroup of $G$, then $G / H$ is a topological group.

6. The integers $\mathbb{Z}$ are a normal subgroup of $(\mathbb{R},+)$. The quotient $\mathbb{R} / \mathbb{Z}$ is a familiar topological group; what is it?
7. If $A$ and $B$ are subsets of $G$, let $A \cdot B$ denote the set of all points $a \cdot b$ for $a \in A$ and $b \in B$. Let $A^{-1}$ denote the set of all points $a^{-1}$, for $a \in A$.

(a) A neighborhood $V$ of the identity element $e$ is said to be symmetric if $V=$ $V^{-1}$. If $U$ is a neighborhood of $e$, show there is a symmetric neighborhood $V$ of $e$ such that $V \cdot V \subset U$. [Hint: If $W$ is a neighborhood of $e$, then $W \cdot W^{-1}$ is symmetric.]

(b) Show that $G$ is Hausdorff. In fact, show that if $x \neq y$, there is a neighborhood $V$ of $e$ such that $V \cdot x$ and $V \cdot y$ are disjoint.

(c) Show that $G$ satisfies the following separation axiom, which is called the regularity axiom: Given a closed set $A$ and a point $x$ not in $A$, there exist disjoint open sets containing $A$ and $x$, respectively. [Hint: There is a neighborhood $V$ of $e$ such that $V \cdot x$ and $V \cdot A$ are disjoint.]

(d) Let $H$ be a subgroup of $G$ that is closed in the topology of $G$; let $p: G \rightarrow$ $G / H$ be the quotient map. Show that $G / H$ satisfies the regularity axiom. [Hint: Examine the proof of (c) when $A$ is saturated.]

## Chapter 3

## Connectedness and Compactness

In the study of calculus, there are three basic theorems about continuous functions, and on these theorems the rest of calculus depends. They are the following:

Intermediate value theorem. If $f:[a, b] \rightarrow \mathbb{R}$ is continuous and if $r$ is a real number between $f(a)$ and $f(b)$, then there exists an element $c \in[a, b]$ such that $f(c)=r$.

Maximum value theorem. If $f:[a, b] \rightarrow R$ is continuous, then there exists an element $c \in[a, b]$ such that $f(x) \leq f(c)$ for every $x \in[a, b]$.

Uniform continuity theorem. If $f:[a, b] \rightarrow \mathbb{R}$ is continuous, then given $\epsilon>0$, there exists $\delta>0$ such that $\left|f\left(x_{1}\right)-f\left(x_{2}\right)\right|<\epsilon$ for every pair of numbers $x_{1}, x_{2}$ of $[a, b]$ for which $\left|x_{1}-x_{2}\right|<\delta$.

These theorems are used in a number of places. The intermediate value theorem is used for instance in constructing inverse functions, such as $\sqrt[3]{x}$ and $\arcsin x$; and the maximum value theorem is used for proving the mean value theorem for derivatives, upon which the two fundamental theorems of calculus depend. The uniform continuity theorem is used, among other things, for proving that every continuous function is integrable.

We have spoken of these three theorems as theorems about continuous functions. But they can also be considered as theorems about the closed interval $[a, b]$ of real numbers. The theorems depend not only on the continuity of $f$ but also on properties of the topological space $[a, b]$.

The property of the space $[a, b]$ on which the intermediate value theorem depends
is the property called connectedness, and the property on which the other two depend is the property called compactness. In this chapter, we shall define these properties for arbitrary topological spaces, and shall prove the appropriate generalized versions of these theorems.

As the three quoted theorems are fundamental for the theory of calculus, so are the notions of connectedness and compactness fundamental in higher analysis, geometry, and topology —indeed, in almost any subject for which the notion of topological space itself is relevant.

## §23 Connected Spaces

The definition of connectedness for a topological space is a quite natural one. One says that a space can be "separated" if it can be broken up into two "globs"-disjoint open sets. Otherwise, one says that it is connected. From this simple idea much follows.

Definition. Let $X$ be a topological space. A separation of $X$ is a pair $U, V$ of disjoint nonempty open subsets of $X$ whose union is $X$. The space $X$ is said to be connected if there does not exist a separation of $X$.

Connectedness is obviously a topological property, since it is formulated entirely in terms of the collection of open sets of $X$. Said differently, if $X$ is connected, so is any space homeomorphic to $X$.

Another way of formulating the definition of connectedness is the following:

A space $X$ is connected if and only if the only subsets of $X$ that are both open and closed in $X$ are the empty set and $X$ itself.

For if $A$ is a nonempty proper subset of $X$ that is both open and closed in $X$, then the sets $U=A$ and $V=X-A$ constitute a separation of $X$, for they are open, disjoint, and nonempty, and their union is $X$. Conversely, if $U$ and $V$ form a separation of $X$, then $U$ is nonempty and different from $X$, and it is both open and closed in $X$.

For a subspace $Y$ of a topological space $X$, there is another useful way of formulating the definition of connectedness:

Lemma 23.1. If $Y$ is a subspace of $X$, a separation of $Y$ is a pair of disjoint nonempty sets $A$ and $B$ whose union is $Y$, neither of which contains a limit point of the other. The space $Y$ is connected if there exists no separation of $Y$.

Proof. Suppose first that $A$ and $B$ form a separation of $Y$. Then $A$ is both open and closed in $Y$. The closure of $A$ in $Y$ is the set $\bar{A} \cap Y$ (where $\bar{A}$ as usual denotes the closure of $A$ in $X$ ). Since $A$ is closed in $Y, A=\bar{A} \cap Y$; or to say the same thing, $\bar{A} \cap B=\varnothing$. Since $\bar{A}$ is the union of $A$ and its limit points, $B$ contains no limit points of $A$. A similar argument shows that $A$ contains no limit points of $B$.

Conversely, suppose that $A$ and $B$ are disjoint nonempty sets whose union is $Y$, neither of which contains a limit point of the other. Then $\bar{A} \cap B=\varnothing$ and $A \cap \bar{B}=\varnothing$;
therefore, we conclude that $\bar{A} \cap Y=A$ and $\bar{B} \cap Y=B$. Thus both $A$ and $B$ are closed in $Y$, and since $A=Y-B$ and $B=Y-A$, they are open in $Y$ as well.

EXAMPLE 1. Let $X$ denote a two-point space in the indiscrete topology. Obviously there is no separation of $X$, so $X$ is connected.

EXAMPLE 2. Let $Y$ denote the subspace $[-1,0) \cup(0,1]$ of the real line $\mathbb{R}$. Each of the sets $[-1,0)$ and $(0,1]$ is nonempty and open in $Y$ (although not in $\mathbb{R}$ ); therefore, they form a separation of $Y$. Alternatively, note that neither of these sets contains a limit point of the other. (They do have a limit point 0 in common, but that does not matter.)

EXAmple 3. Let $X$ be the subspace $[-1,1]$ of the real line. The sets $[-1,0]$ and $(0,1]$ are disjoint and nonempty, but they do not form a separation of $X$, because the first set is not open in $X$. Alternatively, note that the first set contains a limit point, 0 , of the second. Indeed, there exists no separation of the space $[-1,1]$. We shall prove this fact shortly.

EXAMPLE 4. The rationals $\mathbb{Q}$ are not connected. Indeed, the only connected subspaces of $\mathbb{Q}$ are the one-point sets: If $Y$ is a subspace of $\mathbb{Q}$ containing two points $p$ and $q$, one can choose an irrational number $a$ lying between $p$ and $q$, and write $Y$ as the union of the open sets

$$
Y \cap(-\infty, a) \quad \text { and } \quad Y \cap(a,+\infty)
$$

EXAMPLE 5. Consider the following subset of the plane $\mathbb{R}^{2}$ :

$$
X=\{x \times y \mid y=0\} \cup\{x \times y \mid x>0 \text { and } y=1 / x\} \text {. }
$$

Then $X$ is not connected; indeed, the two indicated sets form a separation of $X$ because neither contains a limit point of the other. See Figure 23.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-150.jpg?height=206&width=635&top_left_y=1443&top_left_x=704)

Figure 23.1

We have given several examples of spaces that are not connected. How can one construct spaces that are connected? We shall now prove several theorems that tell how to form new connected spaces from given ones. In the next section we shall apply these theorems to show that some specific spaces, such as intervals in $\mathbb{R}$, and balls and cubes in $\mathbb{R}^{n}$, are connected. First, a lemma:

Lemma 23.2. If the sets $C$ and $D$ form a separation of $X$, and if $Y$ is a connected subspace of $X$, then $Y$ lies entirely within either $C$ or $D$.

Proof. Since $C$ and $D$ are both open in $X$, the sets $C \cap Y$ and $D \cap Y$ are open in $Y$. These two sets are disjoint and their union is $Y$; if they were both nonempty, they would constitute a separation of $Y$. Therefore, one of them is empty. Hence $Y$ must lie entirely in $C$ or in $D$.

Theorem 23.3. The union of a collection of connected subspaces of $X$ that have a point in common is connected.

Proof. Let $\left\{A_{\alpha}\right\}$ be a collection of connected subspaces of a space $X$; let $p$ be a point of $\bigcap A_{\alpha}$. We prove that the space $Y=\bigcup A_{\alpha}$ is connected. Suppose that $Y=C \cup D$ is a separation of $Y$. The point $p$ is in one of the sets $C$ or $D$; suppose $p \in C$. Since $A_{\alpha}$ is connected, it must lie entirely in either $C$ or $D$, and it cannot lie in $D$ because it contains the point $p$ of $C$. Hence $A_{\alpha} \subset C$ for every $\alpha$, so that $\bigcup A_{\alpha} \subset C$, contradicting the fact that $D$ is nonempty.

Theorem 23.4. Let $A$ be a connected subspace of $X$. If $A \subset B \subset \bar{A}$, then $B$ is also connected.

Said differently: If $B$ is formed by adjoining to the connected subspace $A$ some or all of its limit points, then $B$ is connected.

Proof. Let $A$ be connected and let $A \subset B \subset \bar{A}$. Suppose that $B=C \cup D$ is a separation of $B$. By Lemma 23.2, the set $A$ must lie entirely in $C$ or in $D$; suppose that $A \subset C$. Then $\bar{A} \subset \bar{C}$; since $\bar{C}$ and $D$ are disjoint, $B$ cannot intersect $D$. This contradicts the fact that $D$ is a nonempty subset of $B$.

Theorem 23.5. The image of a connected space under a continuous map is connected.

Proof. Let $f: X \rightarrow Y$ be a continuous map; let $X$ be connected. We wish to prove the image space $Z=f(X)$ is connected. Since the map obtained from $f$ by restricting its range to the space $Z$ is also continuous, it suffices to consider the case of a continuous surjective map

$$
g: X \rightarrow Z
$$

Suppose that $Z=A \cup B$ is a separation of $Z$ into two disjoint nonempty sets open in $Z$. Then $g^{-1}(A)$ and $g^{-1}(B)$ are disjoint sets whose union is $X$; they are open in $X$ because $g$ is continuous, and nonempty because $g$ is surjective. Therefore, they form a separation of $X$, contradicting the assumption that $X$ is connected.

Theorem 23.6. A finite cartesian product of connected spaces is connected.

Proof. We prove the theorem first for the product of two connected spaces $X$ and $Y$. This proof is easy to visualize. Choose a "base point" $a \times b$ in the product $X \times Y$. Note that the "horizontal slice" $X \times b$ is connected, being homeomorphic with $X$, and each "vertical slice" $x \times Y$ is connected, being homeomorphic with $Y$. As a result, each "T-shaped" space

$$
T_{x}=(X \times b) \cup(x \times Y)
$$

is connected, being the union of two connected spaces that have the point $x \times b$ in common. See Figure 23.2. Now form the union $\bigcup_{x \in X} T_{x}$ of all these T-shaped spaces.

This union is connected because it is the union of a collection of connected spaces that have the point $a \times b$ in common. Since this union equals $X \times Y$, the space $X \times Y$ is connected.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-152.jpg?height=314&width=575&top_left_y=548&top_left_x=734)

Figure 23.2

The proof for any finite product of connected spaces follows by induction, using the fact (easily proved) that $X_{1} \times \cdots \times X_{n}$ is homeomorphic with $\left(X_{1} \times \cdots \times X_{n-1}\right) \times$ $X_{n}$.

It is natural to ask whether this theorem extends to arbitrary products of connected spaces. The answer depends on which topology is used for the product, as the following examples show.

EXAMPLE 6. Consider the cartesian product $\mathbb{R}^{\omega}$ in the box topology. We can write $\mathbb{R}^{\omega}$ as the union of the set $A$ consisting of all bounded sequences of real numbers, and the set $B$ of all unbounded sequences. These sets are disjoint, and each is open in the box topology. For if $\mathbf{a}$ is a point of $\mathbb{R}^{\omega}$, the open set

$$
U=\left(a_{1}-1, a_{1}+1\right) \times\left(a_{2}-1, a_{2}+1\right) \times \cdots
$$

consists entirely of bounded sequences if $\mathbf{a}$ is bounded, and of unbounded sequences if $\mathbf{a}$ if unbounded. Thus, even though $\mathbb{R}$ is connected (as we shall prove in the next section), $\mathbb{R}^{\omega}$ is not connected in the box topology.

EXAmple 7. Now consider $\mathbb{R}^{\omega}$ in the product topology. Assuming that $\mathbb{R}$ is connected, we show that $\mathbb{R}^{\omega}$ is connected. Let $\tilde{\mathbb{R}}^{n}$ denote the subspace of $\mathbb{R}^{\omega}$ consisting of all sequences $\mathbf{x}=\left(x_{1}, x_{2}, \ldots\right)$ such that $x_{i}=0$ for $i>n$. The space $\tilde{\mathbb{R}}^{n}$ is clearly homeomorphic to $\mathbb{R}^{n}$, so that it is connected, by the preceding theorem. It follows that the space $\mathbb{R}^{\infty}$ that is the union of the spaces $\tilde{\mathbb{R}}^{n}$ is connected, for these spaces have the point $\mathbf{0}=(0,0, \ldots)$ in common. We show that the closure of $\mathbb{R}^{\infty}$ equals all of $\mathbb{R}^{\omega}$, from which it follows that $\mathbb{R}^{\omega}$ is connected as well.

Let $\mathbf{a}=\left(a_{1}, a_{2}, \ldots\right)$ be a point of $\mathbb{R}^{\omega}$. Let $U=\prod U_{i}$ be a basis element for the product topology that contains a. We show that $U$ intersects $\mathbb{R}^{\infty}$. There is an integer $N$ such that $U_{i}=\mathbb{R}$ for $i>N$. Then the point

$$
\mathbf{x}=\left(a_{1}, \ldots, a_{n}, 0,0, \ldots\right)
$$

of $\mathbb{R}^{\infty}$ belongs to $U$, since $a_{i} \in U_{i}$ for all $i$, and $0 \in U_{i}$ for $i>N$.

The argument just given generalizes to show that an arbitrary product of connected spaces is connected in the product topology. Since we shall not need this result, we leave the proof to the exercises.

## Exercises

1. Let $\mathcal{T}$ and $\mathcal{T}^{\prime}$ be two topologies on $X$. If $\mathcal{T}^{\prime} \supset \mathcal{T}$, what does connectedness of $X$ in one topology imply about connectedness in the other?
2. Let $\left\{A_{n}\right\}$ be a sequence of connected subspaces of $X$, such that $A_{n} \cap A_{n+1} \neq \varnothing$ for all $n$. Show that $\bigcup A_{n}$ is connected.
3. Let $\left\{A_{\alpha}\right\}$ be a collection of connected subspaces of $X$; let $A$ be a connected subspace of $X$. Show that if $A \cap A_{\alpha} \neq \varnothing$ for all $\alpha$, then $A \cup\left(\bigcup A_{\alpha}\right)$ is connected.
4. Show that if $X$ is an infinite set, it is connected in the finite complement topology.
5. A space is totally disconnected if its only connected subspaces are one-point sets. Show that if $X$ has the discrete topology, then $X$ is totally disconnected. Does the converse hold?
6. Let $A \subset X$. Show that if $C$ is a connected subspace of $X$ that intersects both $A$ and $X-A$, then $C$ intersects Bd $A$.
7. Is the space $\mathbb{R}_{\ell}$ connected? Justify your answer.
8. Determine whether or not $\mathbb{R}^{\omega}$ is connected in the uniform topology.
9. Let $A$ be a proper subset of $X$, and let $B$ be a proper subset of $Y$. If $X$ and $Y$ are connected, show that

$$
(X \times Y)-(A \times B)
$$

is connected.

10. Let $\left\{X_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of connected spaces; let $X$ be the product space

$$
X=\prod_{\alpha \in J} X_{\alpha}
$$

Let $\mathbf{a}=\left(a_{\alpha}\right)$ be a fixed point of $X$.

(a) Given any finite subset $K$ of $J$, let $X_{K}$ denote the subspace of $X$ consisting of all points $\mathbf{x}=\left(x_{\alpha}\right)$ such that $x_{\alpha}=a_{\alpha}$ for $\alpha \notin K$. Show that $X_{K}$ is connected.

(b) Show that the union $Y$ of the spaces $X_{K}$ is connected.

(c) Show that $X$ equals the closure of $Y$; conclude that $X$ is connected.

11. Let $p: X \rightarrow Y$ be a quotient map. Show that if each set $p^{-1}(\{y\})$ is connected, and if $Y$ is connected, then $X$ is connected.
12. Let $Y \subset X$; let $X$ and $Y$ be connected. Show that if $A$ and $B$ form a separation of $X-Y$, then $Y \cup A$ and $Y \cup B$ are connected.

## §24 Connected Subspaces of the Real Line

The theorems of the preceding section show us how to construct new connected spaces out of given ones. But where can we find some connected spaces to start with? The best place to begin is the real line. We shall prove that $\mathbb{R}$ is connected, and so are the intervals and rays in $\mathbb{R}$.

One application is the intermediate value theorem of calculus, suitably generalized. Another is the result that such familiar spaces as balls and spheres in euclidean space are connected; the proof involves a new notion, called path connectedness, which we also discuss.

The fact that intervals and rays in $\mathbb{R}$ are connected may be familiar to you from analysis. We prove it again here, in generalized form. It turns out that this fact does not depend on the algebraic properties of $\mathbb{R}$, but only on its order properties. To make this clear, we shall prove the theorem for an arbitrary ordered set that has the order properties of $\mathbb{R}$. Such a set is called a linear continuum.

Definition. A simply ordered set $L$ having more than one element is called a linear continuum if the following hold:

(1) $L$ has the least upper bound property.

(2) If $x<y$, there exists $z$ such that $x<z<y$.

Theorem 24.1. If $L$ is a linear continuum in the order topology, then $L$ is connected, and so are intervals and rays in $L$.

Proof. Recall that a subspace $Y$ of $L$ is said to be convex if for every pair of points $a, b$ of $Y$ with $a<b$, the entire interval $[a, b]$ of points of $L$ lies in $Y$. We prove that if $Y$ is a convex subspace of $L$, then $Y$ is connected.

So suppose that $Y$ is the union of the disjoint nonempty sets $A$ and $B$, each of which is open in $Y$. Choose $a \in A$ and $b \in B$; suppose for convenience that $a<b$. The interval $[a, b]$ of points of $L$ is contained in $Y$. Hence $[a, b]$ is the union of the disjoint sets

$$
A_{0}=A \cap[a, b] \quad \text { and } \quad B_{0}=B \cap[a, b]
$$

each of which is open in $[a, b]$ in the subspace topology, which is the same as the order topology. The sets $A_{0}$ and $B_{0}$ are nonempty because $a \in A_{0}$ and $b \in B_{0}$. Thus, $A_{0}$ and $B_{0}$ constitute a separation of $[a, b]$.

Let $c=\sup A_{0}$. We show that $c$ belongs neither to $A_{0}$ nor to $B_{0}$, which contradicts the fact that $[a, b]$ is the union of $A_{0}$ and $B_{0}$.

Case 1. Suppose that $c \in B_{0}$. Then $c \neq a$, so either $c=b$ or $a<c<b$. In either case, it follows from the fact that $B_{0}$ is open in $[a, b]$ that there is some interval of the form $(d, c]$ contained in $B_{0}$. If $c=b$, we have a contradiction at once, for $d$ is a smaller upper bound on $A_{0}$ than $c$. If $c<b$, we note that $(c, b]$ does not intersect $A_{0}$
(because $c$ is an upper bound on $A_{0}$ ). Then

$$
(d, b]=(d, c] \cup(c, b]
$$

does not intersect $A_{0}$. Again, $d$ is a smaller upper bound on $A_{0}$ than $c$, contrary to construction. See Figure 24.1.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-155.jpg?height=274&width=312&top_left_y=681&top_left_x=752)

Figure 24.1
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-155.jpg?height=270&width=310&top_left_y=684&top_left_x=1332)

Figure 24.2

Case 2. Suppose that $c \in A_{0}$. Then $c \neq b$, so either $c=a$ or $a<c<b$. Because $A_{0}$ is open in $[a, b]$, there must be some interval of the form $[c, e)$ contained in $A_{0}$. See Figure 24.2. Because of order property (2) of the linear continuum $L$, we can choose a point $z$ of $L$ such that $c<z<e$. Then $z \in A_{0}$, contrary to the fact that $c$ is an upper bound for $A_{0}$.

Corollary 24.2. The real line $\mathbb{R}$ is connected and so are intervals and rays in $\mathbb{R}$.

As an application, we prove the intermediate value theorem of calculus, suitably generalized.

Theorem 24.3 (Intermediate value theorem). Let $f: X \rightarrow Y$ be a continuous map, where $X$ is a connected space and $Y$ is an ordered set in the order topology. If $a$ and $b$ are two points of $X$ and if $r$ is a point of $Y$ lying between $f(a)$ and $f(b)$, then there exists a point $c$ of $X$ such that $f(c)=r$.

The intermediate value theorem of calculus is the special case of this theorem that occurs when we take $X$ to be a closed interval in $\mathbb{R}$ and $Y$ to be $\mathbb{R}$.

Proof. Assume the hypotheses of the theorem. The sets

$$
A=f(X) \cap(-\infty, r) \quad \text { and } \quad B=f(X) \cap(r,+\infty)
$$

are disjoint, and they are nonempty because one contains $f(a)$ and the other contains $f(b)$. Each is open in $f(X)$, being the intersection of an open ray in $Y$ with $f(X)$. If there were no point $c$ of $X$ such that $f(c)=r$, then $f(X)$ would be the union of the sets $A$ and $B$. Then $A$ and $B$ would constitute a separation of $f(X)$, contradicting the fact that the image of a connected space under a continuous map is connected.

EXAMPLE 1. One example of a linear continuum different from $\mathbb{R}$ is the ordered square. We check the least upper bound property. (The second property of a linear continuum is trivial to check.) Let $A$ be a subset of $I \times I$; let $\pi_{1}: I \times I \rightarrow I$ be projection on the first coordinate; let $b=\sup \pi_{1}(A)$. If $b \in \pi_{1}(A)$, then $A$ intersects the subset $b \times I$ of $I \times I$. Because $b \times I$ has the order type of $I$, the set $A \cap(b \times I)$ will have a least upper bound $b \times c$, which will be the least upper bound of $A$. See Figure 24.3. If $b \notin \pi_{1}(A)$, then $b \times 0$ is the least upper bound of $A$; no element of the form $b^{\prime} \times c$ with $b^{\prime}<b$ can be an upper bound for $A$, for then $b^{\prime}$ would be an upper bound for $\pi_{1}(A)$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-156.jpg?height=522&width=1138&top_left_y=724&top_left_x=482)

Figure 24.3

EXAMPLE 2. If $X$ is a well-ordered set, then $X \times[0,1)$ is a linear continuum in the dictionary order; this we leave to you to check. This set can be thought of as having been constructed by "fitting in" a set of the order type of $(0,1)$ immediately following each element of $X$.

Connectedness of intervals in $\mathbb{R}$ gives rise to an especially useful criterion for showing that a space $X$ is connected; namely, the condition that every pair of points of $X$ can be joined by a path in $X$ :

Definition. Given points $x$ and $y$ of the space $X$, a path in $X$ from $x$ to $y$ is a continuous map $f:[a, b] \rightarrow X$ of some closed interval in the real line into $X$, such that $f(a)=x$ and $f(b)=y$. A space $X$ is said to be path connected if every pair of points of $X$ can be joined by a path in $X$.

It is easy to see that a path-connected space $X$ is connected. Suppose $X=A \cup B$ is a separation of $X$. Let $f:[a, b] \rightarrow X$ be any path in $X$. Being the continuous image of a connected set, the set $f([a, b])$ is connected, so that it lies entirely in either $A$ or $B$. Therefore, there is no path in $X$ joining a point of $A$ to a point of $B$, contrary to the assumption that $X$ is path connected.

The converse does not hold; a connected space need not be path connected. See Examples 6 and 7 following.

EXAMPLE 3. Define the unit ball $B^{n}$ in $\mathbb{R}^{n}$ by the equation

$$
B^{n}=\{\mathbf{x} \mid\|\mathbf{x}\| \leq 1\}
$$

where

$$
\|\mathbf{x}\|=\left\|\left(x_{1}, \ldots, x_{n}\right)\right\|=\left(x_{1}^{2}+\cdots+x_{n}^{2}\right)^{1 / 2} .
$$

The unit ball is path connected; given any two points $\mathbf{x}$ and $\mathbf{y}$ of $B^{n}$, the straight-line path $f:[0,1] \rightarrow \mathbb{R}^{n}$ defined by

$$
f(t)=(1-t) \mathbf{x}+t \mathbf{y}
$$

lies in $B^{n}$. For if $\mathbf{x}$ and $\mathbf{y}$ are in $B^{n}$ and $t$ is in $[0,1]$,

$$
\|f(t)\| \leq(1-t)\|\mathbf{x}\|+t\|\mathbf{y}\| \leq 1 \text {. }
$$

A similar argument shows that every open ball $B_{d}(\mathbf{x}, \epsilon)$ and every closed ball $\bar{B}_{d}(\mathbf{x}, \epsilon)$ in $\mathbb{R}^{n}$ is path connected.

EXAMPLE 4. Define punctured euclidean space to be the space $\mathbb{R}^{n}-\{\mathbf{0}\}$, where $\mathbf{0}$ is the origin in $\mathbb{R}^{n}$. If $n>1$, this space is path connected: Given $\mathbf{x}$ and $\mathbf{y}$ different from $\mathbf{0}$, we can join $\mathbf{x}$ and $\mathbf{y}$ by the straight-line path between them if that path does not go through the origin. Otherwise, we can choose a point $\mathbf{z}$ not on the line joining $\mathbf{x}$ and $\mathbf{y}$, and take the broken-line path from $\mathbf{x}$ to $\mathbf{z}$, and then from $\mathbf{z}$ to $\mathbf{y}$.

EXAMPLE 5. Define the unit sphere $S^{n-1}$ in $\mathbb{R}^{n}$ by the equation

$$
S^{n-1}=\{\mathbf{x} \mid\|\mathbf{x}\|=1\}
$$

If $n>1$, it is path connected. For the map $g: \mathbb{R}^{n}-\{\boldsymbol{0}\} \rightarrow S^{n-1}$ defined by $g(\mathbf{x})=\mathbf{x} /\|\mathbf{x}\|$ is continuous and surjective; and it is easy to show that the continuous image of a pathconnected space is path connected.

EXAMPLE 6. The ordered square $I_{o}^{2}$ is connected but not path connected.

Being a linear continuum, the ordered square is connected. Let $p=0 \times 0$ and $q=$ $1 \times 1$. We suppose there is a path $f:[a, b] \rightarrow I_{o}^{2}$ joining $p$ and $q$ and derive a contradiction. The image set $f([a, b])$ must contain every point $x \times y$ of $I_{o}^{2}$, by the intermediate value theorem. Therefore, for each $x \in I$, the set

$$
U_{x}=f^{-1}(x \times(0,1))
$$

is a nonempty subset of $[a, b]$; by continuity, it is open in $[a, b]$. See Figure 24.4. Choose, for each $x \in I$, a rational number $q_{x}$ belonging to $U_{x}$. Since the sets $U_{x}$ are disjoint, the map $x \rightarrow q_{x}$ is an injective mapping of $I$ into $\mathbb{Q}$. This contradicts the fact that the interval $I$ is uncountable (which we shall prove later).

EXAMPLE 7. Let $S$ denote the following subset of the plane.

$$
S=\{x \times \sin (1 / x) \mid 0<x \leq 1\} .
$$

Because $S$ is the image of the connected set $(0,1]$ under a continuous map, $S$ is connected. Therefore, its closure $\bar{S}$ in $\mathbb{R}^{2}$ is also connected. The set $\bar{S}$ is a classical example in topology

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-158.jpg?height=281&width=828&top_left_y=373&top_left_x=638)

Figure 24.4

called the topologist's sine curve. It is illustrated in Figure 24.5; it equals the union of $S$ and the vertical interval $0 \times[-1,1]$. We show that $\bar{S}$ is not path connected.

Suppose there is a path $f:[a, c] \rightarrow \bar{S}$ beginning at the origin and ending at a point of $S$. The set of those $t$ for which $f(t) \in 0 \times[-1,1]$ is closed, so it has a largest element $b$. Then $f:[b, c] \rightarrow \bar{S}$ is a path that maps $b$ into the vertical interval $0 \times[-1,1]$ and maps the other points of $[b, c]$ to points of $S$.

Replace $[b, c]$ by $[0,1]$ for convenience; let $f(t)=(x(t), y(t))$. Then $x(0)=0$, while $x(t)>0$ and $y(t)=\sin (1 / x(t))$ for $t>0$. We show there is a sequence of points $t_{n} \rightarrow 0$ such that $y\left(t_{n}\right)=(-1)^{n}$. Then the sequence $y\left(t_{n}\right)$ does not converge, contradicting continuity of $f$.

To find $t_{n}$, we proceed as follows: Given $n$, choose $u$ with $0<u<x(1 / n)$ such that $\sin (1 / u)=(-1)^{n}$. Then use the intermediate value theorem to find $t_{n}$ with $0<t_{n}<1 / n$ such that $x\left(t_{n}\right)=u$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-158.jpg?height=407&width=813&top_left_y=1348&top_left_x=615)

Figure 24.5

## Exercises

1. (a) Show that no two of the spaces $(0,1),(0,1]$, and $[0,1]$ are homeomorphic. [Hint: What happens if you remove a point from each of these spaces?)]

(b) Suppose that there exist imbeddings $f: X \rightarrow Y$ and $g: Y \rightarrow X$. Show by means of an example that $X$ and $Y$ need not be homeomorphic.

(c) Show $\mathbb{R}^{n}$ and $\mathbb{R}$ are not homeomorphic if $n>1$.

2. Let $f: S^{1} \rightarrow \mathbb{R}$ be a continuous map. Show there exists a point $x$ of $S^{1}$ such that $f(x)=f(-x)$.
3. Let $f: X \rightarrow X$ be continuous. Show that if $X=[0,1]$, there is a point $x$ such that $f(x)=x$. The point $x$ is called a fixed point of $f$. What happens if $X$ equals $[0,1)$ or $(0,1)$ ?
4. Let $X$ be an ordered set in the order topology. Show that if $X$ is connected, then $X$ is a linear continuum.
5. Consider the following sets in the dictionary order. Which are linear continua?

(a) $\mathbb{Z}_{+} \times[0,1)$

(b) $[0,1) \times \mathbb{Z}_{+}$

(c) $[0,1) \times[0,1]$

(d) $[0,1] \times[0,1)$

6. Show that if $X$ is a well-ordered set, then $X \times[0,1)$ in the dictionary order is a linear continuum.
7. (a) Let $X$ and $Y$ be ordered sets in the order topology. Show that if $f: X \rightarrow Y$ is order preserving and surjective, then $f$ is a homeomorphism.

(b) Let $X=Y=\overline{\mathbb{R}}_{+}$. Given a positive integer $n$, show that the function $f(x)=$ $x^{n}$ is order preserving and surjective. Conclude that its inverse, the nth root function, is continuous.

(c) Let $X$ be the subspace $(-\infty,-1) \cup[0, \infty)$ of $\mathbb{R}$. Show that the function $f: X \rightarrow \mathbb{R}$ defined by setting $f(x)=x+1$ if $x<-1$, and $f(x)=x$ if $x \geq 0$, is order preserving and surjective. Is $f$ a homeomorphism? Compare with (a).

8. (a) Is a product of path-connected spaces necessarily path connected?

(b) If $A \subset X$ and $A$ is path connected, is $\bar{A}$ necessarily path connected?

(c) If $f: X \rightarrow Y$ is continuous and $X$ is path connected, is $f(X)$ necessarily path connected?

(d) If $\left\{A_{\alpha}\right\}$ is a collection of path-connected subspaces of $X$ and if $\bigcap A_{\alpha} \neq \varnothing$, is $\bigcup A_{\alpha}$ necessarily path connected?

9. Assume that $\mathbb{R}$ is uncountable. Show that if $A$ is a countable subset of $\mathbb{R}^{2}$, then $\mathbb{R}^{2}-A$ is path connected. [Hint: How many lines are there passing through a given point of $\mathbb{R}^{2}$ ?]
10. Show that if $U$ is an open connected subspace of $\mathbb{R}^{2}$, then $U$ is path connected. [Hint: Show that given $x_{0} \in U$, the set of points that can be joined to $x_{0}$ by a path in $U$ is both open and closed in $U$.]
11. If $A$ is a connected subspace of $X$, does it follow that $\operatorname{Int} A$ and $\operatorname{Bd} A$ are connected? Does the converse hold? Justify your answers.

*12. Recall that $S_{\Omega}$ denotes the minimal uncountable well-ordered set. Let $L$ denote the ordered set $S_{\Omega} \times[0,1)$ in the dictionary order, with its smallest element deleted. The set $L$ is a classical example in topology called the long line.

Theorem. The long line is path connected and locally homeomorphic to $\mathbb{R}$, but it cannot be imbedded in $\mathbb{R}$.

(a) Let $X$ be an ordered set; let $a<b<c$ be points of $X$. Show that $[a, c)$ has the order type of $[0,1)$ if and only if both $[a, b)$ and $[b, c)$ have the order type of $[0,1)$.

(b) Let $X$ be an ordered set. Let $x_{0}<x_{1}<\cdots$ be an increasing sequence of points of $X$; suppose $b=\sup \left\{x_{i}\right\}$. Show that $\left[x_{0}, b\right)$ has the order type of $[0,1)$ if and only if each interval $\left[x_{i}, x_{i+1}\right)$ has the order type of $[0,1)$.

(c) Let $a_{0}$ denote the smallest element of $S_{\Omega}$. For each element $a$ of $S_{\Omega}$ different from $a_{0}$, show that the interval $\left[a_{0} \times 0, a \times 0\right)$ of $S_{\Omega} \times[0,1)$ has the order type of $[0,1)$. [Hint: Proceed by transfinite induction. Either $a$ has an immediate predecessor in $S_{\Omega}$, or there is an increasing sequence $a_{i}$ in $S_{\Omega}$ with $a=\sup \left\{a_{i}\right\}$.]

(d) Show that $L$ is path connected.

(e) Show that every point of $L$ has a neighborhood homeomorphic with an open interval in $\mathbb{R}$.

(f) Show that $L$ cannot be imbedded in $\mathbb{R}$, or indeed in $\mathbb{R}^{n}$ for any $n$. [Hint: Any subspace of $\mathbb{R}^{n}$ has a countable basis for its topology.]

## *§25 Components and Local Connectedness ${ }^{\dagger}$

Given an arbitrary space $X$, there is a natural way to break it up into pieces that are connected (or path connected). We consider that process now.

Definition. Given $X$, define an equivalence relation on $X$ by setting $x \sim y$ if there is a connected subspace of $X$ containing both $x$ and $y$. The equivalence classes are called the components (or the "connected components") of $X$.

Symmetry and reflexivity of the relation are obvious. Transitivity follows by noting that if $A$ is a connected subspace containing $x$ and $y$, and if $B$ is a connected subspace containing $y$ and $z$, then $A \cup B$ is a subspace containing $x$ and $z$ that is connected because $A$ and $B$ have the point $y$ in common.

The components of $X$ can also be described as follows:

Theorem 25.1. The components of $X$ are connected disjoint subspaces of $X$ whose union is $X$, such that each nonempty connected subspace of $X$ intersects only one of them.

Proof. Being equivalence classes, the components of $X$ are disjoint and their union is $X$. Each connected subspace $A$ of $X$ intersects only one of them. For if $A$ intersects the components $C_{1}$ and $C_{2}$ of $X$, say in points $x_{1}$ and $x_{2}$, respectively, then $x_{1} \sim x_{2}$ by definition; this cannot happen unless $C_{1}=C_{2}$.[^3]

To show the component $C$ is connected, choose a point $x_{0}$ of $C$. For each point $x$ of $C$, we know that $x_{0} \sim x$, so there is a connected subspace $A_{x}$ containing $x_{0}$ and $x$. By the result just proved, $A_{x} \subset C$. Therefore,

$$
C=\bigcup_{x \in C} A_{x}
$$

Since the subspaces $A_{x}$ are connected and have the point $x_{0}$ in common, their union is connected.

Definition. We define another equivalence relation on the space $X$ by defining $x \sim y$ if there is a path in $X$ from $x$ to $y$. The equivalence classes are called the path components of $X$.

Let us show this is an equivalence relation. First we note that if there exists a path $f:[a, b] \rightarrow X$ from $x$ to $y$ whose domain is the interval $[a, b]$, then there is also a path $g$ from $x$ to $y$ having the closed interval $[c, d]$ as its domain. (This follows from the fact that any two closed intervals in $\mathbb{R}$ are homeomorphic.) Now the fact that $x \sim x$ for each $x$ in $X$ follows from the existence of the constant path $f:[a, b] \rightarrow X$ defined by the equation $f(t)=x$ for all $t$. Symmetry follows from the fact that if $f:[0,1] \rightarrow X$ is a path from $x$ to $y$, then the "reverse path" $g:[0,1] \rightarrow X$ defined by $g(t)=f(1-t)$ is a path from $y$ to $x$. Finally, transitivity is proved as follows: Let $f:[0,1] \rightarrow X$ be a path from $x$ to $y$, and let $g:[1,2] \rightarrow X$ be a path from $y$ to $z$. We can "paste $f$ and $g$ together" to get a path $h:[0,2] \rightarrow X$ from $x$ to $z$; the path $h$ will be continuous by the "pasting lemma," Theorem 18.3.

One has the following theorem, whose proof is similar to that of the theorem preceding:

Theorem 25.2. The path components of $X$ are path-connected disjoint subspaces of $X$ whose union is $X$, such that each nonempty path-connected subspace of $X$ intersects only one of them.

Note that each component of a space $X$ is closed in $X$, since the closure of a connected subspace of $X$ is connected. If $X$ has only finitely many components, then each component is also open in $X$, since its complement is a finite union of closed sets. But in general the components of $X$ need not be open in $X$.

One can say even less about the path components of $X$, for they need be neither open nor closed in $X$. Consider the following examples:

EXAMPLE 1. If $\mathbb{Q}$ is the subspace of $\mathbb{R}$ consisting of the rational numbers, then each component of $\mathbb{Q}$ consists of a single point. None of the components of $\mathbb{Q}$ are open in $\mathbb{Q}$.

EXAMPLE 2. The "topologist's sine curve" $\bar{S}$ of the preceding section is a space that has a single component (since it is connected) and two path components. One path component is the curve $S$ and the other is the vertical interval $V=0 \times[-1,1]$. Note that $S$ is open in $\bar{S}$ but not closed, while $V$ is closed but not open.

If one forms a space from $\bar{S}$ by deleting all points of $V$ having rational second coordinate, one obtains a space that has only one component but uncountably many path components.

Connectedness is a useful property for a space to possess. But for some purposes, it is more important that the space satisfy a connectedness condition locally. Roughly speaking, local connectedness means that each point has "arbitrarily small" neighborhoods that are connected. More precisely, one has the following definition:

Definition. A space $X$ is said to be locally connected at $\boldsymbol{x}$ if for every neighborhood $U$ of $x$, there is a connected neighborhood $V$ of $x$ contained in $U$. If $X$ is locally connected at each of its points, it is said simply to be locally connected. Similarly, a space $X$ is said to be locally path connected at $\boldsymbol{x}$ if for every neighborhood $U$ of $x$, there is a path-connected neighborhood $V$ of $x$ contained in $U$. If $X$ is locally path connected at each of its points, then it is said to be locally path connected.

EXAMPLE 3. Each interval and each ray in the real line is both connected and locally connected. The subspace $[-1,0) \cup(0,1]$ of $\mathbb{R}$ is not connected, but it is locally connected. The topologist's sine curve is connected but not locally connected. The rationals $\mathbb{Q}$ are neither connected nor locally connected.

Theorem 25.3. A space $X$ is locally connected if and only if for every open set $U$ of $X$, each component of $U$ is open in $X$.

Proof. Suppose that $X$ is locally connected; let $U$ be an open set in $X$; let $C$ be a component of $U$. If $x$ is a point of $C$, we can choose a connected neighborhood $V$ of $x$ such that $V \subset U$. Since $V$ is connected, it must lie entirely in the component $C$ of $U$. Therefore, $C$ is open in $X$.

Conversely, suppose that components of open sets in $X$ are open. Given a point $x$ of $X$ and a neighborhood $U$ of $x$, let $C$ be the component of $U$ containing $x$. Now $C$ is connected; since it is open in $X$ by hypothesis, $X$ is locally connected at $x$.

A similar proof holds for the following theorem:

Theorem 25.4. A space $X$ is locally path connected if and only if for every open set $U$ of $X$, each path component of $U$ is open in $X$.

The relation between path components and components is given in the following theorem:

Theorem 25.5. If $X$ is a topological space, each path component of $X$ lies in a component of $X$. If $X$ is locally path connected, then the components and the path components of $X$ are the same.

Proof. Let $C$ be a component of $X$; let $x$ be a point of $C$; let $P$ be the path component of $X$ containing $x$. Since $P$ is connected, $P \subset C$. We wish to show that if $X$ is locally path connected, $P=C$. Suppose that $P \subsetneq C$. Let $Q$ denote the union of all the path
components of $X$ that are different from $P$ and intersect $C$; each of them necessarily lies in $C$, so that

$$
C=P \cup Q
$$

Because $X$ is locally path connected, each path component of $X$ is open in $X$. Therefore, $P$ (which is a path component) and $Q$ (which is a union of path components) are open in $X$, so they constitute a separation of $C$. This contradicts the fact that $C$ is connected.

## Exercises

1. What are the components and path components of $\mathbb{R}_{\ell}$ ? What are the continuous $\operatorname{maps} f: \mathbb{R} \rightarrow \mathbb{R}_{\ell}$ ?
2. (a) What are the components and path components of $\mathbb{R}^{\omega}$ (in the product topology)?

(b) Consider $\mathbb{R}^{\omega}$ in the uniform topology. Show that $\mathbf{x}$ and $\mathbf{y}$ lie in the same component of $\mathbb{R}^{\omega}$ if and only if the sequence

$$
\mathbf{x}-\mathbf{y}=\left(x_{1}-y_{1}, x_{2}-y_{2}, \ldots\right)
$$

is bounded. [Hint: It suffices to consider the case where $\mathbf{y}=\mathbf{0}$.]

(c) Give $\mathbb{R}^{\omega}$ the box topology. Show that $\mathbf{x}$ and $\mathbf{y}$ lie in the same component of $\mathbb{R}^{\omega}$ if and only if the sequence $\mathbf{x}-\mathbf{y}$ is "eventually zero." [Hint: If $\mathbf{x}-\mathbf{y}$ is not eventually zero, show there is homeomorphism $h$ of $\mathbb{R}^{\omega}$ with itself such that $h(\mathbf{x})$ is bounded and $h(\mathbf{y})$ is unbounded.]

3. Show that the ordered square is locally connected but not locally path connected. What are the path components of this space?
4. Let $X$ be locally path connected. Show that every connected open set in $X$ is path connected.
5. Let $X$ denote the rational points of the interval $[0,1] \times 0$ of $\mathbb{R}^{2}$. Let $T$ denote the union of all line segments joining the point $p=0 \times 1$ to points of $X$.

(a) Show that $T$ is path connected, but is locally connected only at the point $p$.

(b) Find a subset of $\mathbb{R}^{2}$ that is path connected but is locally connected at none of its points.

6. A space $X$ is said to be weakly locally connected at $\boldsymbol{x}$ if for every neighborhood $U$ of $x$, there is a connected subspace of $X$ contained in $U$ that contains a neighborhood of $x$. Show that if $X$ is weakly locally connected at each of its points, then $X$ is locally connected. [Hint: Show that components of open sets are open.]
7. Consider the "infinite broom" $X$ pictured in Figure 25.1. Show that $X$ is not locally connected at $p$, but is weakly locally connected at $p$. [Hint: Any connected neighborhood of $p$ must contain all the points $a_{i}$.]

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-164.jpg?height=236&width=1113&top_left_y=376&top_left_x=465)

Figure 25.1

8. Let $p: X \rightarrow Y$ be a quotient map. Show that if $X$ is locally connected, then $Y$ is locally connected. [Hint: If $C$ is a component of the open set $U$ of $Y$, show that $p^{-1}(C)$ is a union of components of $p^{-1}(U)$.]
9. Let $G$ be a topological group; let $C$ be the component of $G$ containing the identity element $e$. Show that $C$ is a normal subgroup of $G$. [Hint: If $x \in G$, then $x C$ is the component of $G$ containing $x$.]
10. Let $X$ be a space. Let us define $x \sim y$ if there is no separation $X=A \cup B$ of $X$ into disjoint open sets such that $x \in A$ and $y \in B$.

(a) Show this relation is an equivalence relation. The equivalence classes are called the quasicomponents of $X$.

(b) Show that each component of $X$ lies in a quasicomponent of $X$, and that the components and quasicomponents of $X$ are the same if $X$ is locally connected.

(c) Let $K$ denote the set $\left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}$and let $-K$ denote the set $\{-1 / n \mid n \in$ $\left.\mathbb{Z}_{+}\right\}$. Determine the components, path components, and quasicomponents of the following subspaces of $\mathbb{R}^{2}$ :

$$
\begin{aligned}
& A=(K \times[0,1]) \cup\{0 \times 0\} \cup\{0 \times 1\} \\
& B=A \cup([0,1] \times\{0\}) \\
& C=(K \times[0,1]) \cup(-K \times[-1,0]) \cup([0,1] \times-K) \cup([-1,0] \times K)
\end{aligned}
$$

## $\$ 26$ Compact Spaces

The notion of compactness is not nearly so natural as that of connectedness. From the beginnings of topology, it was clear that the closed interval $[a, b]$ of the real line had a certain property that was crucial for proving such theorems as the maximum value theorem and the uniform continuity theorem. But for a long time, it was not clear how this property should be formulated for an arbitrary topological space. It used to be thought that the crucial property of $[a, b]$ was the fact that every infinite subset of $[a, b]$ has a limit point, and this property was the one dignified with the name of compactness. Later, mathematicians realized that this formulation does not lie at the heart of the matter, but rather that a stronger formulation, in terms of open coverings of the space, is more central. The latter formulation is what we now call compactness.

It is not as natural or intuitive as the former; some familiarity with it is needed before its usefulness becomes apparent.

Definition. A collection $\mathcal{A}$ of subsets of a space $X$ is said to cover $X$, or to be a covering of $X$, if the union of the elements of $\mathcal{A}$ is equal to $X$. It is called an open covering of $X$ if its elements are open subsets of $X$.

Definition. A space $X$ is said to be compact if every open covering $\mathcal{A}$ of $X$ contains a finite subcollection that also covers $X$.

EXAMPLE 1. The real line $\mathbb{R}$ is not compact, for the covering of $\mathbb{R}$ by open intervals

$$
\mathcal{A}=\{(n, n+2) \mid n \in \mathbb{Z}\}
$$

contains no finite subcollection that covers $\mathbb{R}$.

EXAMPLE 2. The following subspace of $\mathbb{R}$ is compact:

$$
X=\{0\} \cup\left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}
$$

Given an open covering $\mathcal{A}$ of $X$, there is an element $U$ of $\mathcal{A}$ containing 0 . The set $U$ contains all but finitely many of the points $1 / n$; choose, for each point of $X$ not in $U$, an element of $\mathcal{A}$ containing it. The collection consisting of these elements of $\mathcal{A}$, along with the element $U$, is a finite subcollection of $\mathcal{A}$ that covers $X$.

EXAMPLE 3. Any space $X$ containing only finitely many points is necessarily compact, because in this case every open covering of $X$ is finite.

EXAMPLE 4. The interval $(0,1]$ is not compact; the open covering

$$
\mathcal{A}=\left\{(1 / n, 1] \mid n \in \mathbb{Z}_{+}\right\}
$$

contains no finite subcollection covering $(0,1]$. Nor is the interval $(0,1)$ compact; the same argument applies. On the other hand, the interval $[0,1]$ is compact; you are probably already familiar with this fact from analysis. In any case, we shall prove it shortly.

In general, it takes some effort to decide whether a given space is compact or not. First we shall prove some general theorems that show us how to construct new compact spaces out of existing ones. Then in the next section we shall show certain specific spaces are compact. These spaces include all closed intervals in the real line, and all closed and bounded subsets of $\mathbb{R}^{n}$.

Let us first prove some facts about subspaces. If $Y$ is a subspace of $X$, a collection $\mathcal{A}$ of subsets of $X$ is said to cover $Y$ if the union of its elements contains $Y$.

Lemma 26.1. Let $Y$ be a subspace of $X$. Then $Y$ is compact if and only if every covering of $Y$ by sets open in $X$ contains a finite subcollection covering $Y$.

Proof. Suppose that $Y$ is compact and $\mathscr{A}=\left\{A_{\alpha}\right\}_{\alpha \in J}$ is a covering of $Y$ by sets open in $X$. Then the collection

$$
\left\{A_{\alpha} \cap Y \mid \alpha \in J\right\}
$$

is a covering of $Y$ by sets open in $Y$; hence a finite subcollection

$$
\left\{A_{\alpha_{1}} \cap Y, \ldots, A_{\alpha_{n}} \cap Y\right\}
$$

covers $Y$. Then $\left\{A_{\alpha_{1}}, \ldots, A_{\alpha_{n}}\right\}$ is a subcollection of $\mathcal{A}$ that covers $Y$.

Conversely, suppose the given condition holds; we wish to prove $Y$ compact. Let $\mathcal{A}^{\prime}=\left\{A_{\alpha}^{\prime}\right\}$ be a covering of $Y$ by sets open in $Y$. For each $\alpha$, choose a set $A_{\alpha}$ open in $X$ such that

$$
A_{\alpha}^{\prime}=A_{\alpha} \cap Y
$$

The collection $\mathscr{A}=\left\{A_{\alpha}\right\}$ is a covering of $Y$ by sets open in $X$. By hypothesis, some finite subcollection $\left\{A_{\alpha_{1}}, \ldots, A_{\alpha_{n}}\right\}$ covers $Y$. Then $\left\{A_{\alpha_{1}}^{\prime}, \ldots, A_{\alpha_{n}}^{\prime}\right\}$ is a subcollection of $\mathcal{A}^{\prime}$ that covers $Y$.

Theorem 26.2. Every closed subspace of a compact space is compact.

Proof. Let $Y$ be a closed subspace of the compact space $X$. Given a covering $\mathcal{A}$ of $Y$ by sets open in $X$, let us form an open covering $\mathcal{B}$ of $X$ by adjoining to $\mathcal{A}$ the single open set $X-Y$, that is,

$$
\mathscr{B}=\mathcal{A} \cup\{X-Y\} .
$$

Some finite subcollection of $\mathscr{B}$ covers $X$. If this subcollection contains the set $X-Y$, discard $X-Y$; otherwise, leave the subcollection alone. The resulting collection is a finite subcollection of $\mathcal{A}$ that covers $Y$.

Theorem 26.3. Every compact subspace of a Hausdorff space is closed.

Proof. Let $Y$ be a compact subspace of the Hausdorff space $X$. We shall prove that $X-Y$ is open, so that $Y$ is closed.

Let $x_{0}$ be a point of $X-Y$. We show there is a neighborhood of $x_{0}$ that is disjoint from $Y$. For each point $y$ of $Y$, let us choose disjoint neighborhoods $U_{y}$ and $V_{y}$ of the points $x_{0}$ and $y$, respectively (using the Hausdorff condition). The collection $\left\{V_{y} \mid y \in\right.$ $Y\}$ is a covering of $Y$ by sets open in $X$; therefore, finitely many of them $V_{y_{1}}, \ldots, V_{y_{n}}$ cover $Y$. The open set

$$
V=V_{y_{1}} \cup \cdots \cup V_{y_{n}}
$$

contains $Y$, and it is disjoint from the open set

$$
U=U_{y_{1}} \cap \cdots \cap U_{y_{n}}
$$

formed by taking the intersection of the corresponding neighborhoods of $x_{0}$. For if $z$ is a point of $V$, then $z \in V_{y_{i}}$ for some $i$, hence $z \notin U_{y_{i}}$ and so $z \notin U$. See Figure 26.1.

Then $U$ is a neighborhood of $x_{0}$ disjoint from $Y$, as desired.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-167.jpg?height=541&width=864&top_left_y=368&top_left_x=767)

Figure 26.1

The statement we proved in the course of the preceding proof will be useful to us later, so we repeat it here for reference purposes:

Lemma 26.4. If $Y$ is a compact subspace of the Hausdorff space $X$ and $x_{0}$ is not in $Y$, then there exist disjoint open sets $U$ and $V$ of $X$ containing $x_{0}$ and $Y$, respectively.

EXAMPLE 5. Once we prove that the interval $[a, b]$ in $\mathbb{R}$ is compact, it follows from Theorem 26.2 that any closed subspace of $[a, b]$ is compact. On the other hand, it follows from Theorem 26.3 that the intervals $(a, b]$ and $(a, b)$ in $\mathbb{R}$ cannot be compact (which we knew already) because they are not closed in the Hausdorff space $\mathbb{R}$.

EXAMPLE 6. One needs the Hausdorff condition in the hypothesis of Theorem 26.3. Consider, for example, the finite complement topology on the real line. The only proper subsets of $\mathbb{R}$ that are closed in this topology are the finite sets. But every subset of $\mathbb{R}$ is compact in this topology, as you can check.

Theorem 26.5. The image of a compact space under a continuous map is compact.

Proof. Let $f: X \rightarrow Y$ be continuous; let $X$ be compact. Let $\mathcal{A}$ be a covering of the set $f(X)$ by sets open in $Y$. The collection

$$
\left\{f^{-1}(A) \mid A \in \mathcal{A}\right\}
$$

is a collection of sets covering $X$; these sets are open in $X$ because $f$ is continuous. Hence finitely many of them, say

$$
f^{-1}\left(A_{1}\right), \ldots, f^{-1}\left(A_{n}\right)
$$

cover $X$. Then the sets $A_{1}, \ldots, A_{n}$ cover $f(X)$.

One important use of the preceding theorem is as a tool for verifying that a map is a homeomorphism:

Theorem 26.6. Let $f: X \rightarrow Y$ be a bijective continuous function. If $X$ is compact and $Y$ is Hausdorff, then $f$ is a homeomorphism.

Proof. We shall prove that images of closed sets of $X$ under $f$ are closed in $Y$; this will prove continuity of the map $f^{-1}$. If $A$ is closed in $X$, then $A$ is compact, by Theorem 26.2. Therefore, by the theorem just proved, $f(A)$ is compact. Since $Y$ is Hausdorff, $f(A)$ is closed in $Y$, by Theorem 26.3.

Theorem 26.7. The product of finitely many compact spaces is compact.

Proof. We shall prove that the product of two compact spaces is compact; the theorem follows by induction for any finite product.

Step 1. Suppose that we are given spaces $X$ and $Y$, with $Y$ compact. Suppose that $x_{0}$ is a point of $X$, and $N$ is an open set of $X \times Y$ containing the "slice" $x_{0} \times Y$ of $X \times Y$. We prove the following:

There is a neighborhood $W$ of $x_{0}$ in $X$ such that $N$ contains the entire set $W \times Y$.

The set $W \times Y$ is often called a tube about $x_{0} \times Y$.

First let us cover $x_{0} \times Y$ by basis elements $U \times V$ (for the topology of $X \times Y$ ) lying in $N$. The space $x_{0} \times Y$ is compact, being homeomorphic to $Y$. Therefore, we can cover $x_{0} \times Y$ by finitely many such basis elements

$$
U_{1} \times V_{1}, \ldots, U_{n} \times V_{n}
$$

(We assume that each of the basis elements $U_{i} \times V_{i}$ actually intersects $x_{0} \times Y$, since otherwise that basis element would be superfluous; we could discard it from the finite collection and still have a covering of $x_{0} \times Y$.) Define

$$
W=U_{1} \cap \cdots \cap U_{n} .
$$

The set $W$ is open, and it contains $x_{0}$ because each set $U_{i} \times V_{i}$ intersects $x_{0} \times Y$.

We assert that the sets $U_{i} \times V_{i}$, which were chosen to cover the slice $x_{0} \times Y$, actually cover the tube $W \times Y$. Let $x \times y$ be a point of $W \times Y$. Consider the point $x_{0} \times y$ of the slice $x_{0} \times Y$ having the same $y$-coordinate as this point. Now $x_{0} \times y$ belongs to $U_{i} \times V_{i}$ for some $i$, so that $y \in V_{i}$. But $x \in U_{j}$ for every $j$ (because $x \in W$ ). Therefore, we have $x \times y \in U_{i} \times V_{i}$, as desired.

Since all the sets $U_{i} \times V_{i}$ lie in $N$, and since they cover $W \times Y$, the tube $W \times Y$ lies in $N$ also. See Figure 26.2.

Step 2. Now we prove the theorem. Let $X$ and $Y$ be compact spaces. Let $\mathcal{A}$ be an open covering of $X \times Y$. Given $x_{0} \in X$, the slice $x_{0} \times Y$ is compact and may therefore be covered by finitely many elements $A_{1}, \ldots, A_{m}$ of $\mathcal{A}$. Their union $N=A_{1} \cup \cdots \cup A_{m}$ is an open set containing $x_{0} \times Y$; by Step 1 , the open set $N$ contains

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-169.jpg?height=552&width=946&top_left_y=357&top_left_x=723)

Figure 26.2

a tube $W \times Y$ about $x_{0} \times Y$, where $W$ is open in $X$. Then $W \times Y$ is covered by finitely many elements $A_{1}, \ldots, A_{m}$ of $\mathcal{A}$.

Thus, for each $x$ in $X$, we can choose a neighborhood $W_{x}$ of $x$ such that the tube $W_{x} \times Y$ can be covered by finitely many elements of $\mathcal{A}$. The collection of all the neighborhoods $W_{x}$ is an open covering of $X$; therefore by compactness of $X$, there exists a finite subcollection

$$
\left\{W_{1}, \ldots, W_{k}\right\}
$$

covering $X$. The union of the tubes

$$
W_{1} \times Y, \ldots, W_{k} \times Y
$$

is all of $X \times Y$; since each may be covered by finitely many elements of $\mathcal{A}$, so may $X \times Y$ be covered.

The statement proved in Step 1 of the preceding proof will be useful to us later, so we repeat it here as a lemma, for reference purposes:

Lemma 26.8 (The tube lemma). Consider the product space $X \times Y$, where $Y$ is compact. If $N$ is an open set $X \times Y$ containing the slice $x_{0} \times Y$ of $X \times Y$, then $N$ contains some tube $W \times Y$ about $x_{0} \times Y$, where $W$ is a neighborhood of $x_{0}$ in $X$.

EXAMPLE 7. The tube lemma is certainly not true if $Y$ is not compact. For example, let $Y$ be the $y$-axis in $\mathbb{R}^{2}$, and let

$$
N=\left\{x \times y ;|x|<1 /\left(y^{2}+1\right)\right\} .
$$

Then $N$ is an open set containing the set $0 \times \mathbb{R}$, but it contains no tube about $0 \times \mathbb{R}$. It is illustrated in Figure 26.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-170.jpg?height=567&width=355&top_left_y=366&top_left_x=844)

Figure 26.3

There is an obvious question to ask at this point. Is the product of infinitely many compact spaces compact? One would hope that the answer is "yes," and in fact it is. The result is important (and difficult) enough to be called by the name of the man who proved it; it is called the Tychonoff theorem.

In proving the fact that a cartesian product of connected spaces is connected, one proves it first for finite products and derives the general case from that. In proving that cartesian products of compact spaces are compact, however, there is no way to go directly from finite products to infinite ones. The infinite case demands a new approach, and the proof is a difficult one. Because of its difficulty, and also to avoid losing the main thread of our discussion in this chapter, we have decided to postpone it until later. However, you can study it now if you wish; the section in which it is proved (§37) can be studied immediately after this section without causing any disruption in continuity.

There is one final criterion for a space to be compact, a criterion that is formulated in terms of closed sets rather than open sets. It does not look very natural nor very useful at first glance, but it in fact proves to be useful on a number of occasions. First we make a definition.

Definition. A collection $C$ of subsets of $X$ is said to have the finite intersection property if for every finite subcollection

$$
\left\{C_{1}, \ldots, C_{n}\right\}
$$

of $\mathcal{C}$, the intersection $C_{1} \cap \cdots \cap C_{n}$ is nonempty.

Theorem 26.9. Let $X$ be a topological space. Then $X$ is compact if and only if for every collection $C$ of closed sets in $X$ having the finite intersection property, the intersection $\bigcap_{C \in \mathcal{C}} C$ of all the elements of $\mathcal{C}$ is nonempty.

Proof. Given a collection $\mathcal{A}$ of subsets of $X$, let

$$
\mathcal{C}=\{X-A \mid A \in \mathcal{A}\}
$$

be the collection of their complements. Then the following statements hold:

(1) $\mathcal{A}$ is a collection of open sets if and only if $\mathcal{C}$ is a collection of closed sets.

(2) The collection $\mathcal{A}$ covers $X$ if and only if the intersection $\bigcap_{C \in \mathcal{C}} C$ of all the elements of $\mathcal{C}$ is empty.

(3) The finite subcollection $\left\{A_{1}, \ldots, A_{n}\right\}$ of $\mathcal{A}$ covers $X$ if and only if the intersection of the corresponding elements $C_{i}=X-A_{i}$ of $\mathcal{C}$ is empty.

The first statement is trivial, while the second and third follow from DeMorgan's law:

$$
X-\left(\bigcup_{\alpha \in J} A_{\alpha}\right)=\bigcap_{\alpha \in J}\left(X-A_{\alpha}\right)
$$

The proof of the theorem now proceeds in two easy steps: taking the contrapositive (of the theorem), and then the complement (of the sets)!

The statement that $X$ is compact is equivalent to saying: "Given any collection $\mathcal{A}$ of open subsets of $X$, if $\mathcal{A}$ covers $X$, then some finite subcollection of $\mathcal{A}$ covers $X$." This statement is equivalent to its contrapositive, which is the following: "Given any collection $\mathcal{A}$ of open sets, if no finite subcollection of $\mathcal{A}$ covers $X$, then $\mathcal{A}$ does not cover $X$." Letting $C$ be, as earlier, the collection $\{X-A \mid A \in \mathcal{A}\}$ and applying (1)-(3), we see that this statement is in turn equivalent to the following: "Given any collection $\mathcal{C}$ of closed sets, if every finite intersection of elements of $\mathcal{C}$ is nonempty, then the intersection of all the elements of $\mathcal{C}$ is nonempty." This is just the condition of our theorem.

A special case of this theorem occurs when we have a nested sequence $C_{1} \supset C_{2} \supset$ ... $\supset C_{n} \supset C_{n+1} \supset \ldots$ of closed sets in a compact space $X$. If each of the sets $C_{n}$ is nonempty, then the collection $C=\left\{C_{n}\right\}_{n \in \mathbb{Z}_{+}}$automatically has the finite intersection property. Then the intersection

$$
\bigcap_{n \in \mathbb{Z}_{+}} C_{n}
$$

is nonempty.

We shall use the closed set criterion for compactness in the next section to prove the uncountability of the set of real numbers, in Chapter 5 when we prove the Tychonoff theorem, and again in Chapter 8 when we prove the Baire category theorem.

## Exercises

1. (a) Let $\mathcal{T}$ and $\mathcal{T}^{\prime}$ be two topologies on the set $X$; suppose that $\mathcal{T}^{\prime} \supset \mathcal{T}$. What does compactness of $X$ under one of these topologies imply about compactness under the other?

(b) Show that if $X$ is compact Hausdorff under both $\mathcal{T}$ and $\mathcal{T}^{\prime}$, then either $\mathcal{T}$ and $\mathcal{T}^{\prime}$ are equal or they are not comparable.

2. (a) Show that in the finite complement topology on $\mathbb{R}$, every subspace is compact.

(b) If $\mathbb{R}$ has the topology consisting of all sets $A$ such that $\mathbb{R}-A$ is either countable or all of $\mathbb{R}$, is $[0,1]$ a compact subspace?

3. Show that a finite union of compact subspaces of $X$ is compact.
4. Show that every compact subspace of a metric space is bounded in that metric and is closed. Find a metric space in which not every closed bounded subspace is compact.
5. Let $A$ and $B$ be disjoint compact subspaces of the Hausdorff space $X$. Show that there exist disjoint open sets $U$ and $V$ containing $A$ and $B$, respectively.
6. Show that if $f: X \rightarrow Y$ is continuous, where $X$ is compact and $Y$ is Hausdorff, then $f$ is a closed map (that is, $f$ carries closed sets to closed sets).
7. Show that if $Y$ is compact, then the projection $\pi_{1}: X \times Y \rightarrow X$ is a closed map.
8. Theorem. Let $f: X \rightarrow Y$; let $Y$ be compact Hausdorff. Then $f$ is continuous if and only if the graph of $f$,

$$
G_{f}=\{x \times f(x) \mid x \in X\},
$$

is closed in $X \times Y$. [Hint: If $G_{f}$ is closed and $V$ is a neighborhood of $f\left(x_{0}\right)$, then the intersection of $G_{f}$ and $X \times(Y-V)$ is closed. Apply Exercise 7.]

9. Generalize the tube lemma as follows:

Theorem. Let $A$ and $B$ be subspaces of $X$ and $Y$, respectively; let $N$ be an open set in $X \times Y$ containing $A \times B$. If $A$ and $B$ are compact, then there exist open sets $U$ and $V$ in $X$ and $Y$, respectively, such that

$$
A \times B \subset U \times V \subset N
$$

10. (a) Prove the following partial converse to the uniform limit theorem:

Theorem. Let $f_{n}: X \rightarrow \mathbb{R}$ be a sequence of continuous functions, with $f_{n}(x) \rightarrow f(x)$ for each $x \in X$. If $f$ is continuous, and if the sequence $f_{n}$ is monotone increasing, and if $X$ is compact, then the convergence is uniform. [We say that $f_{n}$ is monotone increasing if $f_{n}(x) \leq f_{n+1}(x)$ for all $n$ and $x$.]

(b) Give examples to show that this theorem fails if you delete the requirement that $X$ be compact, or if you delete the requirement that the sequence be monotone. [Hint: See the exercises of §21.]

11. Theorem. Let $X$ be a compact Hausdorff space. Let $\mathcal{A}$ be a collection of closed connected subsets of $X$ that is simply ordered by proper inclusion. Then

$$
Y=\bigcap_{A \in \mathcal{A}} A
$$

is connected. [Hint: If $C \cup D$ is a separation of $Y$, choose disjoint open sets $U$ and $V$ of $X$ containing $C$ and $D$, respectively, and show that

$$
\bigcap_{A \in \mathcal{A}}(A-(U \cup V))
$$

is not empty.]

12. Let $p: X \rightarrow Y$ be a closed continuous surjective map such that $p^{-1}(\{y\})$ is compact, for each $y \in Y$. (Such a map is called a perfect map.) Show that if $Y$ is compact, then $X$ is compact. [Hint: If $U$ is an open set containing $p^{-1}(\{y\})$, there is a neighborhood $W$ of $y$ such that $p^{-1}(W)$ is contained in $U$.]
13. Let $G$ be a topological group.

(a) Let $A$ and $B$ be subspaces of $G$. If $A$ is closed and $B$ is compact, show $A \cdot B$ is closed. [Hint: If $c$ is not in $A \cdot B$, find a neighborhood $W$ of $c$ such that $W \cdot B^{-1}$ is disjoint from $A$.]

(b) Let $H$ be a subgroup of $G$; let $p: G \rightarrow G / H$ be the quotient map. If $H$ is compact, show that $p$ is a closed map.

(c) Let $H$ be a compact subgroup of $G$. Show that if $G / H$ is compact, then $G$ is compact.

## §27 Compact Subspaces of the Real Line

The theorems of the preceding section enable us to construct new compact spaces from existing ones, but in order to get very far we have to find some compact spaces to start with. The natural place to begin is the real line; we shall prove that every closed interval in $\mathbb{R}$ is compact. Applications include the extreme value theorem and the uniform continuity theorem of calculus, suitably generalized. We also give a characterization of all compact subspaces of $\mathbb{R}^{n}$, and a proof of the uncountability of the set of real numbers.

It turns out that in order to prove every closed interval in $\mathbb{R}$ is compact, we need only one of the order properties of the real line-the least upper bound property. We shall prove the theorem using only this hypothesis; then it will apply not only to the real line, but to well-ordered sets and other ordered sets as well.

Theorem 27.1. Let $X$ be a simply ordered set having the least upper bound property. In the order topology, each closed interval in $X$ is compact.

Proof. Step 1. Given $a<b$, let $\mathcal{A}$ be a covering of $[a, b]$ by sets open in $[a, b]$ in the subspace topology (which is the same as the order topology). We wish to prove the existence of a finite subcollection of $\mathcal{A}$ covering $[a, b]$. First we prove the following: If $x$ is a point of $[a, b]$ different from $b$, then there is a point $y>x$ of $[a, b]$ such that the interval $[x, y]$ can be covered by at most two elements of $\mathcal{A}$.

If $x$ has an immediate successor in $X$, let $y$ be this immediate successor. Then $[x, y]$ consists of the two points $x$ and $y$, so that it can be covered by at most two elements of $\mathcal{A}$. If $x$ has no immediate successor in $X$, choose an element $A$ of $\mathcal{A}$ containing $x$. Because $x \neq b$ and $A$ is open, $A$ contains an interval of the form $[x, c)$, for some $c$ in $[a, b]$. Choose a point $y$ in $(x, c)$; then the interval $[x, y]$ is covered by the single element $A$ of $\mathscr{A}$.

Step 2. Let $C$ be the set of all points $y>a$ of $[a, b]$ such that the interval $[a, y]$ can be covered by finitely many elements of $\mathcal{A}$. Applying Step 1 to the case $x=a$, we see that there exists at least one such $y$, so $C$ is not empty. Let $c$ be the least upper bound of the set $C$; then $a<c \leq b$.

Step 3. We show that $c$ belongs to $C$; that is, we show that the interval $[a, c]$ can be covered by finitely many elements of $\mathcal{A}$. Choose an element $A$ of $\mathcal{A}$ containing $c$; since $A$ is open, it contains an interval of the form $(d, c]$ for some $d$ in $[a, b]$. If $c$ is not in $C$, there must be a point $z$ of $C$ lying in the interval $(d, c)$, because otherwise $d$ would be a smaller upper bound on $C$ than $c$. See Figure 27.1. Since $z$ is in $C$, the interval $[a, z]$ can be covered by finitely many, say $n$, elements of $\mathcal{A}$. Now $[z, c]$ lies in the single element $A$ of $\mathcal{A}$, hence $[a, c]=[a, z] \cup[z, c]$ can be covered by $n+1$ elements of $\mathcal{A}$. Thus $c$ is in $C$, contrary to assumption.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-174.jpg?height=161&width=408&top_left_y=952&top_left_x=529)

Figure 27.1

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-174.jpg?height=161&width=402&top_left_y=952&top_left_x=1109)

Figure 27.2

Step 4. Finally, we show that $c=b$, and our theorem is proved. Suppose that $c<b$. Applying Step 1 to the case $x=c$, we conclude that there exists a point $y>c$ of $[a, b]$ such that the interval $[c, y]$ can be covered by finitely many elements of $\mathcal{A}$. See Figure 27.2. We proved in Step 3 that $c$ is in $C$, so $[a, c]$ can be covered by finitely many elements of $\mathcal{A}$. Therefore, the interval

$$
[a, y]=[a, c] \cup[c, y]
$$

can also be covered by finitely many elements of $\mathcal{A}$. This means that $y$ is in $C$, contradicting the fact that $c$ is an upper bound on $C$.

Corollary 27.2. Every closed interval in $\mathbb{R}$ is compact.

Now we characterize the compact subspaces of $\mathbb{R}^{n}$ :

Theorem 27.3. A subspace $A$ of $\mathbb{R}^{n}$ is compact if and only if it is closed and is bounded in the euclidean metric $d$ or the square metric $\rho$.

Proof. It will suffice to consider only the metric $\rho$; the inequalities

$$
\rho(x, y) \leq d(x, y) \leq \sqrt{n} \rho(x, y)
$$

imply that $A$ is bounded under $d$ if and only if is is bounded under $\rho$.

Suppose that $A$ is compact. Then, by Theorem 26.3, it is closed. Consider the collection of open sets

$$
\left\{B_{\rho}(\mathbf{0}, m) \mid m \in \mathbb{Z}_{+}\right\}
$$

whose union is all of $\mathbb{R}^{n}$. Some finite subcollection covers $A$. It follows that $A \subset$ $B_{\rho}(\mathbf{0}, M)$ for some $M$. Therefore, for any two points $x$ and $y$ of $A$, we have $\rho(x, y) \leq$ $2 M$. Thus $A$ is bounded under $\rho$.

Conversely, suppose that $A$ is closed and bounded under $\rho$; suppose that $\rho(x, y) \leq$ $N$ for every pair $x, y$ of points of $A$. Choose a point $x_{0}$ of $A$, and let $\rho\left(x_{0}, \mathbf{0}\right)=b$. The triangle inequality implies that $\rho(x, \mathbf{0}) \leq N+b$ for every $x$ in $A$. If $P=N+b$, then $A$ is a subset of the cube $[-P, P]^{n}$, which is compact. Being closed, $A$ is also compact.

Students often remember this theorem as stating that the collection of compact sets in a metric space equals the collection of closed and bounded sets. This statement is clearly ridiculous as it stands, because the question as to which sets are bounded depends for its answer on the metric, whereas which sets are compact depends only on the topology of the space.

EXAMPLE 1. The unit sphere $S^{n-1}$ and the closed unit ball $B^{n}$ in $\mathbb{R}^{n}$ are compact because they are closed and bounded. The set

$$
A=\{x \times(1 / x) \mid 0<x \leq 1\}
$$

is closed in $\mathbb{R}^{2}$, but it is not compact because it is not bounded. The set

$$
S=\{x \times(\sin (1 / x)) \mid 0<x \leq 1\}
$$

is bounded in $\mathbb{R}^{2}$, but it is not compact because it is not closed.

Now we prove the extreme value theorem of calculus, in suitably generalized form.

Theorem 27.4 (Extreme value theorem). Let $f: X \rightarrow Y$ be continuous, where $Y$ is an ordered set in the order topology. If $X$ is compact, then there exist points $c$ and $d$ in $X$ such that $f(c) \leq f(x) \leq f(d)$ for every $x \in X$.

The extreme value theorem of calculus is the special case of this theorem that occurs when we take $X$ to be a closed interval in $\mathbb{R}$ and $Y$ to be $\mathbb{R}$.

Proof. Since $f$ is continuous and $X$ is compact, the set $A=f(X)$ is compact. We show that $A$ has a largest element $M$ and a smallest element $m$. Then since $m$ and $M$ belong to $A$, we must have $m=f(c)$ and $M=f(d)$ for some points $c$ and $d$ of $X$.

If $A$ has no largest element, then the collection

$$
\{(-\infty, a) \mid a \in A\}
$$

forms an open covering of $A$. Since $A$ is compact, some finite subcollection

$$
\left\{\left(-\infty, a_{1}\right), \ldots,\left(-\infty, a_{n}\right)\right\}
$$

covers $A$. If $a_{i}$ is the largest of the elements $a_{1}, \ldots a_{n}$, then $a_{i}$ belongs to none of these sets, contrary to the fact that they cover $A$.

A similar argument shows that $A$ has a smallest element.

Now we prove the uniform continuity theorem of calculus. In the process, we are led to introduce a new notion that will prove to be surprisingly useful, that of a Lebesgue number for an open covering of a metric space. First, a preliminary notion:

Definition. Let $(X, d)$ be a metric space; let $A$ be a nonempty subset of $X$. For each $x \in X$, we define the distance from $\boldsymbol{x}$ to $\boldsymbol{A}$ by the equation

$$
d(x, A)=\inf \{d(x, a) \mid a \in A\}
$$

It is easy to show that for fixed $A$, the function $d(x, A)$ is a continuous function of $x$ : Given $x, y \in X$, one has the inequalities

$$
d(x, A) \leq d(x, a) \leq d(x, y)+d(y, a),
$$

for each $a \in A$. It follows that

$$
d(x, A)-d(x, y) \leq \inf d(y, a)=d(y, A)
$$

so that

$$
d(x, A)-d(y, A) \leq d(x, y) .
$$

The same inequality holds with $x$ and $y$ interchanged; continuity of the function $d(x, A)$ follows.

Now we introduce the notion of Lebesgue number. Recall that the diameter of a bounded subset $A$ of a metric space $(X, d)$ is the number

$$
\sup \left\{d\left(a_{1}, a_{2}\right) \mid a_{1}, a_{2} \in A\right\}
$$

Lemma 27.5 (The Lebesgue number lemma). Let $\mathscr{A}$ be an open covering of the metric space $(X, d)$. If $X$ is compact, there is a $\delta>0$ such that for each subset of $X$ having diameter less than $\delta$, there exists an element of $\mathcal{A}$ containing it.

The number $\delta$ is called a Lebesgue number for the covering $\mathcal{A}$.

Proof. Let $\mathcal{A}$ be an open covering of $X$. If $X$ itself is an element of $\mathcal{A}$, then any positive number is a Lebesgue number for $\mathcal{A}$. So assume $X$ is not an element of $\mathcal{A}$.

Choose a finite subcollection $\left\{A_{1}, \ldots, A_{n}\right\}$ of $\mathcal{A}$ that covers $X$. For each $i$, set $C_{i}=X-A_{i}$, and define $f: X \rightarrow \mathbb{R}$ by letting $f(x)$ be the average of the numbers $d\left(x, C_{i}\right)$. That is,

$$
f(x)=\frac{1}{n} \sum_{i=1}^{n} d\left(x, C_{i}\right)
$$

We show that $f(x)>0$ for all $x$. Given $x \in X$, choose $i$ so that $x \in A_{i}$. Then choose $\epsilon$ so the $\epsilon$-neighborhood of $x$ lies in $A_{i}$. Then $d\left(x, C_{i}\right) \geq \epsilon$, so that $f(x) \geq \epsilon / n$.

Since $f$ is continuous, it has a minimum value $\delta$; we show that $\delta$ is our required Lebesgue number. Let $B$ be a subset of $X$ of diameter less than $\delta$. Choose a point $x_{0}$ of $B$; then $B$ lies in the $\delta$-neighborhood of $x_{0}$. Now

$$
\delta \leq f\left(x_{0}\right) \leq d\left(x_{0}, C_{m}\right)
$$

where $d\left(x_{0}, C_{m}\right)$ is the largest of the numbers $d\left(x_{0}, C_{i}\right)$. Then the $\delta$-neighborhood of $x_{0}$ is contained in the element $A_{m}=X-C_{m}$ of the covering $\mathcal{A}$.

Definition. A function $f$ from the metric space $\left(X, d_{X}\right)$ to the metric space $\left(Y, d_{Y}\right)$ is said to be uniformly continuous if given $\epsilon>0$, there is a $\delta>0$ such that for every pair of points $x_{0}, x_{1}$ of $X$,

$$
d_{X}\left(x_{0}, x_{1}\right)<\delta \Longrightarrow d_{Y}\left(f\left(x_{0}\right), f\left(x_{1}\right)\right)<\epsilon
$$

Theorem 27.6 (Uniform continuity theorem). Let $f: X \rightarrow Y$ be a continuous map of the compact metric space $\left(X, d_{X}\right)$ to the metric space $\left(Y, d_{Y}\right)$. Then $f$ is uniformly continuous.

Proof. Given $\epsilon>0$, take the open covering of $Y$ by balls $B(y, \epsilon / 2)$ of radius $\epsilon / 2$. Let $\mathcal{A}$ be the open covering of $X$ by the inverse images of these balls under $f$. Choose $\delta$ to be a Lebesgue number for the covering $\mathcal{A}$. Then if $x_{1}$ and $x_{2}$ are two points of $X$ such that $d_{X}\left(x_{1}, x_{2}\right)<\delta$, the two-point set $\left\{x_{1}, x_{2}\right\}$ has diameter less than $\delta$, so that its image $\left\{f\left(x_{1}\right), f\left(x_{2}\right)\right\}$ lies in some ball $B(y, \epsilon / 2)$. Then $d_{Y}\left(f\left(x_{1}\right), f\left(x_{2}\right)\right)<\epsilon$, as desired.

Finally, we prove that the real numbers are uncountable. The interesting thing about this proof is that it involves no algebra at all-no decimal or binary expansions of real numbers or the like-just the order properties of $\mathbb{R}$.

Definition. If $X$ is a space, a point $x$ of $X$ is said to be an isolated point of $X$ if the one-point set $\{x\}$ is open in $X$.

Theorem 27.7. Let $X$ be a nonempty compact Hausdorff space. If $X$ has no isolated points, then $X$ is uncountable.

Proof. Step 1. We show first that given any nonempty open set $U$ of $X$ and any point $x$ of $X$, there exists a nonempty open set $V$ contained in $U$ such that $x \notin \bar{V}$.

Choose a point $y$ of $U$ different from $x$; this is possible if $x$ is in $U$ because $x$ is not an isolated point of $X$ and it is possible if $x$ is not in $U$ simply because $U$ is nonempty. Now choose disjoint open sets $W_{1}$ and $W_{2}$ about $x$ and $y$, respectively. Then the set $V=W_{2} \cap U$ is the desired open set; it is contained in $U$, it is nonempty because it contains $y$, and its closure does not contain $x$. See Figure 27.3.

Step 2. We show that given $f: \mathbb{Z}_{+} \rightarrow X$, the function $f$ is not surjective. It follows that $X$ is uncountable.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-178.jpg?height=391&width=721&top_left_y=365&top_left_x=661)

Figure 27.3

Let $x_{n}=f(n)$. Apply Step 1 to the nonempty open set $U=X$ to choose a nonempty open set $V_{1} \subset X$ such that $\bar{V}_{1}$ does not contain $x_{1}$. In general, given $V_{n-1}$ open and nonempty, choose $V_{n}$ to be a nonempty open set such that $V_{n} \subset V_{n-1}$ and $\bar{V}_{n}$ does not contain $x_{n}$. Consider the nested sequence

$$
\bar{V}_{1} \supset \bar{V}_{2} \supset \cdots
$$

of nonempty closed sets of $X$. Because $X$ is compact, there is a point $x \in \cap \bar{V}_{n}$, by Theorem 26.9. Now $x$ cannot equal $x_{n}$ for any $n$, since $x$ belongs to $\bar{V}_{n}$ and $x_{n}$ does not.

Corollary 27.8. Every closed interval in $\mathbb{R}$ is uncountable.

## Exercises

1. Prove that if $X$ is an ordered set in which every closed interval is compact, then $X$ has the least upper bound property.
2. Let $X$ be a metric space with metric $d$; let $A \subset X$ be nonempty.

(a) Show that $d(x, A)=0$ if and only if $x \in \bar{A}$.

(b) Show that if $A$ is compact, $d(x, A)=d(x, a)$ for some $a \in A$.

(c) Define the $\epsilon$-neighborhood of $A$ in $X$ to be the set

$$
U(A, \epsilon)=\{x \mid d(x, A)<\epsilon\}
$$

Show that $U(A, \epsilon)$ equals the union of the open balls $B_{d}(a, \epsilon)$ for $a \in A$.

(d) Assume that $A$ is compact; let $U$ be an open set containing $A$. Show that some $\epsilon$-neighborhood of $A$ is contained in $U$.

(e) Show the result in (d) need not hold if $A$ is closed but not compact.

3. Recall that $\mathbb{R}_{K}$ denotes $\mathbb{R}$ in the $K$-topology.

(a) Show that $[0,1]$ is not compact as a subspace of $\mathbb{R}_{K}$.
(b) Show that $\mathbb{R}_{K}$ is connected. [Hint: $(-\infty, 0)$ and $(0, \infty)$ inherit their usual topologies as subspaces of $\mathbb{R}_{K}$.]

(c) Show that $\mathbb{R}_{K}$ is not path connected.

4. Show that a connected metric space having more than one point is uncountable.
5. Let $X$ be a compact Hausdorff space; let $\left\{A_{n}\right\}$ be a countable collection of closed sets of $X$. Show that if each set $A_{n}$ has empty interior in $X$, then the union $\cup A_{n}$ has empty interior in $X$. [Hint: Imitate the proof of Theorem 27.7.]

This is a special case of the Baire category theorem, which we shall study in Chapter 8.

6. Let $A_{0}$ be the closed interval $[0,1]$ in $\mathbb{R}$. Let $A_{1}$ be the set obtained from $A_{0}$ by deleting its "middle third" $\left(\frac{1}{3}, \frac{2}{3}\right)$. Let $A_{2}$ be the set obtained from $A_{1}$ by deleting its "middle thirds" $\left(\frac{1}{9}, \frac{2}{9}\right)$ and $\left(\frac{7}{9}, \frac{8}{9}\right)$. In general, define $A_{n}$ by the equation

$$
A_{n}=A_{n-1}-\bigcup_{k=0}^{\infty}\left(\frac{1+3 k}{3^{n}}, \frac{2+3 k}{3^{n}}\right)
$$

The intersection

$$
C=\bigcap_{n \in \mathbb{Z}_{+}} A_{n}
$$

is called the Cantor set; it is a subspace of $[0,1]$.

(a) Show that $C$ is totally disconnected.

(b) Show that $C$ is compact.

(c) Show that each set $A_{n}$ is a union of finitely many disjoint closed intervals of length $1 / 3^{n}$; and show that the end points of these intervals lie in $C$.

(d) Show that $C$ has no isolated points.

(e) Conclude that $C$ is uncountable.

## §28 Limit Point Compactness

As indicated when we first mentioned compact sets, there are other formulations of the notion of compactness that are frequently useful. In this section we introduce one of them. Weaker in general than compactness, it coincides with compactness for metrizable spaces.

Definition. A space $X$ is said to be limit point compact if every infinite subset of $X$ has a limit point.

In some ways this property is more natural and intuitive than that of compactness. In the early days of topology, it was given the name "compactness," while the open covering formulation was called "bicompactness." Later, the word "compact" was shifted to apply to the open covering definition, leaving this one to search for a new
name. It still has not found a name on which everyone agrees. On historical grounds, some call it "Fréchet compactness"; others call it the "Bolzano-Weierstrass property." We have invented the term "limit point compactness." It seems as good a term as any; at least it describes what the property is about.

Theorem 28.1. Compactness implies limit point compactness, but not conversely.

Proof. Let $X$ be a compact space. Given a subset $A$ of $X$, we wish to prove that if $A$ is infinite, then $A$ has a limit point. We prove the contrapositive-if $A$ has no limit point, then $A$ must be finite.

So suppose $A$ has no limit point. Then $A$ contains all its limit points, so that $A$ is closed. Furthermore, for each $a \in A$ we can choose a neighborhood $U_{a}$ of $a$ such that $U_{a}$ intersects $A$ in the point $a$ alone. The space $X$ is covered by the open set $X-A$ and the open sets $U_{a}$; being compact, it can be covered by finitely many of these sets. Since $X-A$ does not intersect $A$, and each set $U_{a}$ contains only one point of $A$, the set $A$ must be finite.

EXAmple 1. Let $Y$ consist of two points; give $Y$ the topology consisting of $Y$ and the empty set. Then the space $X=\mathbb{Z}_{+} \times Y$ is limit point compact, for every nonempty subset of $X$ has a limit point. It is not compact, for the covering of $X$ by the open sets $U_{n}=\{n\} \times Y$ has no finite subcollection covering $X$.

EXAmple 2. Here is a less trivial example. Consider the minimal uncountable wellordered set $S_{\Omega}$, in the order topology. The space $S_{\Omega}$ is not compact, since it has no largest element. However, it is limit point compact: Let $A$ be an infinite subset of $S_{\Omega}$. Choose a subset $B$ of $A$ that is countably infinite. Being countable, the set $B$ has an uper bound $b$ in $S_{\Omega}$; then $B$ is a subset of the interval $\left[a_{0}, b\right]$ of $S_{\Omega}$, where $a_{0}$ is the smallest element of $S_{\Omega}$. Since $S_{\Omega}$ has the least upper bound property, the interval $\left[a_{0}, b\right]$ is compact. By the preceding theorem, $B$ has a limit point $x$ in $\left[a_{0}, b\right]$. The point $x$ is also a limit point of $A$. Thus $S_{\Omega}$ is limit point compact.

We now show these two versions of compactness coincide for metrizable spaces; for this purpose, we introduce yet another version of compactness called sequential compactness. This result will be used in Chapter 7.

Definition. Let $X$ be a topological space. If $\left(x_{n}\right)$ is a sequence of points of $X$, and if

$$
n_{1}<n_{2}<\cdots<n_{i}<\cdots
$$

is an increasing sequence of positive integers, then the sequence $\left(y_{i}\right)$ defined by setting $y_{i}=x_{n_{i}}$ is called a subsequence of the sequence $\left(x_{n}\right)$. The space $X$ is said to be sequentially compact if every sequence of points of $X$ has a convergent subsequence.

*Theorem 28.2. Let $X$ be a metrizable space. Then the following are equivalent:

(1) $X$ is compact.

(2) $X$ is limit point compact.

(3) $X$ is sequentially compact.

Proof. We have already proved that (1) $\Rightarrow$ (2). To show that (2) $\Rightarrow$ (3), assume that $X$ is limit point compact. Given a sequence $\left(x_{n}\right)$ of points of $X$, consider the set $A=\left\{x_{n} \mid n \in \mathbb{Z}_{+}\right\}$. If the set $A$ is finite, then there is a point $x$ such that $x=x_{n}$ for infinitely many values of $n$. In this case, the sequence $\left(x_{n}\right)$ has a subsequence that is constant, and therefore converges trivially. On the other hand, if $A$ is infinite, then $A$ has a limit point $x$. We define a subsequence of $\left(x_{n}\right)$ converging to $x$ as follows: First choose $n_{1}$ so that

$$
x_{n_{1}} \in B(x, 1) \text {. }
$$

Then suppose that the positive integer $n_{i-1}$ is given. Because the ball $B(x, 1 / i)$ intersects $A$ in infinitely many points, we can choose an index $n_{i}>n_{i-1}$ such that

$$
x_{n_{i}} \in B(x, 1 / i) .
$$

Then the subsequence $x_{n_{1}}, x_{n_{2}}, \ldots$ converges to $x$.

Finally, we show that $(3) \Rightarrow$ (1). This is the hardest part of the proof.

First, we show that if $X$ is sequentially compact, then the Lebesgue number lemma holds for $X$. (This would follow from compactness, but compactness is what we are trying to prove!) Let $\mathcal{A}$ be an open covering of $X$. We assume that there is no $\delta>0$ such that each set of diameter less than $\delta$ has an element of $\mathcal{A}$ containing it, and derive a contradiction.

Our assumption implies in particular that for each positive integer $n$, there exists a set of diameter less than $1 / n$ that is not contained in any element of $\mathcal{A}$; let $C_{n}$ be such a set. Choose a point $x_{n} \in C_{n}$, for each $n$. By hypothesis, some subsequence $\left(x_{n_{i}}\right)$ of the sequence $\left(x_{n}\right)$ converges, say to the point $a$. Now $a$ belongs to some element $A$ of the collection $\mathcal{A}$; because $A$ is open, we may choose an $\epsilon>0$ such that $B(a, \epsilon) \subset A$. If $i$ is large enough that $1 / n_{i}<\epsilon / 2$, then the set $C_{n_{i}}$ lies in the $\epsilon / 2$-neighborhood of $x_{n_{i}}$; if $i$ is also chosen large enough that $d\left(x_{n_{i}}, a\right)<\epsilon / 2$, then $C_{n_{i}}$ lies in the $\epsilon$-neighborhood of $a$. But this means that $C_{n_{i}} \subset A$, contrary to hypothesis.

Second, we show that if $X$ is sequentially compact, then given $\epsilon>0$, there exists a finite covering of $X$ by open $\epsilon$-balls. Once again, we proceed by contradiction. Assume that there exists an $\epsilon>0$ such that $X$ cannot be covered by finitely many $\epsilon$-balls. Construct a sequence of points $x_{n}$ of $X$ as follows: First, choose $x_{1}$ to be any point of $X$. Noting that the ball $B\left(x_{1}, \epsilon\right)$ is not all of $X$ (otherwise $X$ could be covered by a single $\epsilon$-ball), choose $x_{2}$ to be a point of $X$ not in $B\left(x_{1}, \epsilon\right)$. In general, given $x_{1}, \ldots, x_{n}$, choose $x_{n+1}$ to be a point not in the union

$$
B\left(x_{1}, \epsilon\right) \cup \cdots \cup B\left(x_{n}, \epsilon\right)
$$

using the fact that these balls do not cover $X$. Note that by construction $d\left(x_{n+1}, x_{i}\right) \geq$ $\epsilon$ for $i=1, \ldots, n$. Therefore, the sequence $\left(x_{n}\right)$ can have no convergent subsequence; in fact, any ball of radius $\epsilon / 2$ can contain $x_{n}$ for at most one value of $n$.

Finally, we show that if $X$ is sequentially compact, then $X$ is compact. Let $\mathcal{A}$ be an open covering of $X$. Because $X$ is sequentially compact, the open covering $\mathcal{A}$ has a Lebesgue number $\delta$. Let $\epsilon=\delta / 3$; use sequential compactness of $X$ to find a finite
covering of $X$ by open $\epsilon$-balls. Each of these balls has diameter at most $2 \delta / 3$, so it lies in an element of $\mathcal{A}$. Choosing one such element of $\mathcal{A}$ for each of these $\epsilon$-balls, we obtain a finite subcollection of $\mathcal{A}$ that covers $X$.

EXAMPLE 3. Recall that $\bar{S}_{\Omega}$ denotes the minimal uncountable well-ordered set $S_{\Omega}$ with the point $\Omega$ adjoined. (In the order topology, $\Omega$ is a limit point of $S_{\Omega}$, which is why we introduced the notation $\bar{S}_{\Omega}$ for $S_{\Omega} \cup\{\Omega\}$, back in $\S 10$.) It is easy to see that the space $\bar{S}_{\Omega}$ is not metrizable, for it does not satisfy the sequence lemma: The point $\Omega$ is a limit point of $S_{\Omega}$; but it is not the limit of a sequence of points of $S_{\Omega}$, for any sequence of points of $S_{\Omega}$ has an upper bound in $S_{\Omega}$. The space $S_{\Omega}$, on the other hand, does satisfy the sequence lemma, as you can readily check. Nevertheless, $S_{\Omega}$ is not metrizable, for it is limit point compact but not compact.

## Exercises

1. Give $[0,1]^{\omega}$ the uniform topology. Find an infinite subset of this space that has no limit point.
2. Show that $[0,1]$ is not limit point compact as a subspace of $\mathbb{R}_{\ell}$.
3. Let $X$ be limit point compact.

(a) If $f: X \rightarrow Y$ is continuous, does it follow that $f(X)$ is limit point compact?

(b) If $A$ is a closed subset of $X$, does it follow that $A$ is limit point compact?

(c) If $X$ is a subspace of the Hausdorff space $Z$, does it follow that $X$ is closed in $Z$ ?

We comment that it is not in general true that the product of two limit point compact spaces is limit point compact, even if the Hausdorff condition is assumed. But the examples are fairly sophisticated. See [S-S], Example 112.

4. A space $X$ is said to be countably compact if every countable open covering of $X$ contains a finite subcollection that covers $X$. Show that for a $T_{1}$ space $X$, countable compactness is equivalent to limit point compactness. [Hint: If no finite subcollection of $U_{n}$ covers $X$, choose $x_{n} \notin U_{1} \cup \cdots \cup U_{n}$, for each $n$.]
5. Show that $X$ is countably compact if and only if every nested sequence $C_{1} \supset$ $C_{2} \supset \cdots$ of closed nonempty sets of $X$ has a nonempty intersection.
6. Let $(X, d)$ be a metric space. If $f: X \rightarrow X$ satisfies the condition

$$
d(f(x), f(y))=d(x, y)
$$

for all $x, y \in X$, then $f$ is called an isometry of $X$. Show that if $f$ is an isometry and $X$ is compact, then $f$ is bijective and hence a homeomorphism. [Hint: If $a \notin f(X)$, choose $\epsilon$ so that the $\epsilon$-neighborhood of $a$ is disjoint from $f(X)$. Set $x_{1}=a$, and $x_{n+1}=f\left(x_{n}\right)$ in general. Show that $d\left(x_{n}, x_{m}\right) \geq \epsilon$ for $n \neq m$.]

7. Let $(X, d)$ be a metric space. If $f$ satisfies the condition

$$
d(f(x), f(y))<d(x, y)
$$

for all $x, y \in X$ with $x \neq y$, then $f$ is called a shrinking map. If there is a number $\alpha<1$ such that

$$
d(f(x), f(y)) \leq \alpha d(x, y)
$$

for all $x, y \in X$, then $f$ is called a contraction. A fixed point of $f$ is a point $x$ such that $f(x)=x$.

(a) If $f$ is a contraction and $X$ is compact, show $f$ has a unique fixed point. [Hint: Define $f^{1}=f$ and $f^{n+1}=f \circ f^{n}$. Consider the intersection $A$ of the sets $A_{n}=f^{n}(X)$.]

(b) Show more generally that if $f$ is a shrinking map and $X$ is compact, then $f$ has a unique fixed point. [Hint: Let $A$ be as before. Given $x \in A$, choose $x_{n}$ so that $x=f^{n+1}\left(x_{n}\right)$. If $a$ is the limit of some subsequence of the sequence $y_{n}=f^{n}\left(x_{n}\right)$, show that $a \in A$ and $f(a)=x$. Conclude that $A=f(A)$, so that $\operatorname{diam} A=0$.]

(c) Let $X=[0,1]$. Show that $f(x)=x-x^{2} / 2$ maps $X$ into $X$ and is a shrinking map that is not a contraction. [Hint: Use the mean-value theorem of calculus.]

(d) The result in (a) holds if $X$ is a complete metric space, such as $\mathbb{R}$; see the exercises of $\S 43$. The result in (b) does not: Show that the map $f: \mathbb{R} \rightarrow$ $\mathbb{R}$ given by $f(x)=\left[x+\left(x^{2}+1\right)^{1 / 2}\right] / 2$ is a shrinking map that is not a contraction and has no fixed point.

## §29 Local Compactness

In this section we study the notion of local compactness, and we prove the basic theorem that any locally compact Hausdorff space can be imbedded in a certain compact Hausdorff space that is called its one-point compactification.

Definition. A space $X$ is said to be locally compact at $\boldsymbol{x}$ if there is some compact subspace $C$ of $X$ that contains a neighborhood of $x$. If $X$ is locally compact at each of its points, $X$ is said simply to be locally compact.

Note that a compact space is automatically locally compact.

EXAMPLE 1. The real line $\mathbb{R}$ is locally compact. The point $x$ lies in some interval $(a, b)$, which in turn is contained in the compact subspace $[a, b]$. The subspace $\mathbb{Q}$ of rational numbers is not locally compact, as you can check.

EXAMPLE 2. The space $\mathbb{R}^{n}$ is locally compact; the point $x$ lies in some basis element $\left(a_{1}, b_{1}\right) \times \cdots \times\left(a_{n}, b_{n}\right)$, which in turn lies in the compact subspace $\left[a_{1}, b_{1}\right] \times \cdots \times\left[a_{n}, b_{n}\right]$. The space $\mathbb{R}^{\omega}$ is not locally compact; none of its basis elements are contained in compact subspaces. For if

$$
B=\left(a_{1}, b_{1}\right) \times \cdots \times\left(a_{n}, b_{n}\right) \times \mathbb{R} \times \cdots \times \mathbb{R} \times \cdots
$$

were contained in a compact subspace, then its closure

$$
\bar{B}=\left[a_{1}, b_{1}\right] \times \cdots \times\left[a_{n}, b_{n}\right] \times \mathbb{R} \times \cdots
$$

would be compact, which it is not.

EXAMPLE 3. Every simply ordered set $X$ having the least upper bound property is locally compact: Given a basis element for $X$, it is contained in a closed interval in $X$, which is compact.

Two of the most well-behaved classes of spaces to deal with in mathematics are the metrizable spaces and the compact Hausdorff spaces. Such spaces have many useful properties, which one can use in proving theorems and making constructions and the like. If a given space is not of one of these types, the next best thing one can hope for is that it is a subspace of one of these spaces. Of course, a subspace of a metrizable space is itself metrizable, so one does not get any new spaces in this way. But a subspace of a compact Hausdorff space need not be compact. Thus arises the question: Under what conditions is a space homeomorphic with a subspace of a compact Hausdorff space? We give one answer here. We shall return to this question in Chapter 5 when we study compactifications in general.

Theorem 29.1. Let $X$ be a space. Then $X$ is locally compact Hausdorff if and only if there exists a space $Y$ satisfying the following conditions:

(1) $X$ is a subspace of $Y$.

(2) The set $Y-X$ consists of a single point.

(3) $Y$ is a compact Hausdorff space.

If $Y$ and $Y^{\prime}$ are two spaces satisfying these conditions, then there is a homeomorphism of $Y$ with $Y^{\prime}$ that equals the identity map on $X$.

Proof. Step 1. We first verify uniqueness. Let $Y$ and $Y^{\prime}$ be two spaces satisfying these conditions. Define $h: Y \rightarrow Y^{\prime}$ by letting $h$ map the single point $p$ of $Y-X$ to the point $q$ of $Y^{\prime}-X$, and letting $h$ equal the identity on $X$. We show that if $U$ is open in $Y$, then $h(U)$ is open in $Y^{\prime}$. Symmetry then implies that $h$ is a homeomorphism.

First, consider the case where $U$ does not contain $p$. Then $h(U)=U$. Since $U$ is open in $Y$ and is contained in $X$, it is open in $X$. Because $X$ is open in $Y^{\prime}$, the set $U$ is also open in $Y^{\prime}$, as desired.

Second, suppose that $U$ contains $p$. Since $C=Y-U$ is closed in $Y$, it is compact as a subspace of $Y$. Because $C$ is contained in $X$, it is a compact subspace of $X$. Then because $X$ is a subspace of $Y^{\prime}$, the space $C$ is also a compact subspace of $Y^{\prime}$. Because $Y^{\prime}$ is Hausdorff, $C$ is closed in $Y^{\prime}$, so that $h(U)=Y^{\prime}-C$ is open in $Y^{\prime}$, as desired.

Step 2. Now we suppose $X$ is locally compact Hausdorff and construct the space $Y$. Step 1 gives us an idea how to proceed. Let us take some object that is not a point of $X$, denote it by the symbol $\infty$ for convenience, and adjoin it to $X$, forming the set $Y=X \cup\{\infty\}$. Topologize $Y$ by defining the collection of open sets of $Y$ to consist
of (1) all sets $U$ that are open in $X$, and (2) all sets of the form $Y-C$, where $C$ is a compact subspace of $X$.

We need to check that this collection is, in fact, a topology on $Y$. The empty set is a set of type (1), and the space $Y$ is a set of type (2). Checking that the intersection of two open sets is open involves three cases:

$$
\begin{array}{rlrl}
U_{1} \cap U_{2} & & \text { is of type (1). } \\
\left(Y-C_{1}\right) \cap\left(Y-C_{2}\right) & =Y-\left(C_{1} \cup C_{2}\right) & & \text { is of type (2). } \\
U_{1} \cap\left(Y-C_{1}\right) & =U_{1} \cap\left(X-C_{1}\right) & & \text { is of type (1), }
\end{array}
$$

because $C_{1}$ is closed in $X$. Similarly, one checks that the union of any collection of open sets is open:

$$
\begin{aligned}
& \bigcup U_{\alpha}=U \quad \text { is of type (1). } \\
& \bigcup\left(Y-C_{\beta}\right)=Y-\left(\bigcap C_{\beta}\right)=Y-C \quad \text { is of type (2). } \\
& \left(\bigcup U_{\alpha}\right) \cup\left(\bigcup\left(Y-C_{\beta}\right)\right)=U \cup(Y-C)=Y-(C-U) \text {, }
\end{aligned}
$$

which is of type (2) because $C-U$ is a closed subspace of $C$ and therefore compact.

Now we show that $X$ is a subspace of $Y$. Given any open set of $Y$, we show its intersection with $X$ is open in $X$. If $U$ is of type (1), then $U \cap X=U$; if $Y-C$ is of type (2), then $(Y-C) \cap X=X-C$; both of these sets are open in $X$. Conversely, any set open in $X$ is a set of type (1) and therefore open in $Y$ by definition.

To show that $Y$ is compact, let $\mathcal{A}$ be an open covering of $Y$. The collection $\mathcal{A}$ must contain an open set of type (2), say $Y-C$, since none of the open sets of type (1) contain the point $\infty$. Take all the members of $\mathcal{A}$ different from $Y-C$ and intersect them with $X$; they form a collection of open sets of $X$ covering $C$. Because $C$ is compact, finitely many of them cover $C$; the corresponding finite collection of elements of $\mathcal{A}$ will, along with the element $Y-C$, cover all of $Y$.

To show that $Y$ is Hausdorff, let $x$ and $y$ be two points of $Y$. If both of them lie in $X$, there are disjoint sets $U$ and $V$ open in $X$ containing them, respectively. On the other hand, if $x \in X$ and $y=\infty$, we can choose a compact set $C$ in $X$ containing a neighborhood $U$ of $x$. Then $U$ and $Y-C$ are disjoint neighborhoods of $x$ and $\infty$, respectively, in $Y$.

Step 3. Finally, we prove the converse. Suppose a space $Y$ satisfying conditions (1)-(3) exists. Then $X$ is Hausdorff because it is a subspace of the Hausdorff space $Y$. Given $x \in X$, we show $X$ is locally compact at $x$. Choose disjoint open sets $U$ and $V$ of $Y$ containing $x$ and the single point of $Y-X$, respectively. Then the set $C=Y-V$ is closed in $Y$, so it is a compact subspace of $Y$. Since $C$ lies in $X$, it is also compact as a subspace of $X$; it contains the neighborhood $U$ of $x$.

If $X$ itself should happen to be compact, then the space $Y$ of the preceding theorem is not very interesting, for it is obtained from $X$ by adjoining a single isolated point. However, if $X$ is not compact, then the point of $Y-X$ is a limit point of $X$, so that $\bar{X}=Y$.

Definition. If $Y$ is a compact Hausdorff space and $X$ is a proper subspace of $Y$ whose closure equals $Y$, then $Y$ is said to be a compactification of $X$. If $Y-X$ equals a single point, then $Y$ is called the one-point compactification of $X$.

We have shown that $X$ has a one-point compactification $Y$ if and only if $X$ is a locally compact Hausdorff space that is not itself compact. We speak of $Y$ as "the" one-point compactification because $Y$ is uniquely determined up to a homeomorphism.

EXAMPLE 4. The one-point compactification of the real line $\mathbb{R}$ is homeomorphic with the circle, as you may readily check. Similarly, the one-point compactification of $\mathbb{R}^{2}$ is homeomorphic to the sphere $S^{2}$. If $\mathbb{R}^{2}$ is looked at as the space $\mathbb{C}$ of complex numbers, then $\mathbb{C} \cup\{\infty\}$ is called the Riemann sphere, or the extended complex plane.

In some ways our definition of local compactness is not very satisfying. Usually one says that a space $X$ satisfies a given property "locally" if every $x \in X$ has "arbitrarily small" neighborhoods having the given property. Our definition of local compactness has nothing to do with "arbitrarily small" neighborhoods, so there is some question whether we should call it local compactness at all.

Here is another formulation of local compactness, one more truly "local" in nature; it is equivalent to our definition when $X$ is Hausdorff.

Theorem 29.2. Let $X$ be a Hausdorff space. Then $X$ is locally compact if and only if given $x$ in $X$, and given a neighborhood $U$ of $x$, there is a neighborhood $V$ of $x$ such that $\bar{V}$ is compact and $\bar{V} \subset U$.

Proof. Clearly this new formulation implies local compactness; the set $C=\bar{V}$ is the desired compact set containing a neighborhood of $x$. To prove the converse, suppose $X$ is locally compact; let $x$ be a point of $X$ and let $U$ be a neighborhood of $x$. Take the one-point compactification $Y$ of $X$, and let $C$ be the set $Y-U$. Then $C$ is closed in $Y$, so that $C$ is a compact subspace of $Y$. Apply Lemma 26.4 to choose disjoint open sets $V$ and $W$ containing $x$ and $C$, respectively. Then the closure $\bar{V}$ of $V$ in $Y$ is compact; furthermore, $\bar{V}$ is disjoint from $C$, so that $\bar{V} \subset U$, as desired.

Corollary 29.3. Let $X$ be locally compact Hausdorff; let $A$ be a subspace of $X$. If $A$ is closed in $X$ or open in $X$, then $A$ is locally compact.

Proof. Suppose that $A$ is closed in $X$. Given $x \in A$, let $C$ be a compact subspace of $X$ containing the neighborhood $U$ of $x$ in $X$. Then $C \cap A$ is closed in $C$ and thus compact, and it contains the neighborhood $U \cap A$ of $x$ in $A$. (We have not used the Hausdorff condition here.)

Suppose now that $A$ is open in $X$. Given $x \in A$, we apply the preceding theorem to choose a neighborhood $V$ of $x$ in $X$ such that $\bar{V}$ is compact and $\bar{V} \subset A$. Then $C=\bar{V}$ is a compact subspace of $A$ containing the neighborhood $V$ of $x$ in $A$.

Corollary 29.4. A space $X$ is homeomorphic to an open subspace of a compact Hausdorff space if and only if $X$ is locally compact Hausdorff.

Proof. This follows from Theorem 29.1 and Corollary 29.3.

## Exercises

1. Show that the rationals $\mathbb{Q}$ are not locally compact.
2. Let $\left\{X_{\alpha}\right\}$ be an indexed family of nonempty spaces.

(a) Show that if $\prod X_{\alpha}$ is locally compact, then each $X_{\alpha}$ is locally compact and $X_{\alpha}$ is compact for all but finitely many values of $\alpha$.

(b) Prove the converse, assuming the Tychonoff theorem.

3. Let $X$ be a locally compact space. If $f: X \rightarrow Y$ is continuous, does it follow that $f(X)$ is locally compact? What if $f$ is both continuous and open? Justify your answer.
4. Show that $[0,1]^{\omega}$ is not locally compact in the uniform topology.
5. If $f: X_{1} \rightarrow X_{2}$ is a homeomorphism of locally compact Hausdorff spaces, show $f$ extends to a homeomorphism of their one-point compactifications.
6. Show that the one-point compactification of $\mathbb{R}$ is homeomorphic with the circle $S^{1}$.
7. Show that the one-point compactification of $S_{\Omega}$ is homeomorphic with $\bar{S}_{\Omega}$.
8. Show that the one-point compactification of $\mathbb{Z}_{+}$is homeomorphic with the subspace $\{0\} \cup\left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}$of $\mathbb{R}$.
9. Show that if $G$ is a locally compact topological group and $H$ is a subgroup, then $G / H$ is locally compact.
10. Show that if $X$ is a Hausdorff space that is locally compact at the point $x$, then for each neighborhood $U$ of $x$, there is a neighborhood $V$ of $x$ such that $\bar{V}$ is compact and $\bar{V} \subset U$.

*11. Prove the following:

(a) Lemma. If $p: X \rightarrow Y$ is a quotient map and if $Z$ is a locally compact Hausdorff space, then the map

$$
\pi=p \times i_{Z}: X \times Z \longrightarrow Y \times Z
$$

is a quotient map.

[Hint: If $\pi^{-1}(A)$ is open and contains $x \times y$, choose open sets $U_{1}$ and $V$ with $\bar{V}$ compact, such that $x \times y \in U_{1} \times V$ and $U_{1} \times \bar{V} \subset \pi^{-1}(A)$. Given $U_{i} \times \bar{V} \subset \pi^{-1}(A)$, use the tube lemma to choose an open set $U_{i+1}$ containing $p^{-1}\left(p\left(U_{i}\right)\right)$ such that $U_{i+1} \times \bar{V} \subset \pi^{-1}(A)$. Let $U=\bigcup U_{i}$; show that $U \times V$ is a saturated neighborhood of $x \times y$ that is contained in $\pi^{-1}(A)$.]

An entirely different proof of this result will be outlined in the exercises of $\S 46$.

(b) Theorem. Let $p: A \rightarrow B$ and $q: C \rightarrow D$ be quotient maps. If $B$ and $C$ are locally compact Hausdorff spaces, then $p \times q: A \times C \rightarrow B \times D$ is a quotient map.

## *Supplementary Exercises: Nets

We have already seen that sequences are "adequate" to detect limit points, continuous functions, and compact sets in metrizable spaces. There is a generalization of the notion of sequence, called a net, that will do the same thing for an arbitrary topological space. We give the relevant definitions here, and leave the proofs as exercises. Recall that a relation $\preceq$ on a set $A$ is called a partial order relation if the following conditions hold:

(1) $\alpha \preceq \alpha$ for all $\alpha$.

(2) If $\alpha \preceq \beta$ and $\beta \preceq \alpha$, then $\alpha=\beta$.

(3) If $\alpha \preceq \beta$ and $\beta \preceq \gamma$, then $\alpha \preceq \gamma$.

Now we make the following definition:

A directed set $J$ is a set with a partial order $\preceq$ such that for each pair $\alpha, \beta$ of elements of $J$, there exists an element $\gamma$ of $J$ having the property that $\alpha \preceq \gamma$ and $\beta \preceq \gamma$.

1. Show that the following are directed sets:

(a) Any simply ordered set, under the relation $\leq$.

(b) The collection of all subsets of a set $S$, partially ordered by inclusion (that is, $A \preceq B$ if $A \subset B$ ).

(c) A collection $\mathcal{A}$ of subsets of $S$ that is closed under finite intersections, partially ordered by reverse inclusion (that is $A \preceq B$ if $A \supset B$ ).

(d) The collection of all closed subsets of a space $X$, partially ordered by inclusion.

2. A subset $K$ of $J$ is said to be cofinal in $J$ if for each $\alpha \in J$, there exists $\beta \in K$ such that $\alpha \preceq \beta$. Show that if $J$ is a directed set and $K$ is cofinal in $J$, then $K$ is a directed set.
3. Let $X$ be a topological space. A net in $X$ is a function $f$ from a directed set $J$ into $X$. If $\alpha \in J$, we usually denote $f(\alpha)$ by $x_{\alpha}$. We denote the net $f$ itself by the symbol $\left(x_{\alpha}\right)_{\alpha \in J}$, or merely by $\left(x_{\alpha}\right)$ if the index set is understood.

The net $\left(x_{\alpha}\right)$ is said to converge to the point $x$ of $X$ (written $x_{\alpha} \rightarrow x$ ) if for each neighborhood $U$ of $x$, there exists $\alpha \in J$ such that

$$
\alpha \preceq \beta \Longrightarrow x_{\beta} \in U
$$

Show that these definitions reduce to familiar ones when $J=\mathbb{Z}_{+}$.

4. Suppose that

$$
\left(x_{\alpha}\right)_{\alpha \in J} \longrightarrow x \text { in } X \text { and }\left(y_{\alpha}\right)_{\alpha \in J} \longrightarrow y \text { in } Y \text {. }
$$

Show that $\left(x_{\alpha} \times y_{\alpha}\right) \longrightarrow x \times y$ in $X \times Y$.

5. Show that if $X$ is Hausdorff, a net in $X$ converges to at most one point.
6. Theorem. Let $A \in X$. Then $x \in \bar{A}$ if and only if there is a net of points of $A$ converging to $x$.

[Hint: To prove the implication $\Rightarrow$, take as index set the collection of all neighborhoods of $x$, partially ordered by reverse inclusion.]

7. Theorem. Let $f: X \rightarrow Y$. Then $f$ is continuous if and only if for every convergent net $\left(x_{\alpha}\right)$ in $X$, converging to $x$, say, the net $\left(f\left(x_{\alpha}\right)\right)$ converges to $f(x)$.
8. Let $f: J \rightarrow X$ be a net in $X$; let $f(\alpha)=x_{\alpha}$. If $K$ is a directed set and $g: K \rightarrow J$ is a function such that

(i) $i \preceq j \Rightarrow g(i) \preceq g(j)$,

(ii) $g(K)$ is cofinal in $J$,

then the composite function $f \circ g: K \rightarrow X$ is called a subnet of $\left(x_{\alpha}\right)$. Show that if the net $\left(x_{\alpha}\right)$ converges to $x$, so does any subnet.

9. Let $\left(x_{\alpha}\right)_{\alpha \in J}$ be a net in $X$. We say that $x$ is an accumulation point of the net $\left(x_{\alpha}\right)$ if for each neighborhood $U$ of $x$, the set of those $\alpha$ for which $x_{\alpha} \in U$ is cofinal in $J$.

Lemma. The net $\left(x_{\alpha}\right)$ has the point $x$ as an accumulation point if and only if some subnet of $\left(x_{\alpha}\right)$ converges to $x$.

[Hint: To prove the implication $\Rightarrow$, let $K$ be the set of all pairs $(\alpha, U)$ where $\alpha \in J$ and $U$ is a neighborhood of $x$ containing $x_{\alpha}$. Define $(\alpha, U) \preceq(\beta, V)$ if $\alpha \preceq \beta$ and $V \subset U$. Show that $K$ is a directed set and use it to define the subnet.]

10. Theorem. $X$ is compact if and only if every net in $X$ has a convergent subnet.

[Hint: To prove the implication $\Rightarrow$, let $B_{\alpha}=\left\{x_{\beta} \mid \alpha \preceq \beta\right\}$ and show that $\left\{B_{\alpha}\right\}$ has the finite intersection property. To prove $\Leftarrow$, let $\mathcal{A}$ be a collection of closed sets having the finite intersection property, and let $\mathscr{B}$ be the collection of all finite intersections of elements of $\mathcal{A}$, partially ordered by reverse inclusion.]

11. Corollary. Let $G$ be a topological group; let $A$ and $B$ be subsets of $G$. If $A$ is closed in $G$ and $B$ is compact, then $A \cdot B$ is closed in $G$.

[Hint: First give a proof using sequences, assuming that $G$ is metrizable.]

12. Check that the preceding exercises remain correct if condition (2) is omitted from the definition of directed set. Many mathematicians use the term "directed set" in this more general sense.

## Chapter 4

## Countability and Separation Axioms

The concepts we are going to introduce now, unlike compactness and connectedness, do not arise naturally from the study of calculus and analysis. They arise instead from a deeper study of topology itself. Such problems as imbedding a given space in a metric space or in a compact Hausdorff space are basically problems of topology rather than analysis. These particular problems have solutions that involve the countability and separation axioms.

We have already introduced the first countability axiom; it arose in connection with our study of convergent sequences in $\$ 21$. We have also studied one of the separation axioms-the Hausdorff axiom, and mentioned another-the $T_{1}$ axiom. In this chapter we shall introduce other, and stronger, axioms like these and explore some of their consequences. Our basic goal is to prove the Urysohn metrization theorem. It says that if a topological space $X$ satisfies a certain countability axiom (the second) and a certain separation axiom (the regularity axiom), then $X$ can be imbedded in a metric space and is thus metrizable.

Another imbedding theorem, important to geometers, appears in the last section of the chapter. Given a space that is a compact manifold (the higher-dimensional analogue of a surface), we show that it can be imbedded in some finite-dimensional euclidean space.

## §30 The Countability Axioms

Recall the definition we gave in $\S 21$.

Definition. A space $X$ is said to have a countable basis at $\boldsymbol{x}$ if there is a countable collection $\mathscr{B}$ of neighborhoods of $x$ such that each neighborhood of $x$ contains at least one of the elements of $\mathscr{B}$. A space that has a countable basis at each of its points is said to satisfy the first countability axiom, or to be first-countable.

We have already noted that every metrizable space satisfies this axiom; see $\$ 21$.

The most useful fact concerning spaces that satisfy this axiom is the fact that in such a space, convergent sequences are adequate to detect limit points of sets and to check continuity of functions. We have noted this before; now we state it formally as a theorem:

Theorem 30.1. Let $X$ be a topological space.

(a) Let $A$ be a subset of $X$. If there is a sequence of points of $A$ converging to $x$, then $x \in \bar{A}$; the converse holds if $X$ is first-countable.

(b) Let $f: X \rightarrow Y$. If $f$ is continuous, then for every convergent sequence $x_{n} \rightarrow x$ in $X$, the sequence $f\left(x_{n}\right)$ converges to $f(x)$. The converse holds if $X$ is firstcountable.

The proof is a direct generalization of the proof given in $\$ 21$ under the hypothesis of metrizability, so it will not be repeated here.

Of much greater importance than the first countability axiom is the following:

Definition. If a space $X$ has a countable basis for its topology, then $X$ is said to satisfy the second countability axiom, or to be second-countable.

Obviously, the second axiom implies the first: if $\mathscr{B}$ is a countable basis for the topology of $X$, then the subset of $\mathscr{B}$ consisting of those basis elements containing the point $x$ is a countable basis at $x$. The second axiom is, in fact, much stronger than the first; it is so strong that not even every metric space satisfies it.

Why then is this second axiom interesting? Well, for one thing, many familiar spaces do satisfy it. For another, it is a crucial hypothesis used in proving such theorems as the Urysohn metrization theorem, as we shall see.

EXAMPLE 1. The real line $\mathbb{R}$ has a countable basis-the collection of all open intervals $(a, b)$ with rational end points. Likewise, $\mathbb{R}^{n}$ has a countable basis-the collection of all products of intervals having rational end points. Even $\mathbb{R}^{\omega}$ has a countable basis-the collection of all products $\prod_{n \in \mathbb{Z}_{+}} U_{n}$, where $U_{n}$ is an open interval with rational end points for finitely many values of $n$, and $U_{n}=\mathbb{R}$ for all other values of $n$.

EXAMPLE 2. In the uniform topology, $\mathbb{R}^{\omega}$ satisfies the first countability axiom (being metrizable). However, it does not satisfy the second. To verify this fact, we first show that if $X$ is a space having a countable basis $\mathcal{B}$, then any discrete subspace $A$ of $X$ must be countable. Choose, for each $a \in A$, a basis element $B_{a}$ that intersects $A$ in the point $a$
alone. If $a$ and $b$ are distinct points of $A$, the sets $B_{a}$ and $B_{b}$ are different, since the first contains $a$ and the second does not. It follows that the map $a \rightarrow B_{a}$ is an injection of $A$ into $\mathcal{B}$, so $A$ must be countable.

Now we note that the subspace $A$ of $\mathbb{R}^{\omega}$ consisting of all sequences of 0 's and 1 's is uncountable; and it has the discrete topology because $\bar{\rho}(a, b)=1$ for any two distinct points $a$ and $b$ of $A$. Therefore, in the uniform topology $\mathbb{R}^{\omega}$ does not have a countable basis.

Both countability axioms are well behaved with respect to the operations of taking subspaces or countable products:

Theorem 30.2. A subspace of a first-countable space is first-countable, and a countable product of first-countable spaces is first-countable. A subspace of a secondcountable space is second-countable, and a countable product of second-countable spaces is second-countable.

Proof. Consider the second countability axiom. If $\mathscr{B}$ is a countable basis for $X$, then $\{B \cap A \mid B \in \mathscr{B}\}$ is a countable basis for the subspace $A$ of $X$. If $\mathscr{B}_{i}$ is a countable basis for the space $X_{i}$, then the collection of all products $\prod U_{i}$, where $U_{i} \in \mathcal{B}_{i}$ for finitely many values of $i$ and $U_{i}=X_{i}$ for all other values of $i$, is a countable basis for $\prod X_{i}$.

The proof for the first countability axiom is similar.

Two consequences of the second countability axiom that will be useful to us later are given in the following theorem. First, a definition:

Definition. A subset $A$ of a space $X$ is said to be dense in $X$ if $\bar{A}=X$.

Theorem 30.3. Suppose that $X$ has a countable basis. Then:

(a) Every open covering of $X$ contains a countable subcollection covering $X$.

(b) There exists a countable subset of $X$ that is dense in $X$.

Proof. Let $\left\{B_{n}\right\}$ be a countable basis for $X$.

(a) Let $\mathcal{A}$ be an open covering of $X$. For each positive integer $n$ for which it is possible, choose an element $A_{n}$ of $\mathcal{A}$ containing the basis element $B_{n}$. The collection $\mathcal{A}^{\prime}$ of the sets $A_{n}$ is countable, since it is indexed with a subset $J$ of the positive integers. Furthermore, it covers $X$ : Given a point $x \in X$, we can choose an element $A$ of $\mathscr{A}$ containing $x$. Since $A$ is open, there is a basis element $B_{n}$ such that $x \in B_{n} \subset A$. Because $B_{n}$ lies in an element of $\mathcal{A}$, the index $n$ belongs to the set $J$, so $A_{n}$ is defined; since $A_{n}$ contains $B_{n}$, it contains $x$. Thus $\mathcal{A}^{\prime}$ is a countable subcollection of $\mathcal{A}$ that covers $X$.

(b) From each nonempty basis element $B_{n}$, choose a point $x_{n}$. Let $D$ be the set consisting of the points $x_{n}$. Then $D$ is dense in $X$ : Given any point $x$ of $X$, every basis element containing $x$ intersects $D$, so $x$ belongs to $\bar{D}$.

The two properties listed in Theorem 30.3 are sometimes taken as alternative countability axioms. A space for which every open covering contains a countable subcovering is called a Lindelöf space. A space having a countable dense subset is often said to be separable (an unfortunate choice of terminology). ${ }^{\dagger}$ Weaker in general than the second countability axiom, each of these properties is equivalent to the second countability axiom when the space is metrizable (see Exercise 5). They are less important than the second countability axiom, but you should be aware of their existence, for they are sometimes useful. It is often easier, for instance, to show that a space $X$ has a countable dense subset than it is to show that $X$ has a countable basis. If the space is metrizable (as it usually is in analysis), it follows that $X$ is second-countable as well.

We shall not use these properties to prove any theorems, but one of them-the Lindelöf condition-will be useful in dealing with some examples. They are not as well behaved as one might wish under the operations of taking subspaces and cartesian products, as we shall see in the examples and exercises that follow.

EXAMPLE 3. The space $\mathbb{R}_{\ell}$ satisfies all the countability axioms but the second.

Given $x \in \mathbb{R}_{\ell}$, the set of all basis elements of the form $[x, x+1 / n)$ is a countable basis at $x$. And it is easy to see that the rational numbers are dense in $\mathbb{R}_{\ell}$.

To see that $\mathbb{R}_{\ell}$ has no countable basis, let $\mathscr{B}$ be a basis for $\mathbb{R}_{\ell}$. Choose for each $x$, an element $B_{x}$ of $\mathscr{B}$ such that $x \in B_{x} \subset[x, x+1)$. If $x \neq y$, then $B_{x} \neq B_{y}$, since $x=\inf B_{x}$ and $y=\inf B_{y}$. Therefore, $\mathscr{B}$ must be uncountable.

To show that $\mathbb{R}_{\ell}$ is Lindelöf requires more work. It will suffice to show that every open covering of $\mathbb{R}_{\ell}$ by basis elements contains a countable subcollection covering $\mathbb{R}_{\ell}$. (You can check this.) So let

$$
\mathcal{A}=\left\{\left[a_{\alpha}, b_{\alpha}\right)\right\}_{\alpha \in J}
$$

be a covering of $\mathbb{R}$ by basis elements for the lower limit topology. We wish to find a countable subcollection that covers $\mathbb{R}$.

Let $C$ be the set

$$
C=\bigcup_{\alpha \in J}\left(a_{\alpha}, b_{\alpha}\right)
$$

which is a subset of $\mathbb{R}$. We show the set $\mathbb{R}-C$ is countable.

Let $x$ be a point of $\mathbb{R}-C$. We know that $x$ belongs to no open interval $\left(a_{\alpha}, b_{\alpha}\right)$; therefore $x=a_{\beta}$ for some index $\beta$. Choose such a $\beta$ and then choose $q_{x}$ to be a rational number belonging to the interval $\left(a_{\beta}, b_{\beta}\right)$. Because $\left(a_{\beta}, b_{\beta}\right)$ is contained in $C$, so is the interval $\left(a_{\beta}, q_{x}\right)=\left(x, q_{x}\right)$. It follows that if $x$ and $y$ are two points of $\mathbb{R}-C$ with $x<y$, then $q_{x}<q_{y}$. (For otherwise, we would have $x<y<q_{y} \leq q_{x}$, so that $y$ would lie in the interval $\left(x, q_{x}\right)$ and hence in $C$.) Therefore the map $x \rightarrow q_{x}$ of $\mathbb{R}-C$ into $\mathbb{Q}$ is injective, so that $\mathbb{R}-C$ is countable.

Now we show that some countable subcollection of $\mathcal{A}$ covers $\mathbb{R}$. To begin, choose for each element of $\mathbb{R}-C$ an element of $\mathcal{A}$ containing it; one obtains a countable subcollection $\mathcal{A}^{\prime}$ of $\mathcal{A}$ that covers $\mathbb{R}-C$. Now take the set $C$ and topologize it as a subspace of $\mathbb{R}$; in this topology, $C$ satisfies the second countability axiom. Now $C$ is covered by the sets $\left(a_{\alpha}, b_{\alpha}\right)$, which are open in $\mathbb{R}$ and hence open in $C$. Then some countable subcollection[^4]covers $C$. Suppose this subcollection consists of the elements $\left(a_{\alpha}, b_{\alpha}\right)$ for $\alpha=\alpha_{1}, \alpha_{2}, \ldots$ Then the collection

$$
\mathcal{A}^{\prime \prime}=\left\{\left[a_{\alpha}, b_{\alpha}\right) \mid \alpha=\alpha_{1}, \alpha_{2}, \ldots\right\}
$$

is a countable subcollection of $\mathcal{A}$ that covers the set $C$, and $\mathcal{A}^{\prime} \cup \mathcal{A}^{\prime \prime}$ is a countable subcollection of $\mathcal{A}$ that covers $\mathbb{R}_{\ell}$.

EXAMPLE 4. The product of two Lindelöf spaces need not be Lindelöf. Although the space $\mathbb{R}_{\ell}$ is Lindelöf, we shall show that the product space $\mathbb{R}_{\ell} \times \mathbb{R}_{\ell}=\mathbb{R}_{\ell}^{2}$ is not. The space $\mathbb{R}_{\ell}^{2}$ is an extremely useful example in topology called the Sorgenfrey plane.

The space $\mathbb{R}_{\ell}^{2}$ has as basis all sets of the form $[a, b) \times[c, d)$. To show it is not Lindelöf, consider the subspace

$$
L=\left\{x \times(-x) \mid x \in \mathbb{R}_{\ell}\right\}
$$

It is easy to check that $L$ is closed in $\mathbb{R}_{\ell}^{2}$. Let us cover $\mathbb{R}_{\ell}^{2}$ by the open set $\mathbb{R}_{\ell}^{2}-L$ and by all basis elements of the form

$$
[a, b) \times[-a, d) \text {. }
$$

Each of these open sets intersects $L$ in at most one point. Since $L$ is uncountable, no countable subcollection covers $\mathbb{R}_{\ell}^{2}$. See Figure 30.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-194.jpg?height=692&width=938&top_left_y=1286&top_left_x=550)

Figure 30.1

EXAMPLE 5. A subspace of a Lindelöf space need not be Lindelöf. The ordered square $I_{o}^{2}$ is compact; therefore it is Lindelöf, trivially. However, the subspace $A=I \times(0,1)$ is not Lindelöf. For $A$ is the union of the disjoint sets $U_{x}=\{x\} \times(0,1)$, each of which is open in $A$. This collection of sets is uncountable, and no proper subcollection covers $A$.

## Exercises

1. (a) A $G_{\delta}$ set in a space $X$ is a set $A$ that equals a countable intersection of open sets of $X$. Show that in a first-countable $T_{1}$ space, every one-point set is a $G_{\delta}$ set.

(b) There is a familiar space in which every one-point set is a $G_{\delta}$ set, which nevertheless does not satisfy the first countability axiom. What is it?

The terminology here comes from the German. The " $G$ " stands for "Gebiet," which means "open set," and the " $\delta$ " for "Durchschnitt," which means "intersection."

2. Show that if $X$ has a countable basis $\left\{B_{n}\right\}$, then every basis $C$ for $X$ contains a countable basis for $X$. [Hint: For every pair of indices $n, m$ for which it is possible, choose $C_{n, m} \in \mathcal{C}$ such that $B_{n} \subset C_{n, m} \subset B_{m}$.]
3. Let $X$ have a countable basis; let $A$ be an uncountable subset of $X$. Show that uncountably many points of $A$ are limit points of $A$.
4. Show that every compact metrizable space $X$ has a countable basis. [Hint: Let $\mathcal{A}_{n}$ be a finite covering of $X$ by $1 / n$-balls.]
5. (a) Show that every metrizable space with a countable dense subset has a countable basis.

(b) Show that every metrizable Lindelöf space has a countable basis.

6. Show that $\mathbb{R}_{\ell}$ and $I_{o}^{2}$ are not metrizable.
7. Which of our four countability axioms does $S_{\Omega}$ satisfy? What about $\bar{S}_{\Omega}$ ?
8. Which of our four countability axioms does $\mathbb{R}^{\omega}$ in the uniform topology satisfy?
9. Let $A$ be a closed subspace of $X$. Show that if $X$ is Lindelöf, then $A$ is Lindelöf. Show by example that if $X$ has a countable dense subset, $A$ need not have a countable dense subset.
10. Show that if $X$ is a countable product of spaces having countable dense subsets, then $X$ has a countable dense subset.
11. Let $f: X \rightarrow Y$ be continuous. Show that if $X$ is Lindelöf, or if $X$ has a countable dense subset, then $f(X)$ satisfies the same condition.
12. Let $f: X \rightarrow Y$ be a continuous open map. Show that if $X$ satisfies the first or the second countability axiom, then $f(X)$ satisfies the same axiom.
13. Show that if $X$ has a countable dense subset, every collection of disjoint open sets in $X$ is countable.
14. Show that if $X$ is Lindelöf and $Y$ is compact, then $X \times Y$ is Lindelöf.
15. Give $\mathbb{R}^{I}$ the uniform metric, where $I=[0,1]$. Let $\mathcal{C}(I, \mathbb{R})$ be the subspace consisting of continuous functions. Show that $\mathcal{C}(I, \mathbb{R})$ has a countable dense subset, and therefore a countable basis. [Hint: Consider those continuous functions whose graphs consist of finitely many line segments with rational end points.]
16. (a) Show that the product space $\mathbb{R}^{I}$, where $I=[0,1]$, has a countable dense subset.

(b) Show that if $J$ has cardinality greater than $\mathcal{P}\left(\mathbb{Z}_{+}\right)$, then the product space $\mathbb{R}^{J}$ does not have a countable dense subset. [Hint: If $D$ is dense in $\mathbb{R}^{J}$, define $f: J \rightarrow \mathcal{P}(D)$ by the equation $f(\alpha)=D \cap \pi_{\alpha}^{-1}((a, b))$, where $(a, b)$ is a fixed interval in $\mathbb{R}$.]

*17. Give $\mathbb{R}^{\omega}$ the box topology. Let $\mathbb{Q}^{\infty}$ denote the subspace consisting of sequences of rationals that end in an infinite string of 0 's. Which of our four countability axioms does this space satisfy?

*18. Let $G$ be a first-countable topological group. Show that if $G$ has a countable dense subset, or is Lindelöf, then $G$ has a countable basis. [Hint: Let $\left\{B_{n}\right\}$ be a countable basis at $e$. If $D$ is a countable dense subset of $G$, show the sets $d B_{n}$, for $d \in D$, form a basis for $G$. If $G$ is Lindelöf, choose for each $n$ a countable set $C_{n}$ such that the sets $c B_{n}$, for $c \in C_{n}$, cover $G$. Show that as $n$ ranges over $\mathbb{Z}_{+}$, these sets form a basis for $G$.]

## §31 The Separation Axioms

In this section, we introduce three separation axioms and explore some of their properties. One you have already seen-the Hausdorff axiom. The others are similar but stronger. As always when we introduce new concepts, we shall examine the relationship between these axioms and the concepts introduced earlier in the book.

Recall that a space $X$ is said to be Hausdorff if for each pair $x, y$ of distinct points of $X$, there exist disjoint open sets containing $x$ and $y$, respectively.

Definition. Suppose that one-point sets are closed in $X$. Then $X$ is said to be regular if for each pair consisting of a point $x$ and a closed set $B$ disjoint from $x$, there exist disjoint open sets containing $x$ and $B$, respectively. The space $X$ is said to be normal if for each pair $A, B$ of disjoint closed sets of $X$, there exist disjoint open sets containing $A$ and $B$, respectively.

It is clear that a regular space is Hausdorff, and that a normal space is regular. (We need to include the condition that one-point sets be closed as part of the definition of regularity and normality in order for this to be the case. A two-point space in the indiscrete topology satisfies the other part of the definitions of regularity and normality, even though it is not Hausdorff.) For examples showing the regularity axiom stronger than the Hausdorff axiom, and normality stronger than regularity, see Examples 1 and 3 .

These axioms are called separation axioms for the reason that they involve "separating" certain kinds of sets from one another by disjoint open sets. We have used the word "separation" before, of course, when we studied connected spaces. But in that case, we were trying to find disjoint open sets whose union was the entire space.

The present situation is quite different because the open sets need not satisfy this condition.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-197.jpg?height=222&width=250&top_left_y=597&top_left_x=616)

Hausdorff

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-197.jpg?height=397&width=380&top_left_y=551&top_left_x=909)

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-197.jpg?height=448&width=472&top_left_y=492&top_left_x=1304)

Figure 31.1

The three separation axioms are illustrated in Figure 31.1.

There are other ways to formulate the separation axioms. One formulation that is sometimes useful is given in the following lemma:

Lemma 31.1. Let $X$ be a topological space. Let one-point sets in $X$ be closed.

(a) $X$ is regular if and only if given a point $x$ of $X$ and a neighborhood $U$ of $x$, there is a neighborhood $V$ of $x$ such that $\bar{V} \subset U$.

(b) $X$ is normal if and only if given a closed set $A$ and an open set $U$ containing $A$, there is an open set $V$ containing $A$ such that $\bar{V} \subset U$.

Proof. (a) Suppose that $X$ is regular, and suppose that the point $x$ and the neighborhood $U$ of $x$ are given. Let $B=X-U$; then $B$ is a closed set. By hypothesis, there exist disjoint open sets $V$ and $W$ containing $x$ and $B$, respectively. The set $\bar{V}$ is disjoint from $B$, since if $y \in B$, the set $W$ is a neighborhood of $y$ disjoint from $V$. Therefore, $\bar{V} \subset U$, as desired.

To prove the converse, suppose the point $x$ and the closed set $B$ not containing $x$ are given. Let $U=X-B$. By hypothesis, there is a neighborhood $V$ of $x$ such that $\bar{V} \subset U$. The open sets $V$ and $X-\bar{V}$ are disjoint open sets containing $x$ and $B$, respectively. Thus $X$ is regular.

(b) This proof uses exactly the same argument; one just replaces the point $x$ by the set $A$ throughout.

Now we relate the separation axioms with the concepts previously introduced.

Theorem 31.2. (a) A subspace of a Hausdorff space is Hausdorff; a product of Hausdorff spaces is Hausdorff.

(b) A subspace of a regular space is regular; a product of regular spaces is regular.

Proof. (a) This result was an exercise in $\S 17$. We provide a proof here. Let $X$ be Hausdorff. Let $x$ and $y$ be two points of the subspace $Y$ of $X$. If $U$ and $V$ are disjoint neighborhoods in $X$ of $x$ and $y$, respectively, then $U \cap Y$ and $V \cap Y$ are disjoint neighborhoods of $x$ and $y$ in $Y$.

Let $\left\{X_{\alpha}\right\}$ be a family of Hausdorff spaces. Let $\mathbf{x}=\left(x_{\alpha}\right)$ and $\mathbf{y}=\left(y_{\alpha}\right)$ be distinct points of the product space $\prod X_{\alpha}$. Because $\mathbf{x} \neq \mathbf{y}$, there is some index $\beta$ such that $x_{\beta} \neq y_{\beta}$. Choose disjoint open sets $U$ and $V$ in $X_{\beta}$ containing $x_{\beta}$ and $y_{\beta}$, respectively. Then the sets $\pi_{\beta}^{-1}(U)$ and $\pi_{\beta}^{-1}(V)$ are disjoint open sets in $\prod X_{\alpha}$ containing $\mathbf{x}$ and $\mathbf{y}$, respectively.

(b) Let $Y$ be a subspace of the regular space $X$. Then one-point sets are closed in $Y$. Let $x$ be a point of $Y$ and let $B$ be a closed subset of $Y$ disjoint from $x$. Now $\bar{B} \cap Y=B$, where $\bar{B}$ denotes the closure of $B$ in $X$. Therefore, $x \notin \bar{B}$, so, using regularity of $X$, we can choose disjoint open sets $U$ and $V$ of $X$ containing $x$ and $\bar{B}$, respectively. Then $U \cap Y$ and $V \cap Y$ are disjoint open sets in $Y$ containing $x$ and $B$, respectively.

Let $\left\{X_{\alpha}\right\}$ be a family of regular spaces; let $X=\prod X_{\alpha}$. By (a), $X$ is Hausdorff, so that one-point sets are closed in $X$. We use the preceding lemma to prove regularity of $X$. Let $\mathbf{x}=\left(x_{\alpha}\right)$ be a point of $X$ and let $U$ be a neighborhood of $\mathbf{x}$ in $X$. Choose a basis element $\prod U_{\alpha}$ about $\mathbf{x}$ contained in $U$. Choose, for each $\alpha$, a neighborhood $V_{\alpha}$ of $x_{\alpha}$ in $X_{\alpha}$ such that $\bar{V}_{\alpha} \subset U_{\alpha}$; if it happens that $U_{\alpha}=X_{\alpha}$, choose $V_{\alpha}=X_{\alpha}$. Then $V=\prod V_{\alpha}$ is a neighborhood of $x$ in $X$. Since $\bar{V}=\prod \bar{V}_{\alpha}$ by Theorem 19.5, it follows at once that $\bar{V} \subset \prod U_{\alpha} \subset U$, so that $X$ is regular.

There is no analogous theorem for normal spaces, as we shall see shortly, in this section and the next.

EXAMPLE 1. The space $\mathbb{R}_{K}$ is Hausdorff but not regular. Recall that $\mathbb{R}_{K}$ denotes the reals in the topology having as basis all open intervals $(a, b)$ and all sets of the form $(a, b)-K$, where $K=\left\{1 / n \mid n \in \mathbb{Z}_{+}\right\}$. This space is Hausdorff, because any two distinct points have disjoint open intervals containing them.

But it is not regular. The set $K$ is closed in $\mathbb{R}_{K}$, and it does not contain the point 0 . Suppose that there exist disjoint open sets $U$ and $V$ containing 0 and $K$, respectively. Choose a basis element containing 0 and lying in $U$. It must be a basis element of the form $(a, b)-K$, since each basis element of the form $(a, b)$ containing 0 intersects $K$. Choose $n$ large enough that $1 / n \in(a, b)$. Then choose a basis element about $1 / n$ contained in $V$; it must be a basis element of the form $(c, d)$. Finally, choose $z$ so that $z<1 / n$ and $z>\max \{c, 1 /(n+1)\}$. Then $z$ belongs to both $U$ and $V$, so they are not disjoint. See Figure 31.2.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-198.jpg?height=122&width=905&top_left_y=2037&top_left_x=569)

Figure 31.2

EXAMPLE 2. The space $\mathbb{R}_{\ell}$ is normal. It is immediate that one-point sets are closed in $\mathbb{R}_{\ell}$, since the topology of $\mathbb{R}_{\ell}$ is finer than that of $\mathbb{R}$. To check normality, suppose that $A$ and $B$ are disjoint closed sets in $\mathbb{R}_{\ell}$. For each point $a$ of $A$ choose a basis element $\left[a, x_{a}\right)$ not intersecting $B$; and for each point $b$ of $B$ choose a basis element $\left[b, x_{b}\right)$ not intersecting $A$. The open sets

$$
U=\bigcup_{a \in A}\left[a, x_{a}\right) \quad \text { and } \quad V=\bigcup_{b \in B}\left[b, x_{b}\right)
$$

are disjoint open sets about $A$ and $B$, respectively.

EXAMPLE 3. The Sorgenfrey plane $\mathbb{R}_{\ell}^{2}$ is not normal.

The space $\mathbb{R}_{\ell}$ is regular (in fact, normal), so the product space $\mathbb{R}_{\ell}^{2}$ is also regular. Thus this example serves two purposes. It shows that a regular space need not be normal, and it shows that the product of two normal spaces need not be normal.

We suppose $\mathbb{R}_{\ell}^{2}$ is normal and derive a contradiction. Let $L$ be the subspace of $\mathbb{R}_{\ell}^{2}$ consisting of all points of the form $x \times(-x)$. Then $L$ is closed in $\mathbb{R}_{\ell}^{2}$, and $L$ has the discrete topology. Hence every subset $A$ of $L$, being closed in $L$, is closed in $\mathbb{R}_{\ell}^{2}$. Because $L-A$ is also closed in $\mathbb{R}_{\ell}^{2}$, this means that for every nonempty proper subset $A$ of $L$, one can find disjoint open sets $U_{A}$ and $V_{A}$ containing $A$ and $L-A$, respectively.

Let $D$ denote the set of points of $\mathbb{R}_{\ell}^{2}$ having rational coordinates; it is dense in $\mathbb{R}_{\ell}^{2}$. We define a map $\theta$ that assigns, to each subset of the line $L$, a subset of the set $D$, by setting

$$
\begin{aligned}
& \theta(A)=D \cap U_{A} \quad \text { if } \varnothing \varsubsetneqq A \varsubsetneqq L, \\
& \theta(\varnothing)=\varnothing, \\
& \theta(L)=D .
\end{aligned}
$$

We show that $\theta: \mathcal{P}(L) \rightarrow \mathcal{P}(D)$ is injective.

Let $A$ be a proper nonempty subset of $L$. Then $\theta(A)=D \cap U_{A}$ is neither empty (since $U_{A}$ is open and $D$ is dense in $\mathbb{R}_{\ell}^{2}$ ) nor all of $D$ (since $D \cap V_{A}$ is nonempty). It remains to show that if $B$ is another proper nonempty subset of $L$, then $\theta(A) \neq \theta(B)$.

One of the sets $A, B$ contains a point not in the other; suppose that $x \in A$ and $x \notin B$. Then $x \in L-B$, so that $x \in U_{A} \cap V_{B}$; since the latter set is open and nonempty, it must contain points of $D$. These points belong to $U_{A}$ and not to $U_{B}$; therefore, $D \cap U_{A} \neq D \cap U_{B}$, as desired. Thus $\theta$ is injective.

Now we show there exists an injective map $\phi: \mathcal{P}(D) \rightarrow L$. Because $D$ is countably infinite and $L$ has the cardinality of $\mathbb{R}$, it suffices to define an injective map $\psi$ of $\mathcal{P}\left(\mathbb{Z}_{+}\right)$ into $\mathbb{R}$. For that, we let $\psi$ assign to the subset $S$ of $\mathbb{Z}_{+}$the infinite decimal . $a_{1} a_{2} \ldots$, where $a_{i}=0$ if $i \in S$ and $a_{i}=1$ if $i \notin S$. That is,

$$
\psi(S)=\sum_{i=1}^{\infty} a_{i} / 10^{i}
$$

Now the composite

$$
\mathcal{P}(L) \xrightarrow{\theta} \mathcal{P}(D) \xrightarrow{\psi} L
$$

is an injective map of $\mathcal{P}(L)$ into $L$. But Theorem 7.8 tells us such a map does not exist! Thus we have reached a contradiction.

This proof that $\mathbb{R}_{\ell}^{2}$ is not normal is in some ways not very satisfying. We showed only that there must exist some proper nonempty subset $A$ of $L$ such that the sets $A$ and $B=L-A$ are not contained in disjoint open sets of $\mathbb{R}_{\ell}^{2}$. But we did not actually find such a set $A$. In fact, the set $A$ of points of $L$ having rational coordinates is such a set, but the proof is not easy. It is left to the exercises.

## Exercises

1. Show that if $X$ is regular, every pair of points of $X$ have neighborhoods whose closures are disjoint.
2. Show that if $X$ is normal, every pair of disjoint closed sets have neighborhoods whose closures are disjoint.
3. Show that every order topology is regular.
4. Let $X$ and $X^{\prime}$ denote a single set under two topologies $\mathcal{T}$ and $\mathcal{T}^{\prime}$, respectively; assume that $\mathcal{T}^{\prime} \supset \mathcal{T}$. If one of the spaces is Hausdorff (or regular, or normal), what does that imply about the other?
5. Let $f, g: X \rightarrow Y$ be continuous; assume that $Y$ is Hausdorff. Show that $\{x \mid$ $f(x)=g(x)\}$ is closed in $X$.
6. Let $p: X \rightarrow Y$ be a closed continuous surjective map. Show that if $X$ is normal, then so is $Y$. [Hint: If $U$ is an open set containing $p^{-1}(\{y\})$, show there is a neighborhood $W$ of $y$ such that $p^{-1}(W) \subset U$.]
7. Let $p: X \rightarrow Y$ be a closed continuous surjective map such that $p^{-1}(\{y\})$ is compact for each $y \in Y$. (Such a map is called a perfect map.)

(a) Show that if $X$ is Hausdorff, then so is $Y$.

(b) Show that if $X$ is regular, then so is $Y$.

(c) Show that if $X$ is locally compact, then so is $Y$.

(d) Show that if $X$ is second-countable, then so is $Y$. [Hint: Let $\mathscr{B}$ be a countable basis for $X$. For each finite subset $J$ of $\mathscr{B}$, let $U_{J}$ be the union of all sets of the form $p^{-1}(W)$, for $W$ open in $Y$, that are contained in the union of the elements of $J$.]

8. Let $X$ be a space; let $G$ be a topological group. An action of $G$ on $X$ is a continuous map $\alpha: G \times X \rightarrow X$ such that, denoting $\alpha(g \times x)$ by $g \cdot x$, one has:

(i) $e \cdot x=x$ for all $x \in X$.

(ii) $g_{1} \cdot\left(g_{2} \cdot x\right)=\left(g_{1} \cdot g_{2}\right) \cdot x$ for all $x \in X$ and $g_{1}, g_{2} \in G$.

Define $x \sim g \cdot x$ for all $x$ and $g$; the resulting quotient space is denoted $X / G$ and called the orbit space of the action $\alpha$.

Theorem. Let $G$ be a compact topological group; let $X$ be a topological space; let $\alpha$ be an action of $G$ on $X$. If $X$ is Hausdorff, or regular, or normal, or locally compact, or second-countable, so is $X / G$.

[Hint: See Exercise 13 of §26.]

*9. Let $A$ be the set of all points of $\mathbb{R}_{\ell}^{2}$ of the form $x \times(-x)$, for $x$ rational; let $B$ be the set of all points of this form for $x$ irrational. If $V$ is an open set of $\mathbb{R}_{\ell}^{2}$ containing $B$, show there exists no open set $U$ containing $A$ that is disjoint from $V$, as follows:

(a) Let $K_{n}$ consist of all irrational numbers $x$ in [0,1] such that $[x, x+1 / n) \times$ $[-x,-x+1 / n)$ is contained in $V$. Show $[0,1]$ is the union of the sets $K_{n}$ and countably many one-point sets.

(b) Use Exercise 5 of $\S 27$ to show that some set $\bar{K}_{n}$ contains an open interval $(a, b)$ of $\mathbb{R}$.

(c) Show that $V$ contains the open parallelogram consisting of all points of the form $x \times(-x+\epsilon)$ for which $a<x<b$ and $0<\epsilon<1 / n$.

(d) Conclude that if $q$ is a rational number with $a<q<b$, then the point $q \times(-q)$ of $\mathbb{R}_{\ell}^{2}$ is a limit point of $V$.

## §32 Normal Spaces

Now we turn to a more thorough study of spaces satisfying the normality axiom. In one sense, the term "normal" is something of a misnomer, for normal spaces are not as well-behaved as one might wish. On the other hand, most of the spaces with which we are familiar do satisfy this axiom, as we shall see. Its importance comes from the fact that the results one can prove under the hypothesis of normality are central to much of topology. The Urysohn metrization theorem and the Tietze extension theorem are two such results; we shall deal with them later in this chapter.

We begin by proving three theorems that give three important sets of hypotheses under which normality of a space is assured.

Theorem 32.1. Every regular space with a countable basis is normal.

Proof. Let $X$ be a regular space with a countable basis $\mathcal{B}$. Let $A$ and $B$ be disjoint closed subsets of $X$. Each point $x$ of $A$ has a neighborhood $U$ not intersecting $B$. Using regularity, choose a neighborhood $V$ of $x$ whose closure lies in $U$; finally, choose an element of $\mathcal{B}$ containing $x$ and contained in $V$. By choosing such a basis element for each $x$ in $A$, we construct a countable covering of $A$ by open sets whose closures do not intersect $B$. Since this covering of $A$ is countable, we can index it with the positive integers; let us denote it by $\left\{U_{n}\right\}$.

Similarly, choose a countable collection $\left\{V_{n}\right\}$ of open sets covering $B$, such that each set $\bar{V}_{n}$ is disjoint from $A$. The sets $U=\bigcup U_{n}$ and $V=\bigcup V_{n}$ are open sets containing $A$ and $B$, respectively, but they need not be disjoint. We perform the following simple trick to construct two open sets that are disjoint. Given $n$, define

$$
U_{n}^{\prime}=U_{n}-\bigcup_{i=1}^{n} \bar{V}_{i} \quad \text { and } \quad V_{n}^{\prime}=V_{n}-\bigcup_{i=1}^{n} \bar{U}_{i}
$$

Note that each set $U_{n}^{\prime}$ is open, being the difference of an open set $U_{n}$ and a closed set $\bigcup_{i=1}^{n} \bar{V}_{i}$. Similarly, each set $V_{n}^{\prime}$ is open. The collection $\left\{U_{n}^{\prime}\right\}$ covers $A$, because each $x$ in $A$ belongs to $U_{n}$ for some $n$, and $x$ belongs to none of the sets $\bar{V}_{i}$. Similarly, the collection $\left\{V_{n}^{\prime}\right\}$ covers $B$. See Figure 32.1.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-202.jpg?height=1162&width=830&top_left_y=638&top_left_x=612)

Figure 32.1

Finally, the open sets

$$
U^{\prime}=\bigcup_{n \in \mathbb{Z}_{+}} U_{n}^{\prime} \quad \text { and } \quad V^{\prime}=\bigcup_{n \in \mathbb{Z}_{+}} V_{n}^{\prime}
$$

are disjoint. For if $x \in U^{\prime} \cap V^{\prime}$, then $x \in U_{j}^{\prime} \cap V_{k}^{\prime}$ for some $j$ and $k$. Suppose that $j \leq k$. It follows from the definition of $U_{j}^{\prime}$ that $x \in U_{j}$; and since $j \leq k$ it follows from the definition of $V_{k}^{\prime}$ that $x \notin \bar{U}_{j}$. A similar contradiction arises if $j \geq k$.

Theorem 32.2. Every metrizable space is normal.

Proof. Let $X$ be a metrizable space with metric $d$. Let $A$ and $B$ be disjoint closed subsets of $X$. For each $a \in A$, choose $\epsilon_{a}$ so that the ball $B\left(a, \epsilon_{a}\right)$ does not intersect $B$. Similarly, for each $b$ in $B$, choose $\epsilon_{b}$ so that the ball $B\left(b, \epsilon_{b}\right)$ does not intersect $A$. Define

$$
U=\bigcup_{a \in A} B\left(a, \epsilon_{a} / 2\right) \quad \text { and } \quad V=\bigcup_{b \in B} B\left(b, \epsilon_{b} / 2\right) \text {. }
$$

Then $U$ and $V$ are open sets containing $A$ and $B$, respectively; we assert they are disjoint. For if $z \in U \cap V$, then

$$
z \in B\left(a, \epsilon_{a} / 2\right) \cap B\left(b, \epsilon_{b} / 2\right)
$$

for some $a \in A$ and some $b \in B$. The triangle inequality applies to show that $d(a, b)<\left(\epsilon_{a}+\epsilon_{b}\right) / 2$. If $\epsilon_{a} \leq \epsilon_{b}$, then $d(a, b)<\epsilon_{b}$, so that the ball $B\left(b, \epsilon_{b}\right)$ contains the point $a$. If $\epsilon_{b} \leq \epsilon_{a}$, then $d(a, b)<\epsilon_{a}$, so that the ball $B\left(a, \epsilon_{a}\right)$ contains the point $b$. Neither situation is possible.

Theorem 32.3. Every compact Hausdorff space is normal.

Proof. Let $X$ be a compact Hausdorff space. We have already essentially proved that $X$ is regular. For if $x$ is a point of $X$ and $B$ is a closed set in $X$ not containing $x$, then $B$ is compact, so that Lemma 26.4 applies to show there exist disjoint open sets about $x$ and $B$, respectively.

Essentially the same argument as given in that lemma can be used to show that $X$ is normal: Given disjoint closed sets $A$ and $B$ in $X$, choose, for each point $a$ of $A$, disjoint open sets $U_{a}$ and $V_{a}$ containing $a$ and $B$, respectively. (Here we use regularity of $X$.) The collection $\left\{U_{a}\right\}$ covers $A$; because $A$ is compact, $A$ may be covered by finitely many sets $U_{a_{1}}, \ldots, U_{a_{m}}$. Then

$$
U=U_{a_{1}} \cup \cdots \cup U_{a_{m}} \quad \text { and } \quad V=V_{a_{1}} \cap \cdots \cap V_{a_{m}}
$$

are disjoint open sets containing $A$ and $B$, respectively.

Here is a further result about normality that we shall find useful in dealing with some examples.

Theorem 32.4. Every well-ordered set $X$ is normal in the order topology.

It is, in fact, true that every order topology is normal (see Example 39 of [S-S]); but we shall not have occasion to use this stronger result.

Proof. Let $X$ be a well-ordered set. We assert that every interval of the form $(x, y]$ is open in $X$ : If $X$ has a largest element and $y$ is that element, $(x, y]$ is just a basis element about $y$. If $y$ is not the largest element of $X$, then $(x, y]$ equals the open set $\left(x, y^{\prime}\right)$, where $y^{\prime}$ is the immediate successor of $y$.

Now let $A$ and $B$ be disjoint closed sets in $X$; assume for the moment that neither $A$ nor $B$ contains the smallest element $a_{0}$ of $X$. For each $a \in A$, there exists a basis element about $a$ disjoint from $B$; it contains some interval of the form $(x, a]$. (Here is where we use the fact that $a$ is not the smallest element of $X$.) Choose, for each $a \in A$, such an interval $\left(x_{a}, a\right]$ disjoint from $B$. Similarly, for each $b \in B$, choose an interval $\left(y_{b}, b\right]$ disjoint from $A$. The sets

$$
U=\bigcup_{a \in A}\left(x_{a}, a\right] \quad \text { and } \quad V=\bigcup_{b \in B}\left(y_{b}, b\right]
$$

are open sets containing $A$ and $B$, respectively; we assert they are disjoint. For suppose that $z \in U \cap V$. Then $z \in\left(x_{a}, a\right] \cap\left(y_{b}, b\right]$ for some $a \in A$ and some $b \in B$. Assume that $a<b$. Then if $a \leq y_{b}$, the two intervals are disjoint, while if $a>y_{b}$, we have $a \in\left(y_{b}, b\right]$, contrary to the fact that $\left(y_{b}, b\right]$ is disjoint from $A$. A similar contradiction occurs if $b<a$.

Finally, assume that $A$ and $B$ are disjoint closed sets in $X$, and $A$ contains the smallest element $a_{0}$ of $X$. The set $\left\{a_{0}\right\}$ is both open and closed in $X$. By the result of the preceding paragraph, there exist disjoint open sets $U$ and $V$ containing the closed sets $A-\left\{a_{0}\right\}$ and $B$, respectively. Then $U \cup\left\{a_{0}\right\}$ and $V$ are disjoint open sets containing $A$ and $B$, respectively.

EXAMPLE 1. If $J$ is uncountable, the product space $\mathbb{R}^{J}$ is not normal. The proof is fairly difficult; we leave it as a challenging exercise (see Exercise 9).

This example serves three purposes. It shows that a regular space $\mathbb{R}^{J}$ need not be normal. It shows that a subspace of a normal space need not be normal, for $\mathbb{R}^{J}$ is homeomorphic to the subspace $(0,1)^{J}$ of $[0,1]^{J}$, which (assuming the Tychonoff theorem) is compact Hausdorff and therefore normal. And it shows that an uncountable product of normal spaces need not be normal. It leaves unsettled the question as to whether a finite or a countable product of normal spaces might be normal.

## EXAMPLE 2. The product space $S_{\Omega} \times \bar{S}_{\Omega}$ is not normal. ${ }^{\dagger}$

Consider the well-ordered set $\bar{S}_{\Omega}$, in the order topology, and consider the subset $S_{\Omega}$, in the subspace topology (which is the same as the order topology). Both spaces are normal, by Theorem 32.4. We shall show that the product space $S_{\Omega} \times \bar{S}_{\Omega}$ is not normal.

This example serves three purposes. First, it shows that a regular space need not be normal, for $S_{\Omega} \times \bar{S}_{\Omega}$ is a product of regular spaces and therefore regular. Second, it shows that a subspace of a normal space need not be normal, for $S_{\Omega} \times \bar{S}_{\Omega}$ is a subspace of $\bar{S}_{\Omega} \times \bar{S}_{\Omega}$, which is a compact Hausdorff space and therefore normal. Third, it shows that the product of two normal spaces need not be normal.

First, we consider the space $\bar{S}_{\Omega} \times \bar{S}_{\Omega}$, and its "diagonal" $\Delta=\left\{x \times x \mid x \in \bar{S}_{\Omega}\right\}$. Because $\bar{S}_{\Omega}$ is Hausdorff, $\Delta$ is closed in $\bar{S}_{\Omega} \times \bar{S}_{\Omega}$ : If $U$ and $V$ are disjoint neighborhoods of $x$ and $y$, respectively, then $U \times V$ is a neighborhood of $x \times y$ that does not intersect $\Delta$.

Therefore, in the subspace $S_{\Omega} \times \bar{S}_{\Omega}$, the set

$$
A=\Delta \cap\left(S_{\Omega} \times \bar{S}_{\Omega}\right)=\Delta-\{\Omega \times \Omega\}
$$[^5]

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-205.jpg?height=783&width=908&top_left_y=372&top_left_x=745)

Figure 32.2

is closed. Likewise, the set

$$
B=S_{\Omega} \times\{\Omega\}
$$

is closed in $S_{\Omega} \times \bar{S}_{\Omega}$, being a "slice" of this product space. The sets $A$ and $B$ are disjoint. We shall assume there exist disjoint open sets $U$ and $V$ of $S_{\Omega} \times \bar{S}_{\Omega}$ containing $A$ and $B$, respectively, and derive a contradiction. See Figure 32.2.

Given $x \in S_{\Omega}$, consider the vertical slice $x \times \bar{S}_{\Omega}$. We assert that there is some point $\beta$ with $x<\beta<\Omega$ such that $x \times \beta$ lies outside $U$. For if $U$ contained all points $x \times \beta$ for $x<\beta<\Omega$, then the top point $x \times \Omega$ of the slice would be a limit point of $U$, which it is not because $V$ is an open set disjoint from $U$ containing this top point.

Choose $\beta(x)$ to be such a point; just to be definite, let $\beta(x)$ be the smallest element of $S_{\Omega}$ such that $x<\beta(x)<\Omega$ and $x \times \beta(x)$ lies outside $U$. Define a sequence of points of $S_{\Omega}$ as follows: Let $x_{1}$ be any point of $S_{\Omega}$. Let $x_{2}=\beta\left(x_{1}\right)$, and in general, $x_{n+1}=\beta\left(x_{n}\right)$. We have

$$
x_{1}<x_{2}<\ldots
$$

because $\beta(x)>x$ for all $x$. The set $\left\{x_{n}\right\}$ is countable and therefore has an uper bound in $S_{\Omega}$; let $b \in S_{\Omega}$ be its least upper bound. Because the sequence is increasing, it must converge to its least upper bound; thus $x_{n} \rightarrow b$. But $\beta\left(x_{n}\right)=x_{n+1}$, so that $\beta\left(x_{n}\right) \rightarrow b$ also. Then

$$
x_{n} \times \beta\left(x_{n}\right) \longrightarrow b \times b
$$

in the product space. See Figure 32.3. Now we have a contradiction, for the point $b \times b$ lies in the set $A$, which is contained in the open set $U$; and $U$ contains none of the points $x_{n} \times \beta\left(x_{n}\right)$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-206.jpg?height=750&width=935&top_left_y=366&top_left_x=551)

Figure 32.3

## Exercises

1. Show that a closed subspace of a normal space is normal.
2. Show that if $\prod X_{\alpha}$ is Hausdorff, or regular, or normal, then so is $X_{\alpha}$. (Assume that each $X_{\alpha}$ is nonempty.)
3. Show that every locally compact Hausdorff space is regular.
4. Show that every regular Lindelöf space is normal.
5. Is $\mathbb{R}^{\omega}$ normal in the product topology? In the uniform topology?

It is not known whether $\mathbb{R}^{\omega}$ is normal in the box topology. Mary-Ellen Rudin has shown that the answer is affirmative if one assumes the continuum hypothesis $[\mathrm{RM}]$. In fact, she shows it satisfies a stronger condition called paracompactness.

6. A space $X$ is said to be completely normal if every subspace of $X$ is normal. Show that $X$ is completely normal if and only if for every pair $A, B$ of separated sets in $X$ (that is, sets such that $\bar{A} \cap B=\varnothing$ and $A \cap \bar{B}=\varnothing$ ), there exist disjoint open sets containing them. [Hint: If $X$ is completely normal, consider $X-(\bar{A} \cap \bar{B})$.
7. Which of the following spaces are completely normal? Justify your answers.

(a) A subspace of a completely normal space.

(b) The product of two completely normal spaces.

(c) A well-ordered set in the order topology.

(d) A metrizable space.
(e) A compact Hausdorff space.

(f) A regular space with a countable basis.

(g) The space $\mathbb{R}_{\ell}$.

*8. Prove the following:

Theorem. Every linear continuum $X$ is normal.

(a) Let $C$ be a nonempty closed subset of $X$. If $U$ is a component of $X-C$, show that $U$ is a set of the form $\left(c, c^{\prime}\right)$ or $(c, \infty)$ or $(-\infty, c)$, where $c, c^{\prime} \in C$.

(b) Let $A$ and $B$ be closed disjoint subsets of $X$. For each component $W$ of $X-A \cup B$ that is an open interval with one end point in $A$ and the other in $B$, choose a point $c_{W}$ of $W$. Show that the set $C$ of the points $c_{W}$ is closed.

(c) Show that if $V$ is a component of $X-C$, then $V$ does not intersect both $A$ and $B$.

*9. Prove the following:

Theorem. If $J$ is uncountable, then $\mathbb{R}^{J}$ is not normal.

Proof. (This proof is due to A. H. Stone, as adapted in [S-S].) Let $X=\left(\mathbb{Z}_{+}\right)^{J}$; it will suffice to show that $X$ is not normal, since $X$ is a closed subspace of $R^{J}$. We use functional notation for the elements of $X$, so that the typical element of $X$ is a function $\mathbf{x}: J \rightarrow \mathbb{Z}_{+}$.

(a) If $\mathbf{x} \in X$ and if $B$ is a finite subset of $J$, let $U(\mathbf{x}, B)$ denote the set consisting of all those elements $\mathbf{y}$ of $X$ such that $\mathbf{y}(\alpha)=\mathbf{x}(\alpha)$ for $\alpha \in B$. Show the sets $U(\mathbf{x}, B)$ are a basis for $X$.

(b) Define $P_{n}$ to be the subset of $X$ consisting of those $\mathbf{x}$ such that on the set $J-\mathbf{x}^{-1}(n)$, the map $\mathbf{x}$ is injective. Show that $P_{1}$ and $P_{2}$ are closed and disjoint.

(c) Suppose $U$ and $V$ are open sets containing $P_{1}$ and $P_{2}$, respectively. Given a sequence $\alpha_{1}, \alpha_{2}, \ldots$ of distinct elements of $J$, and a sequence

$$
0=n_{0}<n_{1}<n_{2}<\cdots
$$

of integers, for each $i \geq 1$ let us set

$$
B_{i}=\left\{\alpha_{1}, \cdots, \alpha_{n_{i}}\right\}
$$

and define $\mathbf{x}_{i} \in X$ by the equations

$$
\begin{aligned}
\mathbf{x}_{i}\left(\alpha_{j}\right)=j & \text { for } 1 \leq j \leq n_{i-1} \\
\mathbf{x}_{i}(\alpha)=1 & \text { for all other values of } \alpha .
\end{aligned}
$$

Show that one can choose the sequences $\alpha_{j}$ and $n_{j}$ so that for each $i$, one has the inclusion

$$
U\left(\mathbf{x}_{i}, B_{i}\right) \subset U .
$$

[Hint: To begin, note that $\mathbf{x}_{1}(\alpha)=1$ for all $\alpha$; now choose $B_{1}$ so that $\left.U\left(\mathbf{x}_{1}, B_{1}\right) \subset U.\right]$
(d) Let $A$ be the set $\left\{\alpha_{1}, \alpha_{2}, \ldots\right\}$ constructed in (c). Define $\mathbf{y}: J \rightarrow \mathbb{Z}_{+}$by the equations

$$
\begin{aligned}
\mathbf{y}\left(\alpha_{j}\right)=j & \text { for } \alpha_{j} \in A \\
\mathbf{y}(\alpha)=2 & \text { for all other values of } \alpha .
\end{aligned}
$$

Choose $B$ so that $U(\mathbf{y}, B) \subset V$. Then choose $i$ so that $B \cap A$ is contained in the set $B_{i}$. Show that

$$
U\left(\mathbf{x}_{i+1}, B_{i+1}\right) \cap U(\mathbf{y}, B)
$$

is not empty.

10. Is every topological group normal?

## §33 The Urysohn Lemma

Now we come to the first deep theorem of the book, a theorem that is commonly called the "Urysohn lemma." It asserts the existence of certain real-valued continuous functions on a normal space $X$. It is the crucial tool used in proving a number of important theorems. We shall prove three of them-the Urysohn metrization theorem, the Tietze extension theorem, and an imbedding theorem for manifolds-in succeeding sections of this chapter.

Why do we call the Urysohn lemma a "deep" theorem? Because its proof involves a really original idea, which the previous proofs did not. Perhaps we can explain what we mean this way: By and large, one would expect that if one went through this book and deleted all the proofs we have given up to now and then handed the book to a bright student who had not studied topology, that student ought to be able to go through the book and work out the proofs independently. (It would take a good deal of time and effort, of course; and one would not expect the student to handle the trickier examples.) But the Urysohn lemma is on a different level. It would take considerably more originality than most of us possess to prove this lemma unless we were given copious hints!

Theorem 33.1 (Urysohn lemma). Let $X$ be a normal space; let $A$ and $B$ be disjoint closed subsets of $X$. Let $[a, b]$ be a closed interval in the real line. Then there exists a continuous map

$$
f: X \longrightarrow[a, b]
$$

such that $f(x)=a$ for every $x$ in $A$, and $f(x)=b$ for every $x$ in $B$.

Proof. We need consider only the case where the interval in question is the interval $[0,1]$; the general case follows from that one. The first step of the proof is to construct, using normality, a certain family $U_{p}$ of open sets of $X$, indexed by the rational numbers. Then one uses these sets to define the continuous function $f$.

Step 1. Let $P$ be the set of all rational numbers in the interval $[0,1] .{ }^{\dagger}$ We shall define, for each $p$ in $P$, an open set $U_{p}$ of $X$, in such a way that whener $p<q$, we have

$$
\bar{U}_{p} \subset U_{q} .
$$

Thus, the sets $U_{p}$ will be simply ordered by inclusion in the same way their subscripts are ordered by the usual ordering in the real line.

Because $P$ is countable, we can use induction to define the sets $U_{p}$ (or rather, the principle of recursive definition). Arrange the elements of $P$ in an infinite sequence in some way; for convenience, let us suppose that the numbers 1 and 0 are the first two elements of the sequence.

Now define the sets $U_{p}$, as follows: First, define $U_{1}=X-B$. Second, because $A$ is a closed set contained in the open set $U_{1}$, we may by normality of $X$ choose an open set $U_{0}$ such that

$$
A \subset U_{0} \quad \text { and } \quad \bar{U}_{0} \subset U_{1}
$$

In general, let $P_{n}$ denote the set consisting of the first $n$ rational numbers in the sequence. Suppose that $U_{p}$ is defined for all rational numbers $p$ belonging to the set $P_{n}$, satisfying the condition

$$
\begin{equation*}
p<q \Longrightarrow \bar{U}_{p} \subset U_{q} . \tag{*}
\end{equation*}
$$

Let $r$ denote the next rational number in the sequence; we wish to define $U_{r}$.

Consider the set $P_{n+1}=P_{n} \cup\{r\}$. It is a finite subset of the interval [0,1], and, as such, it has a simple ordering derived from the usual order relation $<$ on the real line. In a finite simply ordered set, every element (other than the smallest and the largest) has an immediate predecessor and an immediate successor. (See Theorem 10.1.) The number 0 is the smallest element, and 1 is the largest element, of the simply ordered set $P_{n+1}$, and $r$ is neither 0 nor 1. So $r$ has an immediate predecessor $p$ in $P_{n+1}$ and an immediate successor $q$ in $P_{n+1}$. The sets $U_{p}$ and $U_{q}$ are already defined, and $\bar{U}_{p} \subset U_{q}$ by the induction hypothesis. Using normality of $X$, we can find an open set $U_{r}$ of $X$ such that

$$
\bar{U}_{p} \subset U_{r} \quad \text { and } \quad \bar{U}_{r} \subset U_{q} .
$$

We assert that $(*)$ now holds for every pair of elements of $P_{n+1}$. If both elements lie in $P_{n},(*)$ holds by the induction hypothesis. If one of them is $r$ and the other is a point $s$ of $P_{n}$, then either $s \leq p$, in which case

$$
\bar{U}_{s} \subset \bar{U}_{p} \subset U_{r}
$$

or $s \geq q$, in which case

$$
\bar{U}_{r} \subset U_{q} \subset U_{s} .
$$[^6]

Thus, for every pair of elements of $P_{n+1}$, relation $(*)$ holds.

By induction, we have $U_{p}$ defined for all $p \in P$.

To illustrate, let us suppose we started with the standard way of arranging the elements of $P$ in an infinite sequence:

$$
P=\left\{1,0, \frac{1}{2}, \frac{1}{3}, \frac{2}{3}, \frac{1}{4}, \frac{3}{4}, \frac{1}{5}, \frac{2}{5}, \frac{3}{5}, \ldots\right\}
$$

After defining $U_{0}$ and $U_{1}$, we would define $U_{1 / 2}$ so that $\bar{U}_{0} \subset U_{1 / 2}$ and $\bar{U}_{1 / 2} \subset U_{1}$. Then we would fit in $U_{1 / 3}$ between $U_{0}$ and $U_{1 / 2}$; and $U_{2 / 3}$ between $U_{1 / 2}$ and $U_{1}$. And so on. At the eighth step of the proof we would have the situation pictured in Figure 33.1. And the ninth step would consist of choosing an open set $U_{2 / 5}$ to fit in between $U_{1 / 3}$ and $U_{1 / 2}$. And so on.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-210.jpg?height=725&width=1129&top_left_y=870&top_left_x=457)

Figure 33.1

Step 2. Now we have defined $U_{p}$ for all rational numbers $p$ in the interval $[0,1]$. We extend this definition to all rational numbers $p$ in $\mathbb{R}$ by defining

$$
\begin{array}{ll}
U_{p}=\varnothing & \text { if } p<0 \\
U_{p}=X & \text { if } p>1
\end{array}
$$

It is still true (as you can check) that for any pair of rational numbers $p$ and $q$,

$$
p<q \Longrightarrow \bar{U}_{p} \subset U_{q} .
$$

Step 3. Given a point $x$ of $X$, let us define $\mathbb{Q}(x)$ to be the set of those rational numbers $p$ such that the corresponding open sets $U_{p}$ contain $x$ :

$$
\mathbb{Q}(x)=\left\{p \mid x \in U_{p}\right\} .
$$

This set contains no number less than 0 , since no $x$ is in $U_{p}$ for $p<0$. And it contains every number greater than 1 , since every $x$ is in $U_{p}$ for $p>1$. Therefore, $\mathbb{Q}(x)$ is bounded below, and its greatest lower bound is a point of the interval [0,1]. Define

$$
f(x)=\inf \mathbb{Q}(x)=\inf \left\{p \mid x \in U_{p}\right\} .
$$

Step 4. We show that $f$ is the desired function. If $x \in A$, then $x \in U_{p}$ for every $p \geq 0$, so that $\mathbb{Q}(x)$ equals the set of all nonnegative rationals, and $f(x)=\inf \mathbb{Q}(x)=$ 0 . Similarly, if $x \in B$, then $x \in U_{p}$ for no $p \leq 1$, so that $\mathbb{Q}(x)$ consists of all rational numbers greater than 1 , and $f(x)=1$.

All this is easy. The only hard part is to show that $f$ is continuous. For this purpose, we first prove the following elementary facts:

(1) $x \in \bar{U}_{r} \Rightarrow f(x) \leq r$.

(2) $x \notin U_{r} \Rightarrow f(x) \geq r$.

To prove (1), note that if $x \in \bar{U}_{r}$, then $x \in U_{s}$ for every $s>r$. Therefore, $\mathbb{Q}(x)$ contains all rational numbers greater than $r$, so that by definition we have

$$
f(x)=\inf \mathbb{Q}(x) \leq r .
$$

To prove (2), note that if $x \notin U_{r}$, then $x$ is not in $U_{s}$ for any $s<r$. Therefore, $\mathbb{Q}(x)$ contains no rational numbers less than $r$, so that

$$
f(x)=\inf \mathbb{Q}(x) \geq r .
$$

Now we prove continuity of $f$. Given a point $x_{0}$ of $X$ and an open interval $(c, d)$ in $\mathbb{R}$ containing the point $f\left(x_{0}\right)$, we wish to find a neighborhood $U$ of $x_{0}$ such that $f(U) \subset(c, d)$. Choose rational numbers $p$ and $q$ such that

$$
c<p<f\left(x_{0}\right)<q<d .
$$

We assert that the open set

$$
U=U_{q}-\bar{U}_{p}
$$

is the desired neighborhood of $x_{0}$. See Figure 33.2.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-211.jpg?height=300&width=1154&top_left_y=1671&top_left_x=620)

Figure 33.2

First, we note that $x_{0} \in U$. For the fact that $f\left(x_{0}\right)<q$ implies by condition (2) that $x_{0} \in U_{q}$, while the fact that $f\left(x_{0}\right)>p$ implies by (1) that $x_{0} \notin \bar{U}_{p}$.

Second, we show that $f(U) \subset(c, d)$. Let $x \in U$. Then $x \in U_{q} \subset \bar{U}_{q}$, so that $f(x) \leq q$, by (1). And $x \notin \bar{U}_{p}$, so that $x \notin U_{p}$ and $f(x) \geq p$, by (2). Thus, $f(x) \in[p, q] \subset(c, d)$, as desired.

Definition. If $A$ and $B$ are two subsets of the topological space $X$, and if there is a continuous function $f: X \rightarrow[0,1]$ such that $f(A)=\{0\}$ and $f(B)=\{1\}$, we say that $A$ and $B$ can be separated by a continuous function.

The Urysohn lemma says that if every pair of disjoint closed sets in $X$ can be separated by disjoint open sets, then each such pair can be separated by a continuous function. The converse is trivial, for if $f: X \rightarrow[0,1]$ is the function, then $f^{-1}\left(\left[0, \frac{1}{2}\right)\right)$ and $f^{-1}\left(\left(\frac{1}{2}, 1\right]\right)$ are disjoint open sets containing $A$ and $B$, respectively.

This fact leads to a question that may already have occurred to you: Why cannot the proof of the Urysohn lemma be generalized to show that in a regular space, where you can separate points from closed sets by disjoint open sets, you can also separate points from closed sets by continuous functions?

At first glance, it seems that the proof of the Urysohn lemma should go through. You take a point $a$ and a closed set $B$ not containing $a$, and you begin the proof just as before by defining $U_{1}=X-B$ and choosing $U_{0}$ to be an open set about $a$ whose closure is contained in $U_{1}$ (using regularity of $X$ ). But at the very next step of the proof, you run into difficulty. Suppose that $p$ is the next rational number in the sequence after 0 and 1. You want to find an open set $U_{p}$ such that $\bar{U}_{0} \subset U_{p}$ and $\bar{U}_{p} \subset U_{1}$. For this, regularity is not enough.

Requiring that one be able to separate a point from a closed set by a continuous function is, in fact, a stronger condition than requiring that one can separate them by disjoint open sets. We make this requirement into a new separation axiom:

Definition. A space $X$ is completely regular if one-point sets are closed in $X$ and if for each point $x_{0}$ and each closed set $A$ not containing $x_{0}$, there is a continuous function $f: X \rightarrow[0,1]$ such that $f\left(x_{0}\right)=1$ and $f(A)=\{0\}$.

A normal space is completely regular, by the Urysohn lemma, and a completely regular space is regular, since given $f$, the sets $f^{-1}\left(\left[0, \frac{1}{2}\right)\right)$ and $f^{-1}\left(\left(\frac{1}{2}, 1\right]\right)$ are disjoint open sets about $A$ and $x_{0}$, respectively. As a result, this new axiom fits in between regularity and normality in the list of separation axioms. Note that in the definition one could just as well require the function to map $x_{0}$ to 0 , and $A$ to $\{1\}$, for $g(x)=1-f(x)$ satisfies this condition. But our definition is at times a bit more convenient.

In the early years of topology, the separation axioms, listed in order of increasing strength, were labelled $T_{1}, T_{2}$ (Hausdorff), $T_{3}$ (regular), $T_{4}$ (normal), and $T_{5}$ (completely normal), respectively. The letter "T" comes from the German "Trennungsaxiom," which means "separation axiom." Later, when the notion of complete regularity was introduced, someone suggested facetiously that it should be called the " $T-3 \frac{1}{2}$ axiom," since it lies between regularity and normality. This terminology is in fact sometimes used in the literature!

Unlike normality, this new separation axiom is nicely behaved with regard to subspaces and products:

Theorem 33.2. A subspace of a completely regular space is completely regular. A product of completely regular spaces is completely regular.

Proof. Let $X$ be completely regular; let $Y$ be a subspace of $X$. Let $x_{0}$ be a point of $Y$, and let $A$ be a closed set of $Y$ disjoint from $x_{0}$. Now $A=\bar{A} \cap Y$, where $\bar{A}$ denotes the closure of $A$ in $X$. Therefore, $x_{0} \notin \bar{A}$. Since $X$ is completely regular, we can choose a continuous function $f: X \rightarrow[0,1]$ such that $f\left(x_{0}\right)=1$ and $f(\bar{A})=\{0\}$. The restriction of $f$ to $Y$ is the desired continuous function on $Y$.

Let $X=\prod X_{\alpha}$ be a product of completely regular spaces. Let $\mathbf{b}=\left(b_{\alpha}\right)$ be a point of $X$ and let $A$ be a closed set of $X$ disjoint from $\mathbf{b}$. Choose a basis element $\prod U_{\alpha}$ containing $\mathbf{b}$ that does not intersect $A$; then $U_{\alpha}=X_{\alpha}$ except for finitely many $\alpha$, say $\alpha=\alpha_{1}, \ldots, \alpha_{n}$. Given $i=1, \ldots, n$, choose a continuous function

$$
f_{i}: X_{\alpha_{i}} \rightarrow[0,1]
$$

such that $f_{i}\left(b_{\alpha_{i}}\right)=1$ and $f_{i}\left(X-U_{\alpha_{i}}\right)=\{0\}$. Let $\phi_{i}(\mathbf{x})=f_{i}\left(\pi_{\alpha_{i}}(\mathbf{x})\right)$; then $\phi_{i}$ maps $X$ continuously into $\mathbb{R}$ and vanishes outside $\pi_{\alpha_{i}}^{-1}\left(U_{\alpha_{i}}\right)$. The product

$$
f(\mathbf{x})=\phi_{1}(\mathbf{x}) \cdot \phi_{2}(\mathbf{x}) \cdot \cdots \cdot \phi_{n}(\mathbf{x})
$$

is the desired continuous function on $X$, for it equals 1 at $\mathbf{b}$ and vanishes outside $\prod U_{\alpha}$.

EXAMPLE 1. The spaces $\mathbb{R}_{\ell}^{2}$ and $S_{\Omega} \times \bar{S}_{\Omega}$ are completely regular but not normal. For they are products of spaces that are completely regular (in fact, normal).

A space that is regular but not completely regular is much harder to find. Most of the examples that have been constructed for this purpose are difficult, and require considerable familiarity with cardinal numbers. Fairly recently, however, John Thomas $[T]$ has constructed a much more elementary example, which we outline in Exercise 11.

## Exercises

1. Examine the proof of the Urysohn lemma, and show that for given $r$,

$$
f^{-1}(r)=\bigcap_{p>r} U_{p}-\bigcup_{q<r} U_{q},
$$

$p, q$ rational.

2. (a) Show that a connected normal space having more than one point is uncountable.

(b) Show that a connected regular space having more than one point is uncountable. ${ }^{\dagger}$ [Hint: Any countable space is Lindelöf.]

3. Give a direct proof of the Urysohn lemma for a metric space $(X, d)$ by setting

$$
f(x)=\frac{d(x, A)}{d(x, A)+d(x, B)} .
$$[^7]

4. Recall that $A$ is a " $G_{\delta}$ set" in $X$ if $A$ is the intersection of a countable collection of open sets of $X$.

Theorem. Let $X$ be normal. There exists a continuous function $f: X \rightarrow[0,1]$ such that $f(x)=0$ for $x \in A$, and $f(x)>0$ for $x \notin A$, if and only if $A$ is a closed $G_{\delta}$ set in $X$.

A function satisfying the requirements of this theorem is said to vanish precisely on $A$.

5. Prove:

Theorem (Strong form of the Urysohn lemma). Let $X$ be a normal space. There is a continuous function $f: X \rightarrow[0,1]$ such that $f(x)=0$ for $x \in A$, and $f(x)=1$ for $x \in B$, and $0<f(x)<1$ otherwise, if and only if $A$ and $B$ are disjoint closed $G_{\delta}$ sets in $X$.

6. A space $X$ is said to be perfectly normal if $X$ is normal and if every closed set in $X$ is a $G_{\delta}$ set in $X$.

(a) Show that every metrizable space is perfectly normal.

(b) Show that a perfectly normal space is completely normal. For this reason the condition of perfect normality is sometimes called the " $T_{6}$ axiom." [Hint: Let $A$ and $B$ be separated sets in $X$. Choose continuous functions $f, g$ : $X \rightarrow[0,1]$ that vanish precisely on $\bar{A}$ and $\bar{B}$, respectively. Consider the function $f-g$.]

(c) There is a familiar space that is completely normal but not perfectly normal. What is it?

7. Show that every locally compact Hausdorff space is completely regular.
8. Let $X$ be completely regular; let $A$ and $B$ be disjoint closed subsets of $X$. Show that if $A$ is compact, there is a continuous function $f: X \rightarrow[0,1]$ such that $f(A)=\{0\}$ and $f(B)=\{1\}$.
9. Show that $\mathbb{R}^{J}$ in the box topology is completely regular. [Hint: Show that it suffices to consider the case where the box neighborhood $(-1,1)^{J}$ is disjoint from $A$ and the point is the origin. Then use the fact that a function continuous in the uniform topology is also continuous in the box topology.]

*10. Prove the following:

Theorem. Every topological group is completely regular.

Proof. Let $V_{0}$ be a neighborhood of the identity element $e$, in the topological group $G$. In general, choose $V_{n}$ to be a neighborhood of $e$ such that $V_{n} \cdot V_{n} \subset$ $V_{n-1}$. Consider the set of all dyadic rationals $p$, that is, all rational numbers of the form $k / 2^{n}$, with $k$ and $n$ integers. For each dyadic rational $p$ in $(0,1]$, define an open set $U(p)$ inductively as follows: $U(1)=V_{0}$ and $U\left(\frac{1}{2}\right)=V_{1}$. Given $n$, if $U\left(k / 2^{n}\right)$ is defined for $0<k / 2^{n} \leq 1$, define

$$
\begin{aligned}
U\left(1 / 2^{n+1}\right) & =V_{n+1}, \\
U\left((2 k+1) / 2^{n+1}\right) & =V_{n+1} \cdot U\left(k / 2^{n}\right)
\end{aligned}
$$

for $0<k<2^{n}$. For $p \leq 0$, let $U(p)=\varnothing$; and for $p>1$, let $U(p)=G$. Show that

$$
V_{n} \cdot U\left(k / 2^{n}\right) \subset U\left((k+1) / 2^{n}\right)
$$

for all $k$ and $n$. Proceed as in the Urysohn lemma.

This exercise is adapted from [M-Z], to which the reader is referred for further results on topological groups.

*11. Define a set $X$ as follows: For each even integer $m$, let $L_{m}$ denote the line segment $m \times[-1,0]$ in the plane. For each odd integer $n$ and each integer $k \geq 2$, let $C_{n, k}$ denote the union of the line segments $(n+1-1 / k) \times[-1,0]$ and $(n-1+1 / k) \times[-1,0]$ and the semicircle

$$
\left\{x \times y \mid(x-n)^{2}+y^{2}=(1-1 / k)^{2} \text { and } y \geq 0\right\}
$$

in the plane. Let $p_{n, k}$ denote the topmost point $n \times(1-1 / k)$ of this semicircle. Let $X$ be the union of all the sets $L_{m}$ and $C_{n, k}$, along with two extra points $a$ and $b$. Topologize $X$ by taking sets of the following four types as basis elements:

(i) The intersection of $X$ with a horizontal open line segment that contains none of the points $p_{n, k}$.

(ii) A set formed from one of the sets $C_{n, k}$ by deleting finitely many points.

(iii) For each even integer $m$, the union of $\{a\}$ and the set of points $x \times y$ of $X$ for which $x<m$.

(iv) For each even integer $m$, the union of $\{b\}$ and the set of points $x \times y$ of $X$ for which $x>m$.

(a) Sketch $X$; show that these sets form a basis for a topology on $X$.

(b) Let $f$ be a continuous real-valued function on $X$. Show that for any $c$, the set $f^{-1}(c)$ is a $G_{\delta}$ set in $X$. (This is true for any space $X$.) Conclude that the set $S_{n, k}$ consisting of those points $p$ of $C_{n, k}$ for which $f(p) \neq f\left(p_{n, k}\right)$ is countable. Choose $d \in[-1,0]$ so that the line $y=d$ intersects none of the sets $S_{n, k}$. Show that for $n$ odd,

$$
f((n-1) \times d)=\lim _{k \rightarrow \infty} f\left(p_{n, k}\right)=f((n+1) \times d) .
$$

Conclude that $f(a)=f(b)$.

(c) Show that $X$ is regular but not completely regular.

## §34 The Urysohn Metrization Theorem

Now we come to the major goal of this chapter, a theorem that gives us conditions under which a topological space is metrizable. The proof weaves together a number of strands from previous parts of the book; it uses results on metric topologies from Chapter 2 as well as facts concerning the countability and separation axioms proved in
the present chapter. The basic construction used in the proof is a simple one, but very useful. You will see it several times more in this book, in various guises.

There are two versions of the proof, and since each has useful generalizations that will appear subsequently, we present both of them here. The first version generalizes to give an imbedding theorem for completely regular spaces. The second version will be generalized in Chapter 6 when we prove the Nagata-Smirnov metrization theorem.

Theorem 34.1 (Urysohn metrization theorem). Every regular space $X$ with a countable basis is metrizable.

Proof. We shall prove that $X$ is metrizable by imbedding $X$ in a metrizable space $Y$; that is, by showing $X$ homeomorphic with a subspace of $Y$. The two versions of the proof differ in the choice of the metrizable space $Y$. In the first version, $Y$ is the space $\mathbb{R}^{\omega}$ in the product topology, a space that we have previously proved to be metrizable (Theorem 20.5). In the second version, the space $Y$ is also $\mathbb{R}^{\omega}$, but this time in the topology given by the uniform metric $\bar{\rho}$ (see $\S 20$ ). In each case, it turns out that our construction actually imbeds $X$ in the subspace $[0,1]^{\omega}$ of $\mathbb{R}^{\omega}$.

Step 1. We prove the following: There exists a countable collection of continuous functions $f_{n}: X \rightarrow[0,1]$ having the property that given any point $x_{0}$ of $X$ and any neighborhood $U$ of $x_{0}$, there exists an index $n$ such that $f_{n}$ is positive at $x_{0}$ and vanishes outside $U$.

It is a consequence of the Urysohn lemma that, given $x_{0}$ and $U$, there exists such a function. However, if we choose one such function for each pair $\left(x_{0}, U\right)$, the resulting collection will not in general be countable. Our task is to cut the collection down to size. Here is one way to proceed:

Let $\left\{B_{n}\right\}$ be a countable basis for $X$. For each pair $n, m$ of indices for which $\bar{B}_{n} \subset B_{m}$, apply the Urysohn lemma to choose a continuous function $g_{n, m}: X \rightarrow$ $[0,1]$ such that $g_{n, m}\left(\bar{B}_{n}\right)=\{1\}$ and $g_{n, m}\left(X-B_{m}\right)=\{0\}$. Then the collection $\left\{g_{n, m}\right\}$ satisfies our requirement: Given $x_{0}$ and given a neighborhood $U$ of $x_{0}$, one can choose a basis element $B_{m}$ containing $x_{0}$ that is contained in $U$. Using regularity, one can then choose $B_{n}$ so that $x_{0} \in B_{n}$ and $\bar{B}_{n} \subset B_{m}$. Then $n, m$ is a pair of indices for which the function $g_{n, m}$ is defined; and it is positive at $x_{0}$ and vanishes outside $U$. Because the collection $\left\{g_{n, m}\right\}$ is indexed with a subset of $\mathbb{Z}_{+} \times \mathbb{Z}_{+}$, it is countable; therefore it can be reindexed with the positive integers, giving us the desired collection $\left\{f_{n}\right\}$.

Step 2 (First version of the proof). Given the functions $f_{n}$ of Step 1 , take $\mathbb{R}^{\omega}$ in the product topology and define a map $F: X \rightarrow \mathbb{R}^{\omega}$ by the rule

$$
F(x)=\left(f_{1}(x), f_{2}(x), \ldots\right) .
$$

We assert that $F$ is an imbedding.

First, $F$ is continuous because $\mathbb{R}^{\omega}$ has the product topology and each $f_{n}$ is continuous. Second, $F$ is injective because given $x \neq y$, we know there is an index $n$ such that $f_{n}(x)>0$ and $f_{n}(y)=0$; therefore, $F(x) \neq F(y)$.

Finally, we must prove that $F$ is a homeomorphism of $X$ onto its image, the subspace $Z=F(X)$ of $\mathbb{R}^{\omega}$. We know that $F$ defines a continuous bijection of $X$ with $Z$,
so we need only show that for each open set $U$ in $X$, the set $F(U)$ is open in $Z$. Let $z_{0}$ be a point of $F(U)$. We shall find an open set $W$ of $Z$ such that

$$
z_{0} \in W \subset F(U)
$$

Let $x_{0}$ be the point of $U$ such that $F\left(x_{0}\right)=z_{0}$. Choose an index $N$ for which $f_{N}\left(x_{0}\right)>0$ and $f_{N}(X-U)=\{0\}$. Take the open ray $(0,+\infty)$ in $\mathbb{R}$, and let $V$ be the open set

$$
V=\pi_{N}^{-1}((0,+\infty))
$$

of $\mathbb{R}^{\omega}$. Let $W=V \cap Z$; then $W$ is open in $Z$, by definition of the subspace topology. See Figure 34.1. We assert that $z_{0} \in W \subset F(U)$. First, $z_{0} \in W$ because

$$
\pi_{N}\left(z_{0}\right)=\pi_{N}\left(F\left(x_{0}\right)\right)=f_{N}\left(x_{0}\right)>0 .
$$

Second, $W \subset F(U)$. For if $z \in W$, then $z=F(x)$ for some $x \in X$, and $\pi_{N}(z) \in$ $(0,+\infty)$. Since $\pi_{N}(z)=\pi_{N}(F(x))=f_{N}(x)$, and $f_{N}$ vanishes outside $U$, the point $x$ must be in $U$. Then $z=F(x)$ is in $F(U)$, as desired.

Thus $F$ is an imbedding of $X$ in $\mathbb{R}^{\omega}$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-217.jpg?height=680&width=1116&top_left_y=1259&top_left_x=641)

Figure 34.1

Step 3 (Second version of the proof). In this version, we imbed $X$ in the metric space $\left(\mathbb{R}^{\omega}, \bar{\rho}\right)$. Actually, we imbed $X$ in the subspace $[0,1]^{\omega}$, on which $\bar{\rho}$ equals the metric

$$
\rho(\mathbf{x}, \mathbf{y})=\sup \left\{\left|x_{i}-y_{i}\right|\right\} .
$$

We use the countable collection of functions $f_{n}: X \rightarrow[0,1]$ constructed in Step 1 . But now we impose the additional condition that $f_{n}(x) \leq 1 / n$ for all $x$. (This condition is easy to satisfy; we can just divide each function $f_{n}$ by $n$.)

Define $F: X \rightarrow[0,1]^{\omega}$ by the equation

$$
F(x)=\left(f_{1}(x), f_{2}(x), \ldots\right)
$$

as before. We assert that $F$ is now an imbedding relative to the metric $\rho$ on $[0,1]^{\omega}$. We know from Step 2 that $F$ is injective. Furthermore, we know that if we use the product topology on $[0,1]^{\omega}$, the map $F$ carries open sets of $X$ onto open sets of the subspace $Z=F(X)$. This statement remains true if one passes to the finer (larger) topology on $[0,1]^{\omega}$ induced by the metric $\rho$.

The one thing left to do is to prove that $F$ is continuous. This does not follow from the fact that each component function is continuous, for we are not using the product topology on $\mathbb{R}^{\omega}$ now. Here is where the assumption $f_{n}(x) \leq 1 / n$ comes in.

Let $x_{0}$ be a point of $X$, and let $\epsilon>0$. To prove continuity, we need to find a neighborhood $U$ of $x_{0}$ such that

$$
x \in U \Longrightarrow \rho\left(F(x), F\left(x_{0}\right)\right)<\epsilon .
$$

First choose $N$ large enough that $1 / N \leq \epsilon / 2$. Then for each $n=1, \ldots, N$ use the continuity of $f_{n}$ to choose a neighborhood $U_{n}$ of $x_{0}$ such that

$$
\left|f_{n}(x)-f_{n}\left(x_{0}\right)\right| \leq \epsilon / 2
$$

for $x \in U_{n}$. Let $U=U_{1} \cap \cdots \cap U_{N}$; we show that $U$ is the desired neighborhood of $x_{0}$. Let $x \in U$. If $n \leq N$,

$$
\left|f_{n}(x)-f_{n}\left(x_{0}\right)\right| \leq \epsilon / 2
$$

by choice of $U$. And if $n>N$, then

$$
\left|f_{n}(x)-f_{n}\left(x_{0}\right)\right|<1 / N \leq \epsilon / 2
$$

because $f_{n}$ maps $X$ into $[0,1 / n]$. Therefore for all $x \in U$,

$$
\rho\left(F(x), F\left(x_{0}\right)\right) \leq \epsilon / 2<\epsilon,
$$

as desired.

In Step 2 of the preceding proof, we actually proved something stronger than the result stated there. For later use, we state it here:

Theorem 34.2 (Imbedding theorem). Let $X$ be a space in which one-point sets are closed. Suppose that $\left\{f_{\alpha}\right\}_{\alpha \in J}$ is an indexed family of continuous functions $f_{\alpha}: X \rightarrow$ $\mathbb{R}$ satisfying the requirement that for each point $x_{0}$ of $X$ and each neighborhood $U$ of $x_{0}$, there is an index $\alpha$ such that $f_{\alpha}$ is positive at $x_{0}$ and vanishes outside $U$. Then the function $F: X \rightarrow \mathbb{R}^{J}$ defined by

$$
F(x)=\left(f_{\alpha}(x)\right)_{\alpha \in J}
$$

is an imbedding of $X$ in $\mathbb{R}^{J}$. If $f_{\alpha}$ maps $X$ into $[0,1]$ for each $\alpha$, then $F$ imbeds $X$ in $[0,1]^{J}$.

The proof is almost a copy of Step 2 of the preceding proof; one merely replaces $n$ by $\alpha$, and $\mathbb{R}^{\omega}$ by $\mathbb{R}^{J}$, throughout. One needs one-point sets in $X$ to be closed in order to be sure that, given $x \neq y$, there is an index $\alpha$ such that $f_{\alpha}(x) \neq f_{\alpha}(y)$.

A family of continuous functions that satisfies the hypotheses of this theorem is said to separate points from closed sets in $X$. The existence of such a family is readily seen to be equivalent, for a space $X$ in which one-point sets are closed, to the requirement that $X$ be completely regular. Therefore one has the following immediate corollary:

Theorem 34.3. A space $X$ is completely regular if and only if it is homeomorphic to a subspace of $[0,1]^{J}$ for some $J$.

## Exercises

1. Give an example showing that a Hausdorff space with a countable basis need not be metrizable.
2. Give an example showing that a space can be completely normal, and satisfy the first countability axiom, the Lindelöf condition, and have a countable dense subset, and still not be metrizable.
3. Let $X$ be a compact Hausdorff space. Show that $X$ is metrizable if and only if $X$ has a countable basis.
4. Let $X$ be a locally compact Hausdorff space. Is it true that if $X$ has a countable basis, then $X$ is metrizable? Is it true that if $X$ is metrizable, then $X$ has a countable basis?
5. Let $X$ be a locally compact Hausdorff space. Let $Y$ be the one-point compactification of $X$. Is it true that if $X$ has a countable basis, then $Y$ is metrizable? Is it true that if $Y$ is metrizable, then $X$ has a countable basis?
6. Check the details of the proof of Theorem 34.2.
7. A space $X$ is locally metrizable if each point $x$ of $X$ has a neighborhood that is metrizable in the subspace topology. Show that a compact Hausdorff space $X$ is metrizable if it is locally metrizable. [Hint: Show that $X$ is a finite union of open subspaces, each of which has a countable basis.]
8. Show that a regular Lindelöf space is metrizable if it is locally metrizable. [Hint: A closed subspace of a Lindelöf space is Lindelöf.] Regularity is essential; where do you use it in the proof?
9. Let $X$ be a compact Hausdorff space that is the union of the closed subspaces $X_{1}$ and $X_{2}$. If $X_{1}$ and $X_{2}$ are metrizable, show that $X$ is metrizable. [Hint: Construct a countable collection $\mathcal{A}$ of open sets of $X$ whose intersections with $X_{i}$ form a basis for $X_{i}$, for $i=1,2$. Assume $X_{1}-X_{2}$ and $X_{2}-X_{1}$ belong to $\mathcal{A}$. Let $\mathscr{B}$ consist of finite intersections of elements of $\mathscr{A}$.]

## *§35 The Tietze Extension Theorem ${ }^{\dagger}$

One immediate consequence of the Urysohn lemma is the useful theorem called the Tietze extension theorem. It deals with the problem of extending a continuous realvalued function that is defined on a subspace of a space $X$ to a continuous function defined on all of $X$. This theorem is important in many of the applications of topology.

Theorem 35.1 (Tietze extension theorem). Let $X$ be a normal space; let $A$ be a closed subspace of $X$.

(a) Any continuous map of $A$ into the closed interval $[a, b]$ of $\mathbb{R}$ may be extended to a continuous map of all of $X$ into $[a, b]$.

(b) Any continuous map of $A$ into $\mathbb{R}$ may be extended to a continuous map of all of $X$ into $\mathbb{R}$.

Proof. The idea of the proof is to construct a sequence of continuous functions $s_{n}$ defined on the entire space $X$, such that the sequence $s_{n}$ converges uniformly, and such that the restriction of $s_{n}$ to $A$ approximates $f$ more and more closely as $n$ becomes large. Then the limit function will be continuous, and its restriction to $A$ will equal $f$.

Step 1. The first step is to construct a particular function $g$ defined on all of $X$ such that $g$ is not too large, and such that $g$ approximates $f$ on the set $A$ to a fair degree of accuracy. To be more precise, let us take the case $f: A \rightarrow[-r, r]$. We assert that there exists a continuous function $g: X \rightarrow \mathbb{R}$ such that

$$
\begin{array}{rlrl}
|g(x)| & \leq \frac{1}{3} r & \text { for all } x \in X \\
|g(a)-f(a)| & \leq \frac{2}{3} r & & \text { for all } a \in A .
\end{array}
$$

The function $g$ is constructed as follows:

Divide the interval $[r, r]$ into three equal intervals of length $\frac{2}{3} r$ :

$$
I_{1}=\left[-r,-\frac{1}{3} r\right], \quad I_{2}=\left[-\frac{1}{3} r, \frac{1}{3} r\right], \quad I_{3}=\left[\frac{1}{3} r, r\right] .
$$

Let $B$ and $C$ be the subsets

$$
B=f^{-1}\left(I_{1}\right) \quad \text { and } \quad C=f^{-1}\left(I_{3}\right)
$$

of $A$. Because $f$ is continuous, $B$ and $C$ are closed disjoint subsets of $A$. Therefore, they are closed in $X$. By the Urysohn lemma, there exists a continuous function

$$
g: X \longrightarrow\left[-\frac{1}{3} r, \frac{1}{3} r\right]
$$

having the property that $g(x)=-\frac{1}{3} r$ for each $x$ in $B$, and $g(x)=\frac{1}{3} r$ for each $x$ in $C$.

Then $|g(x)| \leq \frac{1}{3} r$ for all $x$. We assert that for each $a$ in $A$,

$$
|g(a)-f(a)| \leq \frac{2}{3} r .
$$[^8]

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-221.jpg?height=985&width=1030&top_left_y=368&top_left_x=684)

Figure 35.1

There are three cases. If $a \in B$, then both $f(a)$ and $g(a)$ belong to $I_{1}$. If $a \in C$, then $f(a)$ and $g(a)$ are in $I_{3}$. And if $a \notin B \cup C$, then $f(a)$ and $g(a)$ are in $I_{2}$. In each case, $|g(a)-f(a)| \leq \frac{2}{3} r$. See Figure 35.1.

Step 2. We now prove part (a) of the Tietze theorem. Without loss of generality, we can replace the arbitrary closed interval $[a, b]$ of $\mathbb{R}$ by the interval $[-1,1]$.

Let $f: X \rightarrow[-1,1]$ be a continuous map. Then $f$ satisfies the hypotheses of Step 1, with $r=1$. Therefore, there exists a continuous real-valued function $g_{1}$, defined on all of $X$, such that

$$
\begin{array}{rlrl}
\left|g_{1}(x)\right| & \leq 1 / 3 & & \text { for } x \in X \\
\left|f(a)-g_{1}(a)\right| \leq 2 / 3 & & \text { for } a \in A .
\end{array}
$$

Now consider the function $f-g_{1}$. This function maps $A$ into the interval $[-2 / 3,2 / 3]$, so we can apply Step 1 again, letting $r=2 / 3$. We obtain a real-valued function $g_{2}$
defined on all of $X$ such that

$$
\begin{aligned}
\left|g_{2}(x)\right| & \leq \frac{1}{3}\left(\frac{2}{3}\right) \quad \text { for } x \in X, \\
\left|f(a)-g_{1}(a)-g_{2}(a)\right| & \leq\left(\frac{2}{3}\right)^{2} \quad \text { for } a \in A .
\end{aligned}
$$

Then we apply Step 1 to the function $f-g_{1}-g_{2}$. And so on.

At the general step, we have real-valued functions $g_{1}, \ldots, g_{n}$ defined on all of $X$ such that

$$
\left|f(a)-g_{1}(a)-\cdots-g_{n}(a)\right| \leq\left(\frac{2}{3}\right)^{n}
$$

for $a \in A$. Applying Step 1 to the function $f-g_{1}-\cdots-g_{n}$, with $r=\left(\frac{2}{3}\right)^{n}$, we obtain a real-valued function $g_{n+1}$ defined on all of $X$ such that

$$
\begin{aligned}
\left|g_{n+1}(x)\right| & \leq \frac{1}{3}\left(\frac{2}{3}\right)^{n} \quad \text { for } x \in X, \\
\left|f(a)-g_{1}(a)-\cdots-g_{n+1}(a)\right| & \leq\left(\frac{2}{3}\right)^{n+1} \quad \text { for } a \in A .
\end{aligned}
$$

By induction, the functions $g_{n}$ are defined for all $n$.

We now define

$$
g(x)=\sum_{n=1}^{\infty} g_{n}(x)
$$

for all $x$ in $X$. Of course, we have to know that this infinite series converges. But that follows from the comparison theorem of calculus; it converges by comparison with the geometric series

$$
\frac{1}{3} \sum_{n=1}^{\infty}\left(\frac{2}{3}\right)^{n-1}
$$

To show that $g$ is continuous, we must show that the sequence $s_{n}$ converges to $g$ uniformly. This fact follows at once from the "Weierstrass $M$-test" of analysis. Without assuming this result, one can simply note that if $k>n$, then

$$
\begin{aligned}
\left|s_{k}(x)-s_{n}(x)\right| & =\left|\sum_{i=n+1}^{k} g_{i}(x)\right| \\
& \leq \frac{1}{3} \sum_{i=n+1}^{k}\left(\frac{2}{3}\right)^{i-1} \\
& <\frac{1}{3} \sum_{i=n+1}^{\infty}\left(\frac{2}{3}\right)^{i-1}=\left(\frac{2}{3}\right)^{n} .
\end{aligned}
$$

Holding $n$ fixed and letting $k \rightarrow \infty$, we see that

$$
\left|g(x)-s_{n}(x)\right| \leq\left(\frac{2}{3}\right)^{n}
$$

for all $x \in X$. Therefore, $s_{n}$ converges to $g$ uniformly.

We show that $g(a)=f(a)$ for $a \in A$. Let $s_{n}(x)=\sum_{i=1}^{n} g_{i}(x)$, the $n$th partial sum of the series. Then $g(x)$ is by definition the limit of the infinite sequence $s_{n}(x)$ of partial sums. Since

$$
\left|f(a)-\sum_{i=1}^{n} g_{i}(a)\right|=\left|f(a)-s_{n}(a)\right| \leq\left(\frac{2}{3}\right)^{n}
$$

for all $a$ in $A$, it follows that $s_{n}(a) \rightarrow f(a)$ for all $a \in A$. Therefore, we have $f(a)=g(a)$ for $a \in A$.

Finally, we show that $g$ maps $X$ into the interval $[-1,1]$. This condition is in fact satisfied automatically, since the series $(1 / 3) \sum(2 / 3)^{n}$ converges to 1 . However, this is just a lucky accident rather than an essential part of the proof. If all we knew was that $g$ mapped $X$ into $\mathbb{R}$, then the map $r \circ g$, where $r: \mathbb{R} \rightarrow[-1,1]$ is the map

$$
\begin{array}{ll}
r(y)=y & \text { if }|y| \leq 1, \\
r(y)=y /|y| & \text { if }|y| \geq 1,
\end{array}
$$

would be an extension of $f$ mapping $X$ into $[-1,1]$.

Step 3. We now prove part (b) of the theorem, in which $f$ maps $A$ into $\mathbb{R}$. We can replace $\mathbb{R}$ by the open interval $(-1,1)$, since this interval is homeomorphic to $\mathbb{R}$.

So let $f$ be a continuous map from $A$ into $(-1,1)$. The half of the Tietze theorem already proved shows that we can extend $f$ to a continuous map $g: X \rightarrow[-1,1]$ mapping $X$ into the closed interval. How can we find a map $h$ carrying $X$ into the open interval?

Given $g$, let us define a subset $D$ of $X$ by the equation

$$
D=g^{-1}(\{-1\}) \cup g^{-1}(\{1\}) .
$$

Since $g$ is continuous, $D$ is a closed subset of $X$. Because $g(A)=f(A)$, which is contained in $(-1,1)$, the set $A$ is disjoint from $D$. By the Urysohn lemma, there is a continuous function $\phi: X \rightarrow[0,1]$ such that $\phi(D)=\{0\}$ and $\phi(A)=\{1\}$. Define

$$
h(x)=\phi(x) g(x) .
$$

Then $h$ is continuous, being the product of two continuous functions. Also, $h$ is an extension of $f$, since for $a$ in $A$,

$$
h(a)=\phi(a) g(a)=1 \cdot g(a)=f(a) .
$$

Finally, $h$ maps all of $X$ into the open interval $(-1,1)$. For if $x \in D$, then $h(x)=$ $0 \cdot g(x)=0$. And if $x \notin D$, then $|g(x)|<1$; it follows that $|h(x)| \leq 1 \cdot|g(x)|<1$.

## Exercises

1. Show that the Tietze extension theorem implies the Urysohn lemma.
2. In the proof of the Tietze theorem, how essential was the clever decision in Step 1 to divide the interval $[-r, r]$ into three equal pieces? Suppose instead that one divides this interval into the three intervals

$$
I_{1}=[-r,-a r], \quad I_{2}=[-a r, a r], \quad I_{3}=[a r, r],
$$

for some $a$ with $0<a<1$. For what values of $a$ other than $a=1 / 3$ (if any) does the proof go through?

3. Let $X$ be metrizable. Show that the following are equivalent:

(i) $X$ is bounded under every metric that gives the topology of $X$.

(ii) Every continuous function $\phi: X \rightarrow \mathbb{R}$ is bounded.

(iii) $X$ is limit point compact.

[Hint: If $\phi: X \rightarrow \mathbb{R}$ is a continuous function, then $F(x)=x \times \phi(x)$ is an imbedding of $X$ in $X \times \mathbb{R}$. If $A$ is an infinite subset of $X$ having no limit point, let $\phi$ be a surjection of $A$ onto $\mathbb{Z}_{+}$.]

4. Let $Z$ be a topological space. If $Y$ is a subspace of $Z$, we say that $Y$ is a retract of $Z$ if there is a continuous map $r: Z \rightarrow Y$ such that $r(y)=y$ for each $y \in Y$.

(a) Show that if $Z$ is Hausdorff and $Y$ is a retract of $Z$, then $Y$ is closed in $Z$.

(b) Let $A$ be a two-point set in $\mathbb{R}^{2}$. Show that $A$ is not a retract of $\mathbb{R}^{2}$.

(c) Let $S^{1}$ be the unit circle in $\mathbb{R}^{2}$; show that $S^{1}$ is a retract of $\mathbb{R}^{2}-\{\mathbf{0}\}$, where $\mathbf{0}$ is the origin. Can you conjecture whether or not $S^{1}$ is a retract of $\mathbb{R}^{2}$ ?

5. A space $Y$ is said to have the universal extension property if for each triple consisting of a normal space $X$, a closed subset $A$ of $X$, and a continuous function $f: A \rightarrow Y$, there exists an extension of $f$ to a continuous map of $X$ into $Y$.

(a) Show that $\mathbb{R}^{J}$ has the universal extension property.

(b) Show that if $Y$ is homeomorphic to a retract of $\mathbb{R}^{J}$, then $Y$ has the universal extension property.

6. Let $Y$ be a normal space. Then $Y$ is said to be an absolute retract if for every pair of spaces $\left(Y_{0}, Z\right)$ such that $Z$ is normal and $Y_{0}$ is a closed subspace of $Z$ homeomorphic to $Y$, the space $Y_{0}$ is a retract of $Z$.

(a) Show that if $Y$ has the universal extension property, then $Y$ is an absolute retract.

(b) Show that if $Y$ is an absolute retract and $Y$ is compact, then $Y$ has the universal extension property. [Hint: Assume the Tychonoff theorem, so you know $[0,1]^{J}$ is normal. Imbed $Y$ in $[0,1]^{J}$.]

7. (a) Show the logarithmic spiral

$$
C=\{0 \times 0\} \cup\left\{e^{t} \cos t \times e^{t} \sin t \mid t \in \mathbb{R}\right\}
$$

is a retract of $\mathbb{R}^{2}$. Can you define a specific retraction $r: \mathbb{R}^{2} \rightarrow C$ ?
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-225.jpg?height=340&width=902&top_left_y=368&top_left_x=744)

Figure 35.2

(b) Show that the "knotted x-axis" $K$ of Figure 35.2 is a retract of $\mathbb{R}^{3}$.

*8. Prove the following:

Theorem. Let $Y$ be a normal space. Then $Y$ is an absolute retract if and only if $Y$ has the universal extension property.

[Hint: If $X$ and $Y$ are disjoint normal spaces, $A$ is closed in $X$, and $f: A \rightarrow Y$ is a continuous map, define the adjunction space $Z_{f}$ to be the quotient space obtained from $X \cup Y$ by identifying each point $a$ of $A$ with the point $f(a)$ and with all the points of $f^{-1}(\{f(a)\})$. Using the Tietze theorem, show that $Z_{f}$ is normal. If $p: X \cup Y \rightarrow Z_{f}$ is the quotient map, show that $p \mid Y$ is a homeomorphism of $Y$ with a closed subspace of $Z_{f}$.]

9. Let $X_{1} \subset X_{2} \subset \cdots$ be a sequence of spaces, where $X_{i}$ is a closed subspace of $X_{i+1}$ for each $i$. Let $X$ be the union of the $X_{i}$; let us topologize $X$ by declaring a set $U$ to be open in $X$ if $U \cap X_{i}$ is open in $X$ for each $i$.

(a) Show that this is a topology on $X$ and that each space $X_{i}$ is a subspace (in fact, a closed subspace) of $X$ in this topology. This topology is called the topology coherent with the subspaces $X_{i}$.

(b) Show that $f: X \rightarrow Y$ is continuous if $f \mid X_{i}$ is continuous for each $i$.

(c) Show that if each space $X_{i}$ is normal, then $X$ is normal. [Hint: Given disjoint closed sets $A$ and $B$ in $X$, set $f$ equal to 0 on $A$ and 1 on $B$, and extend $f$ successively to $A \cup B \cup X_{i}$ for $i=1,2, \ldots$ ]

## *§36 Imbeddings of Manifolds ${ }^{\dagger}$

We have shown that every regular space with a countable basis can be imbedded in the "infinite-dimensional" euclidean space $\mathbb{R}^{\omega}$. It is natural to ask under what conditions a space $X$ can be imbedded in some finite-dimensional euclidean space $\mathbb{R}^{N}$. One answer to this question is given in this section. A more general answer will be obtained in Chapter 8, when we study dimension theory.[^9]

Definition. An $\boldsymbol{m}$-manifold is a Hausdorff space $X$ with a countable basis such that each point $x$ of $X$ has a neighborhood that is homeomorphic with an open subset of $\mathbb{R}^{m}$.

A 1-manifold is often called a curve, and a 2-manifold is called a surface. Manifolds form a very important class of spaces; they are much studied in differential geometry and algebraic topology.

We shall prove that if $X$ is a compact manifold, then $X$ can be imbedded in a finitedimensional euclidean space. The theorem holds without the assumption of compactness, but the proof is a good deal harder.

First, we need some terminology.

If $\phi: X \rightarrow \mathbb{R}$, then the support of $\phi$ is defined to be the closure of the set $\phi^{-1}(\mathbb{R}-\{0\})$. Thus if $x$ lies outside the support of $\phi$, there is some neighborhood of $x$ on which $\phi$ vanishes.

Definition. Let $\left\{U_{1}, \ldots, U_{n}\right\}$ be a finite indexed open covering of the space $X$. An indexed family of continuous functions

$$
\phi_{i}: X \longrightarrow[0,1] \text { for } i=1, \ldots, n \text {, }
$$

is said to be a partition of unity dominated by $\left\{U_{i}\right\}$ if:

(1) (support $\left.\phi_{i}\right) \subset U_{i}$ for each $i$.

(2) $\sum_{i=1}^{n} \phi_{i}(x)=1$ for each $x$.

Theorem 36.1 (Existence of finite partitions of unity). Let $\left\{U_{1}, \ldots, U_{n}\right\}$ be a finite open covering of the normal space $X$. Then there exists a partition of unity dominated by $\left\{U_{i}\right\}$.

Proof. Step 1. First, we prove that one can "shrink" the covering $\left\{U_{i}\right\}$ to an open covering $\left\{V_{1}, \ldots, V_{n}\right\}$ of $X$ such that $\bar{V}_{i} \subset U_{i}$ for each $i$.

We proceed by induction. First, note that the set

$$
A=X-\left(U_{2} \cup \cdots \cup U_{n}\right)
$$

is a closed subset of $X$. Because $\left\{U_{1}, \ldots, U_{n}\right\}$ covers $X$, the set $A$ is contained in the open set $U_{1}$. Using normality, choose an open set $V_{1}$ containing $A$ such that $\bar{V}_{1} \subset U_{1}$. Then the collection $\left\{V_{1}, U_{2}, \ldots, U_{n}\right\}$ covers $X$.

In general, given open sets $V_{1}, \ldots, V_{k-1}$ such that the collection

$$
\left\{V_{1}, \ldots, V_{k-1}, U_{k}, U_{k+1}, \ldots, U_{n}\right\}
$$

covers $X$, let

$$
A=X-\left(V_{1} \cup \cdots \cup V_{k-1}\right)-\left(U_{k+1} \cup \cdots \cup U_{n}\right) .
$$

Then $A$ is a closed subset of $X$ which is contained in the open set $U_{k}$. Choose $V_{k}$ to be an open set containing $A$ such that $\bar{V}_{k} \subset U_{k}$. Then $\left\{V_{1}, \ldots, V_{k-1}, V_{k}, U_{k+1}, \ldots, U_{n}\right\}$ covers $X$. At the $n$th step of the induction, our result is proved.

Step 2. Now we prove the theorem. Given the open covering $\left\{U_{1}, \ldots, U_{n}\right\}$ of $X$, choose an open covering $\left\{V_{1}, \ldots, V_{n}\right\}$ of $X$ such that $\bar{V}_{i} \subset U_{i}$ for each $i$. Then choose an open covering $\left\{W_{1}, \ldots, W_{n}\right\}$ of $X$ such that $\bar{W}_{i} \subset V_{i}$ for each $i$. Using the Urysohn lemma, choose for each $i$ a continuous function

$$
\psi_{i}: X \longrightarrow[0,1]
$$

such that $\psi_{i}\left(\bar{W}_{i}\right)=\{1\}$ and $\psi_{i}\left(X-V_{i}\right)=\{0\}$. Since $\psi_{i}^{-1}(R-\{0\})$ is contained in $V_{i}$, we have

$$
\text { (support } \left.\psi_{i}\right) \subset \bar{V}_{i} \subset U_{i} \text {. }
$$

Because the collection $\left\{W_{i}\right\}$ covers $X$, the sum $\Psi(x)=\sum_{i=1}^{n} \psi_{i}(x)$ is positive for each $x$. Therefore, we may define, for each $j$,

$$
\phi_{j}(x)=\frac{\psi_{j}(x)}{\Psi(x)}
$$

It is easy to check that the functions $\phi_{1}, \ldots, \phi_{n}$ form the desired partition of unity.

There is a comparable notion of partition of unity when the open covering and the collection of functions are not finite, nor even countable. We shall consider this matter in Chapter 6, when we study paracompactness.

Theorem 36.2. If $X$ is a compact $m$-manifold, then $X$ can be imbedded in $\mathbb{R}^{N}$ for some positive integer $N$.

Proof. Cover $X$ by finitely many open sets $\left\{U_{1}, \ldots, U_{n}\right\}$, each of which may be imbedded in $\mathbb{R}^{m}$. Choose imbeddings $g_{i}: U_{i} \rightarrow \mathbb{R}^{m}$ for each $i$. Being compact and Hausdorff, $X$ is normal. Let $\phi_{1}, \ldots, \phi_{n}$ be a partition of unity dominated by $\left\{U_{i}\right\}$; let $A_{i}=$ support $\phi_{i}$. For each $i=1, \ldots, n$, define a function $h_{i}: X \rightarrow \mathbb{R}^{m}$ by the rule

$$
h_{i}(x)= \begin{cases}\phi_{i}(x) \cdot g_{i}(x) & \text { for } x \in U_{i} \\ \mathbf{0}=(0, \ldots, 0) & \text { for } x \in X-A_{i}\end{cases}
$$

[Here $\phi_{i}(x)$ is a real number $c$ and $g_{i}(x)$ is a point $\mathbf{y}=\left(y_{1}, \ldots, y_{m}\right)$ of $\mathbb{R}^{m}$; the product $c \cdot \mathbf{y}$ denotes of course the point $\left(c y_{1}, \ldots, c y_{m}\right)$ of $\mathbb{R}^{m}$.] The function $h_{i}$ is well defined because the two definitions of $h_{i}$ agree on the intersection of their domains, and $h_{i}$ is continuous because its restrictions to the open sets $U_{i}$ and $X-A_{i}$ are continuous.

Now define

$$
F: X \longrightarrow(\underbrace{\mathbb{R} \times \cdots \times \mathbb{R}}_{n \text { times }} \times \underbrace{\mathbb{R}^{m} \times \cdots \times \mathbb{R}^{m}}_{n \text { times }})
$$

by the rule

$$
F(x)=\left(\phi_{1}(x), \ldots, \phi_{n}(x), h_{1}(x), \ldots, h_{n}(x)\right) .
$$

Clearly, $F$ is continuous. To prove that $F$ is an imbedding we need only to show that $F$ is injective (because $X$ is compact). Suppose that $F(x)=F(y)$. Then $\phi_{i}(x)=$ $\phi_{i}(y)$ and $h_{i}(x)=h_{i}(y)$ for all $i$. Now $\phi_{i}(x)>0$ for some $i$ [since $\sum \phi_{i}(x)=1$ ]. Therefore, $\phi_{i}(y)>0$ also, so that $x, y \in U_{i}$. Then

$$
\phi_{i}(x) \cdot g_{i}(x)=h_{i}(x)=h_{i}(y)=\phi_{i}(y) \cdot g_{i}(y) .
$$

Because $\phi_{i}(x)=\phi_{i}(y)>0$, we conclude that $g_{i}(x)=g_{i}(y)$. But $g_{i}: U_{i} \rightarrow \mathbb{R}^{m}$ is injective, so that $x=y$, as desired.

In many applications of partitions of unity, such as the one just given, all one needs to know is that the sum $\sum \phi_{i}(x)$ is positive for each $x$. In others, however, one needs the stronger condition that that $\sum \phi_{i}(x)=1$. See $\S 50$.

## Exercises

1. Prove that every manifold is regular and hence metrizable. Where do you use the Hausdorff condition?
2. Let $X$ be a compact Hausdorff space. Suppose that for each $x \in X$, there is a neighborhood $U$ of $x$ and a positive integer $k$ such that $U$ can be imbedded in $\mathbb{R}^{k}$. Show that $X$ can be imbedded in $\mathbb{R}^{N}$ for some positive integer $N$.
3. Let $X$ be a Hausdorff space such that each point of $X$ has a neighborhood that is homeomorphic with an open subset of $\mathbb{R}^{m}$. Show that if $X$ is compact, then $X$ is an $m$-manifold.
4. An indexed family $\left\{A_{\alpha}\right\}$ of subsets of $X$ is said to be a point-finite indexed family if each $x \in X$ belongs to $A_{\alpha}$ for only finitely many values of $\alpha$.

Lemma (The shrinking lemma). Let $X$ be a normal space; let $\left\{U_{1}, U_{2}, \ldots\right\}$ be a point-finite indexed open covering of $X$. Then there exists an indexed open covering $\left\{V_{1}, V_{2}, \ldots\right\}$ of $X$ such that $\bar{V}_{n} \subset U_{n}$ for each $n$.

5. The Hausdorff condition is an essential part of the definition of a manifold; it is not implied by the other parts of the definition. Consider the following space: Let $X$ be the union of the set $\mathbb{R}-\{0\}$ and the two-point set $\{p, q\}$. Topologize $X$ by taking as basis the collection of all open intervals in $\mathbb{R}$ that do not contain 0 , along with all sets of the form $(-a, 0) \cup\{p\} \cup(0, a)$ and all sets of the form $(-a, 0) \cup\{q\} \cup(0, a)$, for $a>0$. The space $X$ is called the line with two origins.

(a) Check that this is a basis for a topology.

(b) Show that each of the spaces $X-\{p\}$ and $X-\{q\}$ is homeomorphic to $\mathbb{R}$.

(c) Show that $X$ satisfies the $T_{1}$ axiom, but is not Hausdorff.

(d) Show that $X$ satisfies all the conditions for a 1-manifold except for the Hausdorff condition.

## *Supplementary Exercises: Review of the Basics

Consider the following properties a space may satisfy:

(1) connected

(2) path connected

(3) locally connected

(4) locally path connected

(5) compact

(6) limit point compact

(7) locally compact Hausdorff

(8) Hausdorff

(9) regular

(10) completely regular

(11) normal

(12) first-countable

(13) second-countable

(14) Lindelöf

(15) has a countable dense subset

(16) locally metrizable

(17) metrizable

1. For each of the following spaces, determine (if you can) which of these properties it satisfies. (Assume the Tychonoff theorem if you need it.)

(a) $S_{\Omega}$

(b) $\bar{S}_{\Omega}$

(c) $S_{\Omega} \times \bar{S}_{\Omega}$

(d) The ordered square

(e) $\mathbb{R}_{\ell}$

(f) $\mathbb{R}_{\ell}^{2}$

(g) $\mathbb{R}^{\omega}$ in the product topology

(h) $\mathbb{R}^{\omega}$ in the uniform topology

(i) $\mathbb{R}^{\omega}$ in the box topology

(j) $\mathbb{R}^{I}$ in the product topology, where $I=[0,1]$

(k) $\mathbb{R}_{K}$

2. Which of these properties does a metric space necessarily have?
3. Which of these properties does a compact Hausdorff space have?
4. Which of these properties are preserved when one passes to a subspace? To a closed subspace? To an open subspace?
5. Which of these properties are preserved under finite products? Countable products? Arbitrary products?
6. Which of these properties are preserved by continuous maps?
7. After studying Chapters 6 and 7, repeat Exercises 1-6 for the following properties:

(18) paracompact

(19) topologically complete

You should be able to answer all but one of the 340 questions involved in Exercises 1-6, and all but one of the 40 questions involved in Exercise 7. These two are unsolved; see the remark in Exercise 5 of $\$ 32$.

## Chapter 5

## The Tychonoff Theorem

We now return to a problem we left unresolved in Chapter 3. We shall prove the Tychonoff theorem, to the effect that arbitrary products of compact spaces are compact. The proof makes use of Zorn's Lemma (see §11). An alternate proof, which relies instead on the well-ordering theorem, is outlined in the exercises.

The Tychonoff theorem is of great usefulness to analysts (less so to geometers). We apply it in $\S 38$ to construct the Stone-Čech compactification of a completely regular space, and in $\S 47$ in proving the general version of Ascoli's theorem.

## §37 The Tychonoff Theorem

Like the Urysohn lemma, the Tychonoff theorem is what we call a "deep" theorem. Its proof involves not one but several original ideas; it is anything but straightforward. We shall discuss the crucial ideas of the proof in some detail before turning to the proof itself.

In Chapter 3, we proved the product $X \times Y$ of two compact spaces to be compact. For that proof the open covering formulation of compactness was quite satisfactory. Given an open covering of $X \times Y$ by basis elements, we covered each slice $x \times Y$ by finitely many of them, and proceeded from that to construct a finite covering of $X \times Y$.

It is quite tricky to make this approach work for an arbitrary product of compact spaces; one must well-order the index set and use transfinite induction. (See

Exercise 5.) An alternate approach is to abandon open coverings and to approach the problem by applying the closed set formulation of compactness, using Zorn's lemma.

To see how this idea might work, let us consider first the simplest possible case: the product of two compact spaces $X_{1} \times X_{2}$. Suppose that $\mathcal{A}$ is a collection of closed subsets of $X_{1} \times X_{2}$ that has the finite intersection property. Consider the projection map $\pi_{1}: X_{1} \times X_{2} \rightarrow X_{1}$. The collection

$$
\left\{\pi_{1}(A) \mid A \in \mathcal{A}\right\}
$$

of subsets of $X_{1}$ also has the finite intersection property, and so does the collection of

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-232.jpg?height=58&width=1251&top_left_y=759&top_left_x=396)
$\overline{\pi_{1}(A)}$ is nonempty. Let us choose a point $x_{1}$ belonging to this intersection. Similarly, let us choose a point $x_{2}$ belonging to all the sets $\overline{\pi_{2}(A)}$. The obvious conclusion we would like to draw is that the point $x_{1} \times x_{2}$ lies in $\bigcap_{A \in \mathcal{A}} A$, for then our theorem would be proved.

But that is unfortunately not true. Consider the following example, in which $X_{1}=$ $X_{2}=[0,1]$ and the collection $\mathcal{A}$ consists of all closed elliptical regions bounded by ellipses that have the points $p=\left(\frac{1}{3}, \frac{1}{3}\right)$ and $q=\left(\frac{1}{2}, \frac{2}{3}\right)$ as their foci. See Figure 37.1. Certainly $\mathcal{A}$ has the finite intersection property. Now let us pick a point $x_{1}$ in the intersection of the sets $\left\{\overline{\pi_{1}(A)} \mid A \in \mathcal{A}\right\}$. Any point of the interval $\left[\frac{1}{3}, \frac{1}{2}\right]$ will do; suppose we choose $x_{1}=\frac{1}{2}$. Similarly, choose a point $x_{2}$ in the intersection of the sets $\left\{\overline{\pi_{2}(A)} \mid A \in \mathcal{A}\right\}$. Any point of the interval $\left[\frac{1}{3}, \frac{2}{3}\right]$ will do; suppose we pick $x_{2}=\frac{1}{2}$. This proves to be an unfortunate choice, for the point

$$
x_{1} \times x_{2}=\frac{1}{2} \times \frac{1}{2}
$$

does not lie in the intersection of the sets $A$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-232.jpg?height=575&width=577&top_left_y=1497&top_left_x=733)

Figure 37.1

"Aha!" you say, "you made a bad choice. If after choosing $x_{1}=\frac{1}{2}$ you had chosen $x_{2}=\frac{2}{3}$, then you would have found a point in $\bigcap_{A \in \mathcal{A}} A$." The difficulty with our
tentative proof is that it gave us too much freedom in picking $x_{1}$ and $x_{2}$; it allowed us to make a "bad" choice instead of a "good" choice.

How can we alter the proof so as to avoid this difficulty?

This question leads to the second idea of the proof: Perhaps if we expand the collection $\mathcal{A}$ (retaining the finite intersection property, of course), that expansion will restrict the choices of $x_{1}$ and $x_{2}$ sufficiently that we will be forced to make the "right" choice. To illustrate, suppose that in the previous example we expand the collection $\mathcal{A}$ to the collection $\mathcal{D}$ consisting of all closed elliptical regions bounded by ellipses that have $p=\left(\frac{1}{3}, \frac{1}{3}\right)$ as one focus and any point of the line segment $p q$ as the other focus. This collection is illustrated in Figure 37.2. The new collection $\mathcal{D}$ still has the finite intersection property. But if you try to choose a point $x_{1}$ in

$$
\bigcap_{D \in \mathscr{D}} \overline{\pi_{1}(D)}
$$

the only possible choice for $x_{1}$ is $\frac{1}{3}$. Similarly, the only possible choice for $x_{2}$ is $\frac{1}{3}$. And $\frac{1}{3} \times \frac{1}{3}$ does belong to every set $D$, and hence to every set $A$. In other words, expanding the collection $\mathcal{A}$ to the collection $\mathcal{D}$ forces the proper choice on us.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-233.jpg?height=569&width=547&top_left_y=1170&top_left_x=920)

Figure 37.2

Now of course in this example we chose $\mathscr{D}$ carefully so that the proof would work. What hope can we have for choosing $\mathcal{D}$ correctly in general? Here is the third idea of the proof: Why not simply choose $\mathscr{D}$ to be a collection that is "as large as possible"so that no larger collection has the finite intersection property-and see whether such a $\mathscr{D}$ will work? It is not at all obvious that such a collection $\mathscr{D}$ exists; to prove it, we must appeal to Zorn's lemma. But after we prove that $\mathscr{D}$ exists, we shall in fact be able to show that $\mathcal{D}$ is large enough to force the proper choices on us.

A final remark. The assumption that the elements of the collection $\mathcal{A}$ were closed sets was irrelevant in this discussion. For even if the set $A \in \mathcal{A}$ is closed, the set $\pi_{1}(A)$ need not be closed, so we had to take its closure in order to apply the closed set formu-
lation of compactness. Therefore, we may as well begin with an arbitrary collection of subsets of $X$ having the finite intersection property, and prove that the intersection of their closures is nonempty. This approach actually proves to be more convenient.

Lemma 37.1. Let $X$ be a set; let $\mathcal{A}$ be a collection of subsets of $X$ having the finite intersection property. Then there is a collection $\mathbb{D}$ of subsets of $X$ such that $\mathbb{D}$ contains $\mathcal{A}$, and $\mathscr{D}$ has the finite intersection property, and no collection of subsets of $X$ that properly contains $\mathscr{D}$ has this property.

We often say that a collection $\mathscr{D}$ satisfying the conclusion of this theorem is maximal with respect to the finite intersection property.

Proof. As you might expect, we construct $\mathscr{D}$ by using Zorn's lemma. It states that, given a set $A$ that is strictly partially ordered, in which every simply ordered subset has an upper bound, $A$ itself has a maximal element.

The set $A$ to which we shall apply Zorn's lemma is not a subset of $X$, nor even a collection of subsets of $X$, but a set whose elements are collections of subsets of $X$. For purposes of this proof, we shall call a set whose elements are collections of subsets of $X$ a "superset" and shall denote it by an outline letter. To summarize the notation:

$c$ is an element of $X$.

$C$ is a subset of $X$.

$C$ is a collection of subsets of $X$.

$\mathbb{C}$ is a superset whose elements are collections of subsets of $X$.

Now by hypothesis, we have a collection $\mathcal{A}$ of subsets of $X$ that has the finite intersection property. Let $\mathbb{A}$ denote the superset consisting of all collections $\mathscr{B}$ of subsets of $X$ such that $\mathscr{B} \supset \mathcal{A}$ and $\mathscr{B}$ has the finite intersection property. We use proper inclusion $\varsubsetneqq$ as our strict partial order on $\mathbb{A}$. To prove our lemma, we need to show that $\mathbb{A}$ has a maximal element $\mathscr{D}$.

In order to apply Zorn's lemma, we must show that if $\mathbb{B}$ is a "subsuperset" of $\mathbb{A}$ that is simply ordered by proper inclusion, then $\mathbb{B}$ has an upper bound in $\mathbb{A}$. We shall show in fact that the collection

$$
\mathcal{C}=\bigcup_{\mathcal{B} \in \mathbb{B}} \mathcal{B},
$$

which is the union of the collections belonging to $\mathbb{B}$, is an element of $\mathbb{A}$; then it is the required upper bound on $\mathbb{B}$.

To show that $\mathcal{C}$ is an element of $\mathbb{A}$, we must show that $\mathcal{C} \supset \mathcal{A}$ and that $\mathcal{C}$ has the finite intersection property. Certainly $\mathcal{C}$ contains $\mathcal{A}$, since each element of $\mathbb{B}$ contains $\mathcal{A}$. To show that $\mathcal{C}$ has the finite intersection property, let $C_{1}, \ldots, C_{n}$ be elements of $\mathcal{C}$. Because $\mathcal{C}$ is the union of the elements of $\mathbb{B}$, there is, for each $i$, an element $\mathscr{B}_{i}$ of $\mathbb{B}$ such that $C_{i} \in \mathscr{B}_{i}$. The superset $\left\{\mathscr{B}_{1}, \ldots, \mathscr{B}_{n}\right\}$ is contained in $\mathbb{B}$, so it is simply ordered by the relation of proper inclusion. Being finite, it has a largest element; that is, there is an index $k$ such that $\mathscr{B}_{i} \subset \mathscr{B}_{k}$ for $i=1, \ldots, n$. Then all the sets $C_{1}, \ldots, C_{n}$ are elements of $\mathscr{B}_{k}$. Since $\mathscr{B}_{k}$ has the finite intersection property, the intersection of the sets $C_{1}, \ldots, C_{n}$ is nonempty, as desired.

Lemma 37.2. Let $X$ be a set; let $\mathcal{D}$ be a collection of subsets of $X$ that is maximal with respect to the finite intersection property. Then:

(a) Any finite intersection of elements of $\mathcal{D}$ is an element of $\mathcal{D}$.

(b) If $A$ is a subset of $X$ that intersects every element of $\mathcal{D}$, then $A$ is an element of $\mathcal{D}$.

Proof. (a) Let $B$ equal the intersection of finitely many elements of $\mathcal{D}$. Define a collection $\mathcal{E}$ by adjoining $B$ to $\mathcal{D}$, so that $\mathcal{E}=\mathcal{D} \cup\{B\}$. We show that $\mathcal{E}$ has the finite intersection property; then maximality of $\mathcal{D}$ implies that $\mathcal{E}=\mathcal{D}$, so that $B \in \mathcal{D}$ as desired.

Take finitely many elements of $\mathcal{E}$. If none of them is the set $B$, then their intersection is nonempty because $\mathscr{D}$ has the finite intersection property. If one of them is the set $B$, then their intersection is of the form

$$
D_{1} \cap \cdots \cap D_{m} \cap B .
$$

Since $B$ equals a finite intersection of elements of $\mathcal{D}$, this set is nonempty.

(b) Given $A$, define $\varepsilon=D \cup\{A\}$. We show that $\mathscr{E}$ has the finite intersection property, from which we conclude that $A$ belongs to $\mathcal{D}$. Take finitely many elements of $\mathcal{E}$. If none of them is the set $A$, their intersection is automatically nonempty. Otherwise, it is of the form

$$
D_{1} \cap \cdots \cap D_{n} \cap A
$$

Now $D_{1} \cap \cdots \cap D_{n}$ belongs to $\mathcal{D}$, by (a); therefore, this intersection is nonempty, by hypothesis.

Theorem 37.3 (Tychonoff theorem). An arbitrary product of compact spaces is compact in the product topology.

Proof. Let

$$
X=\prod_{\alpha \in J} X_{\alpha}
$$

where each space $X_{\alpha}$ is compact. Let $\mathcal{A}$ be a collection of subsets of $X$ having the finite intersection property. We prove that the intersection

$$
\bigcap_{A \in \mathcal{A}} \bar{A}
$$

is nonempty. Compactness of $X$ follows.

Applying Lemma 37.1, choose a collection $\mathscr{D}$ of subsets of $X$ such that $\mathscr{D} \supset \mathcal{A}$ and $\mathscr{D}$ is maximal with respect to the finite intersection property. It will suffice to show that the intersection $\bigcap_{D \in \mathscr{D}} \bar{D}$ is nonempty.

Given $\alpha \in J$, let $\pi_{\alpha}: X \rightarrow X_{\alpha}$ be the projection map, as usual. Consider the collection

$$
\left\{\pi_{\alpha}(D) \mid D \in \mathscr{D}\right\}
$$

of subsets of $X_{\alpha}$. This collection has the finite intersection property because $\mathscr{D}$ does. By compactness of $X_{\alpha}$, we can for each $\alpha$ choose a point $x_{\alpha}$ of $X_{\alpha}$ such that

$$
x_{\alpha} \in \bigcap_{D \in D} \overline{\pi_{\alpha}(D)}
$$

Let $\mathbf{x}$ be the point $\left(x_{\alpha}\right)_{\alpha \in J}$ of $X$. We shall show that $\mathbf{x} \in \bar{D}$ for every $D \in \mathscr{D}$; then our proof will be finished.

First we show that if $\pi_{\beta}^{-1}\left(U_{\beta}\right)$ is any subbasis element (for the product topology on $X$ ) containing $\mathbf{x}$, then $\pi_{\beta}^{-1}\left(U_{\beta}\right)$ intersects every element of $\mathscr{D}$. The set $U_{\beta}$ is a neighborhood of $x_{\beta}$ in $X_{\beta}$. Since $x_{\beta} \in \overline{\pi_{\beta}(D)}$ by definition, $U_{\beta}$ intersects $\pi_{\beta}(D)$ in some point $\pi_{\beta}(\mathbf{y})$, where $\mathbf{y} \in D$. Then it follows that $\mathbf{y} \in \pi_{\beta}^{-1}\left(U_{\beta}\right) \cap D$.

It follows from (b) of Lemma 37.2 that every subbasis element containing $\mathbf{x}$ belongs to $\mathcal{D}$. And then it follows from (a) of the same lemma that every basis element containing $\mathbf{x}$ belongs to $\mathscr{D}$. Since $\mathscr{D}$ has the finite intersection property, this means that every basis element containing $\mathbf{x}$ intersects every element of $\mathscr{D}$; hence $\mathbf{x} \in \bar{D}$ for every $D \in \mathcal{D}$ as desired.

## Exercises

1. Let $X$ be a space. Let $\mathscr{D}$ be a collection of subsets of $X$ that is maximal with respect to the finite intersection property.

(a) Show that $x \in \bar{D}$ for every $D \in \mathscr{D}$ if and only if every neighborhood of $x$ belongs to $\mathscr{D}$. Which implication uses maximality of $\mathscr{D}$ ?

(b) Let $D \in \mathcal{D}$. Show that if $A \supset D$, then $A \in \mathbb{D}$.

(c) Show that if $X$ satisfies the $T_{1}$ axiom, there is at most one point belonging to $\bigcap_{D \in \mathcal{D}} \bar{D}$.

2. A collection $\mathcal{A}$ of subsets of $X$ has the countable intersection property if every countable intersection of elements of $\mathcal{A}$ is nonempty. Show that $X$ is a Lindelöf space if and only if for every collection $\mathcal{A}$ of subsets of $X$ having the countable intersection property,

$$
\bigcap_{A \in \mathcal{A}} \bar{A}
$$

is nonempty.

3. Consider the three statements:

(i) If $X$ is a set and $\mathcal{A}$ is a collection of subsets of $X$ having the countable intersection property, then there is a collection $\mathscr{D}$ of subsets of $X$ such that $\mathscr{D} \supset \mathcal{A}$ and $\mathscr{D}$ is maximal with respect to the countable intersection property.
(ii) Suppose $\mathscr{D}$ is maximal with respect to the countable intersection property. Then countable intersections of elements of $\mathscr{D}$ are in $\mathscr{D}$. Furthermore, if $A$ is a subset of $X$ that intersects every element of $\mathscr{D}$, then $A$ is an element of $\mathscr{D}$.

(iii) Products of Lindelöf spaces are Lindelöf.

(a) Show that (i) and (ii) together imply (iii).

(b) Show that (ii) holds.

(c) Products of Lindelöf spaces need not be Lindelöf (see §30). Therefore (i) does not hold. If one attempts to generalize the proof of Lemma 37.1 to the countable intersection property, at what point does the proof break down?

4. Here is another theorem whose proof uses Zorn's lemma. Recall that if $A$ is a space and if $x, y \in A$, we say that $x$ and $y$ belong to the same quasicomponent of $A$ if there is no separation $A=C \cup D$ of $A$ into two disjoint sets open in $A$ such that $x \in C$ and $y \in D$.

Theorem. Let $X$ be a compact Hausdorff space. Then $x$ and $y$ belong to the same quasicomponent of $X$ if and only if they belong to the same component of $X$.

(a) Let $\mathcal{A}$ be the collection of all closed subspaces $A$ of $X$ such that $x$ and $y$ lie in the same quasicomponent of $A$. Let $\mathscr{B}$ be a subcollection of $\mathcal{A}$ that is simply ordered by proper inclusion. Show that the intersection of the elements of $\mathscr{B}$ belongs to $\mathcal{A}$. [Hint: Compare Exercise 11 of §26.]

(b) Show $\mathcal{A}$ has a minimal element $D$.

(c) Show $D$ is connected.

*5. Here is a proof of the Tychonoff theorem that relies on the well-ordering theorem rather than on Zorn's lemma. First, prove the following version of the tube lemma; then prove the theorem.

Lemma. Let $\mathcal{A}$ be a collection of basis elements for the topology of the product space $X \times Y$, such that no finite subcollection of $\mathcal{A}$ covers $X \times Y$. If $X$ is compact, there is a point $x \in X$ such that no finite subcollection of $\mathcal{A}$ covers the slice $\{x\} \times Y$.

Theorem. An arbitrary product of compact spaces is compact in the product topology.

Proof. Let $\left\{X_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of compact spaces; let

$$
X=\prod_{\alpha \in J} X_{\alpha}
$$

Let $\pi_{\alpha}: X \rightarrow X_{\alpha}$ be the projection map. Well-order $J$, once and for all, in such a way that $J$ has a largest element.

(a) Let $\beta \in J$. Suppose points $p_{i} \in X_{i}$ are given, for all $i<\beta$. For any $\alpha<\beta$, let $Y_{\alpha}$ denote the subspace of $X$ defined by the equation

$$
Y_{\alpha}=\left\{\mathbf{x} \mid \pi_{i}(\mathbf{x})=p_{i} \text { for } i \leq \alpha\right\}
$$

Note that if $\alpha<\alpha^{\prime}$, then $Y_{\alpha} \supset Y_{\alpha^{\prime}}$. Show that if $\mathcal{A}$ is a finite collection of
basis elements for $X$ that covers the space

$$
Z_{\beta}=\bigcap_{\alpha<\beta} Y_{\alpha}=\left\{\mathbf{x} \mid \pi_{i}(\mathbf{x})=p_{i} \text { for } i<\beta\right\}
$$

then $\mathcal{A}$ actually covers $Y_{\alpha}$ for some $\alpha<\beta$. [Hint: If $\beta$ has an immediate predecessor in $J$, let $\alpha$ be that immediate predecessor. Otherwise, for each $A \in \mathcal{A}$, let $J_{A}$ denote the set of those indices $i<\beta$ for which $\pi_{i}(A) \neq X_{i}$; the union of the sets $J_{A}$, for $A \in \mathcal{A}$, is finite; let $\alpha$ be the largest element of this union.]

(b) Assume $\mathcal{A}$ is a collection of basis elements for $X$ such that no finite subcollection of $\mathcal{A}$ covers $X$. Show that one can choose points $p_{i} \in X_{i}$ for all $i$, such that for each $\alpha$, the space $Y_{\alpha}$ defined in (a) cannot be finitely covered by $\mathcal{A}$. When $\alpha$ is the largest element of $J$, one has a contradiction. [Hint: If $\alpha$ is the smallest element of $J$, use the preceding lemma to choose $p_{\alpha}$. If $p_{i}$ is defined for all $i<\beta$, note that (a) implies that the space $Z_{\beta}$ cannot be finitely covered by $\mathcal{A}$ and use the lemma to find $p_{\beta}$.]

## §38 The Stone-Čech Compactification

We have already studied one way of compactifying a topological space $X$, the onepoint compactification (§29); it is in some sense the minimal compactification of $X$. The Stone-Čech compactification of $X$, which we study now, is in some sense the maximal compactification of $X$. It was constructed by M. Stone and E. Čech, independently, in 1937. It has a number of applications in modern analysis, but these lie outside the scope of this book.

We recall the following definition:

Definition. A compactification of a space $X$ is a compact Hausdorff space $Y$ containing $X$ as a subspace such that $\bar{X}=Y$. Two compactifications $Y_{1}$ and $Y_{2}$ of $X$ are said to be equivalent if there is a homeomorphism $h: Y_{1} \rightarrow Y_{2}$ such that $h(x)=x$ for every $x \in X$.

If $X$ has a compactification $Y$, then $X$ must be completely regular, being a subspace of the completely regular space $Y$. Conversely, if $X$ is completely regular, then $X$ has a compactification. For $X$ can be imbedded in the compact Hausdorff space $[0,1]^{J}$ for some $J$, and any such imbedding gives rise to a compactification of $X$, as the following lemma shows:

Lemma 38.1. Let $X$ be a space; suppose that $h: X \rightarrow Z$ is an imbedding of $X$ in the compact Hausdorff space $Z$. Then there exists a corresponding compactification $Y$ of $X$; it has the property that there is an imbedding $H: Y \rightarrow Z$ that equals $h$ on $X$. The compactification $Y$ is uniquely determined up to equivalence.

We call $Y$ the compactification induced by the imbedding $h$.

Proof. Given $h$, let $X_{0}$ denote the subspace $h(X)$ of $Z$, and let $Y_{0}$ denote its closure in $Z$. Then $Y_{0}$ is a compact Hausdorff space and $\bar{X}_{0}=Y_{0}$; therefore, $Y_{0}$ is a compactification of $X_{0}$.

We now construct a space $Y$ containing $X$ such that the pair $(X, Y)$ is homeomorphic to the pair $\left(X_{0}, Y_{0}\right)$. Let us choose a set $A$ disjoint from $X$ that is in bijective correspondence with the set $Y_{0}-X_{0}$ under some map $k: A \rightarrow Y_{0}-X_{0}$. Define $Y=X \cup A$, and define a bijective correspondence $H: Y \rightarrow Y_{0}$ by the rule

$$
\begin{array}{ll}
H(x)=h(x) & \text { for } x \in X \\
H(a)=k(a) & \text { for } a \in A .
\end{array}
$$

Then topologize $Y$ by declaring $U$ to be open in $Y$ if and only if $H(U)$ is open in $Y_{0}$. The map $H$ is automatically a homeomorphism; and the space $X$ is a subspace of $Y$ because $H$ equals the homeomorphism $h$ when restricted to the subspace $X$ of $Y$. By expanding the range of $H$, we obtain the required imbedding of $Y$ into $Z$.

Now suppose $Y_{i}$ is a compactification of $X$ and that $H_{i}: Y_{i} \rightarrow Z$ is an imbedding that is an extension of $h$, for $i=1,2$. Now $H_{i}$ maps $X$ onto $h(X)=X_{0}$. Because $H_{i}$ is continuous, it must map $Y_{i}$ into $\bar{X}_{0}$; because $H_{i}\left(Y_{i}\right)$ contains $X_{0}$ and is closed (being compact), it contains $\bar{X}_{0}$. Hence $H_{i}\left(Y_{i}\right)=\bar{X}_{0}$, and $H_{2}^{-1} \circ H_{1}$ defines a homeomorphism of $Y_{1}$ with $Y_{2}$ that equals the identity on $X$.

In general, there are many different ways of compactifying a given space $X$. Consider for instance the following compactifications of the open interval $X=(0,1)$ :

EXAMPLE 1. Take the unit circle $S^{1}$ in $\mathbb{R}^{2}$ and let $h:(0,1) \rightarrow S^{1}$ be the map

$$
h(t)=(\cos 2 \pi t) \times(\sin 2 \pi t)
$$

The compactification induced by the imbedding $h$ is equivalent to the one-point compactification of $X$.

EXAMPle 2. Let $Y$ be the space [0,1]. Then $Y$ is a compactification of $X$; it is obtained by "adding one point at each end of $(0,1)$."

EXAMPLE 3. Consider the square $[-1,1]^{2}$ in $\mathbb{R}^{2}$ and let $h:(0,1) \rightarrow[-1,1]^{2}$ be the map

$$
h(x)=x \times \sin (1 / x)
$$

The space $Y_{0}=\overline{h(X)}$ is the topologist's sine curve (see Example 7 of §24). The imbedding $h$ gives rise to a compactification of $(0,1)$ quite different from the other two. It is obtained by adding one point at the right-hand end of $(0,1)$, and an entire line segment of points at the left-hand end!

A basic problem that occurs in studying compactifications is the following:

If $Y$ is a compactification of $X$, under what conditions can a continuous real-valued function $f$ defined on $X$ be extended continuously to $Y$ ?

The function $f$ will have to be bounded if it is to be extendable, since its extension will carry the compact space $Y$ into $\mathbb{R}$ and will thus be bounded. But boundedness is not enough, in general. Consider the following example:

EXAmple 4. Let $X=(0,1)$. Consider the one-point compactification of $X$ given in Example 1. A bounded continuous function $f:(0,1) \rightarrow \mathbb{R}$ is extendable to this compactification if and only if the limits

$$
\lim _{x \rightarrow 0+} f(x) \quad \text { and } \quad \lim _{x \rightarrow 1-} f(x)
$$

exist and are equal.

For the "the two-point compactification" of $X$ considered in Example 2, the function $f$ is extendable if and only if both these limits simply exist.

For the compactification of Example 3, extensions exist for a still broader class of functions. It is easy to see that $f$ is extendable if both the above limits exist. But the function $f(x)=\sin (1 / x)$ is also extendable to this compactification: Let $H$ be the imbedding of $Y$ in $\mathbb{R}^{2}$ that equals $h$ on the subspace $X$. Then the composite map

$$
Y \xrightarrow{H} \mathbb{R} \times \mathbb{R} \xrightarrow{\pi_{2}} \mathbb{R}
$$

is the desired extension of $f$. For if $x \in X$, then $H(x)=h(x)=x \times \sin (1 / x)$, so that $\pi_{2}(H(x))=\sin (1 / x)$, as desired.

There is something especially interesting about this last compactification. We constructed it by choosing an imbedding

$$
h:(0,1) \longrightarrow \mathbb{R}^{2}
$$

whose component functions were the functions $x$ and $\sin (1 / x)$. Then we found that both the functions $x$ and $\sin (1 / x)$ could be extended to the compactification. This suggests that if we have a whole collection of bounded continuous functions defined on $(0,1)$, we might use them as component functions of an imbedding of $(0,1)$ into $\mathbb{R}^{J}$ for some $J$, and thereby obtain a compactification for which every function in the collection is extendable.

This idea is the basic idea behind the Stone-Čech compactification. It is defined as follows:

Theorem 38.2. Let $X$ be a completely regular space. There exists a compactification $Y$ of $X$ having the property that every bounded continuous map $f: X \rightarrow \mathbb{R}$ extends uniquely to a continuous map of $Y$ into $\mathbb{R}$.

Proof. Let $\left\{f_{\alpha}\right\}_{\alpha \in J}$ be the collection of all bounded continuous real-valued functions on $X$, indexed by some index set $J$. For each $\alpha \in J$, choose a closed interval $I_{\alpha}$ in $\mathbb{R}$ containing $f_{\alpha}(X)$. To be definite, choose

$$
I_{\alpha}=\left[\inf f_{\alpha}(X), \sup f_{\alpha}(X)\right]
$$

Then define $h: X \rightarrow \prod_{\alpha \in J} I_{\alpha}$ by the rule

$$
h(x)=\left(f_{\alpha}(x)\right)_{\alpha \in J} .
$$

By the Tychonoff theorem, $\prod I_{\alpha}$ is compact. Because $X$ is completely regular, the collection $\left\{f_{\alpha}\right\}$ separates points from closed sets in $X$. Therefore, by Theorem 34.2, the map $h$ is an imbedding.

Let $Y$ be the compactification of $X$ induced by the imbedding $h$. Then there is an imbedding $H: Y \rightarrow \prod I_{\alpha}$ that equals $h$ when restricted to the subspace $X$ of $Y$. Given a bounded continuous real-valued function $f$ on $X$, we show it extends to $Y$. The function $f$ belongs to the collection $\left\{f_{\alpha}\right\}_{\alpha \in J}$, so it equals $f_{\beta}$ for some index $\beta$. Let $\pi_{\beta}: \prod I_{\alpha} \rightarrow I_{\beta}$ be the projection mapping. Then the continuous map $\pi_{\beta} \circ H$ : $Y \rightarrow I_{\beta}$ is the desired extension of $f$. For if $x \in X$, we have

$$
\pi_{\beta}(H(x))=\pi_{\beta}(h(x))=\pi_{\beta}\left(\left(f_{\alpha}(x)\right)_{\alpha \in J}\right)=f_{\beta}(x) .
$$

Uniqueness of the extension is a consequence of the following lemma.

Lemma 38.3. Let $A \subset X$; let $f: A \rightarrow Z$ be a continuous map of $A$ into the Hausdorff space $Z$. There is at most one extension of $f$ to a continuous function $g: \bar{A} \rightarrow Z$.

Proof. This lemma was given as an exercise in $\S 18$; we give a proof here. Suppose that $g, g^{\prime}: \bar{A} \rightarrow X$ are two different extensions of $f$; choose $x$ so that $g(x) \neq g^{\prime}(x)$. Let $U$ and $U^{\prime}$ be disjoint neighborhoods of $g(x)$ and $g^{\prime}(x)$, respectively. Choose a neighborhood $V$ of $x$ so that $g(V) \subset U$ and $g^{\prime}(V) \subset U^{\prime}$. Now $V$ intersects $A$ in some point $y$; then $g(y) \in U$ and $g^{\prime}(y) \in U^{\prime}$. But since $y \in A$, we have $g(y)=f(y)$ and $g^{\prime}(y)=f(y)$. This contradicts the fact that $U$ and $U^{\prime}$ are disjoint.

Theorem 38.4. Let $X$ be a completely regular space; let $Y$ be a compactification of $X$ satisfying the extension property of Theorem 38.2. Given any continuous map $f: X \rightarrow C$ of $X$ into a compact Hausdorff space $C$, the map $f$ extends uniquely to a continuous map $g: Y \rightarrow C$.

Proof. Note that $C$ is completely regular, so that it can be imbedded in $[0,1]^{J}$ for some $J$. So we may as well assume that $C \subset[0,1]^{J}$. Then each component function $f_{\alpha}$ of the map $f$ is a bounded continuous real-valued function on $X$; by hypothesis, $f_{\alpha}$ can be extended to a continuous map $g_{\alpha}$ of $Y$ into $\mathbb{R}$. Define $g: Y \rightarrow \mathbb{R}^{J}$ by setting $g(y)=\left(g_{\alpha}(y)\right)_{\alpha \in J}$; then $g$ is continuous because $\mathbb{R}^{J}$ has the product topology. Now in fact $g$ maps $Y$ into the subspace $C$ of $\mathbb{R}^{J}$. For continuity of $g$ implies that

$$
g(Y)=g(\bar{X}) \subset \overline{g(X)}=\overline{f(X)} \subset \bar{C}=C .
$$

Thus $g$ is the desired extension of $f$.

Theorem 38.5. Let $X$ be a completely regular space. If $Y_{1}$ and $Y_{2}$ are two compactifications of $X$ satisfying the extension property of Theorem 38.2, then $Y_{1}$ and $Y_{2}$ are equivalent.

Proof. Consider the inclusion mapping $j_{2}: X \rightarrow Y_{2}$. It is a continuous map of $X$ into the compact Hausdorff space $Y_{2}$. Because $Y_{1}$ has the extension property, we may, by the preceding theorem, extend $j_{2}$ to a continuous map $f_{2}: Y_{1} \rightarrow Y_{2}$. Similarly, we may extend the inclusion map $j_{1}: X \rightarrow Y_{1}$ to a continuous map $f_{1}: Y_{2} \rightarrow Y_{1}$ (because $Y_{2}$ has the extension property and $Y_{1}$ is compact Hausdorff).
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-242.jpg?height=182&width=488&top_left_y=630&top_left_x=776)

The composite $f_{1} \circ f_{2}: Y_{1} \rightarrow Y_{1}$ has the property that for every $x \in X$, one has $f_{1}\left(f_{2}(x)\right)=x$. Therefore, $f_{1} \circ f_{2}$ is a continuous extension of the identity map $i_{X}: X \rightarrow X$. But the identity map of $Y_{1}$ is also a continuous extension of $i_{X}$. By uniqueness of extensions (Lemma 38.3), $f_{1} \circ f_{2}$ must equal the identity map of $Y_{1}$. Similarly, $f_{2} \circ f_{1}$ must equal the identity map of $Y_{2}$. Thus $f_{1}$ and $f_{2}$ are homeomorphisms.

Definition. For each completely regular space $X$, let us choose, once and for all, a compactification of $X$ satisfying the extension condition of Theorem 38.2. We will denote this compactification of $X$ by $\beta(X)$ and call it the Stone-Čech compactification of $X$. It is characterized by the fact that any continuous map $f: X \rightarrow C$ of $X$ into a compact Hausdorff space $C$ extends uniquely to a continuous map $g: \beta(X) \rightarrow C$.

## Exercises

1. Verify the statements made in Example 4.
2. Show that the bounded continuous function $g:(0,1) \rightarrow \mathbb{R}$ defined by $g(x)=$ $\cos (1 / x)$ cannot be extended to the compactification of Example 3. Define an imbedding $h:(0,1) \rightarrow[0,1]^{3}$ such that the functions $x, \sin (1 / x)$, and $\cos (1 / x)$ are all extendable to the compactification induced by $h$.
3. Under what conditions does a metrizable space have a metrizable compactification?
4. Let $Y$ be an arbitrary compactification of $X$; let $\beta(X)$ be the Stone-Čech compactification. Show there is a continuous surjective closed map $g: \beta(X) \rightarrow Y$ that equals the identity on $X$.

[This exercise makes precise what we mean by saying that $\beta(X)$ is the "maximal" compactification of $X$. It shows that every compactification of $X$ is equivalent to a quotient space of $\beta(X)$.]

5. (a) Show that every continuous real-valued function defined on $S_{\Omega}$ is "eventually constant." [Hint: First prove that for each $\epsilon$, there is an element $\alpha$ of $S_{\Omega}$
such that $|f(\beta)-f(\alpha)|<\epsilon$ for all $\beta>\alpha$. Then let $\epsilon=1 / n$ for $n \in \mathbb{Z}_{+}$ and consider the corresponding points $\alpha_{n}$.]

(b) Show that the one-point compactification of $S_{\Omega}$ and the Stone-Čech compactification are equivalent.

(c) Conclude that every compactification of $S_{\Omega}$ is equivalent to the one-point compactification.

6. Let $X$ be completely regular. Show that $X$ is connected if and only if $\beta(X)$ is connected. [Hint: If $X=A \cup B$ is a separation of $X$, let $f(x)=0$ for $x \in A$ and $f(x)=1$ for $x \in B$.]
7. Let $X$ be a discrete space; consider the space $\beta(X)$.

(a) Show that if $A \subset X$, then $\bar{A}$ and $\overline{X-A}$ are disjoint, where the closures are taken in $\beta(X)$.

(b) Show that if $U$ is open in $\beta(X)$, then $\bar{U}$ is open in $\beta(X)$.

(c) Show that $\beta(X)$ is totally disconnected.

8. Show that $\beta\left(\mathbb{Z}_{+}\right)$has cardinality at least as great as $I^{I}$, where $I=[0,1]$. [Hint: The space $I^{I}$ has a countable dense subset.]
9. (a) If $X$ is normal and $y$ is a point of $\beta(X)-X$, show that $y$ is not the limit of a sequence of points of $X$.

(b) Show that if $X$ is completely regular and noncompact, then $\beta(X)$ is not metrizable.

10. We have constructed a correspondence $X \rightarrow \beta(X)$ that assigns, to each completely regular space, its Stone-Čech compactification. Now let us assign, to each continuous map $f: X \rightarrow Y$ of completely regular spaces, the unique continuous map $\beta(f): \beta(X) \rightarrow \beta(Y)$ that extends the map $i \circ f$, where $i: Y \rightarrow \beta(Y)$ is the inclusion map. Verify the following:

(i) If $1_{X}: X \rightarrow X$ is the identity map of $X$, then $\beta\left(1_{X}\right)$ is the identity $\operatorname{map}$ of $\beta(X)$.

(ii) If $f: X \rightarrow Y$ and $g: Y \rightarrow Z$, then $\beta(g \circ f)=\beta(g) \circ \beta(f)$.

These properties tell us that the correspondence we have constructed is what is called a functor; it is a functor from the "category" of completely regular spaces and continuous maps of such spaces, to the "category" of compact Hausdorff spaces and continuous maps of such spaces. You will see these properties again in Part II of the book; they are fundamental in algebra and in algebraic topology.

## Chapter 6

## Metrization Theorems and Paracompactness

The Urysohn metrization theorem of Chapter 4 was the first step-a giant one-toward an answer to the question: When is a topological space metrizable? It gives conditions under which a space $X$ is metrizable: that it be regular and have a countable basis. But mathematicians are never satisfied with a theorem if there is some hope of proving a stronger one. In the present case, one can hope to strengthen the theorem by finding conditions on $X$ that are both necessary and sufficient for $X$ to be metrizable, that is, conditions that are equivalent to metrizability.

We know that the regularity hypothesis in the Urysohn metrization theorem is a necessary one, but the countable basis condition is not. So the obvious thing to do is try to replace the countable basis condition by something weaker. Finding such condition is a delicate task. The condition has to be strong enough to imply metrizability, and yet weak enough that all metrizable spaces satisfy it. In a situation like this, discovering the right hypothesis is more than half the battle.

The condition that was eventually formulated, by J. Nagata and Y. Smirnov independently, involves a new notion, that of local finiteness. We say that a collection $\mathcal{A}$ of subsets of a space $X$ is locally finite if every point of $X$ has a neighborhood that intersects only finitely many elements of $\mathcal{A}$.

Now one way of expressing the condition that the basis $\mathscr{B}$ is countable is to say that $\mathscr{B}$ can be expressed in the form

$$
\mathscr{B}=\bigcup_{n \in \mathbb{Z}_{+}} \mathscr{B}_{n},
$$

where each collection $\mathscr{B}_{n}$ is finite. This is an awkward way of saying that $\mathcal{B}$ is countable, but it suggests how to formulate a weaker version of it. The Nagata-Smirnov condition is to require that the basis $\mathcal{B}$ can be expressed in the form

$$
\mathscr{B}=\bigcup_{n \in \mathbb{Z}_{+}} \mathscr{B}_{n},
$$

where each collection $\mathscr{B}_{n}$ is locally finite. We say that such a collection $\mathscr{B}$ is countably locally finite. Surprisingly enough, this condition, along with regularity, is both necessary and sufficient for metrizability of $X$. This we shall we prove.

There is another concept in topology that involves the notion of local finiteness. It is a generalization of the concept of compactness called "paracompactness." Although of fairly recent origin, it has proved useful in many parts of mathematics. We introduce it here so that we can give another set of necessary and sufficient conditions for a space $X$ to be metrizable. It turns out that $X$ is metrizable if and only if it is both paracompact and locally metrizable. This we prove in $\S 42$.

Some of the sections of this chapter are independent of one another. The dependence among them is expressed in the following diagram:

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-245.jpg?height=286&width=910&top_left_y=1134&top_left_x=819)

## §39 Local Finiteness

In this sections we prove some elementary properties of locally finite collections and a crucial lemma about metrizable spaces.

Definition. Let $X$ be a topological space. A collection $\mathcal{A}$ of subsets of $X$ is said to be locally finite in $X$ if every point of $X$ has a neighborhood that intersects only finitely many elements of $\mathcal{A}$.

EXAMPLE 1. The collection of intervals

$$
\mathcal{A}=\{(n, n+2) \mid n \in \mathbb{Z}\}
$$

is locally finite in the topological space $\mathbb{R}$, as you can check. On the other hand, the collection

$$
\mathcal{B}=\left\{(0,1 / n) \mid n \in \mathbb{Z}_{+}\right\}
$$

is locally finite in $(0,1)$ but not in $\mathbb{R}$, as is the collection

$$
\mathcal{C}=\left\{(1 /(n+1), 1 / n) \mid n \in \mathbb{Z}_{+}\right\}
$$

Lemma 39.1. Let $\mathscr{A}$ be a locally finite collection of subsets of $X$. Then:

(a) Any subcollection of $\mathcal{A}$ is locally finite.

(b) The collection $\mathscr{B}=\{\bar{A}\}_{A \in \mathcal{A}}$ of the closures of the elements of $\mathcal{A}$ is locally finite.

(c) $\overline{\bigcup_{A \in \mathcal{A}} A}=\bigcup_{A \in \mathcal{A}} \bar{A}$.

Proof. Statement (a) is trivial. To prove (b), note that any open set $U$ that intersects the set $\bar{A}$ necessarily intersects $A$. Therefore, if $U$ is a neighborhood of $x$ that intersects only finitely many elements $A$ of $\mathscr{A}$, then $U$ can intersect at most the same number of sets of the collection $\mathscr{B}$. (It might intersect fewer sets of $\mathscr{B}$, since $\bar{A}_{1}$ and $\bar{A}_{2}$ can be equal even though $A_{1}$ and $A_{2}$ are not).

To prove (c), let $Y$ denote the union of the elements of $\mathscr{A}$ :

$$
\bigcup_{A \in \mathcal{A}} A=Y .
$$

In general, $\bigcup \bar{A} \subset \bar{Y}$; we prove the reverse inclusion, under the assumption of local finiteness. Let $x \in \bar{Y}$; let $U$ be a neighborhood of $x$ that intersects only finitely many elements of $\mathcal{A}$, say $A_{1}, \ldots, A_{k}$. We assert that $x$ belongs to one of the sets $\bar{A}_{1}$, $\ldots, \bar{A}_{k}$, and hence belongs to $\bigcup \bar{A}$. For otherwise, the set $U-\bar{A}_{1}-\cdots-\bar{A}_{k}$ would be a neighborhood of $x$ that intersects no element of $\mathcal{A}$ and hence does not intersect $Y$, contrary to the assumption that $x \in \bar{Y}$.

There is an analogous concept of local finiteness for an indexed family of subsets of $X$. The indexed family $\left\{A_{\alpha}\right\}_{\alpha \in J}$ is said to be a locally finite indexed family in $X$ if every $x \in X$ has a neighborhood that intersects $A_{\alpha}$ for only finitely many values of $\alpha$. What is the relation between the two formulations of local finiteness? It is easy to see that $\left\{A_{\alpha}\right\}_{\alpha \in J}$ is a locally finite indexed family if and only if it is locally finite as a collection of sets and each nonempty subset $A$ of $X$ equals $A_{\alpha}$ for at most finitely many values of $\alpha$.

We shall be concerned with locally finite indexed families only in $\S 41$, when we deal with partitions of unity.

Definition. A collection $\mathscr{B}$ of subsets of $X$ is said to be countably locally finite if $\mathscr{B}$ can be written as the countable union of collections $\mathcal{B}_{n}$, each of which is locally finite.

Most authors use the term " $\sigma$-locally finite" for this concept. The $\sigma$ comes from measure theory and stands for the phrase "countable union of." Note that both a countable collection and a locally finite collection are countably locally finite.

Definition. Let $\mathcal{A}$ be a collection of subsets of the space $X$. A collection $\mathscr{B}$ of subsets of $X$ is said to be a refinement of $\mathcal{A}$ (or is said to refine $\mathcal{A}$ ) if for each element $B$ of $\mathscr{B}$, there is an element $A$ of $\mathcal{A}$ containing $B$. If the elements of $\mathscr{B}$ are open sets, we call $\mathscr{B}$ an open refinement of $\mathcal{A}$; if they are closed sets, we call $\mathscr{B}$ a closed refinement.

Lemma 39.2. Let $X$ be a metrizable space. If $\mathcal{A}$ is an open covering of $X$, then there is an open covering $\mathcal{E}$ of $X$ refining $\mathcal{A}$ that is countably locally finite.

Proof. We shall use the well-ordering theorem in proving this theorem. Choose a well-ordering $<$ for the collection $\mathcal{A}$. Let us denote the elements of $\mathcal{A}$ generically by the letters $U, V, W, \ldots$.

Choose a metric for $X$. Let $n$ be a positive integer, fixed for the moment. Given an element $U$ of $\mathcal{A}$, let us define $S_{n}(U)$ to be the subset of $U$ obtained by "shrinking" $U$ a distance of $1 / n$. More precisely, let

$$
S_{n}(U)=\{x \mid B(x, 1 / n) \subset U\}
$$

(It happens that $S_{n}(U)$ is a closed set, but that is not important for our purposes.) Now we use the well-ordering $<$ of $\mathcal{A}$ to pass to a still smaller set. For each $U$ in $\mathcal{A}$, define

$$
T_{n}(U)=S_{n}(U)-\bigcup_{V<U} V .
$$

The situation where $\mathcal{A}$ consists of the three sets $U<V<W$ is pictured in Figure 39.1. Just as the figure suggests, the sets we have formed are disjoint.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-247.jpg?height=602&width=810&top_left_y=1220&top_left_x=794)

Figure 39.1

In fact, they are separated by a distance of at least $1 / n$. This means that if $V$ and $W$ are distinct elements of $\mathcal{A}$, then $d(x, y) \geq 1 / n$ whenever $x \in T_{n}(V)$ and $y \in T_{n}(W)$.

To prove this fact, assume the notation has been so chosen that $V<W$. Since $x$ is in $T_{n}(V)$, then $x$ is in $S_{n}(V)$, so the $1 / n$-neighborhood of $x$ lies in $V$. On the other hand, since $V<W$ and $y$ is in $T_{n}(W)$, the definition of the latter set tells us that $y$ is not in $V$. It follows that $y$ is not in the $1 / n$-neighborhood of $x$.

The sets $T_{n}(U)$ are not yet the ones we want, for we do not know that they are open sets. (In fact, they are closed.) So let us expand each of them slightly to obtain
an open set $E_{n}(U)$. Specifically, let $E_{n}(U)$ be the $1 / 3 n$-neighborhood of $T_{n}(U)$; that is, let $E_{n}(U)$ be the union of the open balls $B(x, 1 / 3 n)$, for $x \in T_{n}(U)$.

In the case $U<V<W$, we have the situation pictured in Figure 39.2. As the figure suggests, the sets we have formed are disjoint. Indeed, if $V$ and $W$ are distinct elements of $\mathcal{A}$, we assert that $d(x, y) \geq 1 / 3 n$ whenever $x \in E_{n}(V)$ and $y \in E_{n}(W)$; this fact follows at once from the triangle inequality. Note that for each $V \in \mathcal{A}$, the set $E_{n}(V)$ is contained in $V$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-248.jpg?height=588&width=813&top_left_y=716&top_left_x=615)

Figure 39.2

Now let us define

$$
\mathcal{E}_{n}=\left\{E_{n}(U) \mid U \in \mathcal{A}\right\} .
$$

We claim that $\mathcal{E}_{n}$ is a locally finite collection of open sets that refines $\mathcal{A}$. The fact that $\varepsilon_{n}$ refines $\mathcal{A}$ comes from the fact that $E_{n}(V) \subset V$ for each $V \in \mathcal{A}$. The fact that $\mathcal{E}_{n}$ is locally finite comes from the fact that for any $x$ in $X$, the $1 / 6 n$-neighborhood of $x$ can intersect at most one element of $\varepsilon_{n}$.

Of course, the collection $\varepsilon_{n}$, will not cover $X$. (Figure 39.2 illustrates that fact.) But we assert that the collection

$$
\mathcal{E}=\bigcup_{n \in \mathbb{Z}_{+}} \varepsilon_{n}
$$

does cover $X$.

Let $x$ be a point of $X$. The collection $\mathcal{A}$ with which we began covers $X$; let us choose $U$ to be the first element of $\mathcal{A}$ (in the well-ordering $<$ ) that contains $x$. Since $U$ is open, we can choose $n$ so that $B(x, 1 / n) \subset U$. Then, by definition, $x \in S_{n}(U)$. Now because $U$ is the first element of $\mathscr{A}$ that contains $x$, the point $x$ belongs to $T_{n}(U)$. Then $x$ also belongs to the element $E_{n}(U)$ of $\mathcal{E}_{n}$, as desired.

## Exercises

1. Check the statements in Example 1.
2. Find a point-finite open covering $\mathcal{A}$ of $\mathbb{R}$ that is not locally finite. (The collection $\mathcal{A}$ is point-finite if each point of $\mathbb{R}$ lies in only finitely many elements of $\mathcal{A}$.)
3. Give an example of a collection of sets $\mathcal{A}$ that is not locally finite, such that the collection $\mathscr{B}=\{\bar{A} \mid A \in \mathcal{A}\}$ is locally finite.
4. Let $\mathcal{A}$ be the following collection of subsets of $\mathbb{R}$ :

$$
\mathcal{A}=\{(n, n+2) \mid n \in \mathbb{Z}\}
$$

Which of the following collections refine $\mathcal{A}$ ?

$$
\begin{aligned}
\mathcal{B} & =\{(x, x+1) \mid x \in \mathbb{R}\} \\
\mathcal{C} & =\left\{\left.\left(n, n+\frac{3}{2}\right) \right\rvert\, n \in \mathbb{Z}\right\} \\
\mathcal{D} & =\left\{\left.\left(x, x+\frac{3}{2}\right) \right\rvert\, x \in \mathbb{R}\right\} .
\end{aligned}
$$

5. Show that if $X$ has a countable basis, a collection $\mathcal{A}$ of subsets of $X$ is countably locally finite if and only if it is countable.
6. Consider $\mathbb{R}^{\omega}$ in the uniform topology. Given $n$, let $\mathcal{B}_{n}$ be the collection of all subsets of $\mathbb{R}^{\omega}$ of the form $\prod A_{i}$, where $A_{i}=\mathbb{R}$ for $i \leq n$ and $A_{i}$ equals either $\{0\}$ or $\{1\}$ otherwise. Show that the collection $\mathscr{B}=\bigcup \mathscr{B}_{n}$ is countably locally finite, but neither countable nor locally finite.

## §40 The Nagata-Smirnov Metrization Theorem

Now we prove that regularity of $X$ and the existence of a countably locally finite basis for $X$ are equivalent to metrizability of $X$.

The proof that these conditions imply metrizability follows very closely the second proof we gave of the Urysohn metrization theorem. In that proof we constructed a map of the space $X$ into $\mathbb{R}^{\omega}$ that was an imbedding relative to the uniform metric $\bar{\rho}$ on $\mathbb{R}^{\omega}$. So let us review the major elements of that proof. The first step of the proof was to prove that every regular space $X$ with a countable basis is normal. The second step was to construct a countable collection $\left\{f_{n}\right\}$ of real-valued functions on $X$ that separated points from closed sets. The third step was to use the functions $f_{n}$ to define a map imbedding $X$ in the product space $\mathbb{R}^{\omega}$. And the fourth step was to show that if $f_{n}(x) \leq 1 / n$ for all $x$, then this map actually imbeds $X$ in the metric space $\left(\mathbb{R}^{\omega}, \bar{\rho}\right)$.

Each of these steps needs to be generalized in order to prove the general metrization theorem. First, we show that a regular space $X$ with a basis that is countably locally finite is normal. Second, we construct a certain collection of real-valued functions $\left\{f_{\alpha}\right\}$ on $X$ that separates points from closed sets. Third, we use these functions to imbed $X$ in the product space $\mathbb{R}^{J}$, for some $J$. And fourth, we show that if the
functions $f_{\alpha}$ are sufficiently small, this map actually imbeds $X$ in the metric space $\left(\mathbb{R}^{J}, \bar{\rho}\right)$.

Before we start, we need to recall a notion we have already introduced in the exercises, that of a $G_{\delta}$ set.

Definition. A subset $A$ of a space $X$ is called a $\boldsymbol{G}_{\delta}$ set in $X$ if it equals the intersection of a countable collection of open subsets of $X$.

EXAMPLE 1. Each open subset of $X$ is a $G_{\delta}$ set, trivially. In a first-countable Hausdorff space, each one-point set is a $G_{\delta}$ set. The one-point subset $\{\Omega\}$ of $\bar{S}_{\Omega}$ is not a $G_{\delta}$ set, as you can check.

EXAMPLE 2. In a metric space $X$, each closed set is a $G_{\delta}$ set. Given $A \subset X$, let $U(A, \epsilon)$ denote the $\epsilon$-neighborhood of $A$. If $A$ is closed, you can check that

$$
A=\bigcap_{n \in \mathbb{Z}_{+}} U(A, 1 / n) .
$$

Lemma 40.1. Let $X$ be a regular space with a basis $\mathscr{B}$ that is countably locally finite. Then $X$ is normal, and every closed set in $X$ is a $G_{\delta}$ set in $X$.

Proof. Step 1. Let $W$ be open in $X$. We show there is a countable collection $\left\{U_{n}\right\}$ of open sets of $X$ such that

$$
W=\bigcup U_{n}=\bigcup \bar{U}_{n}
$$

Since the basis $\mathscr{B}$ for $X$ is countably locally finite, we can write $\mathscr{B}=\bigcup \mathscr{B}_{n}$, where each collection $\mathscr{B}_{n}$ is locally finite. Let $\mathcal{C}_{n}$ be the collection of those basis elements $B$ such that $B \in \mathscr{B}_{n}$ and $\bar{B} \subset W$. Then $\mathcal{C}_{n}$ is locally finite, being a subcollection of $\mathscr{B}_{n}$. Define

$$
U_{n}=\bigcup_{B \in \mathcal{C}_{n}} B
$$

Then $U_{n}$ is an open set, and by Lemma 39.1,

$$
\bar{U}_{n}=\bigcup_{B \in C_{n}} \bar{B} .
$$

Therefore, $\bar{U}_{n} \subset W$, so that

$$
\bigcup U_{n} \subset \bigcup \bar{U}_{n} \subset W .
$$

We assert that equality holds. Given $x \in W$, there is by regularity a basis element $B \in \mathcal{B}$ such that $x \in B$ and $\bar{B} \subset W$. Now $B \in \mathcal{B}_{n}$ for some $n$. Then $B \in \mathcal{C}_{n}$ by definition, so that $x \in U_{n}$. Thus $W \subset \bigcup U_{n}$, as desired.

Step 2. We show that every closed set $C$ in $X$ is a $G_{\delta}$ set in $X$. Given $C$, let $W=X-C$. By Step 1, there are sets $U_{n}$ in $X$ such that $W=\bigcup \bar{U}_{n}$. Then

$$
C=\bigcap\left(X-\bar{U}_{n}\right),
$$

so that $C$ equals a countable intersection of open sets $X$.

Step 3. We show $X$ is normal. Let $C$ and $D$ be disjoint closed sets in $X$. Applying Step 1 to the open set $X-D$, we construct a countable collection $\left\{U_{n}\right\}$ of open sets such that $\bigcup U_{n}=\bigcup \bar{U}_{n}=X-D$. Then $\left\{U_{n}\right\}$ covers $C$ and each set $\bar{U}_{n}$ is disjoint from $D$. Similarly, there is a countable covering $\left\{V_{n}\right\}$ of $D$ by open sets whose closures are disjoint from $C$.

Now we are back in the situation that arose in the proof that a regular space with a countable basis is normal (Theorem 32.1). We can repeat that proof verbatim. Define

$$
U_{n}^{\prime}=U_{n}-\bigcup_{i=1}^{n} \bar{V}_{i} \quad \text { and } \quad V_{n}^{\prime}=V_{n}-\bigcup_{i=1}^{n} \bar{U}_{i}
$$

Then the sets

$$
U^{\prime}=\bigcup_{n \in \mathbb{Z}_{+}} U_{n}^{\prime} \quad \text { and } \quad V^{\prime}=\bigcup_{n \in \mathbb{Z}_{+}} V_{n}^{\prime}
$$

are disjoint open sets about $C$ and $D$, respectively.

Lemma 40.2. Let $X$ be normal; let $A$ be a closed $G_{\delta}$ set in $X$. Then there is a continuous function $f: X \rightarrow[0,1]$ such that $f(x)=0$ for $x \in A$ and $f(x)>0$ for $x \notin A$.

Proof. We gave this as an exercise in $\S 33$; we provide a proof here. Write $A$ as the intersection of the open sets $U_{n}$, for $n \in \mathbb{Z}_{+}$. For each $n$, choose a continuous function $f_{n}: X \rightarrow[0,1]$ such that $f(x)=0$ for $x \in A$ and $f(x)=1$ for $x \in X-U_{n}$. Define $f(x)=\sum f_{n}(x) / 2^{n}$. The series converges uniformly, by comparison with $\sum 1 / 2^{n}$, so that $f$ is continuous. Also, $f$ vanishes on $A$ and is positive on $X-A$.

Theorem 40.3 (Nagata-Smirnov metrization theorem). A space $X$ is metrizable if and only if $X$ is regular and has a basis that is countably locally finite.

Proof. Step 1. Assume $X$ is regular with a countably locally finite basis $\mathcal{B}$. Then $X$ is normal, and every closed set in $X$ is a $G_{\delta}$ set in $X$. We shall show that $X$ is metrizable by imbedding $X$ in the metric space $\left(\mathbb{R}^{J}, \bar{\rho}\right)$ for some $J$.

Let $\mathcal{B}=\bigcup \mathscr{B}_{n}$, where each collection $\mathscr{B}_{n}$ is locally finite. For each positive integer $n$, and each basis element $B \in \mathscr{B}_{n}$, choose a continuous function

$$
f_{n, B}: X \longrightarrow[0,1 / n]
$$

such that $f_{n, B}(x)>0$ for $x \in B$ and $f_{n, B}(x)=0$ for $x \notin B$. The collection $\left\{f_{n, B}\right\}$ separates points from closed sets in $X$ : Given a point $x_{0}$ and a neighborhood $U$ of $x_{0}$, there is a basis element $B$ such that $x_{0} \in B \subset U$. Then $B \in \mathscr{B}_{n}$ for some $n$, so that $f_{n, B}\left(x_{0}\right)>0$ and $f_{n, B}$ vanishes outside $U$.

Let $J$ be the subset of $\mathbb{Z}_{+} \times \mathscr{B}$ consisting of all pairs $(n, B)$ such that $B$ is an element of $\mathscr{B}_{n}$. Define

$$
F: X \longrightarrow[0,1]^{J}
$$

by the equation

$$
F(x)=\left(f_{n, B}(x)\right)_{(n, b) \in J} .
$$

Relative to the product topology on $[0,1]^{J}$, the map $F$ is an imbedding, by Theorem 34.2.

Now we give $[0,1]^{J}$ the topology induced by the uniform metric and show that $F$ is an imbedding relative to this topology as well. Here is where the condition $f_{n, B}(x)<1 / n$ comes in. The uniform topology is finer (larger) than the product topology. Therefore, relative to the uniform metric, the map $F$ is injective and carries open sets of $X$ onto open sets of the image space $Z=F(X)$. We must give a separate proof that $F$ is continuous.

Note that on the subspace $[0,1]^{J}$ of $\mathbb{R}^{J}$, the uniform metric equals the metric

$$
\rho\left(\left(x_{\alpha}\right),\left(y_{\alpha}\right)\right)=\sup \left\{\left|x_{\alpha}-y_{\alpha}\right|\right\} .
$$

To prove continuity, we take a point $x_{0}$ of $X$ and a number $\epsilon>0$, and find a neighborhood $W$ of $x_{0}$ such that

$$
x \in W \Longrightarrow \rho\left(F(x), F\left(x_{0}\right)\right)<\epsilon \text {. }
$$

Let $n$ be fixed for the moment. Choose a neighborhood $U_{n}$ of $x_{0}$ that intersects only finitely many elements of the collection $\mathscr{B}_{n}$. This means that as $B$ ranges over $\mathcal{B}_{n}$, all but finitely many of the functions $f_{n, B}$ are identically equal to zero on $U_{n}$. Because each function $f_{n, B}$ is continuous, we can now choose a neighborhood $V_{n}$ of $x_{0}$ contained in $U_{n}$ on which each of the remaining functions $f_{n, B}$, for $B \in \mathscr{B}_{n}$, varies by at most $\epsilon / 2$.

Choose such a neighborhood $V_{n}$ of $x_{0}$ for each $n \in \mathbb{Z}_{+}$. Then choose $N$ so that $1 / N \leq \epsilon / 2$, and define $W=V_{1} \cap \cdots \cap V_{N}$. We assert that $W$ is the desired neighborhood of $x_{0}$. Let $x \in W$. If $n \leq N$, then

$$
\left|f_{n, B}(x)-f_{n, B}\left(x_{0}\right)\right| \leq \epsilon / 2
$$

because the function $f_{n, B}$ either vanishes identically or varies by at most $\epsilon / 2$ on $W$. If $n>N$, then

$$
\left|f_{n, B}(x)-f_{n, B}\left(x_{0}\right)\right| \leq 1 / n<\epsilon / 2
$$

because $f_{n, B}$ maps $X$ into $[0,1 / n]$. Therefore,

$$
\rho\left(F(x), F\left(x_{0}\right)\right) \leq \epsilon / 2<\epsilon,
$$

as desired.

Step 2. Now we prove the converse. Assume $X$ is metrizable. We know $X$ is regular; let us show that $X$ has a basis that is countably locally finite.

Choose a metric for $X$. Given $m$, let $\mathcal{A}_{m}$ be the covering of $X$ by all open balls of radius $1 / m$. By Lemma 39.2, there is an open covering $\mathscr{B}_{m}$ of $X$ refining $\mathcal{A}_{m}$ such
that $\mathcal{B}_{m}$ is countably locally finite. Note that each element of $\mathscr{B}_{m}$ has diameter at most $2 / m$. Let $\mathscr{B}$ be the union of the collections $\mathcal{B}_{m}$, for $m \in \mathbb{Z}_{+}$. Because each collection $\mathscr{B}_{m}$ is countably locally finite, so is $\mathscr{B}$. We show that $\mathscr{B}$ is a basis for $X$.

Given $x \in X$ and given $\epsilon>0$, we show that there is an element $B$ of $\mathscr{B}$ containing $x$ that is contained in $B(x, \epsilon)$. First choose $m$ so that $1 / m<\epsilon / 2$. Then, because $\mathscr{B}_{m}$ covers $X$, we can choose an element $B$ of $\mathscr{B}_{m}$ that contains $x$. Since $B$ contains $x$ and has diameter at most $2 / m<\epsilon$, it is contained in $B(x, \epsilon)$, as desired.

## Exercises

1. Check the details of Examples 1 and 2 .
2. A subset $W$ of $X$ is said to be an " $F_{\sigma}$ set" in $X$ if $W$ equals a countable union of closed sets of $X$. Show that $W$ is an $F_{\sigma}$ set in $X$ if and only if $X-W$ is a $G_{\delta}$ set in $X$.

[The terminology comes from the French. The "F" stands for "fermé," which means "closed," and the " $\sigma$ " for "somme," which means "union."]

3. Many spaces have countable bases; but no $T_{1}$ space has a locally finite basis unless it is discrete. Prove this fact.
4. Find a nondiscrete space that has a countably locally finite basis but does not have a countable basis.
5. A collection $\mathcal{A}$ of subsets of $X$ is said to be locally discrete if each point of $X$ has a neighborhood that intersects at most one element of $\mathcal{A}$. A collection $\mathcal{B}$ is countably locally discrete (or " $\sigma$-locally discrete") if it equals a countable union of locally discrete collections. Prove the following:

Theorem (Bing metrization theorem). A space $X$ is metrizable if and only if it is regular and has a basis that is countably locally discrete.

## §41 Paracompactness

The concept of paracompactness is one of the most useful generalizations of compactness that has been discovered in recent years. It is particularly useful for applications in topology and differential geometry. We shall give just one application, a metrization theorem that we prove in the next section.

Many of the spaces that are familiar to us already are paracompact. For instance, every compact space is paracompact; this will be an immediate consequence of the definition. It is also true that every metrizable space is paracompact; this is a theorem due to A. H. Stone, which we shall prove. Thus the class of paracompact spaces includes the two most important classes of spaces we have studied. It includes many other spaces as well.

To see how paracompactness generalizes compactness, we recall the definition of compactness: A space $X$ is said to be compact if every open covering $\mathcal{A}$ of $X$ contains a finite subcollection that covers $X$. An equivalent way of saying this is the following:

A space $X$ is compact if every open covering $\mathcal{A}$ of $X$ has a finite open refinement $\mathscr{B}$ that covers $X$.

This definition is equivalent to the usual one; given such a refinement $\mathscr{B}$, one can choose for each element of $\mathcal{B}$ an element of $\mathcal{A}$ containing it; in this way one obtains a finite subcollection of $\mathcal{A}$ that covers $X$.

This new formulation of compactness is an awkward one, but it suggests a way to generalize:

Definition. A space $X$ is paracompact if every open covering $\mathcal{A}$ of $X$ has a locally finite open refinement $\mathscr{B}$ that covers $X$.

Many authors, following the lead of Bourbaki, include as part of the definition of the term paracompact the requirement that the space be Hausdorff. (Bourbaki also includes the Hausdorff condition as part of the definition of the term compact.) We shall not follow this convention.

EXAMPLE 1. The space $\mathbb{R}^{n}$ is paracompact. Let $X=\mathbb{R}^{n}$. Let $\mathcal{A}$ be an open covering of $X$. Let $B_{0}=\varnothing$, and for each positive integer $m$, let $B_{m}$ denote the open ball of radius $m$ centered at the origin. Given $m$, choose finitely many elements of $\mathcal{A}$ that cover $\bar{B}_{m}$ and intersect each one with the open set $X-\bar{B}_{m-1}$; let this finite collection of open sets be denoted $\mathcal{C}_{m}$. Then the collection $\mathcal{C}=\bigcup \mathcal{C}_{m}$ is a refinement of $\mathcal{A}$. It is clearly locally finite, for the open set $B_{m}$ intersects only finitely many elements of $\mathcal{C}$, namely those elements belonging to the collection $\mathcal{C}_{1} \cup \cdots \cup \mathcal{C}_{m}$. Finally, $\mathcal{C}$ covers $X$. For, given $x$, let $m$ be the smallest integer such that $x \in \bar{B}_{m}$. Then $x$ belongs to an element of $\mathcal{C}_{m}$, by definition.

Some of the properties of a paracompact space are similar to those of a compact space. For instance, a subspace of a paracompact space is not necessarily paracompact; but a closed subspace is paracompact. Also, a paracompact Hausdorff space is normal. In other ways, a paracompact space is not similar to a compact space; in particular, the product of two paracompact spaces need not be paracompact. We shall verify these facts shortly.

## Theorem 41.1. Every paracompact Hausdorff space $X$ is normal.

Proof. The proof is somewhat similar to the proof that a compact Hausdorff space is normal.

First one proves regularity. Let $a$ be a point of $X$ and let $B$ be a closed set $X$ disjoint from $a$. The Hausdorff condition enables us to choose, for each $b$ in $B$, an open set $U_{b}$ about $b$ whose closure is disjoint from $a$. Cover $X$ by the open sets $U_{b}$, along with the open set $X-B$; take a locally finite open refinement $\mathcal{C}$ that covers $X$. Form the subcollection $\mathscr{D}$ of $\mathcal{C}$ consisting of every element of $\mathcal{C}$ that intersects $B$. Then $\mathscr{D}$
covers $B$. Furthermore, if $D \in \mathcal{D}$, then $\bar{D}$ is disjoint from $a$. For $D$ intersects $B$, so it lies in some set $U_{b}$, whose closure is disjoint from $a$. Let

$$
V=\bigcup_{D \in \mathcal{D}} D
$$

then $V$ is an open set in $X$ containing $B$. Because $\mathscr{D}$ is locally finite,

$$
\bar{V}=\bigcup_{D \in D} \bar{D},
$$

so that $\bar{V}$ is disjoint from $a$. Thus regularity is proved.

To prove normality, one merely repeats the same argument, replacing $a$ by the closed set $A$ throughout and replacing the Hausdorff condition by regularity.

Theorem 41.2. Every closed subspace of a paracompact space is paracompact.

Proof. Let $Y$ be a closed subspace of the paracompact space $X$; let $\mathcal{A}$ be a covering of $Y$ by sets open in $Y$. For each $A \in \mathcal{A}$, choose an open set $A^{\prime}$ of $X$ such that $A^{\prime} \cap Y=A$. Cover $X$ by the open sets $A^{\prime}$, along with the open set $X-Y$. Let $\mathscr{B}$ be a locally finite open refinement of this covering that covers $X$. The collection

$$
\mathcal{C}=\{B \cap Y \mid B \in \mathscr{B}\}
$$

is the required locally finite open refinement of $\mathcal{A}$.

EXAMPLE 2. A paracompact subspace of a Hausdorff space $X$ need not be closed in X. Indeed, the open interval $(0,1)$ is paracompact, being homeomorphic to $\mathbb{R}$, but it is not closed in $\mathbb{R}$.

EXAMPLE 3. A subspace of a paracompact space need not be paracompact. The space $\bar{S}_{\Omega} \times \bar{S}_{\Omega}$ is compact and, therefore, paracompact. But the subspace $S_{\Omega} \times \bar{S}_{\Omega}$ is not paracompact, for it is Hausdorff but not normal.

To prove the important theorem that every metrizable space is paracompact, we need the following lemma, due to E. Michael, which is also useful for other purposes:

Lemma 41.3. Let $X$ be regular. Then the following conditions on $X$ are equivalent: Every open covering of $X$ has a refinement that is:

(1) An open covering of $X$ and countably locally finite.

(2) A covering of $X$ and locally finite.

(3) A closed covering of $X$ and locally finite.

(4) An open covering of $X$ and locally finite.

Proof. It is trivial that $(4) \Rightarrow(1)$. What we need to prove our theorem is the converse. In order to prove the converse, we must go through the steps $(1) \Rightarrow(2) \Rightarrow(3) \Rightarrow$ (4) anyway, so we have for convenience listed these conditions in the statement of the lemma.
$(1) \Rightarrow(2)$. Let $\mathcal{A}$ be an open covering of $X$. Let $\mathscr{B}$ be an open refinement of $\mathcal{A}$ that covers $X$ and is countably locally finite; let

$$
\mathscr{B}=\bigcup \mathscr{B}_{n}
$$

where each $\mathscr{B}_{n}$ is locally finite.

Now we apply essentially the same sort of shrinking trick we have used before to make sets from different $\mathscr{B}_{n}$ 's disjoint. Given $i$, let

$$
V_{i}=\bigcup_{U \in \mathscr{B}_{i}} U
$$

Then for each $n \in \mathbb{Z}_{+}$and each element $U$ of $\mathscr{B}_{n}$, define

$$
S_{n}(U)=U-\bigcup_{i<n} V_{i}
$$

[Note that $S_{n}(U)$ is not necessarily open, nor closed.] Let

$$
\mathcal{C}_{n}=\left\{S_{n}(U) \mid U \in \mathscr{B}_{n}\right\} .
$$

Then $\mathcal{C}_{n}$ is a refinement of $\mathscr{B}_{n}$, because $S_{n}(U) \subset U$ for each $U \in \mathscr{B}_{n}$.

Let $\mathcal{C}=\cup \mathcal{C}_{n}$. We assert that $\mathcal{C}$ is the required locally finite refinement of $\mathcal{A}$, covering $X$.

Let $x$ be a point of $X$. We wish to prove that $x$ lies in an element of $\mathcal{C}$, and that $x$ has a neighborhood intersecting only finitely many elements of $\mathcal{C}$. Consider the covering $\mathscr{B}=\bigcup \mathscr{B}_{n}$; let $N$ be the smallest integer such that $x$ lies in an element of $\mathscr{B}_{N}$. Let $U$ be an element of $\mathscr{B}_{N}$ containing $x$. First, note that since $x$ lies in no element of $\mathscr{B}_{i}$ for $i<N$, the point $x$ lies in the element $S_{N}(U)$ of $\mathcal{C}$. Second, note that since each collection $\mathscr{B}_{n}$ is locally finite, we can choose for each $n=1, \ldots, N$ a neighborhood $W_{n}$ of $x$ that intersects only finitely many elements of $\mathscr{B}_{n}$. Now if $W_{n}$ intersects the element $S_{n}(V)$ of $\mathcal{C}_{n}$, it must intersect the element $V$ of $\mathscr{B}_{n}$, since $S_{n}(V) \subset V$. Therefore, $W_{n}$ intersects only finitely many elements of $\mathcal{C}_{n}$. Furthermore, because $U$ is in $\mathscr{B}_{N}, U$ intersects no element of $\mathcal{C}_{n}$ for $n>N$. As a result, the neighborhood

$$
W_{1} \cap W_{2} \cap \cdots \cap W_{N} \cap U
$$

of $x$ intersects only finitely many elements of $\mathcal{C}$.

(2) $\Rightarrow$ (3). Let $\mathcal{A}$ be an open covering of $X$. Let $\mathscr{B}$ be the collection of all open sets $U$ of $X$ such that $\bar{U}$ is contained in an element of $\mathcal{A}$. By regularity, $\mathcal{B}$ covers $X$. Using (2), we can find a refinement $\mathcal{C}$ of $\mathscr{B}$ that covers $X$ and is locally finite. Let

$$
\mathscr{D}=\{\bar{C} \mid C \in \mathcal{C}\} .
$$

Then $\mathscr{D}$ also covers $X$; it is locally finite by Lemma 39.1 ; and it refines $\mathcal{A}$.

$(3) \Rightarrow(4)$. Let $\mathcal{A}$ be an open covering of $X$. Using (3), choose $\mathscr{B}$ to be a refinement of $\mathscr{A}$ that covers $X$ and is locally finite. (We can take $\mathscr{B}$ to be a closed refinement if we like, but that is irrelevant.) We seek to expand each element $B$ of $\mathscr{B}$ slightly to
an open set, making the expansion slight enough that the resulting collection of open sets will still be locally finite and will still refine $\mathcal{A}$.

This step involves a new trick. The previous trick, used several times, consisted of ordering the sets in some way and forming a new set by subtracting off all the previous ones. That trick shrinks the sets; to expand them we need something different. We shall introduce an auxiliary locally finite closed covering $\mathcal{C}$ of $X$ and use it to expand the elements of $\mathcal{B}$.

For each point $x$ of $X$, there is a neighborhood of $x$ that intersects only finitely many elements of $\mathscr{B}$. The collection of all open sets that intersect only finitely many elements of $\mathcal{B}$ is thus an open covering of $X$. Using (3) again, let $\mathcal{C}$ be a closed refinement of this covering that covers $X$ and is locally finite. Each element of $\mathcal{C}$ intersects only finitely many elements of $\mathscr{B}$.

For each element $B$ of $\mathcal{B}$, let

$$
\mathcal{C}(B)=\{C \mid C \in \mathcal{C} \text { and } C \subset X-B\} \text {. }
$$

Then define

$$
E(B)=X-\bigcup_{C \in \mathcal{C}(B)} C .
$$

Because $\mathcal{C}$ is a locally finite collection of closed sets, the union of the elements of any subcollection of $\mathcal{C}$ is closed, by Lemma 39.1. Therefore, the set $E(B)$ is an open set. Furthermore, $E(B) \supset B$ by definition. (See Figure 41.1, in which the elements of $\mathscr{B}$ are represented as closed circular regions and line segments, and the elements of $\mathcal{C}$ are represented as closed square regions.)

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-257.jpg?height=691&width=874&top_left_y=1522&top_left_x=754)

Figure 41.1

Now we may have expanded each $B$ too much; the collection $\{E(B)\}$ may not be a refinement of $\mathcal{A}$. This is easily remedied. For each $B \in \mathcal{B}$, choose an element $F(B)$ of $\mathcal{A}$ containing $B$. Then define

$$
\mathscr{D}=\{E(B) \cap F(B) \mid B \in \mathscr{B}\} .
$$

The collection $\mathscr{D}$ is a refinement of $\mathcal{A}$. Because $B \subset(E(B) \cap F(B))$ and $\mathscr{B}$ covers $X$, the collection $\mathscr{D}$ also covers $X$.

We have finally to prove that $\mathscr{D}$ is locally finite. Given a point $x$ of $X$, choose a neighborhood $W$ of $x$ that intersects only finitely many elements of $\mathcal{C}$, say $C_{1}, \ldots, C_{k}$. We show that $W$ intersects only finitely many elements of $\mathcal{D}$. Because $\mathcal{C}$ covers $X$, the set $W$ is covered by $C_{1}, \ldots, C_{k}$. Thus, it suffices to show that each element $C$ of $C$ intersects only finitely many elements of $\mathscr{D}$. Now if $C$ intersects the set $E(B) \cap F(B)$, then it intersects $E(B)$, so by definition of $E(B)$ it is not contained in $X-B$; hence $C$ must intersect $B$. Since $C$ intersects only finitely many elements of $\mathscr{B}$, it can intersect at most the same number of elements of the collection $\mathscr{D}$.

## Theorem 41.4. Every metrizable space is paracompact.

Proof. Let $X$ be a metrizable space. We already know from Lemma 39.2 that, given an open covering $\mathcal{A}$ of $X$, it has an open refinement that covers $X$ and is countably locally finite. The preceding lemma then implies that $\mathcal{A}$ has an open refinement that covers $X$ and is locally finite.

Theorem 41.5. Every regular Lindelöf space is paracompact.

Proof. Let $X$ be regular and Lindelöf. Given an open covering $\mathcal{A}$ of $X$, it has a countable subcollection that covers $X$; this subcollection is automatically countably locally finite. The preceding lemma applies to show $\mathcal{A}$ has an open refinement that covers $X$ and is locally finite.

EXAMPLE 4. The product of two paracompact spaces need not be paracompact. The space $\mathbb{R}_{\ell}$ is paracompact, for it is regular and Lindelöf. However, $\mathbb{R}_{\ell} \times \mathbb{R}_{\ell}$ is not paracompact, for it is Hausdorff but not normal.

EXAMPLE 5. The space $\mathbb{R}^{\omega}$ is paracompact in both the product and uniform topologies. This result follows from the fact that $\mathbb{R}^{\omega}$ is metrizable in these topologies. It is not known whether $\mathbb{R}^{\omega}$ is paracompact in the box topology. (See the comment in Exercise 5 of §32.)

EXAMPLE 6. The product space $\mathbb{R}^{J}$ is not paracompact if $J$ is uncountable. For $\mathbb{R}^{J}$ is Hausdorff but not normal.

One of the most useful properties that a paracompact space $X$ possesses has to do with the existence of partitions of unity on $X$. We have already seen the finite version of this notion in $\S 36$; we discuss the general case now. Recall that if $\phi: X \rightarrow \mathbb{R}$, the support of $\phi$ is the closure of the set of those $x$ for which $\phi(x) \neq 0$.

Definition. Let $\left\{U_{\alpha}\right\}_{\alpha \in J}$ be an indexed open covering of $X$. An indexed family of continuous functions

$$
\phi_{\alpha}: X \rightarrow[0,1]
$$

is said to be a partition of unity on $X$, dominated by $\left\{U_{\alpha}\right\}$, if:

(1) (Support $\left.\phi_{\alpha}\right) \subset U_{\alpha}$ for each $\alpha$.

(2) The indexed family $\left\{\right.$ Support $\left.\phi_{\alpha}\right\}$ is locally finite.

(3) $\sum \phi_{\alpha}(x)=1$ for each $x$.

Condition (2) implies that each $x \in X$ has a neighborhood on which the function $\phi_{\alpha}$ vanishes identically for all but finitely many values of $\alpha$. Thus we can make sense of the "sum" indicated in (3); we interpret it to mean the sum of the terms $\phi_{\alpha}(x)$ that do not equal zero.

We now construct a partition of unity on an arbitrary paracompact Hausdorff space. We begin by proving a "shrinking lemma," just as we did for the finite case in $\S 36$.

*Lemma 41.6. Let $X$ be a paracompact Hausdorff space; let $\left\{U_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of open sets covering $X$. Then there exists a locally finite indexed family $\left\{V_{\alpha}\right\}_{\alpha \in J}$ of open sets covering $X$ such that $\bar{V}_{\alpha} \subset U_{\alpha}$ for each $\alpha$.

The condition that $\bar{V}_{\alpha} \subset U_{\alpha}$ for each $\alpha$ is sometimes expressed by saying that the family $\left\{\bar{V}_{\alpha}\right\}$ is a precise refinement of the family $\left\{U_{\alpha}\right\}$.

Proof. Let $\mathcal{A}$ be the collection of all open sets $A$ such that $\bar{A}$ is contained in some element of the collection $\left\{U_{\alpha}\right\}$. Regularity of $X$ implies that $\mathcal{A}$ covers $X$. Since $X$ is paracompact, we can find a locally finite collection $\mathscr{B}$ of open sets covering $X$ that refines $\mathcal{A}$. Let us index $\mathscr{B}$ bijectively with some index set $K$; then the general element of $\mathcal{B}$ can be denoted $B_{\beta}$, for $\beta \in K$, and $\left\{B_{\beta}\right\}_{\beta \in K}$ is a locally finite indexed family. Since $\mathscr{B}$ refines $\mathcal{A}$, we can define a function $f: K \rightarrow J$ by choosing, for each $\beta$ in $K$, an element $f(\beta) \in J$ such that

$$
\bar{B}_{\beta} \subset U_{f(\beta)} .
$$

Then for each $\alpha \in J$, we define $V_{\alpha}$ to be the union of the elements of the collection

$$
\mathcal{B}_{\alpha}=\left\{B_{\beta} \mid f(\beta)=\alpha\right\} .
$$

(Note that $V_{\alpha}$ is empty if there exists no index $\beta$ such that $f(\beta)=\alpha$.) For each element $B_{\beta}$ of the collection $\mathcal{B}_{\alpha}$ we have $\bar{B}_{\beta} \subset U_{\alpha}$ by definition. Because the collection $\mathscr{B}_{\alpha}$ is locally finite, $\bar{V}_{\alpha}$ equals the union of the closures of the elements of $\mathscr{B}_{\alpha}$, so that $\bar{V}_{\alpha} \subset U_{\alpha}$.

Finally, we check local finiteness. Given $x \in X$, choose a neighborhood $W$ of $x$ such that $W$ intersects $B_{\beta}$ for only finitely many values of $\beta$, say $\beta=\beta_{1}, \ldots, \beta_{K}$. Then $W$ can intersect $V_{\alpha}$ only if $\alpha$ is one of the indices $f\left(\beta_{1}\right), \ldots, f\left(\beta_{K}\right)$.

*Theorem 41.7. Let $X$ be a paracompact Hausdorff space; let $\left\{U_{\alpha}\right\}_{\alpha \in J}$ be an indexed open covering of $X$. Then there exists a partition of unity on $X$ dominated by $\left\{U_{\alpha}\right\}$.

Proof. We begin by applying the shrinking lemma twice, to find locally finite indexed familes of open sets $\left\{W_{\alpha}\right\}$ and $\left\{V_{\alpha}\right\}$ covering $X$, such that $\bar{W}_{\alpha} \subset V_{\alpha}$ and $\bar{V}_{\alpha} \subset U_{\alpha}$ for each $\alpha$. Since $X$ is normal, we may choose, for each $\alpha$, a continuous function $\psi_{\alpha}: X \rightarrow[0,1]$ such that $\psi_{\alpha}\left(\bar{W}_{\alpha}\right)=\{1\}$ and $\psi_{\alpha}\left(X-V_{\alpha}\right)=\{0\}$. Since $\psi_{\alpha}$ is nonzero only at points of $V_{\alpha}$, we have

$$
\text { (Support } \left.\psi_{\alpha}\right) \subset \bar{V}_{\alpha} \subset U_{\alpha} \text {. }
$$

Furthermore, the indexed family $\left\{\bar{V}_{\alpha}\right\}$ is locally finite (since an open set intersects $\bar{V}_{\alpha}$ only if it intersects $V_{\alpha}$ ); hence the indexed family $\left\{\right.$ Support $\left.\psi_{\alpha}\right\}$ is also locally finite. Note that because $\left\{W_{\alpha}\right\}$ covers $X$, for any given $x$ at least one of the functions $\psi_{\alpha}$ is positive at $x$.

We can now make sense of the formally infinite sum

$$
\Psi(x)=\sum_{\alpha} \psi_{\alpha}(x)
$$

Since each $x \in X$ has a neighborhood $W_{x}$ that intersects the set (Support $\psi_{\alpha}$ ) for only finitely many values of $\alpha$, we can interpret this infinite sum to mean the sum of its (finitely many) nonzero terms. It follows that the restriction of $\Psi$ to $W_{x}$ equals a finite sum of continuous functions, and is thus continuous. Then since $\Psi$ is continuous on $W_{x}$ for each $x$, it is continuous on $X$. It is also positive. We now define

$$
\phi_{\alpha}(x)=\psi_{\alpha}(x) / \Psi(x)
$$

to obtain our desired partition of unity.

Partitions of unity are most often used in mathematics to "patch together" functions that are defined locally so as to obtain a function that is defined globally. Their use in $\S 36$ illustrates this process. Here is another such illustration:

*Theorem 41.8. Let $X$ be a paracompact Hausdorff space; let $C$ be a collection of subsets of $X$; for each $C \in \mathcal{C}$, let $\epsilon_{C}$ be a positive number. If $\mathcal{C}$ is locally finite, there is a continuous function $f: X \rightarrow \mathbb{R}$ such that $f(x)>0$ for all $x$, and $f(x) \leq \epsilon_{C}$ for $x \in C$.

Proof. Cover $X$ by open sets each of which intersects at most finitely many elements of $\mathcal{C}$; index this collection of open sets so that it becomes an indexed family $\left\{U_{\alpha}\right\}_{\alpha \in J}$. Choose a partition of unity $\left\{\phi_{\alpha}\right\}$ on $X$ dominated by $\left\{U_{\alpha}\right\}$. Given $\alpha$, let $\delta_{\alpha}$ be the minimum of the numbers $\epsilon_{C}$, as $C$ ranges over all those elements of $\mathcal{C}$ that intersect the support of $\phi_{\alpha}$; if there are no such elements of $C$, set $\delta_{\alpha}=1$. Then define

$$
f(x)=\sum \delta_{\alpha} \phi_{\alpha}(x)
$$

Because all the numbers $\delta_{\alpha}$ are positive, so is $f$. We show that $f(x) \leq \epsilon_{C}$ for $x \in C$. It will suffice to show that for $x \in C$ and arbitrary $\alpha$, we have

$$
\begin{equation*}
\delta_{\alpha} \phi_{\alpha}(x) \leq \epsilon_{C} \phi_{\alpha}(x) \tag{*}
\end{equation*}
$$

then the desired inequality follows by summing, as $\sum \phi_{\alpha}(x)=1$. If $x \notin \operatorname{Support} \phi_{\alpha}$, then inequality (*) is trivial because $\phi_{\alpha}(x)=0$. And if $x \in$ Support $\phi_{\alpha}$ and $x \in C$, then $C$ intersects the support of $\phi_{\alpha}$, so that $\delta_{\alpha} \leq \epsilon_{C}$ by construction; thus (*) holds.

## Exercises

1. Give an example to show that if $X$ is paracompact, it does not follow that for every open covering $\mathcal{A}$ of $X$, there is a locally finite subcollection of $\mathcal{A}$ that covers $X$.
2. (a) Show that the product of a paracompact space and a compact space is paracompact. [Hint: Use the tube lemma.]

(b) Conclude that $S_{\Omega}$ is not paracompact.

3. Is every locally compact Hausdorff space paracompact?
4. (a) Show that if $X$ has the discrete topology, then $X$ is paracompact.

(b) Show that if $f: X \rightarrow Y$ is continuous and $X$ is paracompact, the subspace $f(X)$ of $Y$ need not be paracompact.

5. Let $X$ be paracompact. We proved a "shrinking lemma" for arbitrary indexed open coverings of $X$. Here is an "expansion lemma" for arbitrary locally finite indexed families in $X$.

Lemma. Let $\left\{B_{\alpha}\right\}_{\alpha \in J}$ be a locally finite indexed family of subsets of the paracompact Hausdorff space $X$. Then there is a locally finite indexed family $\left\{U_{\alpha}\right\}_{\alpha \in J}$ of open sets in $X$ such that $B_{\alpha} \subset U_{\alpha}$ for each $\alpha$.

6. (a) Let $X$ be a regular space. If $X$ is a countable union of compact subspaces of $X$, then $X$ is paracompact.

(b) Show $\mathbb{R}^{\infty}$ is paracompact as a subspace of $\mathbb{R}^{\omega}$ in the box topology.

*7. Let $X$ be a regular space.

(a) If $X$ is a finite union of closed paracompact subspaces of $X$, then $X$ is paracompact.

(b) If $X$ is a countable union of closed paracompact subspaces of $X$ whose interiors cover $X$, show $X$ is paracompact.

8. Let $p: X \rightarrow Y$ be a perfect map. (See Exercise 7 of $\S 31$.)

(a) Show that if $Y$ is paracompact, so is $X$. [Hint: If $\mathcal{A}$ is an open covering of $X$, find a locally finite open covering of $Y$ by sets $B$ such that $p^{-1}(B)$ can be covered by finitely many elements of $\mathcal{A}$; then intersect $p^{-1}(B)$ with these elements of $\mathcal{A}$.]

(b) Show that if $X$ is a paracompact Hausdorff space, then so is $Y$. [Hint: If $\mathscr{B}$ is a locally finite closed covering of $X$, then $\{p(B) \mid B \in \mathcal{B}\}$ is a locally finite closed covering of $Y$.]

9. Let $G$ be a locally compact, connected topological group. Show that $G$ is paracompact. [Hint: Let $U_{1}$ be a neighborhood of $e$ having compact closure. In general, define $U_{n+1}=\bar{U}_{n} \cdot U_{1}$. Show the union of the sets $\bar{U}_{n}$ is both open and closed in $G$.]

This result holds without assuming $G$ is connected, but the proof requires more effort.

10. Theorem. If $X$ is a Hausdorff space that is locally compact and paracompact, then each component of $X$ has a countable basis.

Proof. If $X_{0}$ is a component of $X$, then $X_{0}$ is locally compact and paracompact. Let $C$ be a locally finite covering of $X_{0}$ by sets open in $X_{0}$ that have compact closures. Let $U_{1}$ be a nonempty element of $\mathcal{C}$, and in general let $U_{n}$ be the union of all elements of $\mathcal{C}$ that intersect $\bar{U}_{n-1}$. Show $\bar{U}_{n}$ is compact, and the sets $U_{n}$ cover $X_{0}$.

## §42 The Smirnov Metrization Theorem

The Nagata-Smirnov metrization theorem gives one set of necessary and sufficient conditions for metrizability of a space. In this section we prove a theorem that gives another such set of conditions. It is a corollary of the Nagata-Smirnov theorem and was first proved by Smirnov.

Definition. A space $X$ is locally metrizable if every point $x$ of $X$ has a neighborhood $U$ that is metrizable in the subspace topology.

Theorem 42.1 (Smirnov metrization theorem). A space $X$ is metrizable if and only if it is a paracompact Hausdorff space that is locally metrizable.

Proof. Suppose that $X$ is metrizable. Then $X$ is locally metrizable; it is also paracompact, by Theorem 41.4 .

Conversely, suppose that $X$ is a paracompact Hausdorff space that is locally metrizable. We shall show that $X$ has a basis that is countably locally finite. Since $X$ is regular, it will then follow from the Nagata-Smirnov theorem that $X$ is metrizable.

The proof is an adaptation of the last part of the proof of Theorem 40.3. Cover $X$ by open sets that are metrizable; then choose a locally finite open refinement $\mathcal{C}$ of this covering that covers $X$. Each element $C$ of $\mathcal{C}$ is metrizable; let the function $d_{C}$ : $C \times C \rightarrow \mathbb{R}$ be a metric that gives the topology of $C$. Given $x \in C$, let $B_{C}(x, \epsilon)$ denote the set of all points $y$ of $C$ such that $d_{C}(x, y)<\epsilon$. Being open in $C$, the set $B_{C}(x, \epsilon)$ is also open in $X$.

Given $m \in \mathbb{Z}_{+}$, let $\mathcal{A}_{m}$ be the covering of $X$ by all these open balls of radius $1 / m$; that is, let

$$
\mathcal{A}_{m}=\left\{B_{C}(x, 1 / m) \mid x \in C \text { and } C \in \mathcal{C}\right\} .
$$

Let $\mathcal{D}_{m}$ be a locally finite open refinement of $\mathcal{A}_{m}$ that covers $X$. (Here we use paracompactness.) Let $\mathcal{D}$ be the union of the collections $\mathcal{D}_{m}$. Then $\mathscr{D}$ is countably locally finite. We assert that $\mathscr{D}$ is a basis for $X$; our theorem follows.

Let $x$ be a point of $X$ and let $U$ be a neighborhood of $x$. We seek to find an element $D$ of $\mathcal{D}$ such that $x \in D \subset U$. Now $x$ belongs to only finitely many elements of $\mathcal{C}$, say to $C_{1}, \ldots, C_{k}$. Then $U \cap C_{i}$ is a neighborhood of $x$ in the set $C_{i}$, so there is an $\epsilon_{i}>0$ such that

$$
B_{C_{i}}(x, \epsilon) \subset\left(U \cap C_{i}\right)
$$

Choose $m$ so that $2 / m<\min \left\{\epsilon_{1}, \ldots, \epsilon_{k}\right\}$. Because the collection $\mathscr{D}_{m}$ covers $X$, there must be an element $D$ of $\mathscr{D}_{m}$ containing $x$. Because $\mathcal{D}_{m}$ refines $\mathcal{A}_{m}$, there must be an element $B_{C}(y, 1 / m)$ of $\mathcal{A}_{m}$, for some $C \in \mathcal{C}$ and some $y \in C$, that contains $D$. Because

$$
x \in D \subset B_{C}(y, 1 / m)
$$

the point $x$ belongs to $C$, so that $C$ must be one of the sets $C_{1}, \ldots, C_{k}$. Say $C=C_{i}$. Since $B_{C}(y, 1 / m)$ has diameter at most $2 / m<\epsilon_{i}$, it follows that

$$
x \in D \subset B_{C_{i}}(y, 1 / m) \subset B_{C_{i}}\left(x, \epsilon_{i}\right) \subset U,
$$

as desired.

## Exercises

1. Compare Theorem 42.1 with Exercises 7 and 8 of $\S 34$.
2. (a) Show that for each $x \in S_{\Omega}$, the section of $S_{\Omega}$ by $x$ has a countable basis and hence is metrizable.

(b) Conclude that $S_{\Omega}$ is not paracompact.

## Chapter 7

## Complete Metric Spaces and Function Spaces

The concept of completeness for a metric space is one you may have seen already. It is basic for all aspects of analysis. Although completeness is a metric property rather than a topological one, there are a number of theorems involving complete metric spaces that are topological in character. In this chapter, we shall study the most important examples of complete metric spaces and shall prove some of these theorems.

The most familiar example of a complete metric space is euclidean space in either of its usual metrics. Another example, just as important, is the set $\mathcal{C}(X, Y)$ of all continuous functions mapping a space $X$ into a metric space $Y$. This set has a metric called the uniform metric, analogous to the uniform metric defined for $\mathbb{R}^{J}$ in $\S 20$. If $Y$ is a complete metric space, then $\mathcal{C}(X, Y)$ is complete in the uniform metric. This we demonstrate in $\S 43$. As an application, we construct in $\S 44$ the well-known Peano space-filling curve.

One theorem of topological character concerning complete metric spaces is a theorem relating compactness of a space to completeness. We prove it in §45. An immediate corollary is a theorem concerning compact subspaces of the function space $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$; it is the classical version of a famous theorem called Ascoli's theorem.

There are other useful topologies on the function space $\mathcal{C}(X, Y)$ besides the one derived from the uniform metric. We study some of them in $\S 46$, leading to a proof of a general version of Ascoli's theorem in $\S 47$.

## §43 Complete Metric Spaces

In this section we define the notion of completeness and show that if $Y$ is a complete metric space, then the function space $\mathcal{C}(X, Y)$ is complete in the uniform metric. We also show that every metric space can be imbedded isometrically in a complete metric space.

Definition. Let $(X, d)$ be a metric space. A sequence $\left(x_{n}\right)$ of points of $X$ is said to be a Cauchy sequence in $(X, d)$ if it has the property that given $\epsilon>0$, there is an integer $N$ such that

$$
d\left(x_{n}, x_{m}\right)<\epsilon \quad \text { whenever } n, m \geq N \text {. }
$$

The metric space $(X, d)$ is said to be complete if every Cauchy sequence in $X$ converges.

Any convergent sequence in $X$ is necessarily a Cauchy sequence, of course; completeness requires that the converse hold.

Note that a closed subset $A$ of a complete metric space $(X, d)$ is necessarily complete in the restricted metric. For a Cauchy sequence in $A$ is also a Cauchy sequence in $X$, hence it converges in $X$. Because $A$ is a closed subset of $X$, the limit must lie in A.

Note also that if $X$ is complete under the metric $d$, then $X$ is complete under the standard bounded metric

$$
\bar{d}(x, y)=\min \{d(x, y), 1\}
$$

corresponding to $d$, and conversely. For a sequence $\left(x_{n}\right)$ is a Cauchy sequence under $\bar{d}$ if and only if it is a Cauchy sequence under $d$. And a sequence converges under $\bar{d}$ if and only if it converges under $d$.

A useful criterion for a metric space to be complete is the following:

Lemma 43.1. A metric space $X$ is complete if every Cauchy sequence in $X$ has a convergent subsequence.

Proof. Let $\left(x_{n}\right)$ be a Cauchy sequence in $(X, d)$. We show that if $\left(x_{n}\right)$ has a subsequence $\left(x_{n_{i}}\right)$ that converges to a point $x$, then the sequence $\left(x_{n}\right)$ itself converges to $x$.

Given $\epsilon>0$, first choose $N$ large enough that

$$
d\left(x_{n}, x_{m}\right)<\epsilon / 2
$$

for all $n, m \geq N$ [using the fact that $\left(x_{n}\right)$ is a Cauchy sequence]. Then choose an integer $i$ large enough that $n_{i} \geq N$ and

$$
d\left(x_{n_{i}}, x\right)<\epsilon / 2
$$

[using the fact that $n_{1}<n_{2}<\ldots$ is an increasing sequence of integers and $x_{n_{i}}$ converges to $x$ ]. Putting these facts together, we have the desired result that for $n \geq N$,

$$
d\left(x_{n}, x\right) \leq d\left(x_{n}, x_{n_{i}}\right)+d\left(x_{n_{i}}, x\right)<\epsilon .
$$

Theorem 43.2. Euclidean space $\mathbb{R}^{k}$ is complete in either of its usual metrics, the euclidean metric $d$ or the square metric $\rho$.

Proof. To show the metric space $\left(\mathbb{R}^{k}, \rho\right)$ is complete, let $\left(x_{n}\right)$ be a Cauchy sequence

in $\left(\mathbb{R}^{k}, \rho\right)$. Then the set $\left\{x_{n}\right\}$ is a bounded subset of $\left(\mathbb{R}^{k}, \rho\right)$. For if we choose $N$ so that

$$
\rho\left(x_{n}, x_{m}\right) \leq 1
$$

for all $n, m \geq N$, then the number

$$
M=\max \left\{\rho\left(x_{1}, \mathbf{0}\right), \ldots, \rho\left(x_{N-1}, \mathbf{0}\right), \rho\left(x_{N}, \mathbf{0}\right)+1\right\}
$$

is an upper bound for $\rho\left(x_{n}, \mathbf{0}\right)$. Thus the points of the sequence $\left(x_{n}\right)$ all lie in the cube $[-M, M]^{k}$. Since this cube is compact, the sequence $\left(x_{n}\right)$ has a convergent subsequence, by Theorem 28.2. Then $\left(\mathbb{R}^{k}, \rho\right)$ is complete.

To show that $\left(\mathbb{R}^{k}, d\right.$ ) is complete, note that a sequence is a Cauchy sequence relative to $d$ if and only if it is a Cauchy sequence relative to $\rho$, and a sequence converges relative to $d$ if and only if it converges relative to $\rho$.

Now we deal with the product space $\mathbb{R}^{\omega}$. We need a lemma about sequences in a product space.

Lemma 43.3. Let $X$ be the product space $X=\prod X_{\alpha}$; let $\mathbf{x}_{n}$ be a sequence of points of $X$. Then $\mathbf{x}_{n} \rightarrow \mathbf{x}$ if and only if $\pi_{\alpha}\left(\mathbf{x}_{n}\right) \rightarrow \pi_{\alpha}(\mathbf{x})$ for each $\alpha$.

Proof. This result was given as an exercise in $\S 19$; we give a proof here. Because the projection mapping $\pi_{\alpha}: X \rightarrow X_{\alpha}$ is continuous, it preserves convergent sequences; the "only if" part of the lemma follows. To prove the converse, suppose $\pi_{\alpha}\left(\mathbf{x}_{n}\right) \rightarrow$ $\pi_{\alpha}(\mathbf{x})$ for each $\alpha \in J$. Let $U=\prod U_{\alpha}$ be a basis element for $X$ that contains $\mathbf{x}$. For each $\alpha$ for which $U_{\alpha}$ does not equal the entire space $X_{\alpha}$, choose $N_{\alpha}$ so that $\pi_{\alpha}\left(\mathbf{x}_{n}\right) \in$ $U_{\alpha}$ for $n \geq N_{\alpha}$. Let $N$ be the largest of the numbers $N_{\alpha}$; then for all $n \geq N$, we have $\mathbf{x}_{n} \in U$.

Theorem 43.4. There is a metric for the product space $\mathbb{R}^{\omega}$ relative to which $\mathbb{R}^{\omega}$ is complete.

Proof. Let $\bar{d}(a, b)=\min \{|a-b|, 1\}$ be the standard bounded metric on $\mathbb{R}$. Let $D$ be the metric on $\mathbb{R}^{\omega}$ defined by

$$
D(\mathbf{x}, \mathbf{y})=\sup \left\{\bar{d}\left(x_{i}, y_{i}\right) / i\right\} .
$$

Then $D$ induces the product topology on $\mathbb{R}^{\omega}$; we verify that $\mathbb{R}^{\omega}$ is complete under $D$. Let $\mathbf{x}_{n}$ be a Cauchy sequence in $\left(\mathbb{R}^{\omega}, D\right)$. Because

$$
\bar{d}\left(\pi_{i}(\mathbf{x}), \pi_{i}(\mathbf{y})\right) \leq i D(\mathbf{x}, \mathbf{y})
$$

we see that for fixed $i$ the sequence $\pi_{i}\left(\mathbf{x}_{n}\right)$ is a Cauchy sequence in $\mathbb{R}$, so it converges, say to $a_{i}$. Then the sequence $\mathbf{x}_{n}$ converges to the point $\mathbf{a}=\left(a_{1}, a_{2}, \ldots\right)$ of $\mathbb{R}^{\omega}$.

EXAMPLE 1. An example of a noncomplete metric space is the space $\mathbb{Q}$ of rational numbers in the usual metric $d(x, y)=|x-y|$. For instance, the sequence

$$
1.4,1.41,1.414,1.4142,1.41421, \ldots
$$

of finite decimals converging (in $\mathbb{R}$ ) to $\sqrt{2}$ is a Cauchy sequence in $\mathbb{Q}$ that does not converge (in $\mathbb{Q}$ ).

EXAMPLE 2. Another noncomplete space is the open interval $(-1,1)$ in $\mathbb{R}$, in the metric $d(x, y)=|x-y|$. In this space the sequence $\left(x_{n}\right)$ defined by

$$
x_{n}=1-1 / n
$$

is a Cauchy sequence that does not converge. This example shows that completeness is not a topological property, that is, it is not preserved by homeomorphisms. For $(-1,1)$ is homeomorphic to the real line $\mathbb{R}$, and $\mathbb{R}$ is complete in its usual metric.

Although both the product spaces $\mathbb{R}^{n}$ and $\mathbb{R}^{\omega}$ have metrics relative to which they are complete, one cannot hope to prove the same result for the product space $\mathbb{R}^{J}$ in general, because $\mathbb{R}^{J}$ is not even metrizable if $J$ is uncountable (see $\$ 21$ ). There is, however, another topology on the set $\mathbb{R}^{J}$, the one given by the uniform metric. Relative to this metric, $\mathbb{R}^{J}$ is complete, as we shall see.

We define the uniform metric in general as follows:

Definition. Let $(Y, d)$ be a metric space; let $\bar{d}(a, b)=\min \{d(a, b), 1\}$ be the standard bounded metric on $Y$ derived from $d$. If $\mathbf{x}=\left(x_{\alpha}\right)_{\alpha \in J}$ and $\mathbf{y}=\left(y_{\alpha}\right)_{\alpha \in J}$ are points of the cartesian product $Y^{J}$, let

$$
\bar{\rho}(\mathbf{x}, \mathbf{y})=\sup \left\{\bar{d}\left(x_{\alpha}, y_{\alpha}\right) \mid \alpha \in J\right\} .
$$

It is easy to check that $\rho$ is a metric; it is called the uniform metric on $Y^{J}$ corresponding to the metric $d$ on $Y$.

Here we have used the standard "tuple" notation for the elements of the cartesian product $Y^{J}$. Since the elements of $Y^{J}$ are simply functions from $J$ to $Y$, we could also use functional notation for them. In this chapter, functional notation will be more convenient than tuple notation, so we shall use it throughout. In this notation, the definition of the uniform metric takes the following form: If $f, g: J \rightarrow Y$, then

$$
\bar{\rho}(f, g)=\sup \{\bar{d}(f(\alpha), g(\alpha)) \mid \alpha \in J\} .
$$

Theorem 43.5. If the space $Y$ is complete in the metric $d$, then the space $Y^{J}$ is complete in the uniform metric $\bar{\rho}$ corresponding to $d$.

Proof. Recall that if $(Y, d)$ is complete, so is $(Y, \bar{d})$, where $\bar{d}$ is the bounded metric corresponding to $d$. Now suppose that $f_{1}, f_{2}, \ldots$ is a sequence of points of $Y^{J}$ that is a Cauchy sequence relative to $\bar{\rho}$. Given $\alpha$ in $J$, the fact that

$$
\bar{d}\left(f_{n}(\alpha), f_{m}(\alpha)\right) \leq \bar{\rho}\left(f_{n}, f_{m}\right)
$$

for all $n, m$ means that the sequence $f_{1}(\alpha), f_{2}(\alpha), \ldots$ is a Cauchy sequence in $(Y, \bar{d})$. Hence this sequence converges, say to a point $y_{\alpha}$. Let $f: J \rightarrow Y$ be the function defined by $f(\alpha)=y_{\alpha}$. We assert that the sequence $\left(f_{n}\right)$ converges to $f$ in the metric $\bar{\rho}$.

Given $\epsilon>0$, first choose $N$ large enough that $\bar{\rho}\left(f_{n}, f_{m}\right)<\epsilon / 2$ whenever $n, m \geq$ $N$. Then, in particular,

$$
\bar{d}\left(f_{n}(\alpha), f_{m}(\alpha)\right)<\epsilon / 2
$$

for $n, m \geq N$ and $\alpha \in J$. Letting $n$ and $\alpha$ be fixed, and letting $m$ become arbitrarily large, we see that

$$
\bar{d}\left(f_{n}(\alpha), f(\alpha)\right) \leq \epsilon / 2
$$

This inequality holds for all $\alpha$ in $J$, provided merely that $n \geq N$. Therefore,

$$
\bar{\rho}\left(f_{n}, f\right) \leq \epsilon / 2<\epsilon
$$

for $n \geq N$, as desired.

Now let us specialize somewhat, and consider the set $Y^{X}$ where $X$ is a topological space rather than merely a set. Of course, this has no effect on what has gone before; the topology of $X$ is irrelevant when considering the set of all functions $f: X \rightarrow Y$. But suppose that we consider the subset $\mathcal{C}(X, Y)$ of $Y^{X}$ consisting of all continuous functions $f: X \rightarrow Y$. It turns out that if $Y$ is complete, this subset is also complete in the uniform metric. The same holds for the set $\mathcal{B}(X, Y)$ of all bounded functions $f: X \rightarrow Y$. (A function $f$ is said to be bounded if its image $f(X)$ is a bounded subset of the metric space $(Y, d)$.)

Theorem 43.6. Let $X$ be a topological space and let $(Y, d)$ be a metric space. The set $\mathcal{C}(X, Y)$ of continuous functions is closed in $Y^{X}$ under the uniform metric. So is the set $\mathcal{B}(X, Y)$ of bounded functions. Therefore, if $Y$ is complete, these spaces are complete in the uniform metric.

Proof. The first part of this theorem is just the uniform limit theorem (Theorem 21.6) in a new guise. First, we show that if a sequence of elements $f_{n}$ of $Y^{X}$ converges to the element $f$ of $Y^{X}$ relative to the metric $\bar{\rho}$ on $Y^{X}$, then it converges to $f$ uniformly in the sense defined in $\S 21$, relative to the metric $\bar{d}$ on $Y$. Given $\epsilon>0$, choose an integer $N$ such that

$$
\bar{\rho}\left(f, f_{n}\right)<\epsilon
$$

for all $n>N$. Then for all $x \in X$ and all $n \geq N$,

$$
\bar{d}\left(f_{n}(x), f(x)\right) \leq \bar{\rho}\left(f_{n}, f\right)<\epsilon .
$$

Thus $\left(f_{n}\right)$ converges uniformly to $f$.

Now we show that $\mathcal{C}(X, Y)$ is closed in $Y^{X}$ relative to the metric $\bar{\rho}$. Let $f$ be an element of $Y^{X}$ that is a limit point of $\mathcal{C}(X, Y)$. Then there is a sequence $\left(f_{n}\right)$ of elements of $\mathcal{C}(X, Y)$ converging to $f$ in the metric $\bar{\rho}$. By the uniform limit theorem, $f$ is continuous, so that $f \in \mathcal{C}(X, Y)$.

Finally, we show that $\mathcal{B}(X, Y)$ is closed in $Y^{X}$. If $f$ is a limit point of $\mathcal{B}(X, Y)$, there is a sequence of elements $f_{n}$ of $\mathcal{B}(X, Y)$ converging to $f$. Choose $N$ so large that $\bar{\rho}\left(f_{N}, f\right)<1 / 2$. Then for $x \in X$, we have $\bar{d}\left(f_{N}(x), f(x)\right)<1 / 2$, which implies that $d\left(f_{N}(x), f(x)\right)<1 / 2$. It follows that if $M$ is the diameter of the set $f_{N}(X)$, then $f(X)$ has diameter at most $M+1$. Hence $f \in \mathcal{B}(X, Y)$.

We conclude that $\mathcal{C}(X, Y)$ and $\mathscr{B}(X, Y)$ are complete in the metric $\bar{\rho}$ if $Y$ is complete in $d$.

Definition. If $(Y, d)$ is a metric space, one can define another metric on the set $\mathcal{B}(X, Y)$ of bounded functions from $X$ to $Y$ by the equation

$$
\rho(f, g)=\sup \{d(f(x), g(x)) \mid x \in X\} \text {. }
$$

It is easy to see that $\rho$ is well-defined, for the set $f(X) \cup g(X)$ is bounded if both $f(X)$ and $g(X)$ are. The metric $\rho$ is called the sup metric.

There is a simple relation between the sup metric and the uniform metric. Indeed, if $f, g \in \mathscr{B}(X, Y)$, then

$$
\bar{\rho}(f, g)=\min \{\rho(f, g), 1\} .
$$

For if $\rho(f, g)>1$, then $d\left(f\left(x_{0}\right), g\left(x_{0}\right)\right)>1$ for at least one $x_{0} \in X$, so that $\bar{d}\left(f\left(x_{0}\right), g\left(x_{0}\right)\right)=1$ and $\bar{\rho}(f, g)=1$ by definition. On the other hand, if $\rho(f, g) \leq 1$, then $\bar{d}(f(x), g(x))=d(f(x), g(x)) \leq 1$ for all $x$, so that $\bar{\rho}(f, g)=\rho(f, g)$. Thus on $\mathcal{B}(X, Y)$, the metric $\bar{\rho}$ is just the standard bounded metric derived from the metric $\rho$. That is the reason we introduced the notation $\bar{\rho}$ for the uniform metric, back in $\S 20$ !

If $X$ is a compact space, then every continuous function $f: X \rightarrow Y$ is bounded; hence the sup metric is defined on $\mathcal{C}(X, Y)$. If $Y$ is complete under $d$, then $\mathcal{C}(X, Y)$ is complete under the corresponding uniform metric $\bar{\rho}$, so it is also complete under the sup metric $\rho$. We often use the sup metric rather than the uniform metric in this situation.

We now prove a classical theorem, to the effect that every metric space can be imbedded isometrically in a complete metric space. (A different proof, somewhat more direct, is outlined in Exercise 9.) Although we shall not need this theorem, it is useful in other parts of mathematics.

*Theorem 43.7. Let $(X, d)$ be a metric space. There is an isometric imbedding of $X$ into a complete metric space.

Proof. Let $\mathcal{B}(X, \mathbb{R})$ be the set of all bounded functions mapping $X$ into $\mathbb{R}$. Let $x_{0}$ be a fixed point of $X$. Given $a \in X$, define $\phi_{a}: X \rightarrow \mathbb{R}$ by the equation

$$
\phi_{a}(x)=d(x, a)-d\left(x, x_{0}\right) .
$$

We assert that $\phi_{a}$ is bounded. For it follows, from the inequalities

$$
\begin{aligned}
d(x, a) & \leq d(x, b)+d(a, b) \\
d(x, b) & \leq d(x, a)+d(a, b)
\end{aligned}
$$

that

$$
|d(x, a)-d(x, b)| \leq d(a, b) .
$$

Setting $b=x_{0}$, we conclude that $\left|\phi_{a}(x)\right| \leq d\left(a, x_{0}\right)$ for all $x$.

Define $\Phi: X \rightarrow \mathscr{B}(X, \mathbb{R})$ by setting

$$
\Phi(a)=\phi_{a} .
$$

We show that $\Phi$ is an isometric imbedding of $(X, d)$ into the complete metric space $(\mathcal{B}(X, \mathbb{R}), \rho)$. That is, we show that for every pair of points $a, b \in X$,

$$
\rho\left(\phi_{a}, \phi_{b}\right)=d(a, b) .
$$

By definition,

$$
\begin{aligned}
\rho\left(\phi_{a}, \phi_{b}\right) & =\sup \left\{\left|\phi_{a}(x)-\phi_{b}(x)\right| ; x \in X\right\} \\
& =\sup \{|d(x, a)-d(x, b)| ; x \in X\} .
\end{aligned}
$$

We conclude that

$$
\rho\left(\phi_{a}, \phi_{b}\right) \leq d(a, b)
$$

On the other hand, this inequality cannot be strict, for when $x=a$,

$$
|d(x, a)-d(x, b)|=d(a, b) .
$$

Definition. Let $X$ be a metric space. If $h: X \rightarrow Y$ is an isometric imbedding of $X$ into a complete metric space $Y$, then the subspace $\overline{h(X)}$ of $Y$ is a complete metric space. It is called the completion of $X$.

The completion of $X$ is uniquely determined up to an isometry. See Exercise 10.

## Exercises

1. Let $X$ be a metric space.

(a) Suppose that for some $\epsilon>0$, every $\epsilon$-ball in $X$ has compact closure. Show that $X$ is complete.

(b) Suppose that for each $x \in X$ there is an $\epsilon>0$ such that the ball $B(x, \epsilon)$ has compact closure. Show by means of an example that $X$ need not be complete.

2. Let $\left(X, d_{X}\right)$ and $\left(Y, d_{Y}\right)$ be metric spaces; let $Y$ be complete. Let $A \subset X$. Show that if $f: A \rightarrow Y$ is uniformly continuous, then $f$ can be uniquely extended to a continuous function $g: \bar{A} \rightarrow Y$, and $g$ is uniformly continuous.
3. Two metrics $d$ and $d^{\prime}$ on a set $X$ are said to be metrically equivalent if the identity map $i:(X, d) \rightarrow\left(X, d^{\prime}\right)$ and its inverse are both uniformly continuous.

(a) Show that $d$ is metrically equivalent to the standard bounded metric $\bar{d}$ derived from $d$.

(b) Show that if $d$ and $d^{\prime}$ are metrically equivalent, then $X$ is complete under $d$ if and only if it is complete under $d^{\prime}$.

4. Show that the metric space $(X, d)$ is complete if and only if for every nested sequence $A_{1} \supset A_{2} \supset \cdots$ of nonempty closed sets of $X$ such that diam $A_{n} \rightarrow 0$, the intersection of the sets $A_{n}$ is nonempty.
5. If $(X, d)$ is a metric space, recall that a map $f: X \rightarrow X$ is called a contraction if there is a number $\alpha<1$ such that

$$
d(f(x), f(y)) \leq \alpha d(x, y)
$$

for all $x, y \in X$. Show that if $f$ is a contraction of a complete metric space, then there is a unique point $x \in X$ such that $f(x)=x$. Compare Exercise 7 of $\S 28$.

6. A space $X$ is said to be topologically complete if there exists a metric for the topology of $X$ relative to which $X$ is complete.

(a) Show that a closed subspace of a topologically complete space is topologically complete.

(b) Show that a countable product of topologically complete spaces is topologically complete (in the product topology).

(c) Show that an open subspace of a topologically complete space is topologically complete. [Hint: If $U \subset X$ and $X$ is complete under the metric $d$, define $\phi: U \rightarrow \mathbb{R}$ by the equation

$$
\phi(x)=1 / d(x, X-U) .
$$

Imbed $U$ in $X \times \mathbb{R}$ by setting $f(x)=x \times \phi(x)$.]

(d) Show that if $A$ is a $G_{\delta}$ set in a topologically complete space, then $A$ is topologically complete. [Hint: Let $A$ be the intersection of the open sets $U_{n}$, for $n \in \mathbb{Z}_{+}$. Consider the diagonal imbedding $f(a)=(a, a, \ldots)$ of $A$ into $\prod U_{n}$.] Conclude that the irrationals are topologically complete.

7. Show that the set of all sequences $\left(x_{1}, x_{2}, \ldots\right)$ such that $\sum x_{i}^{2}$ converges is complete in the $\ell^{2}$-metric. (See Exercise 8 of $\S 20$.)
8. If $X$ and $Y$ are spaces, define

$$
e: X \times \mathcal{C}(X, Y) \rightarrow Y
$$

by the equation $e(x, f)=f(x)$; the map $e$ is called the evaluation map. Show that if $d$ is a metric for $Y$ and $\mathcal{C}(X, Y)$ has the corresponding uniform topology, then $e$ is continuous. We shall generalize this result in $\$ 46$.

9. Let $(X, d)$ be a metric space. Show that there is an isometric imbedding $h$ of $X$ into a complete metric space $(Y, D)$, as follows: Let $\tilde{X}$ denote the set of all Cauchy sequences

$$
\mathbf{x}=\left(x_{1}, x_{2}, \ldots\right)
$$

of points of $X$. Define $\mathbf{x} \sim \mathbf{y}$ if

$$
d\left(x_{n}, y_{n}\right) \longrightarrow 0 .
$$

Let $[\mathbf{x}]$ denote the equivalence class of $\mathbf{x}$; and let $Y$ denote the set of these equivalence classes. Define a metric $D$ on $Y$ by the equation

$$
D([\mathbf{x}],[\mathbf{y}])=\lim _{n \rightarrow \infty} d\left(x_{n}, y_{n}\right) .
$$

(a) Show that $\sim$ is an equivalence relation, and show that $D$ is a well-defined metric.

(b) Define $h: X \rightarrow Y$ by letting $h(x)$ be the equivalence class of the constant sequence $(x, x, \ldots)$ :

$$
h(x)=[(x, x, \ldots)]
$$

Show that $h$ is an isometric imbedding.

(c) Show that $h(X)$ is dense in $Y$; indeed, given $\mathbf{x}=\left(x_{1}, x_{2}, \ldots\right) \in \tilde{X}$, show the sequence $h\left(x_{n}\right)$ of points of $Y$ converges to the point [x] of $Y$.

(d) Show that if $A$ is a dense subset of a metric space $(Z, \rho)$, and if every Cauchy sequence in $A$ converges in $Z$, then $Z$ is complete.

(e) Show that $(Y, D)$ is complete.

10. Theorem (Uniqueness of the completion). Let $h: X \rightarrow Y$ and $h^{\prime}: X \rightarrow Y^{\prime}$ be isometric imbeddings of the metric space $(X, d)$ in the complete metric spaces $(Y, D)$ and $\left(Y^{\prime}, D^{\prime}\right)$, respectively. Then there is an isometry of $(\overline{h(X)}, D)$ with $\left(\overline{h^{\prime}(X)}, D^{\prime}\right)$ that equals $h^{\prime} h^{-1}$ on the subspace $h(X)$.

## *§44 A Space-Filling Curve

As an application of the completeness of the metric space $\mathcal{C}(X, Y)$ in the uniform metric when $Y$ is complete, we shall construct the famous "Peano space-filling curve."

Theorem 44.1. Let $I=[0,1]$. There exists a continuous map $f: I \rightarrow I^{2}$ whose image fills up the entire square $I^{2}$.

The existence of this path violates one's naive geometric intuition in much the same way as does the existence of the continuous nowhere-differentiable function (which we shall come to later).

Proof. Step 1. We shall construct the map $f$ as the limit of a sequence of continuous functions $f_{n}$. First we describe a particular operation on paths, which will be used to generate the sequence $f_{n}$.

Begin with an arbitrary closed interval $[a, b]$ in the real line and an arbitrary square in the plane with sides parallel to the coordinate axes, and consider the triangular path $g$ pictured in Figure 44.1. It is a continuous map of $[a, b]$ into the square. The operation we wish to describe replaces the path $g$ by the path $g^{\prime}$ pictured in Figure 44.2. It is made up of four triangular paths, each half the size of $g$. Note that $g$ and $g^{\prime}$ have the same initial point and the same final point. You can write the equations for $g$ and $g^{\prime}$ if you like.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-273.jpg?height=291&width=713&top_left_y=1098&top_left_x=837)

Figure 44.1

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-273.jpg?height=294&width=718&top_left_y=1527&top_left_x=840)

Figure 44.2

This same operation can also be applied to any triangular path connecting two adjacent corners of the square. For instance, when applied to the path $h$ pictured in Figure 44.3, it gives the path $h^{\prime}$.

Step 2. Now we define a sequence of functions $f_{n}: I \rightarrow I^{2}$. The first function, which we label $f_{0}$ for convenience, is the triangular path pictured in Figure 44.1, letting $a=0$ and $b=1$. The next function $f_{1}$ is the function obtained by applying the operation described in Step 1 to the function $f_{0}$; it is pictured in Figure 44.2. The next function $f_{2}$ is the function obtained by applying this same operation to each of the four
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-274.jpg?height=286&width=1072&top_left_y=365&top_left_x=482)

Figure 44.3

triangular paths that make up $f_{1}$. It is pictured in Figure 44.4. The next function $f_{3}$ is obtained by applying the operation to each of the 16 triangular paths that make up $f_{2}$; it is pictured in Figure 44.5. And so on. At the general step, $f_{n}$ is a path made up of $4^{n}$ triangular paths of the type considered in Step 1, each lying in a square of edge length $1 / 2^{n}$. The function $f_{n+1}$ is obtained by applying the operation of Step 1 to these triangular paths, replacing each one by four smaller triangular paths.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-274.jpg?height=444&width=1107&top_left_y=1138&top_left_x=468)

Figure 44.4

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-274.jpg?height=441&width=1071&top_left_y=1772&top_left_x=483)

Figure 44.5

Step 3. For purposes of this proof, let $d(\mathbf{x}, \mathbf{y})$ denote the square metric on $\mathbb{R}^{2}$,

$$
d(\mathbf{x}, \mathbf{y})=\max \left\{\left|x_{1}-y_{1}\right|,\left|x_{2}-y_{2}\right|\right\} .
$$

Then we can let $\rho$ denote the corresponding sup metric on $C\left(I, I^{2}\right)$ :

$$
\rho(f, g)=\sup \{d(f(t), g(t)) \mid t \in I\} \text {. }
$$

Because $I^{2}$ is closed in $\mathbb{R}^{2}$, it is complete in the square metric; then $C\left(I, I^{2}\right)$ is complete in the metric $\rho$.

We assert that the sequence of functions $\left(f_{n}\right)$ defined in Step 2 is a Cauchy sequence under $\rho$. To prove this fact, let us examine what happens when we pass from $f_{n}$ to $f_{n+1}$. Each of the small triangular paths that make up $f_{n}$ lies in a square of edge length $1 / 2^{n}$. The operation by which we obtain $f_{n+1}$ replaces each such triangular path by four triangular paths that lie in the same square. Therefore, in the square

metric on $I^{2}$, the distance between $f_{n}(t)$ and $f_{n+1}(t)$ is at most $1 / 2^{n}$. As a result, $\rho\left(f_{n}, f_{n+1}\right) \leq 1 / 2^{n}$. It follows that $\left(f_{n}\right)$ is a Cauchy sequence, since

$$
\rho\left(f_{n}, f_{n+m}\right) \leq 1 / 2^{n}+1 / 2^{n+1}+\cdots+1 / 2^{n+m-1}<2 / 2^{n}
$$

for all $n$ and $m$.

Step 4. Because $\mathcal{C}\left(I, I^{2}\right)$ is complete, the sequence $f_{n}$ converges to a continuous function $f: I \rightarrow I^{2}$. We prove that $f$ is surjective.

Let $\mathbf{x}$ be a point of $I^{2}$; we show that $\mathbf{x}$ belongs to $f(I)$. First we note that, given $n$, the path $f_{n}$ comes within a distance of $1 / 2^{n}$ of the point $\mathbf{x}$. For the path $f_{n}$ touches each of the little squares of edge length $1 / 2^{n}$ into which we have divided $I^{2}$.

Using this fact, we shall prove that, given $\epsilon>0$, the $\epsilon$-neighborhood of $\mathbf{x}$ intersects $f(I)$. Choose $N$ large enough that

$$
\rho\left(f_{N}, f\right)<\epsilon / 2 \text { and } 1 / 2^{N}<\epsilon / 2 \text {. }
$$

By the result of the previous paragraph, there is a point $t_{0} \in I$ such that $d\left(\mathbf{x}, f_{N}\left(t_{0}\right)\right) \leq$ $1 / 2^{N}$. Then since $d\left(f_{N}(t), f(t)\right)<\epsilon / 2$ for all $t$, it follows that

$$
d\left(\mathbf{x}, f\left(t_{0}\right)\right)<\epsilon
$$

so the $\epsilon$-neighborhood of $\mathbf{x}$ intersects $f(I)$.

It follows that $\mathbf{x}$ belongs to the closure of $f(I)$. But $I$ is compact, so $f(I)$ is compact and is therefore closed. Hence $\mathbf{x}$ lies in $f(I)$, as desired.

## Exercises

1. Given $n$, show there is a continuous surjective map $g: I \rightarrow I^{n}$. [Hint: Consider $f \times f: I \times I \rightarrow I^{2} \times I^{2}$.]
2. Show there is a continuous surjective map $f: \mathbb{R} \rightarrow \mathbb{R}^{n}$.
3. (a) If $\mathbb{R}^{\omega}$ is given the product topology, show there is no continuous surjective $\operatorname{map} f: \mathbb{R} \rightarrow \mathbb{R}^{\omega}$. [Hint: Show that $\mathbb{R}^{\omega}$ is not a countable union of compact subspaces.]

(b) If $\mathbb{R}^{\omega}$ is given the product topology, determine whether or not there is a continuous surjective map of $\mathbb{R}$ onto the subspace $\mathbb{R}^{\infty}$.

(c) What happens to the statements in (a) and (b) if $\mathbb{R}^{\omega}$ is given the uniform topology or the box topology?

4. (a) Let $X$ be a Hausdorff space. Show that if there is a continuous surjective map $f: I \rightarrow X$, then $X$ is compact, connected, weakly locally connected, and metrizable. [Hint: Show $f$ is a perfect map.]

(b) The converse of the result in (a) is a famous theorem of point-set topology called the Hahn-Mazurkiewicz theorem (see [H-Y], p. 129). Assuming this theorem, show there is a continuous surjective map $f: I \rightarrow I^{\omega}$.

A Hausdorff space that is the continuous image of the closed unit interval is often called a Peano space.

## $\$ 45$ Compactness in Metric Spaces

We have already shown that compactness, limit point compactness, and sequential compactness are equivalent for metric spaces. There is still another formulation of compactness for metric spaces, one that involves the notion of completeness. We study it in this section. As an application, we shall prove a theorem characterizing those subspaces of $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ that are compact in the uniform topology.

How is compactness of a metric space $X$ related to completeness of $X$ ? It follows from Lemma 43.1 that every compact metric space is complete. The converse does not hold-a complete metric space need not be compact. It is reasonable to ask what extra condition one needs to impose on a complete space to be assured of its compactness. Such a condition is the one called total boundedness.

Definition. A metric space $(X, d)$ is said to be totally bounded if for every $\epsilon>0$, there is a finite covering of $X$ by $\epsilon$-balls.

EXAMPLE 1. Total boundedness clearly implies boundedness. For if $B\left(x_{1}, 1 / 2\right), \ldots$, $B\left(x_{n}, 1 / 2\right)$ is a finite covering of $X$ by open balls of radius $1 / 2$, then $X$ has diameter at $\operatorname{most} 1+\max \left\{d\left(x_{i}, x_{j}\right)\right\}$. The converse does not hold, however. For example, in the metric $\bar{d}(a, b)=\min \{1,|a-b|\}$, the real line $\mathbb{R}$ is bounded but not totally bounded.

EXAMPLE 2. Under the metric $d(a, b)=|a-b|$, the real line $\mathbb{R}$ is complete but not totally bounded, while the subspace $(-1,1)$ is totally bounded but not complete. The subspace $[-1,1]$ is both complete and totally bounded.

Theorem 45.1. A metric space $(X, d)$ is compact if and only if it is complete and totally bounded.

Proof. If $X$ is a compact metric space, then $X$ is complete, as noted above. The fact that $X$ is totally bounded is a consequence of the fact that the covering of $X$ by all open $\epsilon$-balls must contain a finite subcovering.

Conversely, let $X$ be complete and totally bounded. We shall prove that $X$ is sequentially compact. This will suffice.

Let $\left(x_{n}\right)$ be a sequence of points of $X$. We shall construct a subsequence of $\left(x_{n}\right)$ that is a Cauchy sequence, so that it necessarily converges. First cover $X$ by finitely many balls of radius 1 . At least one of these balls, say $B_{1}$, contains $x_{n}$ for infinitely many values of $n$. Let $J_{1}$ be the subset of $\mathbb{Z}_{+}$consisting of those indices $n$ for which $x_{n} \in B_{1}$.

Next, cover $X$ by finitely many balls of radius $1 / 2$. Because $J_{1}$ is infinite, at least one of these balls, say $B_{2}$, must contain $x_{n}$ for infinitely many values of $n$ in $J_{1}$. Choose $J_{2}$ to be the set of those indices $n$ for which $n \in J_{1}$ and $x_{n} \in B_{2}$. In general, given an infinite set $J_{k}$ of positive integers, choose $J_{k+1}$ to be an infinite subset of $J_{k}$ such that there is a ball $B_{k+1}$ of radius $1 /(k+1)$ that contains $x_{n}$ for all $n \in J_{k+1}$.

Choose $n_{1} \in J_{1}$. Given $n_{k}$, choose $n_{k+1} \in J_{k+1}$ such that $n_{k+1}>n_{k}$; this we can do because $J_{k+1}$ is an infinite set. Now for $i, j \geq k$, the indices $n_{i}$ and $n_{j}$ both belong to $J_{k}$ (because $J_{1} \supset J_{2} \supset \cdots$ is a nested sequence of sets). Therefore, for all $i, j \geq k$, the points $x_{n_{i}}$ and $x_{n_{j}}$ are contained in a ball $B_{k}$ of radius $1 / k$. It follows that the sequence $\left(x_{n_{i}}\right)$ is a Cauchy sequence, as desired.

We now apply this result to find the compact subspaces of the space $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$, in the uniform topology. We know that a subspace of $\mathbb{R}^{n}$ is compact if and only if it is closed and bounded. One might hope that an analogous result holds for $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$. But it does not, even if $X$ is compact. One needs to assume that the subspace of $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ satisfies an additional condition, called equicontinuity. We consider that notion now.

Definition. Let $(Y, d)$ be a metric space. Let $\mathcal{F}$ be a subset of the function space $\mathcal{C}(X, Y)$. If $x_{0} \in X$, the set $\mathcal{F}$ of functions is said to be equicontinuous at $x_{0}$ if given $\epsilon>0$, there is a neighborhood $U$ of $x_{0}$ such that for all $x \in U$ and all $f \in \mathcal{F}$,

$$
d\left(f(x), f\left(x_{0}\right)\right)<\epsilon
$$

If the set $\mathcal{F}$ is equicontinuous at $x_{0}$ for each $x_{0} \in X$, it is said simply to be equicontinuous.

Continuity of the function $f$ at $x_{0}$ means that given $f$ and given $\epsilon>0$, there exists a neighborhood $U$ of $x_{0}$ such that $d\left(f(x), f\left(x_{0}\right)\right)<\epsilon$ for $x \in U$. Equicontinuity of $\mathcal{F}$ means that a single neighborhood $U$ can be chosen that will work for all the functions $f$ in the collection $\mathcal{F}$.

Note that equicontinuity depends on the specific metric $d$ rather than merely on the topology of $Y$.

Lemma 45.2. Let $X$ be a space; let $(Y, d)$ be a metric space. If the subset $\mathcal{F}$ of $\mathcal{C}(X, Y)$ is totally bounded under the uniform metric corresponding to $d$, then $\mathcal{F}$ is equicontinuous under $d$.

Proof. Assume $\mathcal{F}$ is totally bounded. Given $0<\epsilon<1$, and given $x_{0}$, we find a neighborhood $U$ of $x_{0}$ such that $d\left(f(x), f\left(x_{0}\right)<\epsilon\right.$ for $x \in U$ and $f \in \mathcal{F}$.

Set $\delta=\epsilon / 3$; cover $\mathcal{F}$ by finitely many open $\delta$-balls

$$
B\left(f_{1}, \delta\right), \ldots, B\left(f_{n}, \delta\right)
$$

in $\mathcal{C}(X, Y)$. Each function $f_{i}$ is continuous; therefore, we can choose a neighborhood $U$ of $x_{0}$ such that for $i=1, \ldots, n$,

$$
d\left(f_{i}(x), f_{i}\left(x_{0}\right)\right)<\delta
$$

whenever $x \in U$.

Let $f$ be an arbitrary element of $\mathcal{F}$. Then $f$ belongs to at least one of the above $\delta$-balls, say to $B\left(f_{i}, \delta\right)$. Then for $x \in U$, we have

$$
\begin{aligned}
\bar{d}\left(f(x), f_{i}(x)\right) & <\delta, \\
d\left(f_{i}(x), f_{i}\left(x_{0}\right)\right) & <\delta, \\
\bar{d}\left(f_{i}\left(x_{0}\right), f\left(x_{0}\right)\right) & <\delta .
\end{aligned}
$$

The first and third inequalities hold because $\bar{\rho}\left(f, f_{i}\right)<\delta$, and the second holds because $x \in U$. Since $\delta<1$, the first and third also hold if $\bar{d}$ is replaced by $d$; then the triangle inequality implies that for all $x \in U$, we have $d\left(f(x), f\left(x_{0}\right)\right)<\epsilon$, as desired.

Now we prove the classical version of Ascoli's theorem, which concerns compact subspaces of the function space $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$. A more general version, whose proof does not depend on this one, is given in $\S 47$. The general version, however, relies on the Tychonoff theorem, whereas this one does not.

We begin by proving a partial converse to the preceding lemma, which holds when $X$ and $Y$ are compact.

*Lemma 45.3. Let $X$ be a space; let $(Y, d)$ be a metric space; assume $X$ and $Y$ are compact. If the subset $\mathcal{F}$ of $\mathcal{C}(X, Y)$ is equicontinuous under $d$, then $\mathcal{F}$ is totally bounded under the uniform and sup metrics corresponding to $d$.

Proof. Since $X$ is compact, the sup metric $\rho$ is defined on $\mathcal{C}(X, Y)$. Total boundedness under $\rho$ is equivalent to total boundedness under $\bar{\rho}$, for whenever $\epsilon<1$, every $\epsilon$-ball under $\rho$ is also an $\epsilon$-ball under $\bar{\rho}$, and conversely. Therefore, we may as well use the metric $\rho$ throughout.

Assume $\mathcal{F}$ is equicontinuous. Given $\epsilon>0$, we cover $\mathcal{F}$ by finitely many sets that are open $\epsilon$-balls in the metric $\rho$.

Set $\delta=\epsilon / 3$. Given any $a \in X$, there is a corresponding neighborhood $U_{a}$ of $a$ such that $d(f(x), f(a))<\delta$ for all $x \in U_{a}$ and all $f \in \mathcal{F}$. Cover $X$ by finitely many such neighborhoods $U_{a}$, for $a=a_{1}, \ldots, a_{k}$; denote $U_{a_{i}}$ by $U_{i}$. Then cover $Y$ by finitely many open sets $V_{1}, \ldots, V_{m}$ of diameter less than $\delta$.

Let $J$ be the collection of all functions $\alpha:\{1, \ldots, k\} \rightarrow\{1, \ldots, m\}$. Given $\alpha \in J$, if there exists a function $f$ of $\mathcal{F}$ such that $f\left(a_{i}\right) \in V_{\alpha(i)}$ for each $i=1, \ldots, k$, choose one such function and label it $f_{\alpha}$. The collection $\left\{f_{\alpha}\right\}$ is indexed by a subset $J^{\prime}$ of the set $J$ and is thus finite. We assert that the open balls $B_{\rho}\left(f_{\alpha}, \epsilon\right)$, for $\alpha \in J^{\prime}$, cover $\mathcal{F}$.

Let $f$ be an element of $\mathcal{F}$. For each $i=1, \ldots, k$, choose an integer $\alpha(i)$ such that $f\left(a_{i}\right) \in V_{\alpha(i)}$. Then the function $\alpha$ is in $J^{\prime}$. We assert that $f$ belongs to the ball $B_{\rho}\left(f_{\alpha}, \epsilon\right)$.

Let $x$ be a point of $X$. Choose $i$ so that $x \in U_{i}$. Then

$$
\begin{aligned}
d\left(f(x), f\left(a_{i}\right)\right) & <\delta, \\
d\left(f\left(a_{i}\right), f_{\alpha}\left(a_{i}\right)\right) & <\delta, \\
d\left(f_{\alpha}\left(a_{i}\right), f_{\alpha}(x)\right) & <\delta .
\end{aligned}
$$

The first and third inequalities hold because $x \in U_{i}$, and the second holds because $f\left(a_{i}\right)$ and $f_{\alpha}\left(a_{i}\right)$ are in $V_{\alpha(i)}$. We conclude that $d\left(f(x), f_{\alpha}(x)\right)<\epsilon$. Because this inequality holds for every $x \in X$,

$$
\rho\left(f, f_{\alpha}\right)=\max \left\{d\left(f(x), f_{\alpha}(x)\right)\right\}<\epsilon
$$

Thus $f$ belongs to $B_{\rho}\left(f_{\alpha}, \epsilon\right)$, as asserted.

Definition. If $(Y, d)$ is a metric space, a subset $\mathcal{F}$ of $\mathcal{C}(X, Y)$ is said to be pointwise bounded under $d$ if for each $x \in X$, the subset

$$
\mathcal{F}_{a}=\{f(a) \mid f \in \mathcal{F}\}
$$

of $Y$ is bounded under $d$.

*Theorem 45.4 (Ascoli's theorem, classical version). Let $X$ be a compact space; let $\left(\mathbb{R}^{n}, d\right)$ denote euclidean space in either the square metric or the euclidean metric; give $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ the corresponding uniform topology. A subspace $\mathcal{F}$ of $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ has compact closure if and only if $\mathcal{F}$ is equicontinuous and pointwise bounded under $d$.

Proof. Since $X$ is compact, the sup metric $\rho$ is defined on $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ and gives the uniform topology on $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$. Throughout, let $\mathcal{g}$ denote the closure of $\mathcal{F}$ in $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$.

Step 1. We show that if $\mathcal{G}$ is compact, then $\mathcal{g}$ is equicontinuous and pointwise bounded under $d$. Since $\mathcal{F} \subset \mathcal{G}$, it follows that $\mathcal{F}$ is also equicontinuous and pointwise bounded under $d$. This proves the "only if" part of the theorem.

Compactness of $\mathcal{G}$ implies that $\mathcal{G}$ is totally bounded under $\rho$ and $\bar{\rho}$ by Theorem 45.1; this in turn implies that $g$ is equicontinuous under $d$, by Lemma 45.2. Compactness of $\mathcal{G}$ also implies that $\mathcal{G}$ is bounded under $\rho$; this in turn implies that $\mathcal{g}$ is
pointwise bounded under $d$. For if $\rho(f, g) \leq M$ for all $f, g \in \mathcal{g}$, then in particular $d(f(a), g(a)) \leq M$ for $f, g \in \mathcal{G}$, so that $g_{a}$ has diameter at most $M$.

Step 2. We show that if $\mathcal{F}$ is equicontinuous and pointwise bounded under $d$, then so is $g$.

First, we check equicontinuity. Given $x_{0} \in X$ and given $\epsilon>0$, choose a neighborhood $U$ of $x_{0}$ such that $d\left(f(x), f\left(x_{0}\right)\right)<\epsilon / 3$ for all $x \in U$ and $f \in \mathcal{F}$. Given $g \in \mathcal{g}$, choose $f \in \mathcal{F}$ so that $\rho(f, g)<\epsilon / 3$. The triangle inequality implies that $d\left(g(x), g\left(x_{0}\right)\right)<\epsilon$ for all $x \in U$. Since $g$ is arbitrary, equicontinuity of $g$ at $x_{0}$ follows.

Second, we verify pointwise boundedness. Given $a$, choose $M$ so that diam $\mathcal{F}_{a} \leq$ $M$. Then, given $g, g^{\prime} \in \mathcal{G}$, choose $f, f^{\prime} \in \mathcal{F}$ such that $\rho(f, g)<1$ and $\rho\left(f^{\prime}, g^{\prime}\right)<1$. Since $d\left(f(a), f^{\prime}(a)\right) \leq M$, it follows that $d\left(g(a), g^{\prime}(a)\right) \leq M+2$. Then since $g$ and $g^{\prime}$ are arbitrary, it follows that $\operatorname{diam} g_{a} \leq M+2$.

Step 3. We show that if $g$ is equicontinuous and pointwise bounded, then there is a compact subspace $Y$ of $\mathbb{R}^{n}$ that contains the union of the sets $g(X)$, for $g \in \mathcal{G}$.

Choose, for each $a \in X$, a neighborhood $U_{a}$ of $a$ such that $d(g(x), g(a))<1$ for $x \in U_{a}$ and $g \in g$. Since $X$ is compact, we can cover $X$ by finitely many such neighborhoods, say for $a=a_{1}, \ldots, a_{k}$. Because the sets $g_{a_{i}}$ are bounded, their union is also bounded; suppose it lies in the ball of radius $N$ in $\mathbb{R}^{n}$ centered at the origin. Then for all $g \in g$, the set $g(X)$ is contained in the ball of radius $N+1$ centered at the origin. Let $Y$ be the closure of this ball.

Step 4. We prove the "if" part of the theorem. Assume that $\mathcal{F}$ is equicontinuous and pointwise bounded under $d$. We show that $g$ is complete and totally bounded under $\rho$; then Theorem 45.1 implies that $g$ is compact.

Completeness is easy, for $\mathcal{g}$ is a closed subspace of the complete metric space $\left(\mathcal{C}\left(X, \mathbb{R}^{n}\right), \rho\right)$.

We verify total boundedness. First, Step 2 implies that $g$ is equicontinuous and pointwise bounded under $d$; then Step 3 tells us that there is a compact subspace $Y$ of $\mathbb{R}^{n}$ such that $g \subset \mathcal{C}(X, Y)$. Equicontinuity of $g$ now implies, by Lemma 45.3, that $g_{\text {is }}$ is totally bounded under $\rho$, as desired.

*Corollary 45.5. Let $X$ be compact; let $d$ denote either the square metric or the euclidean metric on $\mathbb{R}^{n}$; give $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ the corresponding uniform topology. A subspace $\mathcal{F}$ of $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ is compact if and only if it is closed, bounded under the sup metric $\rho$, and equicontinuous under $d$.

Proof. If $\mathcal{F}$ is compact, it must be closed and bounded; the preceding theorem implies that it is also equicontinuous. Conversely, if $\mathcal{F}$ is closed, it equals its closure $\mathcal{G}$; if it is bounded under $\rho$, it is pointwise bounded under $d$; and if it is also equicontinuous, the preceding theorem implies that it is compact.

## Exercises

1. If $X_{n}$ is metrizable with metric $d_{n}$, then

$$
D(\mathbf{x}, \mathbf{y})=\sup \left\{\bar{d}_{i}\left(x_{i}, y_{i}\right) / i\right\}
$$

is a metric for the product space $X=\prod X_{n}$. Show that $X$ is totally bounded under $D$ if each $X_{n}$ is totally bounded under $d_{n}$. Conclude without using the Tychonoff theorem that a countable product of compact metrizable spaces is compact.

2. Let $(Y, d)$ be a metric space; let $\mathcal{F}$ be a subset of $\mathcal{C}(X, Y)$.

(a) Show that if $\mathcal{F}$ is finite, then $\mathcal{F}$ is equicontinuous.

(b) Show that if $f_{n}$ is a sequence of elements of $\mathcal{C}(X, Y)$ that converges uniformly, then the collection $\left\{f_{n}\right\}$ is equicontinuous.

(c) Suppose that $\mathcal{F}$ is a collection of differentiable functions $f: \mathbb{R} \rightarrow \mathbb{R}$ such that each $x \in \mathbb{R}$ lies in a neighborhood $U$ on which the derivatives of the functions in $\mathscr{F}$ are uniformly bounded. [This means that there is an $M$ such that $\left|f^{\prime}(x)\right| \leq M$ for all $f$ in $\mathcal{F}$ and all $x \in U$.] Show that $\mathcal{F}$ is equicontinuous.

3. Prove the following:

Theorem (Arzela's theorem). Let $X$ be compact; let $f_{n} \in \mathcal{C}\left(X, \mathbb{R}^{k}\right)$. If the collection $\left\{f_{n}\right\}$ is pointwise bounded and equicontinuous, then the sequence $f_{n}$ has a uniformly convergent subsequence.

4. (a) Let $f_{n}: I \rightarrow \mathbb{R}$ be the function $f_{n}(x)=x^{n}$. The collection $\mathcal{F}=\left\{f_{n}\right\}$ is pointwise bounded but the sequence $\left(f_{n}\right)$ has no uniformly convergent subsequence; at what point or points does $\mathscr{F}$ fail to be equicontinuous?

(b) Repeat (a) for the functions $f_{n}$ of Exercise 9 of $\$ 21$.

5. Let $X$ be a space. A subset $\mathscr{F}$ of $\mathcal{C}(X, \mathbb{R})$ is said to vanish uniformly at infinity if given $\epsilon>0$, there is a compact subspace $C$ of $X$ such that $|f(x)|<\epsilon$ for $x \in X-C$ and $f \in \mathcal{F}$. If $\mathscr{F}$ consists of a single function $f$, we say simply that $f$ vanishes at infinity. Let $\mathcal{C}_{0}(X, \mathbb{R})$ denote the set of continuous functions $f: X \rightarrow \mathbb{R}$ that vanish at infinity.

Theorem. Let $X$ be locally compact Hausdorff; give $\mathcal{C}_{0}(X, \mathbb{R})$ the uniform topology. A subset $\mathcal{F}$ of $\mathcal{C}_{0}(X, \mathbb{R})$ has compact closure if and only if is pointwise bounded, equicontinuous, and vanishes uniformly at infinity.

[Hint: Let $Y$ denote the one-point compactification of $X$. Show that $\mathcal{C}_{0}(X, \mathbb{R})$ is isometric with a closed subspace of $\mathcal{C}(Y, \mathbb{R})$ if both are given the sup metric.]

6. Show that our proof of Ascoli's theorem goes through if $\mathbb{R}^{n}$ is replaced by any metric space in which all closed bounded subspaces are compact.

*7. Let $(X, d)$ be a metric space. If $A \subset X$ and $\epsilon>0$, let $U(A, \epsilon)$ be the $\epsilon$ neighborhood of $A$. Let $\mathscr{H}$ be the collection of all (nonempty) closed, bounded subsets of $X$. If $A, B \in \mathscr{H}$, define

$$
D(A, B)=\inf \{\epsilon \mid A \subset U(B, \epsilon) \text { and } B \subset U(A, \epsilon)\}
$$

(a) Show that $D$ is a metric on $\mathscr{H}$; it is called the Hausdorff metric.

(b) Show that if $(X, d)$ is complete, so is $(\mathcal{H}, D)$. [Hint: Let $A_{n}$ be a Cauchy sequence in $\mathscr{H}$; by passing to a subsequence, assume $D\left(A_{n}, A_{n+1}\right)<1 / 2^{n}$. Define $A$ to be the set of all points $x$ that are the limits of sequences $x_{1}, x_{2}$, $\ldots$ such that $x_{i} \in A_{i}$ for each $i$ and $d\left(x_{i}, x_{i+1}\right)<1 / 2^{i}$. Show $A_{n} \rightarrow \bar{A}$.]

(c) Show that if $(X, d)$ is totally bounded, so is $(\mathcal{H}, D)$. [Hint: Given $\epsilon$, choose $\delta<\epsilon$ and let $S$ be a finite subset of $X$ such that the collection $\left\{B_{d}(x, \delta) \mid\right.$ $x \in S\}$ covers $X$. Let $\mathcal{A}$ be the collection of all nonempty subsets of $S$; show that $\left\{B_{D}(A, \epsilon) \mid A \in \mathcal{A}\right\}$ covers $\mathscr{H}$.]

(d) Theorem. If $X$ is compact in the metric $d$, then the space $\mathscr{H}$ is compact in the Hausdorff metric $D$.

*8. Let $\left(X, d_{X}\right)$ and $\left(Y, d_{Y}\right)$ be metric spaces; give $X \times Y$ the corresponding square metric; let $\mathscr{H}$ denote the collection of all nonempty closed, bounded subsets of $X \times Y$ in the resulting Hausdorff metric. Consider the space $\mathcal{C}(X, Y)$ in the uniform metric; let gr : $\mathcal{C}(X, Y) \rightarrow \mathcal{H}$ be the function that assigns, to each continuous function $f: X \rightarrow Y$, its graph

$$
G_{f}=\{x \times f(x) \mid x \in X\} .
$$

(a) Show that the map gr is injective and uniformly continuous.

(b) Let $\mathscr{H}_{0}$ denote the image set of the map gr; let $g: \mathcal{C}(X, Y) \rightarrow \mathscr{H}_{0}$ be the surjective map obtained from gr. Show that if $f: X \rightarrow Y$ is uniformly continuous, then the map $g^{-1}$ is continuous at the point $G_{f}$.

(c) Give an example where $g^{-1}$ is not continuous at the point $G_{f}$.

(d) Theorem. If $X$ is compact, then $g r: \mathcal{C}(X, Y) \rightarrow \mathcal{H}$ is an imbedding.

## §46 Pointwise and Compact Convergence

There are other useful topologies on the spaces $Y^{X}$ and $\mathcal{C}(X, Y)$ in addition to the uniform topology. We shall consider three of them here; they are called the topology of pointwise convergence, the topology of compact convergence, and the compact-open topology.

Definition. Given a point $x$ of the set $X$ and an open set $U$ of the space $Y$, let

$$
S(x, U)=\left\{f \mid f \in Y^{X} \text { and } f(x) \in U\right\} .
$$

The sets $S(x, U)$ are a subbasis for topology on $Y^{X}$, which is called the topology of pointwise convergence (or the point-open topology).

The general basis element for this topology is a finite intersection of subbasis elements $S(x, U)$. Thus a typical basis element about the function $f$ consists of all functions $g$ that are "close" to $f$ at finitely many points. Such a neighborhood is

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-283.jpg?height=652&width=980&top_left_y=368&top_left_x=709)

Figure 46.1

illustrated in Figure 46.1; it consists of all functions $g$ whose graphs intersect the three vertical intervals pictured.

The topology of pointwise convergence on $Y^{X}$ is nothing new. It is just the product topology we have already studied. If we replace $X$ by $J$ and denote the general element of $J$ by $\alpha$ to make it look more familiar, then the set $S(\alpha, U)$ of all functions $\mathbf{x}: J \rightarrow Y$ such that $\mathbf{x}(\alpha) \in U$ is just the subset $\pi_{\alpha}^{-1}(U)$ of $Y^{J}$, which is the standard subbasis element for the product topology.

The reason for calling it the topology of pointwise convergence comes from the following theorem:

Theorem 46.1. A sequence $f_{n}$ of functions converges to the function $f$ in the topology of pointwise convergence if and only if for each $x$ in $X$, the sequence $f_{n}(x)$ of points of $Y$ converges to the point $f(x)$.

Proof. This result is just a reformulation, in function space notation, of a standard result about the product topology proved as Lemma 43.3.

EXAMPLE 1. Consider the space $\mathbb{R}^{I}$, where $I=[0,1]$. The sequence $\left(f_{n}\right)$ of continuous functions given by $f_{n}(x)=x^{n}$ converges in the topology of pointwise convergence to the function $f$ defined by

$$
f(x)= \begin{cases}0 & \text { for } 0 \leq x<1 \\ 1 & \text { for } x=1\end{cases}
$$

This example shows that the subspace $\mathcal{C}(I, \mathbb{R})$ of continuous functions is not closed in $\mathbb{R}^{I}$ in the topology of pointwise convergence.

We know that a sequence $\left(f_{n}\right)$ of continuous functions that converges in the uniform topology has a continuous limit, and the preceding example shows that a sequence that converges only in the topology of pointwise convergence need not. One can ask whether there is a topology intermediate between these two that will suffice to ensure that the limit of a convergent sequence of continuous functions is continuous. The answer is "yes"; assuming the (fairly mild) restriction that the space $X$ be compactly generated, it will suffice if $f_{n}$ converges to $f$ in the topology of compact convergence, which we now define.

Definition. Let $(Y, d)$ be a metric space; let $X$ be a topological space. Given an element $f$ of $Y^{X}$, a compact subspace $C$ of $X$, and a number $\epsilon>0$, let $B_{C}(f, \epsilon)$ denote the set of all those elements $g$ of $Y^{X}$ for which

$$
\sup \{d(f(x), g(x)) \mid x \in C\}<\epsilon .
$$

The sets $B_{C}(f, \epsilon)$ form a basis for a topology on $Y^{X}$. It is called the topology of compact convergence (or sometimes the "topology of uniform convergence on compact sets").

It is easy to show that the sets $B_{C}(f, \epsilon)$ satisfy the conditions for a basis. The crucial step is to note that if $g \in B_{C}(f, \epsilon)$, then for

$$
\delta=\epsilon-\sup \{d(f(x), g(x)) \mid x \in C\},
$$

we have $B_{C}(g, \delta) \subset B_{C}(f, \epsilon)$.

The topology of compact convergence differs from the topology of pointwise convergence in that the general basis element containing $f$ consists of functions that are "close" to $f$ not just at finitely many points, but at all points of some compact set.

The justification for the choice of terminology comes from the following theorem, whose proof is immediate.

Theorem 46.2. A sequence $f_{n}: X \rightarrow Y$ of functions converges to the function $f$ in the topology of compact convergence if and only if for each compact subspace $C$ of $X$, the sequence $f_{n} \mid C$ converges uniformly to $f \mid C$.

Definition. A space $X$ is said to be compactly generated if it satisfies the following condition: A set $A$ is open in $X$ if $A \cap C$ is open in $C$ for each compact subspace $C$ of $X$.

This condition is equivalent to requiring that a set $B$ be closed in $X$ if $B \cap C$ is closed in $C$ for each compact $C$. It is a fairly mild restriction on the space; many familiar spaces are compactly generated. For instance:

Lemma 46.3. If $X$ is locally compact, or if $X$ satisfies the first countability axiom, then $X$ is compactly generated.

Proof. Suppose that $X$ is locally compact. Let $A \cap C$ be open in $C$ for every compact subspace $C$ of $X$. We show $A$ is open in $X$. Given $x \in A$, choose a neighborhood $U$ of $x$ that lies in a compact subspace $C$ of $X$. Since $A \cap C$ is open in $C$ by hypothesis, $A \cap U$ is open in $U$, and hence open in $X$. Then $A \cap U$ is a neighborhood of $x$ contained in $A$, so that $A$ is open in $X$.

Suppose that $X$ satisfies the first countability axiom. If $B \cap C$ is closed in $C$ for each compact subspace $C$ of $X$, we show that $B$ is closed in $X$. Let $x$ be a point of $\bar{B}$; we show that $x \in B$. Since $X$ has a countable basis at $x$, there is a sequence $\left(x_{n}\right)$ of points of $B$ converging to $x$. The subspace

$$
C=\{x\} \cup\left\{x_{n} \mid n \in \mathbb{Z}_{+}\right\}
$$

is compact, so that $B \cap C$ is by assumption closed in $C$. Since $B \cap C$ contains $x_{n}$ for every $n$, it contains $x$ as well. Therefore, $x \in B$, as desired.

The crucial fact about compactly generated spaces is the following:

Lemma 46.4. If $X$ is compactly generated, then a function $f: X \rightarrow Y$ is continuous if for each compact subspace $C$ of $X$, the restricted function $f \mid C$ is continuous.

Proof. Let $V$ be an open subset of $Y$; we show that $f^{-1}(V)$ is open in $X$. Given any subspace $C$ of $X$,

$$
f^{-1}(V) \cap C=(f \mid C)^{-1}(V) .
$$

If $C$ is compact, this set is open in $C$ because $f \mid C$ is continuous. Since $X$ is compactly generated, it follows that $f^{-1}(V)$ is open in $X$.

Theorem 46.5. Let $X$ be a compactly generated space: let $(Y, d)$ be a metric space. Then $\mathcal{C}(X, Y)$ is closed in $Y^{X}$ in the topology of compact convergence.

Proof. Let $f \in Y^{X}$ be a limit point of $\mathcal{C}(X, Y)$; we wish to show $f$ is continuous. It suffices to show that $f \mid C$ is continuous for each compact subspace $C$ of $X$. For each $n$, consider the neighborhood $B_{C}(f, 1 / n)$ of $f$; it intersects $\mathcal{C}(X, Y)$, so we can choose a function $f_{n} \in \mathcal{C}(X, Y)$ lying in this neighborhood. The sequence of functions $f_{n} \mid C: C \rightarrow Y$ converges uniformly to the function $f \mid C$, so that by the uniform limit theorem, $f \mid C$ is continuous.

Corollary 46.6. Let $X$ be a compactly generated space; let $(Y, d)$ be a metric space. If a sequence of continuous functions $f_{n}: X \rightarrow Y$ converges to $f$ in the topology of compact convergence, then $f$ is continuous.

Now we have three topologies for the function space $Y^{X}$ when $Y$ is metric. The relation between them is stated in the following theorem, whose proof is straightforward.

Theorem 46.7. Let $X$ be a space; let $(Y, d)$ be a metric space. For the function space $Y^{X}$, one has the following inclusions of topologies:

(uniform) $\supset$ (compact convergence) $\supset$ (pointwise convergence).

If $X$ is compact, the first two coincide, and if $X$ is discrete, the second two coincide.

Now the definitions of the uniform topology and the compact convergence topology made specific use of the metric $d$ for the space $Y$. But the topology of pointwise convergence did not; in fact, it is defined for any space $Y$. It is natural to ask whether either of these other topologies can be extended to the case where $Y$ is an arbitrary topological space. There is no satisfactory answer to this question for the space $Y^{X}$ of all functions mapping $X$ into $Y$. But for the subspace $\mathcal{C}(X, Y)$ of continuous functions, one can prove something. It turns out that there is in general a topology on $\mathcal{C}(X, Y)$, called the compact-open topology, that coincides with the compact convergence topology when $Y$ is a metric space. This topology is important in its own right, as we shall see.

Definition. Let $X$ and $Y$ be topological spaces. If $C$ is a compact subspace of $X$ and $U$ is an open subset of $\mathrm{Y}$, define

$$
S(C, U)=\{f \mid f \in \mathcal{C}(X, Y) \text { and } f(C) \subset U\}
$$

The sets $S(C, U)$ form a subbasis for a topology on $\mathcal{C}(X, Y)$ that is called the compactopen topology.

It is clear from the definition that the compact-open topology is finer than the pointwise convergence topology. The compact-open topology can in fact be defined on the entire function space $Y^{X}$. It is, however, of interest only for the subspace $\mathcal{C}(X, Y)$, so we shall consider it only for that space.

Theorem 46.8. Let $X$ be a space and let $(Y, d)$ be a metric space. On the set $\mathcal{C}(X, Y)$, the compact-open topology and the topology of compact convergence coincide.

Proof. If $A$ is a subset of $Y$ and $\epsilon>0$, let $U(A, \epsilon)$ be the $\epsilon$-neighborhood of $A$. If $A$ is compact and $V$ is an open set containing $A$, then there is an $\epsilon>0$ such that $U(A, \epsilon) \subset V$. Indeed, the minimum value of the function $d(a, X-V)$ is the required $\epsilon$.

We first prove that the topology of compact convergence is finer than the compactopen topology. Let $S(C, U)$ be a subbasis element for the compact-open topology, and let $f$ be an element of $S(C, U)$. Because $f$ is continuous, $f(C)$ is a compact subset of the open set $U$. Therefore, we can choose $\epsilon$ so that $\epsilon$-neighborhood of $f(C)$ lies in $U$. Then, as desired,

$$
B_{C}(f, \epsilon) \subset S(C, U) .
$$

Now we prove that the compact-open topology is finer than the topology of compact convergence. Let $f \in \mathcal{C}(X, Y)$. Given an open set about $f$ in the topology of
compact convergence, it contains a basis element of the form $B_{C}(f, \epsilon)$. We shall find a basis element for the compact-open topology that contains $f$ and lies in $B_{C}(f, \epsilon)$.

Each point $x$ of $X$ has a neighborhood $V_{x}$ such that $f\left(\bar{V}_{x}\right)$ lies in an open set $U_{x}$ of $Y$ having diameter less than $\epsilon$. [For example, choose $V_{x}$ so that $f\left(V_{x}\right)$ lies in the $\epsilon / 4$-neighborhood of $f(x)$. Then $f\left(\bar{V}_{x}\right)$ lies in the $\epsilon / 3$-neighborhood of $f(x)$, which has diameter at most $2 \epsilon / 3$.] Cover $C$ by finitely many such sets $V_{x}$, say for $x=x_{1}, \ldots, x_{n}$. Let $C_{x}=\bar{V}_{x} \cap C$. Then $C_{x}$ is compact, and the basis element

$$
S\left(C_{x_{1}}, U_{x_{1}}\right) \cap \cdots \cap S\left(C_{x_{n}}, U_{x_{n}}\right)
$$

contains $f$ and lies in $B_{C}(f, \epsilon)$, as desired.

Corollary 46.9. Let $Y$ be a metric space. The compact convergence topology on $\mathcal{C}(X, Y)$ does not depend on the metric of $Y$. Therefore if $X$ is compact, the uniform topology on $\mathcal{C}(X, Y)$ does not depend on the metric of $Y$.

The fact that the definition of the compact-open topology does not involve a metric is just one of its useful features. Another is the fact that it satisfies the requirement of "joint continuity." Roughly speaking, this means that the expression $f(x)$ is continuous not only in the single "variable" $x$, but is continuous jointly in both the "variables" $x$ and $f$. More precisely, one has the following theorem:

Theorem 46.10. Let $X$ be locally compact Hausdorff; let $\mathcal{C}(X, Y)$ have the compactopen topology. Then the map

$$
e: X \times C(X, Y) \rightarrow Y
$$

defined by the equation

$$
e(x, f)=f(x)
$$

is continuous.

The map $e$ is called the evaluation map.

Proof. Given a point $(x, f)$ of $X \times \mathcal{C}(X, Y)$ and an open set $V$ in $Y$ about the image point $e(x, f)=f(x)$, we wish to find an open set about $(x, f)$ that $e$ maps into $V$. First, using the continuity of $f$ and the fact that $X$ is locally compact Hausdorff, we can choose an open set $U$ about $x$ having compact closure $\bar{U}$, such that $f$ carries $\bar{U}$ into $V$. Then consider the open set $U \times S(\bar{U}, V)$ in $X \times \mathcal{C}(X, Y)$. It is an open set containing $(x, f)$. And if $\left(x^{\prime}, f^{\prime}\right)$ belongs to this set, then $e\left(x^{\prime}, f^{\prime}\right)=f^{\prime}\left(x^{\prime}\right)$ belongs to $V$, as desired.

A consequence of this theorem is the theorem that follows. It is useful in algebraic topology.

Definition. Given a function $f: X \times Z \rightarrow Y$, there is a corresponding function $F: Z \rightarrow \mathcal{C}(X, Y)$, defined by the equation

$$
(F(z))(x)=f(x, z) .
$$

Conversely, given $F: Z \rightarrow \mathcal{C}(X, Y)$, this equation defines a corresponding function $f: X \times Z \rightarrow Y$. We say that $F$ is the map of $Z$ into $\mathcal{C}(X, Y)$ that is induced by $f$.

*Theorem 46.11. Let $X$ and $Y$ be spaces; give $\mathcal{C}(X, Y)$ the compact-open topology. If $f: X \times Z \rightarrow Y$ is continuous, then so is the induced function $F: Z \rightarrow \mathcal{C}(X, Y)$. The converse holds if $X$ is locally compact Hausdorff.

Proof. Suppose first that $F$ is continuous and that $X$ is locally compact Hausdorff. It follows that $f$ is continuous, since $f$ equals the composite

$$
X \times Z \xrightarrow{i_{X} \times F} X \times \mathcal{C}(X, Y) \xrightarrow{e} Y,
$$

where $i_{X}$ is the identity map of $X$.

Now suppose that $f$ is continuous. To prove continuity of $F$, we take a point $z_{0}$ of $Z$ and a subbasis element $S(C, U)$ for $\mathcal{C}(X, Y)$ containing $F\left(z_{0}\right)$, and find a neighborhood $W$ of $z_{0}$ that is mapped by $F$ into $S(C, U)$. This will suffice.

The statement that $F\left(z_{0}\right)$ lies in $S(C, U)$ means simply that $\left(F\left(z_{0}\right)\right)(x)=f\left(x, z_{0}\right)$ is in $U$ for all $x \in C$. That is, $f\left(C \times z_{0}\right) \subset U$. Continuity of $f$ implies that $f^{-1}(U)$ is an open set in $X \times Z$ containing $C \times z_{0}$. Then

$$
f^{-1}(U) \cap(C \times Z)
$$

is an open set in the subspace $C \times Z$ containing the slice $C \times z_{0}$. The tube lemma of $\S 26$ implies that there is a neighborhood $W$ of $z_{0}$ in $Z$ such that the entire tube $C \times W$ lies in $f^{-1}(U)$. See Figure 46.2. Then for $z \in W$ and $x \in C$, we have $f(x, z) \in U$. Hence $F(W) \subset S(C, U)$, as desired.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-288.jpg?height=414&width=1110&top_left_y=1786&top_left_x=466)

Figure 46.2

We discuss briefly the connections between the compact-open topology and the concept of homotopy, which arises in algebraic topology.

If $f$ and $g$ are continuous maps of $X$ into $Y$, we say that $f$ and $g$ are homotopic if there is a continuous map

$$
h: X \times[0,1] \longrightarrow Y
$$

such that $h(x, 0)=f(x)$ and $h(x, 1)=g(x)$ for each $x \in X$. The map $h$ is called a homotopy between $f$ and $g$.

Roughly speaking, a homotopy is a "continuous one-parameter family" of maps from $X$ to $Y$. More precisely, we note that a homotopy $h$ gives rise to a map

$$
H:[0,1] \longrightarrow \mathcal{C}(X, Y)
$$

that assigns, to each parameter value $t$ in $[0,1]$, the corresponding continuous map from $X$ to $Y$. Assuming that $X$ is locally compact Hausdorff, we see that $h$ is continuous if and only if $H$ is continuous. This means that a homotopy $h$ between $f$ and $g$ corresponds precisely to a path in the function space $\mathcal{C}(X, Y)$ from the point $f$ of $\mathcal{C}(X, Y)$ to the point $g$.

We shall return to a more detailed study of homotopy in Part II of the book.

## Exercises

1. Show that the sets $B_{C}(f, \epsilon)$ form a basis for a topology on $Y^{X}$.
2. Prove Theorem 46.7.
3. Show that the set $\mathcal{B}(\mathbb{R}, \mathbb{R})$ of bounded functions $f: \mathbb{R} \rightarrow \mathbb{R}$ is closed in $\mathbb{R}^{\mathbb{R}}$ in the uniform topology, but not in the topology of compact convergence.
4. Consider the sequence of continuous functions $f_{n}: \mathbb{R} \rightarrow \mathbb{R}$ defined by

$$
f_{n}(x)=x / n .
$$

In which of the three topologies of Theorem 46.7 does this sequence converge? Answer the same question for the sequence given in Exercise 9 of $\$ 21$.

5. Consider the sequence of functions $f_{n}:(-1,1) \rightarrow \mathbb{R}$, defined by

$$
f_{n}(x)=\sum_{k=1}^{n} k x^{k}
$$

(a) Show that ( $\left.f_{n}\right)$ converges in the topology of compact convergence; conclude that the limit function is continuous. (This is a standard fact about power series.)

(b) Show that $\left(f_{n}\right)$ does not converge in the uniform topology.

6. Show that in the compact-open topology, $\mathcal{C}(X, Y)$ is Hausdorff if $Y$ is Hausdorff, and regular if $Y$ is regular. [Hint: If $\bar{U} \subset V$, then $\overline{S(C, U)} \subset S(C, V)$.]
7. Show that if $Y$ is locally compact Hausdorff, then composition of maps

$$
\mathcal{C}(X, Y) \times \mathcal{C}(Y, Z) \longrightarrow \mathcal{C}(X, Z)
$$

is continuous, provided the compact-open topology is used throughout. [Hint: If $g \circ f \in S(C, U)$, find $V$ such that $f(C) \subset V$ and $g(\bar{V}) \subset U$.]

8. Let $\mathcal{C}^{\prime}(X, Y)$ denote the set $\mathcal{C}(X, Y)$ in some topology $\mathcal{T}$. Show that if the evaluation map

$$
e: X \times \mathcal{C}^{\prime}(X, Y) \longrightarrow Y
$$

is continuous, then $\mathcal{T}$ contains the compact-open topology. [Hint: The induced map $E: \mathcal{C}^{\prime}(X, Y) \rightarrow \mathcal{C}(X, Y)$ is continuous.]

9. Here is an (unexpected) application of Theorem 46.11 to quotient maps. (Compare Exercise 11 of $\$ 29$.)

Theorem. If $p: A \rightarrow B$ is a quotient map and $X$ is locally compact Hausdorff, then $i_{X} \times p: X \times A \rightarrow X \times B$ is a quotient map.

Proof.

(a) Let $Y$ be the quotient space induced by $i_{X} \times p$; let $q: X \times A \rightarrow Y$ be the quotient map. Show there is a bijective continuous map $f: Y \rightarrow X \times B$ such that $f \circ q=i_{X} \times p$.

(b) Let $g=f^{-1}$. Let $G: B \rightarrow \mathcal{C}(X, Y)$ and $Q: A \rightarrow \mathcal{C}(X, Y)$ be the maps induced by $g$ and $q$, respectively. Show that $Q=G \circ p$.

(c) Show that $Q$ is continuous; conclude that $G$ is continuous, so that $g$ is continuous.

*10. A space is locally compact if it can be covered by open sets each of which is contained in a compact subspace of $X$. It is said to be $\sigma$-compact if it can be covered by countably many such open sets.

(a) Show that if $X$ is locally compact and second-countable, it is $\sigma$-compact.

(b) Let $(Y, d)$ be a metric space. Show that if $X$ is $\sigma$-compact, there is a metric for the topology of compact convergence on $Y^{X}$ such that if $(Y, d)$ is complete, $Y^{X}$ is complete in this metric. [Hint: Let $A_{1}, A_{2}, \ldots$ be a countable collection of compact subspaces of $X$ whose interiors cover $X$. Let $Y_{i}$ denote the set of all functions from $A_{i}$ to $Y$, in the uniform topology. Define a homeomorphism of $Y^{X}$ with a closed subspace of the product space $Y_{1} \times Y_{2} \times \cdots$.]

11. Let $(Y, d)$ be a metric space; let $X$ be a space. Define a topology on $\mathcal{C}(X, Y)$ as follows: Given $f \in \mathcal{C}(X, Y)$, and given a positive continuous function $\delta: X \rightarrow$ $\mathbb{R}_{+}$on $X$, let

$$
B(f, \delta)=\{g \mid d(f(x), g(x))<\delta(x) \text { for all } x \in X\}
$$

(a) Show that the sets $B(f, \delta)$ form a basis for a topology on $\mathcal{C}(X, Y)$. We call it the fine topology.

(b) Show that the fine topology contains the uniform topology.
(c) Show that if $X$ is compact, the fine and uniform topologies agree.

(d) Show that if $X$ is discrete, then $\mathcal{C}(X, Y)=Y^{X}$ and the fine and box topologies agree.

## \$47 Ascoli's Theorem

Now we prove a more general version of Ascoli's theorem. It characterizes the compact subspaces of $\mathcal{C}(X, Y)$ in the topology of compact convergence. The proof, however, involves all three of our standard function space topologies: the topology of pointwise convergence, the topology of compact convergence, and the uniform topology.

Theorem 47.1 (Ascoli's theorem). Let $X$ be a space and let $(Y, d)$ be a metric space. Give $\mathcal{C}(X, Y)$ the topology of compact convergence; let $\mathcal{F}$ be a subset of $\mathcal{C}(X, Y)$.

(a) If $\mathcal{F}$ is equicontinuous under $d$ and the set

$$
\mathcal{F}_{a}=\{f(a) \mid f \in \mathcal{F}\}
$$

has compact closure for each $a \in X$, then $\mathcal{F}$ is contained in a compact subspace of $\mathcal{C}(X, Y)$.

(b) The converse holds if $X$ is locally compact Hausdorff.

Proof of (a). Throughout, we give $Y^{X}$ the product topology, which is the same as the topology of pointwise convergence. Then $Y^{X}$ is a Hausdorff space. The space $\mathcal{C}(X, Y)$, which has the topology of compact convergence, is not a subspace of $Y^{X}$. Let $g$ be the closure of $\mathcal{F}$ in $Y^{X}$.

Step 1. We show that $g$ is a compact subspace of $Y^{X}$. Given $a \in X$, let $C_{a}$ denote the closure of $\mathscr{F}_{a}$ in $Y$; by hypothesis, $C_{a}$ is a compact subspace of $Y$. The set $\mathscr{F}$ is contained in the product space

$$
\prod_{a \in X} C_{a},
$$

since this product by definition consists of all functions $f: X \rightarrow Y$ satisfying the condition $f(a) \in C_{a}$ for all $a$. This product space is compact, by the Tychonoff theorem; it is a closed subspace of the product space $Y^{X}$. Because $q$ equals the closure of $\mathcal{F}$ in $Y^{X}, g$ is contained in $\prod C_{a}$; being closed, $g$ is therefore compact.

Step 2. We show that each function belonging to $g$ is continuous, and indeed that $g$ itself is equicontinuous under $d$.

Given $x_{0} \in X$ and $\epsilon>0$, choose a neighborhood $U$ of $x_{0}$ such that

$$
\begin{equation*}
d\left(f(x), f\left(x_{0}\right)\right)<\epsilon / 3 \quad \text { for all } f \in \mathcal{F} \text { and all } x \in U . \tag{*}
\end{equation*}
$$

We shall show that $d\left(g(x), g\left(x_{0}\right)\right)<\epsilon$ for all $g \in g$ and all $x \in U$; it follows that $g$ is equicontinuous.

Let $g \in \mathcal{G}^{2}$ and let $x$ be a point of $U$. Define $V_{x}$ to be the subset of $Y^{X}$, open in $Y^{X}$, consisting of all elements $h$ of $Y^{X}$ such that

$$
\begin{equation*}
d(h(x), g(x))<\epsilon / 3 \quad \text { and } \quad d\left(h\left(x_{0}\right), g\left(x_{0}\right)\right)<\epsilon / 3 . \tag{**}
\end{equation*}
$$

Because $g$ belongs to the closure of $\mathcal{F}$, the neighborhood $V_{x}$ of $g$ must contain an element $f$ of $\mathcal{F}$. Applying the triangle inequality to $(*)$ and $(* *)$, it follows that $d\left(g(x), g\left(x_{0}\right)\right)<\epsilon$, as desired.

Step 3. We show that the product topology on $Y^{X}$ and the compact convergence topology on $\mathcal{C}(X, Y)$ coincide on the subset $q$.

In general, the compact convergence topology is finer than the product topology. We prove that the reverse holds for the subset $g$. Let $g$ be an element of $g$, and let $B_{C}(g, \epsilon)$ be a basis element for the compact convergence topology on $Y^{X}$ that contains $g$. We find a basis element $B$ for the pointwise convergence topology on $Y^{X}$ that contains $g$ such that

$$
[B \cap g] \subset\left[B_{C}(g, \epsilon) \cap \mathcal{g}\right] .
$$

Using equicontinuity of $q_{2}$ and compactness of $C$, we can cover $C$ by finitely many open sets $U_{1}, \ldots, U_{n}$ of $X$, containing points $x_{1}, \ldots, x_{n}$, respectively, such that for each $i$, we have

$$
d\left(g(x), g\left(x_{i}\right)\right)<\epsilon / 3
$$

for $x \in U_{i}$ and $g \in g$. Then we define $B$ to be the basis element for $Y^{X}$ defined by the equation

$$
B=\left\{h \mid h \in Y^{X} \text { and } d\left(h\left(x_{i}\right), g\left(x_{i}\right)\right)<\epsilon / 3 \text { for } i=1, \ldots, n\right\}
$$

We show that if $h$ is an element of $B \cap \mathcal{g}$, then $h$ belongs to $B_{C}(g, \epsilon)$. That is, we show that $d(h(x), g(x))<\epsilon$ for $x \in C$. Given $x \in C$, choose $i$ so that $x \in U_{i}$. Then

$$
\begin{aligned}
& d\left(h(x), h\left(x_{i}\right)\right)<\epsilon / 3 \quad \text { and } \\
& d\left(g(x), g\left(x_{i}\right)\right)<\epsilon / 3
\end{aligned}
$$

because $x \in U_{i}$ and $g, h \in \mathcal{G}$, while

$$
d\left(h\left(x_{i}\right), g\left(x_{i}\right)\right)<\epsilon / 3
$$

because $h \in B$. It follows from the triangle inequality that $d(h(x), g(x))<\epsilon$, as desired.

Step 4. We complete the proof. The set $\mathcal{G}$ contains $\mathcal{F}$ and is contained in $\mathcal{C}(X, Y)$, It is compact as a subspace of $Y^{X}$ in the product topology. By the result just proved, it is also compact as a subspace of $\mathcal{C}(X, Y)$ in the compact convergence topology.

Proof of $(b)$. Let $\mathscr{H}$ be a compact subspace of $\mathcal{C}(X, Y)$ that contains $\mathcal{F}$. We show that $\mathscr{H}$ is equicontinuous and that $\mathscr{H}_{a}$ is compact for each $a \in X$. It follows that $\mathcal{F}$ is
equicontinuous (since $\mathcal{F} \subset \mathscr{H}$ ), and that $\mathcal{F}_{a}$ lies in the compact subspace $\mathscr{H}_{a}$ of $Y$, so that $\overline{\mathcal{F}}_{a}$ is compact.

To show $\mathscr{H}_{a}$ is compact, consider the composite of the map

$$
j: \mathcal{C}(X, Y) \rightarrow X \times \mathcal{C}(X, Y)
$$

defined by $j(f)=a \times f$, and the evaluation map

$$
e: X \times \mathcal{C}(X, Y) \rightarrow Y
$$

given by the equation $e(x \times f)=f(x)$. The map $j$ is obviously continuous, and the map $e$ is continuous by Theorems 46.8 and 46.10. The composite $e \circ j$ maps $\mathscr{H}^{\text {to }} \mathscr{H}_{a}$; since $\mathscr{H}$ is compact, so is $\mathscr{H}_{a}$.

Now we show that $\mathscr{H}$ is equicontinuous at $a$, relative to the metric $d$. Let $A$ be a compact subspace of $X$ that contains a neighborhood of $a$. It suffices to show that the subset

$$
\mathcal{R}=\{f \mid A ; f \in \mathscr{H}\}
$$

of $\mathcal{C}(A, Y)$ is equicontinuous at $a$.

Give $\mathcal{C}(A, Y)$ the compact convergence topology. We show that the restriction map

$$
r: \mathcal{C}(X, Y) \rightarrow \mathcal{C}(A, Y)
$$

is continuous. Let $f$ be an element of $\mathcal{C}(X, Y)$ and let $B=B_{C}(f \mid A, \epsilon)$ be a basis element for $\mathcal{C}(A, Y)$ containing $f \mid A$, where $C$ is a compact subspace of $A$. Then $C$ is a compact subspace of $X$, and $r$ maps the neighborhood $B_{C}(f, \epsilon)$ of $f$ in $\mathcal{C}(X, Y)$ into $B$.

The map $r$ maps $\mathscr{H}$ onto $\mathcal{R}$; because $\mathscr{H}$ is compact, so is $\mathcal{R}$. Now $\mathcal{R}$ is a subspace of $\mathcal{C}(A, Y)$; because $A$ is compact, the compact convergence and the uniform topologies on $\mathcal{C}(A, Y)$ coincide. It follows from Theorem 45.1 that $\mathcal{R}$ is totally bounded in the uniform metric on $\mathcal{C}(A, Y)$; then Lemma 45.2 implies that $\mathcal{R}$ is equicontinuous relative to $d$.

An even more general version of Ascoli's theorem may be found in $[\mathrm{K}]$ or $[\mathrm{Wd}]$. There it is not assumed that $Y$ is a metric space, but only that it has what is called a uniform structure, which is a generalization of the notion of metric.

Ascoli's theorem has many applications in analysis, but these lie outside the scope of this book. See $[\mathrm{K}-\mathrm{F}]$ for several such applications.

## Exercises

1. Which of the following subsets of $\mathcal{C}(\mathbb{R}, \mathbb{R})$ are pointwise bounded? Which are equicontinuous?

(a) The collection $\left\{f_{n}\right\}$, where $f_{n}(x)=x+\sin n x$.
(b) The collection $\left\{g_{n}\right\}$, where $g_{n}(x)=n+\sin x$.

(c) The collection $\left\{h_{n}\right\}$, where $h_{n}(x)=|x|^{1 / n}$.

(d) The collection $\left\{k_{n}\right\}$, where $k_{n}(x)=n \sin (x / n)$.

2. Prove the following:

Theorem. If $X$ is a locally compact Hausdorff space, then a subspace $\mathcal{F}$ of $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ in the topology of compact convergence has compact closure if and only if $\mathcal{F}$ is pointwise bounded and equicontinuous under either of the standard metrics on $\mathbb{R}^{n}$.

3. Show that the general version of Ascoli's theorem implies the classical version (Theorem 45.4) when $X$ is Hausdorff.
4. Prove the following:

Theorem (Arzela's theorem, general version). Let $X$ be a Hausdorff space that is $\sigma$-compact; let $f_{n}$ be a sequence of functions $f_{n}: X \rightarrow \mathbb{R}^{k}$. If the collection $\left\{f_{n}\right\}$ is pointwise bounded and equicontinuous, then the sequence $f_{n}$ has a subsequence that converges, in the topology of compact convergence, to a continuous function.

[Hint: Show $\mathcal{C}\left(X, \mathbb{R}^{k}\right)$ is first-countable.]

5. Let $(Y, d)$ be a metric space; let $f_{n}: X \rightarrow Y$ be a sequence of continuous functions; let $f: X \rightarrow Y$ be a function (not necessarily continuous). Suppose $f_{n}$ converges to $f$ in the topology of pointwise convergence. Show that if $\left\{f_{n}\right\}$ is equicontinuous, then $f$ is continuous and $f_{n}$ converges to $f$ in the topology of compact convergence.

## Chapter 8

## Baire Spaces and Dimension Theory

In this chapter, we introduce a class of topological spaces called the Baire spaces. The defining condition for a Baire space is a bit complicated to state, but it is often useful in the applications, in both analysis and topology. Most of the spaces we have been studying are Baire spaces. For instance, a Hausdorff space is a Baire space if it is compact, or even locally compact. And a metrizable space $X$ is a Baire space if it is topologically complete, that is, if there is a metric for $X$ relative to which $X$ is complete.

It follows that, since the space $\mathcal{C}\left(X, \mathbb{R}^{n}\right)$ of all continuous functions from a space $X$ to $\mathbb{R}^{n}$ is complete in the uniform metric, it is a Baire space in the uniform topology. This fact has a number of interesting applications.

One application is the proof we give in $\S 49$ of the existence of a continuous nowhere-differentiable real-valued function.

Another application arises in that branch of topology called dimension theory. In $\S 50$, we define a topological notion of dimension, due to Lebesgue. And we prove the classical theorem that every compact metrizable space of topological dimension $m$ can be imbedded in euclidean space $\mathbb{R}^{N}$ of dimension $N=2 m+1$. It follows that every compact $m$-manifold can be imbedded in $\mathbb{R}^{2 m+1}$. This generalizes the imbedding theorem proved in $\$ 36$.

Throughout the chapter, we assume familiarity with complete metric spaces ( $\S 43$ ). When we study dimension theory, we shall make use of $\S 36$, Imbeddings of Manifolds, as well as a bit of linear algebra.

## §48 Baire Spaces

The defining condition for a Baire space is probably as "unnatural looking" as any condition we have yet introduced in this book. But bear with us awhile.

In this section, we shall define Baire spaces and shall show that two important classes of spaces-the complete metric spaces and the compact Hausdorff spacesare contained in the class of Baire spaces. Then we shall give some applications, which, even if they do not make the Baire condition seem any more natural, will at least show what a useful tool it can be. In fact, it turns out to be a very useful and fairly sophisticated tool in both analysis and topology.

Definition. Recall that if $A$ is a subset of a space $X$, the interior of $A$ is defined as the union of all open sets of $X$ that are contained in $A$. To say that $A$ has empty interior is to say then that $A$ contains no open set of $X$ other than the empty set. Equivalently, $A$ has empty interior if every point of $A$ is a limit point of the complement of $A$, that is, if the complement of $A$ is dense in $X$.

EXAMPLE 1. The set $\mathbb{Q}$ of rationals has empty interior as a subset of $\mathbb{R}$, but the interval $[0,1]$ has nonempty interior. The interval $[0,1] \times 0$ has empty interior as a subset of the plane $\mathbb{R}^{2}$, and so does the subset $\mathbb{Q} \times \mathbb{R}$.

Definition. A space $X$ is said to be a Baire space if the following condition holds: Given any countable collection $\left\{A_{n}\right\}$ of closed sets of $X$ each of which has empty interior in $X$, their union $\bigcup A_{n}$ also has empty interior in $X$.

EXAMPLE 2. The space $\mathbb{Q}$ of rationals is not a Baire space. For each one-point set in $\mathbb{Q}$ is closed and has empty interior in $\mathbb{Q}$; and $\mathbb{Q}$ is the countable union of its one-point subsets.

The space $\mathbb{Z}_{+}$, on the other hand, does form a Baire space. Every subset of $\mathbb{Z}_{+}$is open, so that there exist no subsets of $\mathbb{Z}_{+}$having empty interior, except for the empty set. Therefore, $\mathbb{Z}_{+}$satisfies the Baire condition vacuously.

More generally, every closed subspace of $\mathbb{R}$, being a complete metric space, is a Baire space. Somewhat surprising is the fact that the irrationals in $\mathbb{R}$ also form a Baire space; see Exercise 6.

The terminology originally used by R. Baire for this concept involved the word "category." A subset $A$ of a space $X$ was said to be of the first category in $X$ if it was contained in the union of a countable collection of closed sets of $X$ having empty interiors in $X$; otherwise, it was said to be of the second category in $X$. Using this terminology, we can say the following:

A space $X$ is a Baire space if and only if every nonempty open set in $X$ is of the second category.

We shall not use the terms "first category" and "second category" in this book.

The preceding definition is the "closed set definition" of a Baire space. There is also a formulation involving open sets that is frequently useful. It is given in the following lemma.

Lemma 48.1. $X$ is a Baire space if and only if given any countable collection $\left\{U_{n}\right\}$ of open sets in $X$, each of which is dense in $X$, their intersection $\bigcap U_{n}$ is also dense in $X$.

Proof. Recall that a set $C$ is dense in $X$ if $\bar{C}=X$. The theorem now follows at once from the two remarks:

(1) $A$ is closed in $X$ if and only if $X-A$ is open in $X$.

(2) $B$ has empty interior in $X$ if and only if $X-B$ is dense in $X$.

There are a number of theorems giving conditions under which a space is a Baire space. The most important is the following:

Theorem 48.2 (Baire category theorem). If $X$ is a compact Hausdorff space or a complete metric space, then $X$ is a Baire space.

Proof. Given a countable collection $\left\{A_{n}\right\}$ of closed set of $X$ having empty interiors, we want to show that their union $\bigcup A_{n}$ also has empty interior in $X$. So, given the nonempty open set $U_{0}$ of $X$, we must find a point $x$ of $U_{0}$ that does not lie in any of the sets $A_{n}$.

Consider the first set $A_{1}$. By hypothesis, $A_{1}$ does not contain $U_{0}$. Therefore, we may choose a point $y$ of $U_{0}$ that is not in $A_{1}$. Regularity of $X$, along with the fact that $A_{1}$ is closed, enables us to choose a neighborhood $U_{1}$ of $y$ such that

$$
\begin{aligned}
\bar{U}_{1} \cap A_{1} & =\varnothing \\
\bar{U}_{1} & \subset U_{0} .
\end{aligned}
$$

If $X$ is metric, we also choose $U_{1}$ small enough that its diameter is less than 1 .

In general, given the nonempty open set $U_{n-1}$, we choose a point of $U_{n-1}$ that is not in the closed set $A_{n}$, and then we choose $U_{n}$ to be a neighborhood of this point such that

$$
\begin{aligned}
\bar{U}_{n} \cap A_{n} & =\varnothing \\
\bar{U}_{n} & \subset U_{n-1}, \\
\operatorname{diam} U_{n} & <1 / n \quad \text { in the metric case. }
\end{aligned}
$$

We assert that the intersection $\bigcap \bar{U}_{n}$ is nonempty. From this fact, our theorem will follow. For if $x$ is a point of $\bigcap \bar{U}_{n}$, then $x$ is in $U_{0}$ because $\bar{U}_{1} \subset U_{0}$. And for each $n$, the point $x$ is not in $A_{n}$ because $\bar{U}_{n}$ is disjoint from $A_{n}$.

The proof that $\bigcap \bar{U}_{n}$ is nonempty splits into two parts, depending on whether $X$ is compact Hausdorff or complete metric. If $X$ is compact Hausdorff, we consider the nested sequence $\bar{U}_{1} \supset \bar{U}_{2} \supset \cdots$ of nonempty subsets of $X$. The collection $\left\{\bar{U}_{n}\right\}$ has the finite intersection property; since $X$ is compact, the intersection $\bigcap \bar{U}_{n}$ must be nonempty.

If $X$ is complete metric, we apply the following lemma.

Lemma 48.3. Let $C_{1} \supset C_{2} \supset \cdots$ be a nested sequence of nonempty closed sets in the complete metric space $X$. If diam $C_{n} \rightarrow 0$, then $\bigcap C_{n} \neq \varnothing$.

Proof. We gave this as an exercise in $\S 43$. Here is a proof: Choose $x_{n} \in C_{n}$ for each $n$. Because $x_{n}, x_{m} \in C_{N}$ for $n, m \geq N$, and because diam $C_{N}$ can be made less than any given $\epsilon$ by choosing $N$ large enough, the sequence $\left(x_{n}\right)$ is a Cauchy sequence. Suppose that it converges to $x$. Then for given $k$, the subsequence $x_{k}, x_{k+1}, \ldots$ also converges to $x$. Thus $x$ necessarily belongs to $\bar{C}_{k}=C_{k}$. Then $x \in \bigcap C_{k}$, as desired.

Here is one application of the theory of Baire spaces; we shall give further applications in the sections that follow. This application is perhaps more amusing than profound. It concerns a question that a student might ask concerning convergent sequences of continuous functions.

Let $f_{n}:[0,1] \rightarrow \mathbb{R}$ be a sequence of continuous functions such that $f_{n}(x) \rightarrow$ $f(x)$ for each $x \in[0,1]$. There are examples that show the limit function $f$ need not be continuous. But one might wonder just how discontinuous $f$ can be. Could it be discontinuous everywhere, for instance? The answer is "no." We shall show that $f$ must be continuous at infinitely many points of [0,1]. In fact, the set of points at which $f$ is continuous is dense in $[0,1]$ !

To prove this result, we need the following lemma:

*Lemma 48.4. Any open subspace $Y$ of a Baire space $X$ is itself a Baire space.

Proof. Let $A_{n}$ be a countable collection of closed sets of $Y$ that have empty interiors in $Y$. We show that $\bigcup A_{n}$ has empty interior in $Y$.

Let $\bar{A}_{n}$ be the closure of $A_{n}$ in $X$; then $\bar{A}_{n} \cap Y=A_{n}$. The set $\bar{A}_{n}$ has empty interior in $X$. For if $U$ is a nonempty open set of $X$ contained in $\bar{A}_{n}$, then $U$ must intersect $A_{n}$. Then $U \cap Y$ is a nonempty open set of $Y$ contained in $A_{n}$, contrary to hypothesis.

If the union of the sets $A_{n}$ contains the nonempty open set $W$ of $Y$, then the union of the sets $\bar{A}_{n}$ also contains the set $W$, which is open in $X$ because $Y$ is open in $X$. But each set $\bar{A}_{n}$ has empty interior in $X$, contradicting the fact that $X$ is a Baire space.

*Theorem 48.5. Let $X$ be a space; let $(Y, d)$ be a metric space. Let $f_{n}: X \rightarrow Y$ be a sequence of continuous functions such that $f_{n}(x) \rightarrow f(x)$ for all $x \in X$, where $f: X \rightarrow Y$. If $X$ is a Baire space, the set of points at which $f$ is continuous is dense in $X$.

Proof. Given a positive integer $N$ and given $\epsilon>0$, define

$$
A_{N}(\epsilon)=\left\{x \mid d\left(f_{n}(x), f_{m}(x)\right) \leq \epsilon \text { for all } n, m \geq N\right\}
$$

Note that $A_{N}(\epsilon)$ is closed in $X$. For the set of those $x$ for which $d\left(f_{n}(x), f_{m}(x)\right) \leq \epsilon$ is closed in $X$, by continuity of $f_{n}$ and $f_{m}$, and $A_{N}(\epsilon)$ is the intersection of these sets for all $n, m \geq N$.

For fixed $\epsilon$, consider the sets $A_{1}(\epsilon) \subset A_{2}(\epsilon) \subset \cdots$. The union of these sets is all of $X$. For, given $x_{0} \in X$, the fact that $f_{n}\left(x_{0}\right) \rightarrow f\left(x_{0}\right)$ implies that the sequence $f_{n}\left(x_{0}\right)$ is a Cauchy sequence; hence $x_{0} \in A_{N}(\epsilon)$ for some $N$.

Now let

$$
U(\epsilon)=\bigcup_{N \in \mathbb{Z}_{+}} \operatorname{Int} A_{N}(\epsilon)
$$

We shall prove two things:

(1) $U(\epsilon)$ is open and dense in $X$.

(2) The function $f$ is continuous at each point of the set

$$
C=U(1) \cap U(1 / 2) \cap U(1 / 3) \cap \ldots .
$$

Our theorem then follows from the fact that $X$ is a Baire space.

To show that $U(\epsilon)$ is dense in $X$, it suffices to show that for any nonempty open set $V$ of $X$, there is an $N$ such that the set $V \cap \operatorname{Int} A_{N}(\epsilon)$ is nonempty. For this purpose, we note first that for each $N$, the set $V \cap A_{N}(\epsilon)$ is closed in $V$. Because $V$ is a Baire space, by the preceding lemma at least one of these sets, say $V \cap A_{M}(\epsilon)$, must contain a nonempty open set $W$ of $V$. Because $V$ is open in $X$, the set $W$ is open in $X$; therefore, it is contained in Int $A_{M}(\epsilon)$.

Now we show that if $x_{0} \in C$, then $f$ is continuous at $x_{0}$. Given $\epsilon>0$, we shall find a neighborhood $W$ of $x_{0}$ such that $d\left(f(x), f\left(x_{0}\right)\right)<\epsilon$ for $x \in W$.

First, choose $k$ so that $1 / k<\epsilon / 3$. Since $x_{0} \in C$, we have $x_{0} \in U(1 / k)$; therefore, there is an $N$ such that $x_{0} \in \operatorname{Int} A_{N}(1 / k)$. Finally, continuity of the function $f_{N}$ enables us to choose a neighborhood $W$ of $x_{0}$, contained in $A_{N}(1 / k)$, such that

$$
\begin{equation*}
d\left(f_{N}(x), f_{N}\left(x_{0}\right)\right)<\epsilon / 3 \quad \text { for } x \in W . \tag{*}
\end{equation*}
$$

The fact that $W \subset A_{N}(1 / k)$ implies that

$$
d\left(f_{n}(x), f_{N}(x)\right) \leq 1 / k \quad \text { for } n \geq N \text { and } x \in W \text {. }
$$

Letting $n \rightarrow \infty$, we obtain the inequality

$$
\begin{equation*}
d\left(f(x), f_{N}(x)\right) \leq 1 / k<\epsilon / 3 \quad \text { for } x \in W . \tag{**}
\end{equation*}
$$

In particular, since $x_{0} \in W$, we have

$$
\begin{equation*}
d\left(f\left(x_{0}\right), f_{N}\left(x_{0}\right)\right)<\epsilon / 3 . \tag{***}
\end{equation*}
$$

Applying the triangle inequality to $(*),(* *)$, and $(* * *)$ gives us our desired result.

## Exercises

1. Let $X$ equal the countable union $\bigcup B_{n}$. Show that if $X$ is a nonempty Baire space, at least one of the sets $\bar{B}_{n}$ has a nonempty interior.
2. The Baire category theorem implies that $\mathbb{R}$ cannot be written as a countable union of closed subsets having empty interiors. Show this fails if the sets are not required to be closed.
3. Show that every locally compact Hausdorff space is a Baire space.
4. Show that if every point $x$ of $X$ has a neighborhood that is a Baire space, then $X$ is a Baire space. [Hint: Use the open set formulation of the Baire condition.]
5. Show that if $Y$ is a $G_{\delta}$ set in $X$, and if $X$ is compact Hausdorff or complete metric, then $Y$ is a Baire space in the subspace topology. [Hint: Suppose that $Y=\bigcap W_{n}$, where $W_{n}$ is open in $X$, and that $B_{n}$ is closed in $Y$ and has empty interior in $Y$. Given $U_{0}$ open in $X$ with $U_{0} \cap Y \neq \varnothing$, find a sequence of open sets $U_{n}$ of $X$ with $U_{n} \cap Y$ nonempty, such that

$$
\begin{aligned}
\bar{U}_{n} & \subset U_{n-1}, \\
\bar{U}_{n} \cap \bar{B}_{n} & =\varnothing, \\
\operatorname{diam} U_{n} & <1 / n \quad \text { in the metric case, } \\
\bar{U}_{n} & \left.\subset W_{n} .\right]
\end{aligned}
$$

6. Show that the irrationals are a Baire space.
7. Prove the following:

Theorem. If $D$ is a countable dense subset of $\mathbb{R}$, there is no function $f: \mathbb{R} \rightarrow \mathbb{R}$ that is continuous precisely at the points of $D$.

Proof.

(a) Show that if $f: \mathbb{R} \rightarrow \mathbb{R}$, then the set $C$ of points at which $f$ is continuous is a $G_{\delta}$ set in $\mathbb{R}$. [Hint: Let $U_{n}$ be the union of all open sets $U$ of $\mathbb{R}$ such that $\operatorname{diam} f(U)<1 / n$. Show that $C=\bigcap U_{n}$.]

(b) Show that $D$ is not a $G_{\delta}$ set in $\mathbb{R}$. [Hint: Suppose $D=\bigcap W_{n}$, where $W_{n}$ is open in $\mathbb{R}$. For $d \in D$, set $V_{d}=\mathbb{R}-\{d\}$. Show $W_{n}$ and $V_{d}$ are dense in $\mathbb{R}$.]

8. If $f_{n}$ is a sequence of continuous functions $f_{n}: \mathbb{R} \rightarrow \mathbb{R}$ such that $f_{n}(x) \rightarrow f(x)$ for each $x \in \mathbb{R}$, show that $f$ is continuous at uncountably many points of $\mathbb{R}$.
9. Let $g: \mathbb{Z}_{+} \rightarrow \mathbb{Q}$ be a bijective function; let $x_{n}=g(n)$. Define $f: \mathbb{R} \rightarrow \mathbb{R}$ as follows:

$$
\begin{aligned}
f\left(x_{n}\right)=1 / n & \text { for } x_{n} \in \mathbb{Q} \\
f(x)=0 & \text { for } x \notin \mathbb{Q}
\end{aligned}
$$

Show that $f$ is continuous at each irrational and discontinuous at each rational. Can you find a sequence of continuous functions $f_{n}$ coverging to $f$ ?

10. Prove the following:

Theorem (Uniform boundedness principle). Let $X$ be a complete metric space, and let $\mathcal{F}$ be a subset of $\mathcal{C}(X, \mathbb{R})$ such that for each $a \in X$, the set

$$
\mathcal{F}_{a}=\{f(a) \mid f \in \mathcal{F}\}
$$

is bounded. Then there is a nonempty open set $U$ of $X$ on which the functions in $\mathcal{F}$ are uniformly bounded, that is, there is a number $M$ such that $|f(x)| \leq M$ for all $x \in U$ and all $f \in \mathcal{F}$. [Hint: Let $A_{N}=\{x ;|f(x)| \leq N$ for all $f \in \mathcal{F}\}$.]

11. Determine whether or not $\mathbb{R}_{\ell}$ is a Baire space
12. Show that $\mathbb{R}^{J}$ is a Baire space in the box, product, and uniform topologies.

*13. Let $X$ be a topological space; let $Y$ be a complete metric space. Show that $\mathcal{C}(X, Y)$ is a Baire space in the fine topology (see Exercise 11 of §46). [Hint: Given basis elements $B\left(f_{i}, \delta_{i}\right)$ such that $\delta_{1} \leq 1$ and $\delta_{i+1} \leq \delta_{i} / 3$ and $f_{i+1} \in$ $B\left(f_{i}, \delta_{i} / 3\right)$, show that

$$
\left.\bigcap B\left(f_{i}, \delta_{i}\right) \neq \varnothing .\right]
$$

## *\$49 A Nowhere-Differentiable Function

We prove the following result from analysis:

Theorem 49.1. Let $h:[0,1] \rightarrow \mathbb{R}$ be a continuous function. Given $\epsilon>0$, there is a function $g:[0,1] \rightarrow \mathbb{R}$ with $|h(x)-g(x)|<\epsilon$ for all $x$, such that $g$ is continuous and nowhere differentiable.

Proof. Let $I=[0,1]$. Consider the space $\mathcal{C}=\mathcal{C}(I, \mathbb{R})$ of continuous maps from $I$ to $\mathbb{R}$, in the metric

$$
\rho(f, g)=\max \{|f(x)-g(x)|\} .
$$

This space is a complete metric space and, therefore, is a Baire space. We shall define, for each $n$, a certain subset $U_{n}$ of $\mathcal{C}$ that is open in $\mathcal{C}$ and dense in $\mathcal{C}$, and has the property that the functions belonging to the intersection

$$
\bigcap_{n \in \mathbb{Z}_{+}} U_{n}
$$

are nowhere differentiable. Because $C$ is a Baire space, this intersection is dense in $C$, by Lemma 48.1. Therefore, given $h$ and $\epsilon$, this intersection must contain a function $g$ such that $\rho(h, g)<\epsilon$. The theorem follows.

The tricky part is to define the set $U_{n}$ properly. We first take a function $f$ and consider its difference quotients. Given $x \in I$ and given $0<h \leq \frac{1}{2}$, consider the expressions

$$
\left|\frac{f(x+h)-f(x)}{h}\right| \quad \text { and } \quad\left|\frac{f(x-h)-f(x)}{-h}\right| .
$$

Since $h \leq \frac{1}{2}$, at least one of the numbers $x+h$ and $x-h$ belongs to $I$, so that at least one of these expressions is defined. Let $\Delta f(x, h)$ denote the larger of the two if both
are defined; otherwise, let it denote the one that is defined. If the derivative $f^{\prime}(x)$ of $f$ at $x$ exists, it equals the limit of these difference quotients, so that

$$
\left|f^{\prime}(x)\right|=\lim _{h \rightarrow 0} \Delta f(x, h)
$$

We seek to find a continuous function for which this limit does not exist. To be specific, we shall construct $f$ so that given $x$, there is a sequence of numbers $h_{n}$ converging to 0 for which the numbers $\Delta f\left(x, h_{n}\right)$ become arbitrarily large.

This gives us the idea for defining the set $U_{n}$. Given any positive number $h \leq 1 / 2$, let

$$
\Delta_{h} f=\inf \{\Delta f(x, h) \mid x \in I\} .
$$

Then for $n \geq 2$, we define $U_{n}$ by declaring that a function $f$ belongs to $U_{n}$ if and only if for some positive number $h \leq 1 / n$, we have $\Delta_{h} f>n$.

EXAMPLE 1. Let $\alpha>0$ be given. The function $f:[0,1] \rightarrow \mathbb{R}$ given by the equation $f(x)=4 \alpha x(1-x)$, whose graph is a parabola, satisfies the condition $\Delta f(x, h) \geq \alpha$ for $h=1 / 4$ and all $x$, as you can check. Geometrically speaking, what this says is that for each $x$, at least one of the indicated secant lines of the parabola in Figure 49.1 has slope of absolute value at least $\alpha$. Hence if $\alpha>4$, the function $f$ belongs to $U_{4}$. The function $g$ pictured in Figure 49.1 satisfies the condition $\Delta g(x, h) \geq \alpha$ for any $h \leq 1 / 4$; hence $g$ belongs to $U_{n}$ provided $\alpha>n$. The function $k$ satisfies the condition $k(x, h) \geq \alpha$ for any $h \leq 1 / 8$; hence $k$ belongs to $U_{n}$ if $\alpha>n$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-302.jpg?height=440&width=1080&top_left_y=1350&top_left_x=480)

Figure 49.1

Now we prove the following facts about the set $U_{n}$ :

(1) $\bigcap U_{n}$ consists of nowhere-differentiable functions. Let $f \in \cap U_{n}$. We shall prove that given $x$ in $[0,1]$, the limit

$$
\lim \Delta f(x, h)
$$

does not exist: Given $n$, the fact that $f$ belongs to $U_{n}$ means that we can find a number $h_{n}$ with $0<h_{n} \leq 1 / n$ such that

$$
\Delta f\left(x, h_{n}\right)>n .
$$

Then the sequence $\left(h_{n}\right)$ converges to zero, but the sequence $\left(\Delta f\left(x, h_{n}\right)\right)$ does not converge. As a result, $f$ is not differentiable at $x$.

(2) $U_{n}$ is open in $C$. Suppose that $f \in U_{n}$; we find a $\delta$-neighborhood of $f$ that is contained in $U_{n}$. Because $f \in U_{n}$, there is a number $h$ with $0<h \leq 1 / n$ such that $\Delta_{h} f>n$. Set $M=\Delta_{h} f$, and let

$$
\delta=h(M-n) / 4 .
$$

We assert that if $g$ is a function with $\rho(f, g)<\delta$, then

$$
\Delta g(x, h) \geq \frac{1}{2}(M+n)>n
$$

for all $x \in I$, so that $g \in U_{n}$.

To prove the assertion, let us first assume that $\Delta f(x, h)$ is equal to the quotient $|f(x+h)-f(x)| / h$. We compute

$$
\begin{aligned}
& \left|\frac{f(x+h)-f(x)}{h}-\frac{g(x+h)-g(x)}{h}\right|= \\
& (1 / h)|[f(x+h)-g(x+h)]-[f(x)-g(x)]| \leq 2 \delta / h=(M-n) / 2 .
\end{aligned}
$$

If the first difference quotient is at least $M$ in absolute value, then the second is in absolute value at least

$$
M-\frac{1}{2}(M-n)=\frac{1}{2}(M+n) .
$$

A similar remark applies if $\Delta f(x, h)$ equals the other difference quotient.

(3) $U_{n}$ is dense in $\mathcal{C}$. We must show that given $f$ in $\mathcal{C}$, given $\epsilon>0$, and given $n$, we can find an element $g$ of $U_{n}$ within $\epsilon$ of $f$.

Choose $\alpha>n$. We shall construct $g$ as a "piecewise-linear" function, that is, a function whose graph is a broken line segment; each line segment in the graph of $g$ will have slope at least $\alpha$ in absolute value. It follows at once that such a function $g$ belongs to $U_{n}$. For let

$$
0=x_{0}<x_{1}<x_{2}<\cdots<x_{k}=1
$$

be a partition of the interval $[0,1]$ such that the restriction of $g$ to each subinterval $I_{i}=\left[x_{i-1}, x_{i}\right]$ is a linear function. Then choose $h$ so that $h \leq 1 / n$ and

$$
h \leq \frac{1}{2} \min \left\{\left|x_{i}-x_{i-1}\right| ; i=1, \ldots, k\right\}
$$

If $x$ is in [0,1], then $x$ belongs to some subinterval $I_{i}$. If $x$ belongs to the first half of the subinterval $I_{i}$, then $x+h$ belongs to $I_{i}$ and $(g(x+h)-g(x)) / h$ equals the slope of the linear function $g \mid I_{i}$. Similarly, if $x$ belongs to the second half of $I_{i}$, then $x-h$ belongs to $I_{i}$ and $(g(x-h)-g(x)) /(-h)$ equals the slope of $g \mid I_{i}$. In either case, $\Delta g(x, h) \geq \alpha$, so $g \in U_{n}$, as desired.

Now given $f, \epsilon$, and $\alpha$, we must show how to construct the desired piecewiselinear function $g$. First, we use uniform continuity of $f$ to choose a partition of the interval

$$
0=t_{0}<t_{1}<\cdots<t_{m}=1
$$

having the property that $f$ varies by at most $\epsilon / 4$ on each subinterval $\left[t_{i-1}, t_{i}\right]$ of this partition. For each $i=1, \ldots, m$, choose a point $a_{i} \in\left(t_{i-1}, t_{i}\right)$. We then define a piecewise-linear function $g_{1}$ by the equations

$$
g_{1}(x)= \begin{cases}f\left(t_{i-1}\right) & \text { for } x \in\left[t_{i-1}, a_{i}\right] \\ f\left(t_{i-1}\right)+m_{i}\left(x-a_{i}\right) & \text { for } x \in\left[a_{i}, t_{i}\right]\end{cases}
$$

where $m_{i}=\left(f\left(t_{i}\right)-f\left(t_{i-1}\right)\right) /\left(t_{i}-a_{i}\right)$. The graphs of $f$ and $g_{1}$ are pictured in Figure 49.2.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-304.jpg?height=702&width=985&top_left_y=1037&top_left_x=529)

Figure 49.2

We have some freedom of choice in choosing the point $a_{i}$. If $f\left(t_{i}\right) \neq f\left(t_{i-1}\right)$, we require $a_{i}$ to be close enough to $t_{i}$ that

$$
t_{i}-a_{i}<\frac{\left|f\left(t_{i}\right)-f\left(t_{i-1}\right)\right|}{\alpha}
$$

Then the graph of $g_{1}$ will consist entirely of line segments of slope zero and line segments of slope at least $\alpha$ in absolute value.

Furthermore, we assert that $\rho\left(g_{1}, f\right) \leq \epsilon / 2$ : On the interval $I_{i}$, both $g_{1}(x)$ and $f(x)$ vary by at most $\epsilon / 4$ from $f\left(t_{i-1}\right)$; therefore, they are within $\epsilon / 2$ of each other. Then $\rho\left(g_{1}, f\right)=\max \left\{\left|g_{1}(x)-f(x)\right|\right\} \leq \epsilon / 2$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-305.jpg?height=658&width=990&top_left_y=365&top_left_x=704)

Figure 49.3

The function $g_{1}$ is not yet the function we want. We now define a function $g$ by replacing each horizontal line segment in the graph of $g_{1}$ by a "sawtooth" graph that lies within $\epsilon / 2$ of the graph of $g_{1}$ and has the property that each edge of the sawtooth has slope at least $\alpha$ in absolute value. We leave this part of the construction to you. The result is the desired piecewise-linear function $g$. See Figure 49.3.

You may find this proof frustrating, in that it seems so abstract and nonconstructive. Implicit in the proof, however, is a procedure for constructing a specific sequence $f_{n}$ of piecewise-linear functions that converges uniformly to the nowheredifferentiable function $f$. And defining the function $f$ in this way is just as constructive as the usual definition of the sine function, for instance, as the limit of an infinite series.

## Exercises

1. Check the stated properties of the functions $f, g$, and $k$ of Example 1 .
2. Given $n$ and $\epsilon$, define a continuous function $f: I \rightarrow \mathbb{R}$ such that $f \in U_{n}$ and $|f(x)| \leq \epsilon$ for all $x$.

## §50 Introduction to Dimension Theory

We showed in $\S 36$ that if $X$ is a compact manifold, then $X$ can be imbedded in $\mathbb{R}^{N}$ for some positive integer $N$. In this section, we generalize this theorem to arbitrary compact metrizable spaces.

We shall define, for an arbitrary topological space $X$, a notion of topological dimension. It is the "covering dimension" originally defined by Lebesgue. We shall prove that each compact subset of $\mathbb{R}^{m}$ has topological dimension at most $m$. We shall also prove that the topological dimension of any compact $m$-manifold is at most $m$. (It is, in fact, precisely $m$, but this we shall not prove.)

The major theorem of this section is the theorem, due to K. Menger and G. Nöbeling, that any compact metrizable space of topological dimension $m$ can be imbedded in $\mathbb{R}^{N}$ for $N=2 m+1$. The proof is an application of the Baire theorem. It follows that every compact $m$-manifold can be imbedded in $\mathbb{R}^{2 m+1}$. It follows also that a compact metrizable space can be imbedded in $\mathbb{R}^{N}$ for some $N$ if and only if it has finite topological dimension.

Much of what we shall do holds without requiring the space in question to be compact. But we shall restrict ourselves to that case whenever it is convenient to do so. Generalizations to the noncompact case are given in the exercises.

Definition. A collection $\mathcal{A}$ of subsets of the space $X$ is said to have order $m+1$ if some point of $X$ lies in $m+1$ elements of $\mathcal{A}$, and no point of $X$ lies in more than $m+1$ elements of $\mathcal{A}$.

Now we define what we mean by the topological dimension of a space $X$. Recall that given a collection $\mathcal{A}$ of subsets of $X$, a collection $\mathscr{B}$ is said to refine $\mathcal{A}$, or to be a refinement of $\mathcal{A}$, if for each element $B$ of $\mathscr{B}$ there is an element $A$ of $\mathscr{A}$ such that $B \subset A$.

Definition. A space $X$ is said to be finite dimensional if there is some integer $m$ such that for every open covering $\mathcal{A}$ of $X$, there is an open covering $\mathcal{B}$ of $X$ that refines $\mathcal{A}$ and has order at most $m+1$. The topological dimension of $X$ is defined to be the smallest value of $m$ for which this statement holds; we denote it by $\operatorname{dim} X$.

EXAMPLE 1. Any compact subspace $X$ of $\mathbb{R}$ has topological dimension at most 1 . We begin by defining an open covering of $\mathbb{R}$ of order 2 . Let $\mathcal{A}_{1}$ denote the collection of all open intervals of the form $(n, n+1)$ in $\mathbb{R}$, where $n$ is an integer. Let $\mathcal{A}_{0}$ denote the collection of all open intervals of the form $(n-1 / 2, n+1 / 2)$, for $n$ an integer. Then $\mathcal{A}=\mathcal{A}_{0} \cup \mathcal{A}_{1}$ is an open covering of $\mathbb{R}$ by sets of diameter one. Because no two elements of $\mathcal{A}_{0}$ intersect, and no two elements of $\mathcal{A}_{1}$ intersect, $\mathcal{A}$ has order 2.

Now let $X$ be a compact subspace of $\mathbb{R}$. Given a covering $\mathcal{C}$ of $X$ by sets open in $X$, this covering has a positive Lebesgue number $\delta$. This means that any collection of subsets of $X$ that have diameter less than $\delta$ is automatically a refinement of $C$. Consider the homeomorphism $f: \mathbb{R} \rightarrow \mathbb{R}$ defined by $f(x)=\left(\frac{1}{2} \delta\right) x$. The images under $f$ of the elements of the collection $\mathcal{A}$ form an open covering of $\mathbb{R}$ of order 2 whose elements have diameter $\frac{1}{2} \delta$; their intersections with $X$ form the required open covering of $X$.

EXAMPLE 2. The interval $X=[0,1]$ has topological dimension 1 . We know that $\operatorname{dim} X \leq 1$. To show equality holds, let $\mathscr{A}$ be the covering of $X$ by the sets $[0,1)$ and $(0,1]$. We show that if $\mathscr{B}$ is any open covering of $X$ that refines $\mathcal{A}$, then $\mathscr{B}$ has order at least 2 . Since $\mathscr{B}$ refines $\mathcal{A}$, it must contain more than one element. Let $U$ be one of the elements
of $\mathscr{B}$ and let $V$ be the union of the others. If $\mathscr{B}$ had order 1 , then the sets $U$ and $V$ would be disjoint and would thus form a separation of $X$. We conclude that $\mathscr{B}$ has order at least 2 .

EXAMPLE 3. Any compact subspace $X$ of $\mathbb{R}^{2}$ has topological dimension at most 2. To prove this fact, we construct a certain open covering $\mathcal{A}$ of $\mathbb{R}^{2}$ that has order 3 . We begin by defining $\mathcal{A}_{2}$ to be the collection of all open unit squares in $\mathbb{R}^{2}$ of the following form:

$$
\mathcal{A}_{2}=\{(n, n+1) \times(m, m+1) \mid n, m \text { integers }\} .
$$

Note that the elements of $\mathcal{A}_{2}$ are disjoint. Then, we define a collection $\mathcal{A}_{1}$ by taking each (open) edge $e$ of one of these squares,

$$
e=\{n\} \times(m, m+1) \quad \text { or } \quad e=(n, n+1) \times\{m\}
$$

and expanding it slightly to an open set $U_{e}$ of $\mathbb{R}^{2}$, being careful to ensure that if $e \neq e^{\prime}$, the sets $U_{e}$ and $U_{e^{\prime}}$ are disjoint. We also choose each $U_{e}$ so that its diameter is at most 2 . Finally, we define $\mathcal{A}_{0}$ to be the collection consisting of all open balls of radius $\frac{1}{2}$ about the points $n \times m$. See Figure 50.1.

The collection of open sets $\mathcal{A}=\mathcal{A}_{2} \cup \mathcal{A}_{1} \cup \mathcal{A}_{0}$ covers $\mathbb{R}^{2}$. Each of its elements has diameter at most 2. And it has order 3, since no point of $\mathbb{R}^{2}$ can lie in more than one set from each $\mathscr{A}_{i}$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-307.jpg?height=316&width=1134&top_left_y=1130&top_left_x=663)

Figure 50.1

Now let $X$ be a compact subspace of $\mathbb{R}^{2}$. Given an open covering of $X$, it has a positive Lebesgue number $\delta$. Consider the homeomorphism $f: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}$ defined by the equation $f(x)=(\delta / 3) x$. The images under $f$ of the open sets of the collection $\mathcal{A}$ form an open covering of $\mathbb{R}^{2}$ by sets of diameter less than $\delta$; their intersections with $X$ form the required open covering of $X$.

We shall generalize this result to compact subsets of $\mathbb{R}^{n}$ shortly.

Some basic facts about topological dimension are given in the following theorems:

Theorem 50.1. Let $X$ be a space having finite dimension. If $Y$ is a closed subspace of $X$, then $Y$ has finite dimension and $\operatorname{dim} Y \leq \operatorname{dim} X$.

Proof. Let $\operatorname{dim} X=m$. Let $\mathcal{A}$ be a covering of $Y$ by sets open in $Y$. For each $A \in \mathcal{A}$, choose an open set $A^{\prime}$ of $X$ such that $A^{\prime} \cap Y=A$. Cover $X$ by the open sets $A^{\prime}$, along with the open set $X-Y$. Let $\mathcal{B}$ be a refinement of this covering that is an open covering of $X$ and has order at most $m+1$. Then the collection

$$
\{B \cap Y \mid B \in \mathcal{B}\}
$$

is a covering of $Y$ by sets open in $Y$, it has order at most $m+1$, and it refines $\mathcal{A}$.

Theorem 50.2. Let $X=Y \cup Z$, where $Y$ and $Z$ are closed subspaces of $X$ having finite topological dimension. Then

$$
\operatorname{dim} X=\max \{\operatorname{dim} Y, \operatorname{dim} Z\} .
$$

Proof. Let $m=\max \{\operatorname{dim} Y, \operatorname{dim} Z\}$. We shall show that $X$ is finite dimensional and has topological dimension at most $m$. It then follows from the preceding theorem that $X$ has topological dimension precisely $m$.

Step 1. If $\mathcal{A}$ is an open covering of $X$, we say that $\mathcal{A}$ has order at most $m+1$ at points of $Y$ provided no point of $Y$ lies in more than $m+1$ elements of $\mathcal{A}$.

We show that if $\mathcal{A}$ is an open covering of $X$, then there is an open covering of $X$ that refines $\mathcal{A}$ and has order at most $m+1$ at points of $Y$.

To prove this fact, consider the collection

$$
\{A \cap Y \mid A \in \mathcal{A}\} .
$$

It is an open covering of $Y$, so it has a refinement $\mathscr{B}$ that is an open covering of $Y$ and has order at most $m+1$. Given $B \in \mathscr{B}$, choose an open set $U_{B}$ of $X$ such that $U_{B} \cap Y=B$. Choose also an element $A_{B}$ of $\mathcal{A}$ such that $B \subset A_{B}$. Let $\mathcal{C}$ be the collection consisting of all the sets $U_{B} \cap A_{B}$, for $B \in \mathcal{B}$, along with all the sets $A-Y$, for $A \in \mathcal{A}$. Then $\mathcal{C}$ is the desired open covering of $X$.

Step 2. Now let $\mathcal{A}$ be an open covering of $X$. We construct an open covering $\mathscr{D}$ of $X$ that refines $\mathcal{A}$ and has order at most $m+1$. Let $\mathscr{B}$ be an open covering of $X$ refining $\mathcal{A}$ that has order at most $m+1$ at points of $Y$. Then let $\mathcal{C}$ be an open covering of $X$ refining $\mathscr{B}$ that has order at most $m+1$ at points of $Z$.

We form a new covering $\mathscr{D}$ of $X$ as follows: Define $f: \mathcal{C} \rightarrow \mathcal{B}$ by choosing for each $C \in \mathcal{C}$ an element $f(C)$ of $\mathscr{B}$ such that $C \subset f(C)$. Given $B \in \mathscr{B}$, define $D(B)$ to be the union of all those elements $C$ of $\mathcal{C}$ for which $f(C)=B$. (Of course, $D(B)$ is empty if $B$ is not in the image of $f$.) Let $\mathscr{D}$ be the collection of all the sets $D(B)$, for $B \in \mathcal{B}$

Now $\mathscr{D}$ refines $\mathscr{B}$, because $D(B) \subset B$ for each $B$; therefore, $\mathscr{D}$ refines $\mathcal{A}$. Also, $\mathcal{D}$ covers $X$ because $\mathcal{C}$ covers $X$ and $C \subset D(f(C))$ for each $C \in \mathcal{C}$. We show that $\mathcal{D}$ has order at most $m+1$. Suppose $x \in D\left(B_{1}\right) \cap \cdots \cap D\left(B_{k}\right)$, where the sets $D\left(B_{i}\right)$ are distinct. We wish to prove that $k \leq m+1$. Note that the sets $B_{1}, \ldots, B_{k}$ must be distinct because the sets $D\left(B_{i}\right)$ are. Because $x \in D\left(B_{i}\right)$, we can choose for each $i$, a set $C_{i} \in \mathcal{C}$ such that $x \in C_{i}$ and $f\left(C_{i}\right)=B_{i}$. The sets $C_{i}$ are distinct because the sets $B_{i}$ are. Furthermore,

$$
x \in\left[C_{1} \cap \cdots \cap C_{k}\right] \subset\left[D\left(B_{1}\right) \cap \cdots \cap D\left(B_{k}\right)\right] \subset\left[B_{1} \cap \cdots \cap B_{k}\right] .
$$

If $x$ happens to lie in $Y$, then $k \leq m+1$ because $\mathcal{B}$ has order at most $m+1$ at points of $Y$; and if $x$ is in $Z$, then $k \leq m+1$ because $C$ has order at most $m+1$ at points of $Z$.

Corollary 50.3. Let $X=Y_{1} \cup \cdots \cup Y_{k}$, where each $Y_{i}$ is a closed subspace of $X$ and is finite dimensional. Then

$$
\operatorname{dim} X=\max \left\{\operatorname{dim} Y_{1}, \ldots, \operatorname{dim} Y_{k}\right\}
$$

EXAMPLE 4. Every compact 1-manifold $X$ has topological dimension 1 . The space $X$ can be written as a finite union of spaces that are homeomorphic to the unit interval $[0,1]$; then the preceding corollary applies.

EXAMPLE 5. Every compact 2-manifold $X$ has topological dimension at most 2 . The space $X$ can be written as a finite union of spaces that are homeomorphic to the closed unit ball in $\mathbb{R}^{2}$; then the preceding corollary applies.

An obvious question occurs at this point: Does a compact 2-manifold have topological dimension precisely 2 ? The answer is "yes," but the proof is not easy; it requires the tools of algebraic topology. We will prove in Part II of this book that every closed triangular region in $\mathbb{R}^{2}$ has topological dimension at least 2. (See §55.) It then follows that any compact subspace of $\mathbb{R}^{2}$ that contains a closed triangular region has topological dimension 2 , from which it follows that every compact 2-manifold has topological dimension 2.

EXAMPLE 6. An arc $A$ is a space homeomorphic to the closed unit interval; the end points of $A$ are the points $p$ and $q$ such that $A-\{p\}$ and $A-\{q\}$ are connected. A (finite) linear graph $G$ is a Hausdorff space that is written as the union of finitely many arcs, each pair of which intersect in at most a common end point. The arcs in the collection are called the edges of $G$, and the end points of the arcs are called the vertices of $G$. Each edge of $G$, being compact, is closed in $G$; the preceding corollary tells us that $G$ has topological dimension 1 .

Two particular linear graphs are sketched in Figure 50.2. The first is a diagram of the familiar "gas-water-electricity problem"; the second is called the "complete graph on five vertices." Neither of them can be imbedded in $\mathbb{R}^{2}$. Although this fact is "intuitively obvious," it is highly nontrivial to prove. We shall give a proof in $\S 64$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-309.jpg?height=390&width=1122&top_left_y=1554&top_left_x=634)

Figure 50.2

EXAMPLE 7. Every finite linear graph can be imbedded in $\mathbb{R}^{3}$. The proof involves the notion of "general position." A set $S$ of points of $\mathbb{R}^{3}$ is said to be in general position if no three of the points of $S$ are collinear and no four of them are coplanar. It is easy to find such a set of points. For example, the points of the curve

$$
S=\left\{\left(t, t^{2}, t^{3}\right) \mid t \in \mathbb{R}\right\}
$$

are in general position. For if four of these points belonged to a single plane $A x+B y+$ $C z=D$, then the polynomial equation

$$
A t+B t^{2}+C t^{3}=D
$$

would have four distinct real roots! And if three of these points belonged to a single line, we could take an additional point of $S$ and obtain four points that lie on a plane.

Now, given a finite linear graph $G$, with vertices $v_{1}, \ldots, v_{n}$, let us choose a set $\left\{\mathbf{z}_{1}, \ldots, \mathbf{z}_{n}\right\}$ of points of $\mathbb{R}^{3}$ that is in general position. Define a map $f: G \rightarrow \mathbb{R}^{3}$ by letting $f$ map the vertex $v_{i}$ to the point $\mathbf{z}_{i}$, and map the edge joining $v_{i}$ and $v_{j}$ homeomorphically onto the line segment joining $\mathbf{z}_{i}$ and $\mathbf{z}_{j}$. Now each edge of $G$ is closed in $G$. It follows that $f$ is continuous, by the pasting lemma. We show that $f$ is injective, from which it follows that $f$ is an imbedding. Let $e=v_{i} v_{j}$ and $e^{\prime}=v_{k} v_{m}$ be two edges of $G$. If they have no vertex in common, then the line segments $f(e)$ and $f\left(e^{\prime}\right)$ are disjoint, for otherwise the points $\mathbf{z}_{i}, \mathbf{z}_{j}, \mathbf{z}_{k}, \mathbf{z}_{m}$ would be coplanar. And if $e$ and $e^{\prime}$ have a vertex in common, so that $i=k$, say, then the line segments $f(e)$ and $f\left(e^{\prime}\right)$ intersect only in the point $\mathbf{z}_{i}=\mathbf{z}_{k}$, for otherwise $\mathbf{z}_{i}, \mathbf{z}_{j}$, and $\mathbf{z}_{m}$ would be collinear.

Now we prove our general imbedding theorem, to the effect that every compact metrizable space of topological dimension $m$ can be imbedded in $\mathbb{R}^{2 m+1}$. This theorem is another "deep" theorem; it is not at all obvious, for instance, why $2 m+1$ should be the crucial dimension. That will come out in the course of the proof.

To prove the imbedding theorem, we shall need to generalize the notion of general position to $\mathbb{R}^{N}$. This involves a bit of the analytic geometry of $\mathbb{R}^{N}$, which is nothing more than the usual linear algebra of $\mathbb{R}^{N}$ translated into somewhat different language.

Definition. A set $\left\{\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}\right\}$ of points of $\mathbb{R}^{N}$ is said to be geometrically independent, or affinely independent, if the equations

$$
\sum_{i=0}^{k} a_{i} \mathbf{x}_{i}=\mathbf{0} \quad \text { and } \quad \sum_{i=0}^{k} a_{i}=0
$$

hold only if each $a_{i}=0$.

Obviously, a set consisting of only one point is geometrically independent. But what does geometric independence mean in general? If we solve the second equation for $a_{0}$ and plug the answer into the first equation, we see that this definition is equivalent to the statement that the equation

$$
\sum_{i=1}^{k} a_{i}\left(\mathbf{x}_{i}-\mathbf{x}_{0}\right)=\mathbf{0}
$$

holds only if each $a_{i}=0$. This is just the definition of linear independence for the set of vectors $\mathbf{x}_{1}-\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}-\mathbf{x}_{0}$ of the vector space $\mathbb{R}^{N}$. This gives us something to visualize: Any two distinct points form a geometrically independent set. Three points form a geometrically independent set if they are not collinear. Four points in $\mathbb{R}^{3}$ form a geometrically independent set if they are not coplanar. And so on.

It follows from these remarks that the points

$$
\begin{aligned}
\mathbf{0} & =(0,0, \ldots, 0), \\
\boldsymbol{\epsilon}_{1} & =(1,0, \ldots, 0), \\
& \ldots \\
\boldsymbol{\epsilon}_{N} & =(0,0, \ldots, 1)
\end{aligned}
$$

are geometrically independent in $\mathbb{R}^{N}$. It also follows that any geometrically independent set of points in $\mathbb{R}^{N}$ contains no more than $N+1$ points.

Definition. Let $\left\{\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}\right\}$ be a set of points of $\mathbb{R}^{N}$ that is geometrically independent. The plane $\boldsymbol{P}$ determined by these points is defined to be the set of all points $\mathbf{x}$ of $\mathbb{R}^{N}$ such that

$$
\mathbf{x}=\sum_{i=0}^{k} t_{i} \mathbf{x}_{i}, \quad \text { where } \sum_{i=0}^{k} t_{i}=1
$$

It is simple algebra to check that $P$ can also be expressed as the set of all points $\mathbf{x}$ such that

$$
\begin{equation*}
\mathbf{x}=\mathbf{x}_{0}+\sum_{i=1}^{k} a_{i}\left(\mathbf{x}_{i}-\mathbf{x}_{0}\right) \tag{*}
\end{equation*}
$$

for some scalars $a_{1}, \ldots, a_{k}$. Thus $P$ can be described not only as "the plane determined by the points $\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}$, " but also as "the plane passing through the point $\mathbf{x}_{0}$ parallel to the vectors $\mathbf{x}_{1}-\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}-\mathbf{x}_{0}$."

Consider now the homeomorphism $T: \mathbb{R}^{N} \rightarrow \mathbb{R}^{N}$ defined by the equation $T(\mathbf{x})=\mathbf{x}-\mathbf{x}_{0}$. It is called a translation of $\mathbb{R}^{N}$. Expression $(*)$ shows that this map carries the plane $P$ onto the vector subspace $V^{k}$ of $\mathbb{R}^{N}$ having as basis the vectors $\mathbf{x}_{1}-\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}-\mathbf{x}_{0}$. For this reason, we often call $P$ a $\boldsymbol{k}$-plane in $\mathbb{R}^{N}$.

Two facts follow at once: First, if $k<N$, the $k$-plane $P$ necessarily has empty interior in $\mathbb{R}^{N}$ (because $V^{k}$ does). And second, if $\mathbf{y}$ is any point of $\mathbb{R}^{N}$ not lying in $P$, then the set

$$
\left\{\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}, \mathbf{y}\right\}
$$

is geometrically independent. For if $\mathbf{y} \notin P$, then $T(\mathbf{y})=\mathbf{y}-\mathbf{x}_{0}$ is not in $V^{k}$. By a standard theorem of linear algebra, the vectors $\left\{\mathbf{x}_{1}-\mathbf{x}_{0}, \ldots, \mathbf{x}_{k}-\mathbf{x}_{0}, \mathbf{y}-\mathbf{x}_{0}\right\}$ are linearly independent, from which our result follows.

Definition. A set $A$ of points of $\mathbb{R}^{N}$ is said to be in general position in $\mathbb{R}^{N}$ if every subset of $A$ containing $N+1$ or fewer points is geometrically independent.

In the case of $\mathbb{R}^{3}$, this is the same as the definition given earlier, as you can check.

Lemma 50.4. Given a finite set $\left\{\mathbf{x}_{1}, \ldots, \mathbf{x}_{n}\right\}$ of points of $\mathbb{R}^{N}$ and given $\delta>0$, there exists a set $\left\{\mathbf{y}_{1}, \ldots, \mathbf{y}_{n}\right\}$ of points of $\mathbb{R}^{N}$ in general position in $\mathbb{R}^{N}$, such that $\left|\mathbf{x}_{i}-\mathbf{y}_{i}\right|<\delta$ for all $i$

Proof. We proceed by induction. Set $\mathbf{y}_{1}=\mathbf{x}_{1}$. Suppose that we are given $\mathbf{y}_{1}, \ldots, \mathbf{y}_{p}$ in general position in $\mathbb{R}^{N}$. Consider the set of all planes in $\mathbb{R}^{N}$ determined by subsets of $\left\{\mathbf{y}_{1}, \ldots, \mathbf{y}_{p}\right\}$ that contain $N$ or fewer elements. Every such subset is geometrically independent and determines a $k$-plane of $\mathbb{R}^{N}$ for some $k \leq N-1$. Each of these planes has empty interior in $\mathbb{R}^{N}$. Because there are only finitely many of them, their union also has empty interior in $\mathbb{R}^{N}$. (Recall that $\mathbb{R}^{N}$ is a Baire space.) Choose $\mathbf{y}_{p+1}$ to be a point of $\mathbb{R}^{N}$ within $\delta$ of $\mathbf{x}_{p+1}$ that does not lie in any of these planes. It follows at once that the set

$$
C=\left\{\mathbf{y}_{1}, \ldots, \mathbf{y}_{p}, \mathbf{y}_{p+1}\right\}
$$

is in general position in $\mathbb{R}^{N}$. For let $D$ be any subset of $C$ containing $N+1$ or fewer elements. If $D$ does not contain $\mathbf{y}_{p+1}$, then $D$ is geometrically independent by the induction hypothesis. If $D$ does contain $\mathbf{y}_{p+1}$, then $D-\left\{\mathbf{y}_{p+1}\right\}$ contains $N$ or fewer points and $\mathbf{y}_{p+1}$ is not in the plane determined by these points, by construction. Then as noted above, $D$ is geometrically independent.

Theorem 50.5 (The imbedding theorem). Every compact metrizable space $X$ of topological dimension $m$ can be imbedded in $\mathbb{R}^{2 m+1}$.

Proof. Let $N=2 m+1$. Let us denote the square metric for $\mathbb{R}^{N}$ by

$$
|\mathbf{x}-\mathbf{y}|=\max \left\{\left|x_{i}-y_{i}\right| ; i=1, \ldots, N\right\}
$$

Then we can use $\rho$ to denote the corresponding sup metric on the space $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$;

$$
\rho(f, g)=\sup \{|f(x)-g(x)| ; x \in X\} \text {. }
$$

The space $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$ is complete in the metric $\rho$, since $\mathbb{R}^{N}$ is complete in the square metric.

Choose a metric $d$ for the space $X$; because $X$ is compact, $d$ is bounded. Given a continuous map $f: X \rightarrow \mathbb{R}^{N}$, let us define

$$
\Delta(f)=\sup \left\{\operatorname{diam} f^{-1}(\{z\}) \mid z \in f(X)\right\}
$$

The number $\Delta(f)$ measures how far $f$ "deviates" from being injective; if $\Delta(f)=0$, each set $f^{-1}(\{z\})$ consists of exactly one point, so $f$ is injective.

Now, given $\epsilon>0$, define $U_{\epsilon}$ to be the set of all those continuous maps $f: X \rightarrow$ $\mathbb{R}^{N}$ for which $\Delta(f)<\epsilon$; it consists of all those maps that "deviate" from being injective by less than $\epsilon$. We shall show that $U_{\epsilon}$ is both open and dense in $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$. It follows that the intersection

$$
\bigcap_{n \in \mathbb{Z}_{+}} U_{1 / n}
$$

is dense in $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$ and is in particular nonempty.

If $f$ is an element of this intersection, then $\Delta(f)<1 / n$ for every $n$. Therefore, $\Delta(f)=0$ and $f$ is injective. Because $X$ is compact, $f$ is an imbedding. Thus, the imbedding theorem is proved.

(1) $U_{\epsilon}$ is open in $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$. Given an element $f$ of $U_{\epsilon}$, we wish to find some ball $B_{\rho}(f, \delta)$ about $f$ that is contained in $U_{\epsilon}$. First choose a number $b$ such that $\Delta(f)<b<\epsilon$. Note that if $f(x)=f(y)=z$, then $x$ and $y$ belong to the set $f^{-1}(\{z\})$, so that $d(x, y)$ must be less than $b$. It follows that if we let $A$ be the following subset of $X \times X$,

$$
A=\{x \times y \mid d(x, y) \geq b\},
$$

then the function $|f(x)-f(y)|$ is positive on $A$. Now $A$ is closed in $X \times X$ and therefore compact; hence the function $|f(x)-f(y)|$ has a positive minimum on $A$. Let

$$
\delta=\frac{1}{2} \min \{|f(x)-f(y)| ; x \times y \in A\}
$$

We assert that this value of $\delta$ will suffice.

Suppose that $g$ is a map such that $\rho(f, g)<\delta$. If $x \times y \in A$, then $|f(x)-f(y)| \geq$ $2 \delta$ by definition; since $g(x)$ and $g(y)$ are within $\delta$ of $f(x)$ and $f(y)$, respectively, we must have $|g(x)-g(y)|>0$. Hence the function $|g(x)-g(y)|$ is positive on $A$. As a result, if $x$ and $y$ are two points such that $g(x)=g(y)$, then necessarily $d(x, y)<b$. We conclude that $\Delta g \leq b<\epsilon$, as desired.

(2) $U_{\epsilon}$ is dense in $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$. This is the difficult part of the proof. We need to use the analytic geometry of $\mathbb{R}^{N}$ discussed earlier. Let $f \in \mathcal{C}\left(X, \mathbb{R}^{N}\right)$. Given $\epsilon>0$ and given $\delta>0$, we wish to find a function $g \in \mathcal{C}\left(X, \mathbb{R}^{N}\right)$ such that $g \in U_{\epsilon}$ and $\rho(f, g)<\delta$.

Let us cover $X$ by finitely many open sets $\left\{U_{1}, \ldots, U_{n}\right\}$ such that

(1) $\operatorname{diam} U_{i}<\epsilon / 2$ in $X$,

(2) $\operatorname{diam} f\left(U_{i}\right)<\delta / 2$ in $\mathbb{R}^{N}$,

(3) $\left\{U_{1}, \ldots, U_{n}\right\}$ has order $\leq m+1$.

Let $\left\{\phi_{i}\right\}$ be a partition of unity dominated by $\left\{U_{i}\right\}$ (see $\S 36$ ). For each $i$, choose a point $x_{i} \in U_{i}$. Then choose, for each $i$, a point $\mathbf{z}_{i} \in \mathbb{R}^{N}$ such that $\mathbf{z}_{i}$ is within $\delta / 2$ of the point $f\left(x_{i}\right)$, and such that the set $\left\{\mathbf{z}_{1}, \ldots, \mathbf{z}_{n}\right\}$ is in general position in $\mathbb{R}^{N}$. Finally, define $g: X \rightarrow \mathbb{R}^{N}$ by the equation

$$
g(x)=\sum_{i=1}^{n} \phi_{i}(x) \mathbf{z}_{i}
$$

We assert that $g$ is the desired function.

First, we show that $\rho(f, g)<\delta$. Note that

$$
g(x)-f(x)=\sum_{i=1}^{n} \phi_{i}(x) \mathbf{z}_{i}-\sum_{i=1}^{n} \phi_{i}(x) f(x)
$$

here we use the fact that $\sum \phi_{i}(x)=1$. Then

$$
g(x)-f(x)=\sum \phi_{i}(x)\left(\mathbf{z}_{i}-f\left(x_{i}\right)\right)+\sum \phi_{i}(x)\left(f\left(x_{i}\right)-f(x)\right) .
$$

Now $\left|\mathbf{z}_{i}-f\left(x_{i}\right)\right|<\delta / 2$ for each $i$, by choice of the points $\mathbf{z}_{i}$. And if $i$ is an index such that $\phi_{i}(x) \neq 0$, then $x \in U_{i}$; because we have $\operatorname{diam} f\left(U_{i}\right)<\delta / 2$, it follows that $\left|f\left(x_{i}\right)-f(x)\right|<\delta / 2$. Since $\sum \phi_{i}(x)=1$, we conclude that $|g(x)-f(x)|<\delta$. Therefore, $\rho(g, f)<\delta$, as desired.

Second, we show that $g \in U_{\epsilon}$. We shall prove that if $x, y \in X$ and $g(x)=g(y)$, then $x$ and $y$ belong to one of the open sets $U_{i}$, so that necessarily $d(x, y)<\epsilon / 2$ (since $\operatorname{diam} U_{i}<\epsilon / 2$ ). As a result, $\Delta(g) \leq \epsilon / 2<\epsilon$, as desired.

So suppose $g(x)=g(y)$. Then

$$
\sum_{i=1}^{n}\left[\phi_{i}(x)-\phi_{i}(y)\right] \mathbf{z}_{i}=\mathbf{0}
$$

Because the covering $\left\{U_{i}\right\}$ has order at most $m+1$, at most $m+1$ of the numbers $\phi_{i}(x)$ are nonzero, and at most $m+1$ of the numbers $\phi_{i}(y)$ are nonzero. Thus, the sum $\sum\left[\phi_{i}(x)-\phi_{i}(y)\right] \mathbf{z}_{i}$ has at most $2 m+2$ nonzero terms. Note that the sum of the coefficients vanishes because

$$
\sum\left[\phi_{i}(x)-\phi_{i}(y)\right]=1-1=0 .
$$

The points $\mathbf{z}_{i}$ are in general position in $\mathbb{R}^{N}$, so that any subset of them having $N+1$ or fewer elements is geometrically independent. And by hypothesis $N+1=2 m+2$. (Aha!) Therefore, we conclude that

$$
\phi_{i}(x)-\phi_{i}(y)=0
$$

for all $i$.

Now $\phi_{i}(x)>0$ for some $i$, so that $x \in U_{i}$. Since $\phi_{i}(y)=\phi_{i}(x)$, we have $y \in U_{i}$ also, as asserted.

To give some content to the imbedding theorem, we need some more examples of spaces that are finite dimensional. We prove the following theorem:

Theorem 50.6. Every compact subspace of $\mathbb{R}^{N}$ has topological dimension at most $N$.

Proof. The proof is a generalization of the proof given in Example 3 for $\mathbb{R}^{2}$. Let $\rho$ be the square metric on $\mathbb{R}^{N}$.

Step 1 . We begin by breaking $\mathbb{R}^{N}$ up into "unit cubes." Define $\mathcal{I}$ to be the following collection of open intervals in $\mathbb{R}$ :

$$
\mathscr{g}=\{(n, n+1) \mid n \in \mathbb{Z}\}
$$

and define $\mathcal{K}$ to be the following collection of one-point sets in $\mathbb{R}$ :

$$
\mathcal{K}=\{\{n\} \mid n \in \mathbb{Z}\} .
$$

If $M$ is an integer such that $0 \leq M \leq N$, let $\mathcal{C}_{M}$ denote the set of all products

$$
C=A_{1} \times A_{2} \times \cdots \times A_{N},
$$

where exactly $M$ of the sets $A_{i}$ belong to $\mathscr{g}$, and the remainder belong to $\mathcal{K}$. If $M>0$, then $C$ is homeomorphic to the product $(0,1)^{M}$ and will be called an $\boldsymbol{M}$-cube. If $M=0$, then $C$ consists of a single point and will be called a 0-cube .

Let $\mathcal{C}=\mathcal{C}_{0} \cup \mathcal{C}_{1} \cup \cdots \cup \mathcal{C}_{N}$. Note that each point $\mathbf{x}$ of $\mathbb{R}^{N}$ lies in precisely one element of $\mathcal{C}$ because each real number $x_{i}$ lies in precisely one element of $\mathfrak{g} \cup \mathcal{K}$. We shall expand each element $C$ of $C$ slightly to an open set $U(C)$ of $\mathbb{R}^{N}$ of diameter at most $3 / 2$, in such a way that if $C$ and $D$ are two different $M$-cubes, then $U(C)$ and $U(D)$ are disjoint.

Let $\mathbf{x}=\left(x_{1}, \ldots, x_{N}\right)$ be a point of the $M$-cube $C$. We show that there is a number $\epsilon(\mathbf{x})>0$ such that the $\epsilon(\mathbf{x})$-neighborhood of $\mathbf{x}$ intersects no $M$-cube other than $C$. If $C$ is a 0 -cube, we set $\epsilon(\mathbf{x})=1 / 2$ and we are finished. Otherwise, $M>0$, and exactly $M$ of the numbers $x_{i}$ are not integers. Choose $\epsilon \leq 1 / 2$ so that for each $x_{i}$ that is not an integer, the interval $\left(x_{i}-\epsilon, x_{i}+\epsilon\right)$ contains no integer. If $\mathbf{y}=\left(y_{1}, \ldots, y_{N}\right)$ is a point lying in the $\epsilon$-neighborhood of $\mathbf{x}$, then $y_{i}$ is nonintegral whenever $x_{i}$ is nonintegral. This means that $\mathbf{y}$ either belongs to the same $M$-cube as $\mathbf{x}$ does, or $\mathbf{y}$ belongs to some $L$-cube for $L>M$. In either case, the $\epsilon$-neighborhood of $\mathbf{x}$ intersects no $M$-cube other than $C$.

Given an $M$-cube $C$, we define the neighborhood $U(C)$ of $C$ to be the union of the $\epsilon(\mathbf{x}) / 2$-neighborhoods of $\mathbf{x}$ for all $\mathbf{x} \in C$. It is then immediate that if $C$ and $D$ are different $M$-cubes, $U(C)$ and $U(D)$ are disjoint. Furthermore, if $\mathbf{z}$ is a point of $U(C)$, then $d(\mathbf{z}, \mathbf{x})<\epsilon(\mathbf{x}) / 2<1 / 4$ for some point $\mathbf{x}$ of $C$. Since $C$ has diameter 1 , the set $U(C)$ has diameter at most $3 / 2$.

Step 2. Given $M$ with $0 \leq M \leq N$, define $\mathcal{A}_{M}$ to be the collection of all sets $U(C)$, where $C \in \mathcal{C}_{M}$. The elements of $\mathcal{A}_{M}$ are disjoint, and each has diameter at most 3/2. The remainder of the proof is a copy of the proof given in Example 3 for $\mathbb{R}^{2}$.

Corollary 50.7. Every compact $m$-manifold has topological dimension at most $m$.

Corollary 50.8. Every compact $m$-manifold can be imbedded in $\mathbb{R}^{2 m+1}$.

Corollary 50.9. Let $X$ be a compact metrizable space. Then $X$ can be imbedded in some euclidean space $\mathbb{R}^{N}$ if and only if $X$ has finite topological dimension.

As mentioned earlier, much of what we have proved holds without assumption of compactness. We ask you to prove the appropriate generalizations in the exercises that follow.

One thing we do not ask you to prove is the fact that the topological dimension of an $m$-manifold is precisely $m$. And for good reason; the proof requires the tools of algebraic topology.

Nor do we ask you to prove that $N=2 m+1$ is the smallest value of $N$ such that every compact metrizable space of topological dimension $m$ can be imbedded in $\mathbb{R}^{N}$. The reason is the same. Even in the case of a linear graph, where $m=1$, the proof is nontrivial, as we remarked earlier.

For further results in dimension theory, the reader is referred to the classical book of Hurewicz and Wallman [H-W]. In particular, this book discusses another, entirely different, definition of topological dimension, due to Menger and Urysohn. It is an inductive definition. The empty set has dimension -1 . And a space has dimension at most $n$ if there is a basis for its topology such that for each basis element $B$, the boundary of $B$ has dimension at most $n-1$. The dimension of a space is the smallest value of $n$ for which this condition holds. This notion of dimension agrees with ours for compact metrizable spaces.

## Exercises

1. Show that any discrete space has dimension 0 .
2. Show that any connected $T_{1}$ space having more than one point has dimension at least 1 .
3. Show that the topologist's sine curve has dimension 1.
4. Show that the points $\mathbf{0}, \epsilon_{1}, \epsilon_{2}, \epsilon_{3}$, and $(1,1,1)$ are in general position in $\mathbb{R}^{3}$. Sketch the corresponding imbedding into $\mathbb{R}^{3}$ of the complete graph on five vertices.
5. Examine the proof of the imbedding theorem in the case $m=1$ and show that the map $g$ of part (2) actually maps $X$ onto a linear graph in $\mathbb{R}^{3}$.
6. Prove the following:

Theorem. Let $X$ be a locally compact Hausdorff space with a countable basis, such that every compact subspace of $X$ has topological dimension at most $m$. Then $X$ is homeomorphic to a closed subspace of $\mathbb{R}^{2 m+1}$.

Proof. If $f: X \rightarrow \mathbb{R}^{N}$ is a continuous map, we say $f(x) \rightarrow \infty$ as $x \rightarrow \infty$ if given $n$, there is a compact subspace $C$ of $X$ such that $f(x)>n$ for $x \in X-C$.

(a) Let $\bar{\rho}$ be the uniform metric on $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$. Show that if $f(x) \rightarrow \infty$ as $x \rightarrow \infty$ and $\bar{\rho}(f, g)<1$, then $g(x) \rightarrow \infty$ as $x \rightarrow \infty$.

(b) Show that if $f(x) \rightarrow \infty$ as $x \rightarrow \infty$, then $f$ extends to a continuous map of one-point compactifications. Conclude that if $f$ is injective as well, then $f$ is a homeomorphism of $X$ with a closed subspace of $\mathbb{R}^{N}$.

(c) Given $f: X \rightarrow \mathbb{R}^{N}$ and given a compact subspace $C$ of $X$, let

$$
U_{\epsilon}(C)=\{f \mid \Delta(f \mid C)<\epsilon\}
$$

Show that $U_{\epsilon}(C)$ is open in $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$.

(d) Show that if $N=2 m+1$, then $U_{\epsilon}(C)$ is dense in $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$. [Hint: Given $f$ and given $\epsilon, \delta>0$, choose $g: C \rightarrow \mathbb{R}^{N}$ so that $d(f(x), g(x))<\delta$ for
$x \in C$, and $\Delta(g)<\epsilon$. Extend $f-g$ to $h: X \rightarrow[-\delta, \delta]^{N}$ using the Tietze theorem.]

(e) Show there exists a map $f: X \rightarrow \mathbb{R}$ such that $f(x) \rightarrow \infty$ as $x \rightarrow \infty$. [Hint: Write $X$ as the union of compact subspaces $C_{n}$ such that $C_{n} \subset$ Int $C_{n+1}$ for each $n$.]

(f) Let $C_{n}$ be as in (e). Use the fact that $\bigcap U_{1 / n}\left(C_{n}\right)$ is dense in $\mathcal{C}\left(X, \mathbb{R}^{N}\right)$ to complete the proof.

7. Corollary. Every $m$-manifold can be imbedded in $\mathbb{R}^{2 m+1}$ as a closed subspace.
8. Recall that $X$ is said to be $\sigma$-compact if there is a countable collection of compact subspaces of $X$ whose interiors cover $X$.

Theorem. Let $X$ be a $\sigma$-compact Hausdorff space. If every compact subspace of $X$ has topological dimension at most $m$, then so does $X$.

Proof. Let $\mathcal{A}$ be an open cover of $X$. Find an open cover $\mathscr{B}$ of $X$ refining $\mathcal{A}$ that has order at most $m+1$, as follows:

(a) Show that $X=\bigcup X_{n}$, where $X_{n}$ is compact and $X_{n} \subset \operatorname{Int} X_{n+1}$ for each $n$. Let $X_{0}=\varnothing$.

(b) Find an open covering $\mathscr{B}_{0}$ of $X$ refining $\mathcal{A}$ such that for each $n$, each element of $\mathscr{B}_{0}$ that intersects $X_{n}$ lies in $X_{n+1}$.

(c) Suppose $n \geq 0$ and $\mathscr{B}_{n}$ is an open covering of $X$ refining $\mathscr{B}_{0}$ such that $\mathcal{B}_{n}$ has order at most $m+1$ at points of $X_{n}$. Choose an open covering $\mathcal{C}$ of $X$ refining $\mathscr{B}_{n}$ that has order at most $m+1$ at points of $X_{n+1}$. Choose $f: \mathcal{C} \rightarrow \mathscr{B}_{n}$ so that $C \subset f(C)$. For $B \in \mathscr{B}_{n}$, let $D(B)$ be the union of those $C$ for which $f(C)=B$. Let $\mathscr{B}_{n+1}$ consist of all sets $B \in \mathscr{B}_{n}$ for which $B \cap X_{n-1} \neq \varnothing$, along with all sets $D(B)$ for which $B \in \mathscr{B}_{n}$ and $B \cap X_{n-1}=\varnothing$. Show that $\mathscr{B}_{n+1}$ is an open covering of $X$ that refines $\mathscr{B}_{n}$ and has order at most $m+1$ at points of $X_{n+1}$.

(d) Define $\mathscr{B}$ as follows: Given a set $B$, it belongs to $\mathscr{B}$ if there is an $N$ such that $B \in \mathscr{B}_{n}$ for all $n \geq N$.

9. Corollary. Every $m$-manifold has topological dimension at most $m$.
10. Corollary. Every closed subspace of $\mathbb{R}^{N}$ has topological dimension at most $N$.
11. Corollary. A space $X$ can be imbedded as a closed subspace of $\mathbb{R}^{N}$ for some $N$ if and only if $X$ is locally compact and Hausdorff with a countable basis, and has finite topological dimension.

## *Supplementary Exercises: Locally Euclidean Spaces

A space $X$ is said to be locally m-euclidean if for each $x \in X$, there is a neighborhood of $x$ that is homeomorphic to an open set of $\mathbb{R}^{m}$. Such a space $X$ automatically satisfies the $T_{1}$ axiom, but it need not be Hausdorff. (See the exercises of §36.) However, if $X$ is Hausdorff and has a countable basis, then $X$ is called an $\boldsymbol{m}$-manifold.

Throughout these exercises, let $X$ be a space that is locally $m$-euclidean.

1. Show that $X$ is locally compact and locally metrizable.
2. Consider the following conditions on $X$ :

(i) $X$ is compact Hausdorff.

(ii) $X$ is an $m$-manifold.

(iii) $X$ is metrizable.

(iv) $X$ is normal.

(v) $X$ is Hausdorff.

Show that (i) $\Rightarrow$ (ii) $\Rightarrow$ (iii) $\Rightarrow$ (iv) $\Rightarrow$ (v).

3. Show that $\mathbb{R}$ is locally 1 -euclidean and satisfies (ii) but not (i).
4. Show that $\mathbb{R} \times \mathbb{R}$ in the dictionary order topology is locally 1 -euclidean and satisfies (iii) but not (ii).
5. Show that the long line is locally 1 -euclidean and satisfies (iv) but not (iii). (See the exercises of §24.)

*6. There is a space that is locally 2-euclidean and satisfies (v) but not (iv). It is constructed as follows. Let $A$ be the following subspace of $\mathbb{R}^{3}$ :

$$
A=\{(x, y, 0) \mid x>0\}
$$

Given $c$ real, let $B_{c}$ be the following subspace of $\mathbb{R}^{3}$ :

$$
B_{c}=\{(x, y, c) \mid x \leq 0\} .
$$

Let $X$ be the set that is the union of $A$ and all the spaces $B_{c}$, for $c$ real. Topologize $X$ by taking as a basis all sets of the following three types:

(i) $U$, where $U$ is open in $A$.

(ii) $V$, where $V$ is open in the subspace of $B_{c}$ consisting of points with $x<0$.

(iii) For each open interval $I=(a, b)$ of $\mathbb{R}$, each real number $c$, and each $\epsilon>0$, the set $A_{c}(I, \epsilon) \cup B_{c}(I, \epsilon)$, where

$$
\begin{aligned}
& A_{c}(I, \epsilon)=\{(x, y, 0) \mid 0<x<\epsilon \text { and } c+a x<y<c+b x\}, \\
& B_{c}(I, \epsilon)=\{(x, y, c) \mid-\epsilon<x \leq 0 \text { and } a<y<b\} .
\end{aligned}
$$

The space $X$ is called the "Prüfer manifold."

(a) Sketch the sets $A_{c}(I, \epsilon)$ and $B_{c}(I, \epsilon)$.

(b) Show the sets of types (i)-(iii) form a basis for a topology on $X$.

(c) Show the map $f_{c}: \mathbb{R}^{2} \rightarrow X$ given by

$$
f_{c}(x, y)= \begin{cases}(x, c+x y, 0) & \text { for } x>0, \\ (x, y, c) & \text { for } x \leq 0\end{cases}
$$

defines a homeomorphism of $\mathbb{R}^{2}$ with the subspace $A \cup B_{c}$ of $X$.
(d) Show that $A \cup B_{c}$ is open in $X$; conclude that $X$ is 2-euclidean.

(e) Show that $X$ is Hausdorff.

(f) Show that $X$ is not normal. [Hint: The subspace

$$
L=\{(0,0, c) \mid c \in \mathbb{R}\}
$$

of $X$ is closed and discrete. Compare Example 3 of §31.]

7. Show that $X$ is Hausdorff if and only if $X$ is completely regular.
8. Show that $X$ is metrizable if and only if $X$ is paracompact Hausdorff.
9. Show that if $X$ is metrizable, then each component of $X$ is an $m$-manifold.

## Chapter 9

## The Fundamental Group

One of the basic problems of topology is to determine whether two given topological spaces are homeomorphic or not. There is no method for solving this problem in general, but techniques do exist that apply in particular cases.

Showing that two spaces are homeomorphic is a matter of constructing a continuous mapping from one to the other having a continuous inverse, and constructing continuous functions is a problem that we have developed techniques to handle.

Showing that two spaces are not homeomorphic is a different matter. For that, one must show that a continuous function with continuous inverse does not exist. If one can find some topological property that holds for one space but not for the other, then the problem is solved-the spaces cannot be homeomorphic. The closed interval $[0,1]$ cannot be homeomorphic to the open interval $(0,1)$, for instance, because the first space is compact and the second one is not. And the real line $\mathbb{R}$ cannot be homeomorphic to the "long line" $L$, because $\mathbb{R}$ has a countable basis and $L$ does not. Nor can the real line $\mathbb{R}$ be homeomorphic to the plane $\mathbb{R}^{2}$; deleting a point from $\mathbb{R}^{2}$ leaves a connected space remaining, and deleting a point from $\mathbb{R}$ does not.

But the topological properties we have studied up to now do not carry us very far in solving the problem. For instance, how does one show that the plane $\mathbb{R}^{2}$ is not homeomorphic to three-dimensional space $\mathbb{R}^{3}$ ? As one goes down the list of topological properties-compactness, connectedness, local connectedness, metrizability, and so on-one can find no topological property that distinguishes between them. As another example, consider such surfaces as the 2-sphere $S^{2}$, the torus $T$ (surface of a
doughnut), and the double torus $T \# T$ (surface of a two-holed doughnut). None of the topological properties we have studied up to now will distinguish between them.

So we must introduce new properties and new techniques. One of the most natural such properties is that of simple connectedness. You probably have studied this notion already, when you studied line integrals in the plane. Roughly speaking, one says that a space $X$ is simply connected if every closed curve in $X$ can be shrunk to a point in $X$. (We shall make this more precise later.) The property of simple connectedness, it turns out, will distinguish between $\mathbb{R}^{2}$ and $\mathbb{R}^{3}$; deleting a point from $\mathbb{R}^{3}$ leaves a simply connected space remaining, but deleting a point from $\mathbb{R}^{2}$ does not. It will also distinguish between $S^{2}$ (which is simply connected) and the torus $T$ (which is not). But it will not distinguish between $T$ and $T \# T$; neither of them is simply connected.

There is an idea more general than the idea of simple connectedness, an idea that includes simple connectedness as a special case. It involves a certain group that is called the fundamental group of the space. Two spaces that are homeomorphic have fundamental groups that are isomorphic. And the condition of simple connectedness is just the condition that the fundamental group of $X$ is the trivial (one-element) group. Thus, the proof that $S^{2}$ and $T$ are not homeomorphic can be rephrased by saying that the fundamental group of $S^{2}$ is trivial and the fundamental group of $T$ is not. The fundamental group will distinguish between more spaces than the condition of simple connectedness will. It can be used, for example, to show that $T$ and $T \# T$ are not homeomorphic; it turns out that $T$ has an abelian fundamental group and $T \# T$ does not.

In this chapter, we define the fundamental group and study its properties. Then we apply it to a number of problems, including the problem of showing that various spaces, such as those already mentioned, are not homeomorphic.

Other applications include theorems about fixed points and antipode-preserving maps of the sphere, as well as the well-known fundamental theorem of algebra, which says that every polynomial equation with real or complex coefficients has a root. Finally, there is the famous Jordan curve theorem, which we shall study in the next chapter; it states that every simple closed curve $C$ in the plane separates the plane into two components, of which $C$ is the common boundary.

Throughout, we assume familiarity with the quotient topology (\$22) and local connectedness ( $\$ 25)$.

## §51 Homotopy of Paths

Before defining the fundamental group of a space $X$, we shall consider paths on $X$ and an equivalence relation called path homotopy between them. And we shall define a certain operation on the collection of the equivalence classes that makes it into what is called in algebra a groupoid.

Definition. If $f$ and $f^{\prime}$ are continuous maps of the space $X$ into the space $Y$, we say that $f$ is homotopic to $f^{\prime}$ if there is a continuous map $F: X \times I \rightarrow Y$ such that

$$
F(x, 0)=f(x) \quad \text { and } \quad F(x, 1)=f^{\prime}(x)
$$

for each $x$. (Here $I=[0,1]$.) The map $F$ is called a homotopy between $f$ and $f^{\prime}$. If $f$ is homotopic to $f^{\prime}$, we write $f \simeq f^{\prime}$. If $f \simeq f^{\prime}$ and $f^{\prime}$ is a constant map, we say that $f$ is nulhomotopic.

We think of a homotopy as a continuous one-parameter family of maps from $X$ to $Y$. If we imagine the parameter $t$ as representing time, then the homotopy $F$ represents a continuous "deforming" of the map $f$ to the map $f^{\prime}$, as $t$ goes from 0 to 1.

Now we consider the special case in which $f$ is a path in $X$. Recall that if $f$ : $[0,1] \rightarrow X$ is a continuous map such that $f(0)=x_{0}$ and $f(1)=x_{1}$, we say that $f$ is a path in $X$ from $x_{0}$ to $x_{1}$. We also say that $x_{0}$ is the initial point, and $x_{1}$ the final point, of the path $f$. In this chapter, we shall for convenience use the interval $I=[0,1]$ as the domain for all paths.

If $f$ and $f^{\prime}$ are two paths in $X$, there is a stronger relation between them than mere homotopy. It is defined as follows:

Definition. Two paths $f$ and $f^{\prime}$, mapping the interval $I=[0,1]$ into $X$, are said to be path homotopic if they have the same initial point $x_{0}$ and the same final point $x_{1}$, and if there is a continuous map $F: I \times I \rightarrow X$ such that

$$
\begin{array}{lll}
F(s, 0)=f(s) & \text { and } & F(s, 1)=f^{\prime}(s), \\
F(0, t)=x_{0} & \text { and } & F(1, t)=x_{1},
\end{array}
$$

for each $s \in I$ and each $t \in I$. We call $F$ a path homotopy between $f$ and $f^{\prime}$. See Figure 51.1. If $f$ is path homotopic to $f^{\prime}$, we write $f \simeq_{p} f^{\prime}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-322.jpg?height=475&width=1079&top_left_y=1697&top_left_x=479)

Figure 51.1

The first condition says simply that $F$ is a homotopy between $f$ and $f^{\prime}$, and the second says that for each $t$, the path $f_{t}$ defined by the equation $f_{t}(s)=F(s, t)$ is a path from $x_{0}$ to $x_{1}$. Said differently, the first condition says that $F$ represents a continuous way of deforming the path $f$ to the path $f^{\prime}$, and the second condition says that the end points of the path remain fixed during the deformation.

Lemma 51.1. The relations $\simeq$ and $\simeq$ are equivalence relations.

If $f$ is a path, we shall denote its path-homotopy equivalence class by $[f]$.

Proof. Let us verify the properties of an equivalence relation.

Given $f$, it is trivial that $f \simeq f$; the map $F(x, t)=f(x)$ is the required homotopy. If $f$ is a path, $F$ is a path homotopy.

Given $f \simeq f^{\prime}$, we show that $f^{\prime} \simeq f$. Let $F$ be a homotopy between $f$ and $f^{\prime}$. Then $G(x, t)=F(x, 1-t)$ is a homotopy between $f^{\prime}$ and $f$. If $F$ is a path homotopy, so is $G$.

Suppose that $f \simeq f^{\prime}$ and $f^{\prime} \simeq f^{\prime \prime}$. We show that $f \simeq f^{\prime \prime}$. Let $F$ be a homotopy between $f$ and $f^{\prime}$, and let $F^{\prime}$ be a homotopy between $f^{\prime}$ and $f^{\prime \prime}$. Define $G: X \times I \rightarrow$ $Y$ by the equation

$$
G(x, t)= \begin{cases}F(x, 2 t) & \text { for } t \in\left[0, \frac{1}{2}\right] \\ F^{\prime}(x, 2 t-1) & \text { for } t \in\left[\frac{1}{2}, 1\right]\end{cases}
$$

The map $G$ is well defined, since if $t=\frac{1}{2}$, we have $F(x, 2 t)=f^{\prime}(x)=F^{\prime}(x, 2 t-1)$. Because $G$ is continuous on the two closed subsets $X \times\left[0, \frac{1}{2}\right]$ and $X \times\left[\frac{1}{2}, 1\right]$ of $X \times I$, it is continuous on all of $X \times I$, by the pasting lemma. Thus $G$ is the required homotopy between $f$ and $f^{\prime \prime}$.

You can check that if $F$ and $F^{\prime}$ are path homotopies, so is $G$. See Figure 51.2.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-323.jpg?height=444&width=1108&top_left_y=1579&top_left_x=645)

Figure 51.2

EXAMPLE 1. Let $f$ and $g$ be any two maps of a space $X$ into $\mathbb{R}^{2}$. It is easy to see that $f$ and $g$ are homotopic; the map

$$
F(x, t)=(1-t) f(x)+\operatorname{tg}(x)
$$

is a homotopy between them. It is called a straight-line homotopy because it moves the point $f(x)$ to the point $g(x)$ along the straight-line segment joining them.

If $f$ and $g$ are paths from $x_{0}$ to $x_{1}$, then $F$ will be a path homotopy, as you can check. This situation is pictured in Figure 51.3.

More generally, let $A$ be any convex subspace of $\mathbb{R}^{n}$. (This means that for any two points $a, b$ of $A$, the straight line segment joining $a$ and $b$ is contained in $A$.) Then any two paths $f, g$ in $A$ from $x_{0}$ to $x_{1}$ are path homotopic in $A$, for the straight-line homotopy $F$ between them has image set in $A$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-324.jpg?height=563&width=532&top_left_y=751&top_left_x=464)

Figure 51.3

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-324.jpg?height=561&width=444&top_left_y=752&top_left_x=1085)

Figure 51.4

EXAMPLE 2. Let $X$ denote the punctured plane, $\mathbb{R}^{2}-\{\mathbf{0}\}$, which we shall denote by $\mathbb{R}^{2}-\mathbf{0}$ for short. The following paths in $X$,

$$
\begin{aligned}
& f(s)=(\cos \pi s, \sin \pi s) \\
& g(s)=(\cos \pi s, 2 \sin \pi s)
\end{aligned}
$$

are path homotopic; the straight-line homotopy between them is an acceptable path homotopy. But the straight-line homotopy between $f$ and the path

$$
h(s)=(\cos \pi s,-\sin \pi s)
$$

is not acceptable, for its image does not lie in the space $X=\mathbb{R}^{2}-\mathbf{0}$. See Figure 51.4.

Indeed, there exists no path homotopy in $X$ between paths $f$ and $h$. This result is hardly surprising; it is intuitively clear that one cannot "deform $f$ past the hole at 0 " without introducing a discontinuity. But it takes some work to prove. We shall return to this example later.

This example illustrates the fact that you must know what the range space is before you can tell whether two paths are path homotopic or not. The paths $f$ and $h$ would be path homotopic if they were paths in $\mathbb{R}^{2}$.

Now we introduce some algebra into this geometric situation. We define a certain operation on path-homotopy classes as follows:

Definition. If $f$ is a path in $X$ from $x_{0}$ to $x_{1}$, and if $g$ is a path in $X$ from $x_{1}$ to $x_{2}$, we define the product $f * g$ of $f$ and $g$ to be the path $h$ given by the equations

$$
h(s)= \begin{cases}f(2 s) & \text { for } s \in\left[0, \frac{1}{2}\right] \\ g(2 s-1) & \text { for } s \in\left[\frac{1}{2}, 1\right]\end{cases}
$$

The function $h$ is well-defined and continuous, by the pasting lemma; it is a path in $X$ from $x_{0}$ to $x_{2}$. We think of $h$ as the path whose first half is the path $f$ and whose second half is the path $g$.

The product operation on paths induces a well-defined operation on path-homotopy classes, defined by the equation

$$
[f] *[g]=[f * g] .
$$

To verify this fact, let $F$ be a path homotopy between $f$ and $f^{\prime}$ and let $G$ be a path homotopy between $g$ and $g^{\prime}$. Define

$$
H(s, t)= \begin{cases}F(2 s, t) & \text { for } s \in\left[0, \frac{1}{2}\right] \\ G(2 s-1, t) & \text { for } s \in\left[\frac{1}{2}, 1\right]\end{cases}
$$

Because $F(1, t)=x_{1}=G(0, t)$ for all $t$, the map $H$ is well-defined; it is continuous by the pasting lemma. You can check that $H$ is the required path homotopy between $f * g$ and $f^{\prime} * g^{\prime}$. It is pictured in Figure 51.5.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-325.jpg?height=433&width=1035&top_left_y=1421&top_left_x=679)

Figure 51.5

The operation $*$ on path-homotopy classes turns out to satisfy properties that look very much like the axioms for a group. They are called the groupoid properties of $*$. One difference from the properties of a group is that $[f] *[g]$ is not defined for every pair of classes, but only for those pairs $[f],[g]$ for which $f(1)=g(0)$.

Theorem 51.2. The operation $*$ has the following properties:

(1) (Associativity) If $[f] *([g] *[h])$ is defined, so is $([f] *[g]) *[h]$, and they are equal.

(2) (Right and left identities) Given $x \in X$, let $e_{x}$ denote the constant path $e_{x}: I \rightarrow$ $X$ carrying all of $I$ to the point $x$. If $f$ is a path in $X$ from $x_{0}$ to $x_{1}$, then

$$
[f] *\left[e_{x_{1}}\right]=[f] \quad \text { and } \quad\left[e_{x_{0}}\right] *[f]=[f]
$$

(3) (Inverse) Given the path $f$ in $X$ from $x_{0}$ to $x_{1}$, let $\bar{f}$ be the path defined by $\bar{f}(s)=f(1-s)$. It is called the reverse of $f$. Then

$$
[f] *[\bar{f}]=\left[e_{x_{0}}\right] \quad \text { and } \quad[\bar{f}] *[f]=\left[e_{x_{1}}\right]
$$

Proof. We shall make use of two elementary facts. The first is the fact that if $k$ : $X \rightarrow Y$ is a continuous map, and if $F$ is a path homotopy in $X$ between the paths $f$ and $f^{\prime}$, then $k \circ F$ is a path homotopy in $Y$ between the paths $k \circ f$ and $k \circ f^{\prime}$. See Figure 51.6.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-326.jpg?height=267&width=1160&top_left_y=996&top_left_x=441)

Figure 51.6

The second is the fact that if $k: X \rightarrow Y$ is a continuous map and if $f$ and $g$ are paths in $X$ with $f(1)=g(0)$, then

$$
k \circ(f * g)=(k \circ f) *(k \circ g) .
$$

This equation follows at once from the definition of the product operation $*$.

Step 1 . We verify properties (2) and (3). To verify (2), we let $e_{0}$ denote the constant path in $I$ at 0 , and we let $i: I \rightarrow I$ denote the identity map, which is a path in $I$ from 0 to 1 . Then $e_{0} * i$ is also a path in $I$ from 0 to 1 . (The graphs of these two paths are pictured in Figure 51.7.)
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-326.jpg?height=472&width=1152&top_left_y=1815&top_left_x=443)

Figure 51.7

Because $I$ is convex, there is a path homotopy $G$ in $I$ between $i$ and $e_{0} * i$. Then $f \circ G$ is a path homotopy in $X$ between the paths $f \circ i=f$ and

$$
f \circ\left(e_{0} * i\right)=\left(f \circ e_{0}\right) *(f \circ i)=e_{x_{0}} * f
$$

An entirely similar argument, using the fact that if $e_{1}$ denotes the constant path at 1 , then $i * e_{1}$ is path homotopic in $I$ to the path $i$, shows that $[f] *\left[e_{x_{1}}\right]=[f]$.

To verify (3), note that the reverse of $i$ is $\bar{l}(s)=1-s$. Then $i * \bar{l}$ is a path in $I$ beginning and ending at 0 , and so is the constant path $e_{0}$. (Their graphs are pictured in Figure 51.8.) Because $I$ is convex, there is a path homotopy $H$ in $I$ between $e_{0}$ and $i * \bar{\imath}$. Then $f \circ H$ is a path homotopy between $f \circ e_{0}=e_{x_{0}}$ and

$$
(f \circ i) *(f \circ \bar{\imath})=f * \bar{f} .
$$

An entirely similar argument, using the fact that $\bar{l} * i$ is path homotopic in $I$ to $e_{1}$, shows that $[\bar{f}] *[f]=\left[e_{x_{1}}\right]$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-327.jpg?height=450&width=1156&top_left_y=1082&top_left_x=620)

Figure 51.8

Step 2. The proof of (1), associativity, is a bit trickier. For this proof, and for later use as well, it will be convenient to describe the product $f * g$ in a different way.

If $[a, b]$ and $[c, d]$ are two intervals in $\mathbb{R}$, there is a unique map $p:[a, b] \rightarrow[c, d]$ of the form $p(x)=m x+k$ that carries $a$ to $c$ and $b$ to $d$; we call it the positive linear map of $[a, b]$ to $[c, d]$ because its graph is a straight line with positive slope. Note that the inverse of such a map is another such map, and so is the composite of two such maps.

With this terminology, the product $f * g$ can be described as follows: On $\left[0, \frac{1}{2}\right]$, it equals the positive linear map of $\left[0, \frac{1}{2}\right]$ to $[0,1]$, followed by $f$; and on $\left[\frac{1}{2}, 1\right]$, it equals the positive linear map of $\left[\frac{1}{2}, 1\right]$ to $[0,1]$, followed by $g$.

Now we verify (1). Given paths $f, g$, and $h$ in $X$, the products $f *(g * h)$ and $(f * g) * h$ are defined precisely when $f(1)=g(0)$ and $g(1)=h(0)$. Assuming these two conditions, we define also a "triple product" of the paths $f, g$, and $h$ as follows: Choose points $a$ and $b$ of $I$ so that $0<a<b<1$. Define a path $k_{a, b}$ in $X$ as follows:

On $[0, a]$ it equals the positive linear map of $[0, a]$ to $I$ followed by $f$; on $[a, b]$ it equals the positive linear map of $[a, b]$ to $I$ followed by $g$; and on $[b, 1]$ it equals the positive linear map of $[b, 1]$ to $I$ followed by $h$. The path $k_{a, b}$ depends of course on the choice of the points $a$ and $b$. But its path-homotopy class does not! We show that if $c$ and $d$ are another pair of points of $I$ with $0<c<d<1$, then $k_{c, d}$ is path homotopic to $k_{a, b}$.

Let $p: I \rightarrow I$ be the map whose graph is pictured in Figure 51.9. When restricted to $[0, a],[a, b]$, and $[b, 1]$, respectively, it equals the positive linear maps of these intervals onto $[0, c],[c, d]$, and $[d, 1]$, respectively. It follows at once that $k_{c, d} \circ p$ equals $k_{a, b}$. But $p$ is a path in $I$ from 0 to 1 ; and so is the identity map $i: I \rightarrow I$. Hence, there is a path homotopy $P$ in $I$ between $p$ and $i$. Then $k_{c, d} \circ P$ is a path homotopy in $X$ between $k_{a, b}$ and $k_{c, d}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-328.jpg?height=460&width=589&top_left_y=958&top_left_x=724)

Figure 51.9

What has this to do with associativity? A great deal. For the product $f *(g * h)$ is exactly the triple product $k_{a, b}$ in the case where $a=1 / 2$ and $b=3 / 4$, as you can check, while the product $(f * g) * h$ equals $k_{c, d}$ in the case where $c=1 / 4$ and $d=1 / 2$. Therefore these two products are path homotopic.

The argument just used to prove associativity goes through for any finite product of paths. Roughly speaking, it says that as far as the path-homotopy class of the result is concerned, it doesn't matter how you chop up the interval when you form the product of paths! This result will be useful to us later, so we state it formally as a theorem here:

Theorem 51.3. Let $f$ be a path in $X$, and let $a_{0}, \ldots, a_{n}$ be numbers such that $0=a_{0}<a_{1}<\cdots<a_{n}=1$. Let $f_{i}: I \rightarrow X$ be the path that equals the positive linear map of $I$ onto $\left[a_{i-1}, a_{i}\right]$ followed by $f$. Then

$$
[f]=\left[f_{1}\right] * \cdots *\left[f_{n}\right]
$$

## Exercises

1. Show that if $h, h^{\prime}: X \rightarrow Y$ are homotopic and $k, k^{\prime}: Y \rightarrow Z$ are homotopic, then $k \circ h$ and $k^{\prime} \circ h^{\prime}$ are homotopic.
2. Given spaces $X$ and $Y$, let $[X, Y]$ denote the set of homotopy classes of maps of $X$ into $Y$.

(a) Let $I=[0,1]$. Show that for any $X$, the set $[X, I]$ has a single element.

(b) Show that if $Y$ is path connected, the set $[I, Y]$ has a single element.

3. A space $X$ is said to be contractible if the identity map $i_{X}: X \rightarrow X$ is nulhomotopic.

(a) Show that $I$ and $\mathbb{R}$ are contractible.

(b) Show that a contractible space is path connected.

(c) Show that if $Y$ is contractible, then for any $X$, the set $[X, Y]$ has a single element.

(d) Show that if $X$ is contractible and $Y$ is path connected, then $[X, Y]$ has a single element.

## §52 The Fundamental Group

The set of path-homotopy classes of paths in a space $X$ does not form a group under the operation $*$ because the product of two path-homotopy classes is not always defined. But suppose we pick out a point $x_{0}$ of $X$ to serve as a "base point" and restrict ourselves to those paths that begin and end at $x_{0}$. The set of these path-homotopy classes does form a group under $*$. It will be called the fundamental group of $X$.

In this section, we shall study the fundamental group and derive some of its properties. In particular, we shall show that the group is a topological invariant of the space $X$, the fact that is of crucial importance in using it to study homeomorphism problems.

Let us first review some terminology from group theory. Suppose $G$ and $G^{\prime}$ are groups, written multiplicatively. A homomorphism $f: G \rightarrow G^{\prime}$ is a map such that $f(x \cdot y)=f(x) \cdot f(y)$ for all $x, y$; it automatically satisfies the equations $f(e)=e^{\prime}$ and $f\left(x^{-1}\right)=f(x)^{-1}$, where $e$ and $e^{\prime}$ are the identities of $G$ and $G^{\prime}$, respectively, and the exponent -1 denotes the inverse. The kernel of $f$ is the set $f^{-1}\left(e^{\prime}\right)$; it is a subgroup of $G$. The image of $f$, similarly, is a subgroup of $G^{\prime}$. The homomorphism $f$ is called a monomorphism if it is injective (or equivalently, if the kernel of $f$ consists of $e$ alone). It is called an epimorphism if it is surjective; and it is called an isomorphism if it is bijective.

Suppose $G$ is a group and $H$ is a subgroup of $G$. Let $x H$ denote the set of all products $x h$, for $h \in H$; it is called a left coset of $H$ in $G$. The collection of all such cosets forms a partition of $G$. Similarly, the collection of all right cosets $H x$ of $H$ in $G$ forms a partition of $G$. We call $H$ a normal subgroup of $G$ if $x \cdot h \cdot x^{-1} \in H$ for each $x \in G$ and each $h \in H$. In this case, we have $x H=H x$ for each $x$, so that our two
partitions of $G$ are the same. We denote this partition by $G / H$; if one defines

$$
(x H) \cdot(y H)=(x \cdot y) H,
$$

one obtains a well-defined operation on $G / H$ that makes it a group. This group is called the quotient of $G$ by $H$. The map $f: G \rightarrow G / H$ carrying $x$ to $x H$ is an epimorphism with kernel $H$. Conversely, if $f: G \rightarrow G^{\prime}$ is an epimorphism, then its kernel $N$ is a normal subgroup of $G$, and $f$ induces an isomorphism $G / N \rightarrow G^{\prime}$ that carries $x N$ to $f(x)$ for each $x \in G$.

If the subgroup $H$ of $G$ is not normal, it will still be convenient to use the symbol $G / H$; we will use it to denote the collection of right cosets of $H$ in $G$.

Now we define the fundamental group.

Definition. Let $X$ be a space; let $x_{0}$ be a point of $X$. A path in $X$ that begins and ends at $x_{0}$ is called a loop based at $x_{0}$. The set of path homotopy classes of loops based at $x_{0}$, with the operation $*$, is called the fundamental group of $X$ relative to the base point $x_{0}$. It is denoted by $\pi_{1}\left(X, x_{0}\right)$.

It follows from Theorem 51.2 that the operation $*$, when restricted to this set, satisfies the axioms for a group. Given two loops $f$ and $g$ based at $x_{0}$, the product $f * g$ is always defined and is a loop based at $x_{0}$. Associativity, the existence of an identity element $\left[e_{x_{0}}\right]$, and the existence of an inverse $[\bar{f}]$ for $[f]$ are immediate.

Sometimes this group is called the first homotopy group of $X$, which term implies that there is a second homotopy group. There are indeed groups $\pi_{n}\left(X, x_{0}\right)$ for all $n \in \mathbb{Z}_{+}$, but we shall not study them in this book. They are part of the general subject called homotopy theory.

EXAMPLE 1. Let $\mathbb{R}^{n}$ denote euclidean $n$-space. Then $\pi_{1}\left(\mathbb{R}^{n}, x_{0}\right)$ is the trivial group (the group consisting of the identity alone). For if $f$ is a loop in $\mathbb{R}^{n}$ based at $x_{0}$, the straight-line homotopy is a path homotopy between $f$ and the constant path at $x_{0}$. More generally, if $X$ is any convex subset of $\mathbb{R}^{n}$, then $\pi_{1}\left(X, x_{0}\right)$ is the trivial group. In particular, the unit ball $B^{n}$ in $\mathbb{R}^{n}$,

$$
B^{n}=\left\{\mathbf{x} \mid x_{1}^{2}+\cdots+x_{n}^{2} \leq 1\right\},
$$

has trivial fundamental group.

An immediate question one asks is the extent to which the fundamental group depends on the base point. We consider that question now.

Definition. Let $\alpha$ be a path in $X$ from $x_{0}$ to $x_{1}$. We define a map

$$
\hat{\alpha}: \pi_{1}\left(X, x_{0}\right) \longrightarrow \pi_{1}\left(X, x_{1}\right)
$$

by the equation

$$
\hat{\alpha}([f])=[\bar{\alpha}] *[f] *[\alpha] .
$$

The map $\hat{\alpha}$, which we call " $\alpha$-hat," is well-defined because the operation $*$ is welldefined. If $f$ is a loop based at $x_{0}$, then $\bar{\alpha} *(f * \alpha)$ is a loop based at $x_{1}$. Hence $\hat{\alpha}$ maps $\pi_{1}\left(X, x_{0}\right)$ into $\pi_{1}\left(X, x_{1}\right)$, as desired; note that it depends only on the path-homotopy class of $\alpha$. It is pictured in Figure 52.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-331.jpg?height=453&width=807&top_left_y=362&top_left_x=790)

Figure 52.1

Theorem 52.1. The map $\hat{\alpha}$ is a group isomorphism.

Proof. To show that $\hat{\alpha}$ is a homomorphism, we compute

$$
\begin{aligned}
\hat{\alpha}([f]) * \hat{\alpha}([g]) & =([\bar{\alpha}] *[f] *[\alpha]) *([\bar{\alpha}] *[g] *[\alpha]) \\
& =[\bar{\alpha}] *[f] *[g] *[\alpha] \\
& =\hat{\alpha}([f] *[g])
\end{aligned}
$$

To show that $\hat{\alpha}$ is an isomorphism, we show that if $\beta$ denotes the path $\bar{\alpha}$, which is the reverse of $\alpha$, then $\hat{\beta}$ is an inverse for $\hat{\alpha}$. We compute, for each element $[h]$ of $\pi_{1}\left(X, x_{1}\right)$,

$$
\begin{aligned}
\hat{\beta}([h]) & =[\bar{\beta}] *[h] *[\beta]=[\alpha] *[h] *[\bar{\alpha}], \\
\hat{\alpha}(\hat{\beta}([h])) & =[\bar{\alpha}] *([\alpha] *[h] *[\bar{\alpha}]) *[\alpha]=[h] .
\end{aligned}
$$

A similar computation shows that $\hat{\beta}(\hat{\alpha}([f]))=[f]$ for each $[f] \in \pi_{1}\left(X, x_{0}\right)$.

Corollary 52.2. If $X$ is path connected and $x_{0}$ and $x_{1}$ are two points of $X$, then $\pi_{1}\left(X, x_{0}\right)$ is isomorphic to $\pi_{1}\left(X, x_{1}\right)$.

Suppose that $X$ is a topological space. Let $C$ be the path component of $X$ containing $x_{0}$. It is easy to see that $\pi_{1}\left(C, x_{0}\right)=\pi_{1}\left(X, x_{0}\right)$, since all loops and homotopies in $X$ that are based at $x_{0}$ must lie in the subspace $C$. Thus $\pi_{1}\left(X, x_{0}\right)$ depends on only the path component of $X$ containing $x_{0}$; it gives us no information whatever about the rest of $X$. For this reason, it is usual to deal with only path-connected spaces when studying the fundamental group.

If $X$ is path connected, all the groups $\pi_{1}(X, x)$ are isomorphic, so it is tempting to try to "identify" all these groups with one another and to speak simply of the fundamental group of the space $X$, without reference to base point. The difficulty with this approach is that there is no natural way of identifying $\pi_{1}\left(X, x_{0}\right)$ with $\pi_{1}\left(X, x_{1}\right)$; different paths $\alpha$ and $\beta$ from $x_{0}$ to $x_{1}$ may give rise to different isomorphisms between these groups. For this reason, omitting the base point can lead to error.

It turns out that the isomorphism of $\pi_{1}\left(X, x_{0}\right)$ with $\pi_{1}\left(X, x_{1}\right)$ is independent of path if and only if the fundamental group is abelian. (See Exercise 3.) This is a stringent requirement on the space $X$.

Definition. A space $X$ is said to be simply connected if it is a path-connected space and if $\pi_{1}\left(X, x_{0}\right)$ is the trivial (one-element) group for some $x_{0} \in X$, and hence for every $x_{0} \in X$. We often express the fact that $\pi_{1}\left(X, x_{0}\right)$ is the trivial group by writing $\pi_{1}\left(X, x_{0}\right)=0$.

Lemma 52.3. In a simply connected space $X$, any two paths having the same initial and final points are path homotopic.

Proof. Let $\alpha$ and $\beta$ be two paths from $x_{0}$ to $x_{1}$. Then $\alpha * \bar{\beta}$ is defined and is a loop on $X$ based at $x_{0}$. Since $X$ is simply connected, this loop is path homotopic to the constant loop at $x_{0}$. Then

$$
[\alpha * \bar{\beta}] *[\beta]=\left[e_{x_{0}}\right] *[\beta],
$$

from which it follows that $[\alpha]=[\beta]$.

It is intuitively clear that the fundamental group is a topological invariant of the space $X$. A convenient way to prove this fact formally is to introduce the notion of the "homomorphism induced by a continuous map."

Suppose that $h: X \rightarrow Y$ is a continuous map that carries the point $x_{0}$ of $X$ to the point $y_{0}$ of $Y$. We often denote this fact by writing

$$
h:\left(X, x_{0}\right) \longrightarrow\left(Y, y_{0}\right) .
$$

If $f$ is a loop in $X$ based at $x_{0}$, then the composite $h \circ f: I \rightarrow Y$ is a loop in $Y$ based at $y_{0}$. The correspondence $f \rightarrow h \circ f$ thus gives rise to a map carrying $\pi_{1}\left(X, x_{0}\right)$ into $\pi_{1}\left(Y, y_{0}\right)$. We define it formally as follows:

Definition. Let $h:\left(X, x_{0}\right) \rightarrow\left(Y, y_{0}\right)$ be a continuous map. Define

$$
h_{*}: \pi_{1}\left(X, x_{0}\right) \longrightarrow \pi_{1}\left(Y, y_{0}\right)
$$

by the equation

$$
h_{*}([f])=[h \circ f] .
$$

The map $h_{*}$ is called the homomorphism induced by $\boldsymbol{h}$, relative to the base point $x_{0}$.

The map $h_{*}$ is well-defined, for if $F$ is a path homotopy between the paths $f$ and $f^{\prime}$, then $h \circ F$ is a path homotopy between the paths $h \circ f$ and $h \circ f^{\prime}$. The fact that $h_{*}$ is a homomorphism follows from the equation

$$
(h \circ f) *(h \circ g)=h \circ(f * g) .
$$

The homomorphism $h_{*}$ depends not only on the map $h: X \rightarrow Y$ but also on the choice of the base point $x_{0}$. (Once $x_{0}$ is chosen, $y_{0}$ is determined by $h$.) So some notational difficulty will arise if we want to consider several different base points for $X$. If $x_{0}$ and $x_{1}$ are two different points of $X$, we cannot use the same symbol $h_{*}$ to stand for two different homomorphisms, one having domain $\pi_{1}\left(X, x_{0}\right)$ and the other having domain $\pi_{1}\left(X, x_{1}\right)$. Even if $X$ is path connected, so these groups are isomorphic, they are still not the same group. In such a case, we shall use the notation

$$
\left(h_{x_{0}}\right)_{*}: \pi_{1}\left(X, x_{0}\right) \longrightarrow \pi_{1}\left(Y, y_{0}\right)
$$

for the first homomorphism and $\left(h_{x_{1}}\right)_{*}$ for the second. If there is only one base point under consideration, we shall omit mention of the base point and denote the induced homomorphism merely by $h_{*}$.

The induced homomorphism has two properties that are crucial in the applications. They are called its "functorial properties" and are given in the following theorem:

Theorem 52.4. If $h:\left(X, x_{0}\right) \rightarrow\left(Y, y_{0}\right)$ and $k:\left(Y, y_{0}\right) \rightarrow\left(Z, z_{0}\right)$ are continuous, then $(k \circ h)_{*}=k_{*} \circ h_{*}$. If $i:\left(X, x_{0}\right) \rightarrow\left(X, x_{0}\right)$ is the identity map, then $i_{*}$ is the identity homomorphism.

Proof. The proof is a triviality. By definition,

$$
\begin{aligned}
(k \circ h)_{*}([f]) & =[(k \circ h) \circ f], \\
\left(k_{*} \circ h_{*}\right)([f]) & =k_{*}\left(h_{*}([f])\right)=k_{*}([h \circ f])=[k \circ(h \circ f)] .
\end{aligned}
$$

Similarly, $i_{*}([f])=[i \circ f]=[f]$.

Corollary 52.5. If $h:\left(X, x_{0}\right) \rightarrow\left(Y, y_{0}\right)$ is a homeomorphism of $X$ with $Y$, then $h_{*}$ is an isomorphism of $\pi_{1}\left(X, x_{0}\right)$ with $\pi_{1}\left(Y, y_{0}\right)$.

Proof. Let $k:\left(Y, y_{0}\right) \rightarrow\left(X, x_{0}\right)$ be the inverse of $h$. Then $k_{*} \circ h_{*}=(k \circ h)_{*}=i_{*}$, where $i$ is the identity map of $\left(X, x_{0}\right)$; and $h_{*} \circ k_{*}=(h \circ k)_{*}=j_{*}$, where $j$ is the identity map of $\left(Y, y_{0}\right)$. Since $i_{*}$ and $j_{*}$ are the identity homomorphisms of the groups $\pi_{1}\left(X, x_{0}\right)$ and $\pi_{1}\left(Y, y_{0}\right)$, respectively, $k_{*}$ is the inverse of $h_{*}$.

## Exercises

1. A subset $A$ of $\mathbb{R}^{n}$ is said to be star convex if for some point $a_{0}$ of $A$, all the line segments joining $a_{0}$ to other points of $A$ lie in $A$.

(a) Find a star convex set that is not convex.

(b) Show that if $A$ is star convex, $A$ is simply connected.

2. Let $\alpha$ be a path in $X$ from $x_{0}$ to $x_{1}$; let $\beta$ be a path in $X$ from $x_{1}$ to $x_{2}$. Show that if $\gamma=\alpha * \beta$, then $\hat{\gamma}=\hat{\beta} \circ \hat{\alpha}$.
3. Let $x_{0}$ and $x_{1}$ be points of the path-connected space $X$. Show that $\pi_{1}\left(X, x_{0}\right)$ is abelian if and only if for every pair $\alpha$ and $\beta$ of paths from $x_{0}$ to $x_{1}$, we have $\hat{\alpha}=\hat{\beta}$.
4. Let $A \subset X$; suppose $r: X \rightarrow A$ is a continuous map such that $r(a)=a$ for each $a \in A$. (The map $r$ is called a retraction of $X$ onto $A$.) If $a_{0} \in A$, show that

$$
r_{*}: \pi_{1}\left(X, a_{0}\right) \longrightarrow \pi_{1}\left(A, a_{0}\right)
$$

is surjective.

5. Let $A$ be a subspace of $\mathbb{R}^{n}$; let $h:\left(A, a_{0}\right) \rightarrow\left(Y, y_{0}\right)$. Show that if $h$ is extendable to a continuous map of $\mathbb{R}^{n}$ into $Y$, then $h_{*}$ is the trivial homomorphism (the homomorphism that maps everything to the identity element).
6. Show that if $X$ is path connected, the homomorphism induced by a continuous map is independent of base point, up to isomorphisms of the groups involved. More precisely, let $h: X \rightarrow Y$ be continuous, with $h\left(x_{0}\right)=y_{0}$ and $h\left(x_{1}\right)=y_{1}$. Let $\alpha$ be a path in $X$ from $x_{0}$ to $x_{1}$, and let $\beta=h \circ \alpha$. Show that

$$
\hat{\beta} \circ\left(h_{x_{0}}\right)_{*}=\left(h_{x_{1}}\right)_{*} \circ \hat{\alpha}
$$

This equation expresses the fact that the following diagram of maps "commutes."

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-334.jpg?height=208&width=406&top_left_y=1195&top_left_x=860)

7. Let $G$ be a topological group with operation - and identity element $x_{0}$. Let $\Omega\left(G, x_{0}\right)$ denote the set of all loops in $G$ based at $x_{0}$. If $f, g \in \Omega\left(G, x_{0}\right)$, let us define a loop $f \otimes g$ by the rule

$$
(f \otimes g)(s)=f(s) \cdot g(s) .
$$

(a) Show that this operation makes the $\operatorname{set} \Omega\left(G, x_{0}\right)$ into a group.

(b) Show that this operation induces a group operation $\otimes$ on $\pi_{1}\left(G, x_{0}\right)$.

(c) Show that the two group operations $*$ and $\otimes$ on $\pi_{1}\left(G, x_{0}\right)$ are the same.

[Hint: Compute $\left(f * e_{x_{0}}\right) \otimes\left(e_{x_{0}} * g\right)$.]

(d) Show that $\pi_{1}\left(G, x_{0}\right)$ is abelian.

## §53 Covering Spaces

We have shown that any convex subspace of $\mathbb{R}^{n}$ has a trivial fundamental group; we turn now to the task of computing some fundamental groups that are not trivial. One of the most useful tools for this purpose is the notion of covering space, which we introduce in this section. Covering spaces are also important in the study of Riemann surfaces and complex manifolds. (See [A-S].) We shall study them in more detail in Chapter 13.

Definition. Let $p: E \rightarrow B$ be a continuous surjective map. The open set $U$ of $B$ is said to be evenly covered by $p$ if the inverse image $p^{-1}(U)$ can be written as the union of disjoint open sets $V_{\alpha}$ in $E$ such that for each $\alpha$, the restriction of $p$ to $V_{\alpha}$ is a homeomorphism of $V_{\alpha}$ onto $U$. The collection $\left\{V_{\alpha}\right\}$ will be called a partition of $p^{-1}(U)$ into slices.

If $U$ is an open set that is evenly covered by $p$, we often picture the set $p^{-1}(U)$ as a "stack of pancakes," each having the same size and shape as $U$, floating in the air above $U$; the map $p$ squashes them all down onto $U$. See Figure 53.1. Note that if $U$ is evenly covered by $p$ and $W$ is an open set contained in $U$, then $W$ is also evenly covered by $p$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-335.jpg?height=664&width=608&top_left_y=867&top_left_x=884)

Figure 53.1

Definition. Let $p: E \rightarrow B$ be continuous and surjective. If every point $b$ of $B$ has a neighborhood $U$ that is evenly covered by $p$, then $p$ is called a covering map, and $E$ is said to be a covering space of $B$.

Note that if $p: E \rightarrow B$ is a covering map, then for each $b \in B$ the subspace $p^{-1}(b)$ of $E$ has the discrete topology. For each slice $V_{\alpha}$ is open in $E$ and intersects the set $p^{-1}(b)$ in a single point; therefore, this point is open in $p^{-1}(b)$.

Note also that if $p: E \rightarrow B$ is a covering map, then $p$ is an open map. For suppose $A$ is an open set of $E$. Given $x \in p(A)$, choose a neighborhood $U$ of $x$ that is evenly covered by $p$. Let $\left\{V_{\alpha}\right\}$ be a partition of $p^{-1}(U)$ into slices. There is a point $y$ of $A$ such that $p(y)=x$; let $V_{\beta}$ be the slice containing $y$. The set $V_{\beta} \cap A$ is open in $E$ and hence open in $V_{\beta}$; because $p$ maps $V_{\beta}$ homeomorphically onto $U$, the set $p\left(V_{\beta} \cap A\right)$ is open in $U$ and hence open in $B$; it is thus a neighborhood of $x$ contained in $p(A)$, as desired.

EXAMPle 1. Let $X$ be any space; let $i: X \rightarrow X$ be the identity map. Then $i$ is a covering map (of the most trivial sort). More generally, let $E$ be the space $X \times\{1, \ldots, n\}$ consisting of $n$ disjoint copies of $X$. The map $p: E \rightarrow X$ given by $p(x, i)=x$ for all $i$ is again a (rather trivial) covering map. In this case, we can picture the entire space $E$ as a stack of pancakes over $X$.

In practice, one often restricts oneself to covering spaces that are path connected, to eliminate trivial coverings of the pancake-stack variety. An example of such a nontrivial covering space is the following:

Theorem 53.1. The map $p: \mathbb{R} \rightarrow S^{1}$ given by the equation

$$
p(x)=(\cos 2 \pi x, \sin 2 \pi x)
$$

is a covering map.

One can picture $p$ as a function that wraps the real line $\mathbb{R}$ around the circle $S^{1}$, and in the process maps each interval $[n, n+1]$ onto $S^{1}$.

Proof. The fact that $p$ is a covering map comes from elementary properties of the sine and cosine functions. Consider, for example, the subset $U$ of $S^{1}$ consisting of those points having positive first coordinate. The set $p^{-1}(U)$ consists of those points $x$ for which $\cos 2 \pi x$ is positive; that is, it is the union of the intervals

$$
V_{n}=\left(n-\frac{1}{4}, n+\frac{1}{4}\right),
$$

for all $n \in \mathbb{Z}$. See Figure 53.2. Now, restricted to any closed interval $\bar{V}_{n}$, the map $p$ is injective because $\sin 2 \pi x$ is strictly monotonic on such an interval. Furthermore, $p$ carries $\bar{V}_{n}$ surjectively onto $\bar{U}$, and $V_{n}$ to $U$, by the intermediate value theorem. Since $\bar{V}_{n}$ is compact, $p \mid \bar{V}_{n}$ is a homeomorphism of $\bar{V}_{n}$ with $\bar{U}$. In particular, $p \mid V_{n}$ is a homeomorphism of $V_{n}$ with $U$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-336.jpg?height=519&width=941&top_left_y=1572&top_left_x=551)

Figure 53.2

Similar arguments can be applied to the intersections of $S^{1}$ with the upper and lower open half-planes, and with the open left-hand half-plane. These open sets
cover $S^{1}$, and each of them is evenly covered by $p$. Hence $p: \mathbb{R} \rightarrow S^{1}$ is a covering map.

If $p: E \rightarrow B$ is a covering map, then $p$ is a local homeomorphism of $E$ with $B$. That is, each point $e$ of $E$ has a neighborhood that is mapped homeomorphically by $p$ onto an open subset of $B$. The condition that $p$ be a local homeomorphism does not suffice, however, to ensure that $p$ is a covering map, as the following example shows.

EXAMPLE 2. The map $p: \mathbb{R}_{+} \rightarrow S^{1}$ given by the equation

$$
p(x)=(\cos 2 \pi x, \sin 2 \pi x)
$$

is surjective, and it is a local homeomorphism. See Figure 53.3. But it is not a covering map, for the point $b_{0}=(1,0)$ has no neighborhood $U$ that is evenly covered by $p$. The typical neighborhood $U$ of $b_{0}$ has an inverse image consisting of small neighborhoods $V_{n}$ of each integer $n$ for $n>0$, along with a small interval $V_{0}$ of the form $(0, \epsilon)$. Each of the intervals $V_{n}$ for $n>0$ is mapped homeomorphically onto $U$ by the map $p$, but the interval $V_{0}$ is only imbedded in $U$ by $p$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-337.jpg?height=430&width=444&top_left_y=1134&top_left_x=974)

Figure 53.3

EXAMPLE 3. The preceding example might lead you to think that the real line $\mathbb{R}$ is the only connected covering space of the circle $S^{1}$. This is not so. Consider, for example, the map $p: S^{1} \rightarrow S^{1}$ given in equations by

$$
p(z)=z^{2} .
$$

[Here we consider $S^{1}$ as the subset of the complex plane $\mathbb{C}$ consisting of those complex numbers $z$ with $|z|=1$.] We leave it to you to check that $p$ is a covering map.

Example 2 shows that the map obtained by restricting a covering map may not be a covering map. Here is one situation where it will be a covering map:

Theorem 53.2. Let $p: E \rightarrow B$ be a covering map. If $B_{0}$ is a subspace of $B$, and if $E_{0}=p^{-1}\left(B_{0}\right)$, then the map $p_{0}: E_{0} \rightarrow B_{0}$ obtained by restricting $p$ is a covering map.

Proof. Given $b_{0} \in B_{0}$, let $U$ be an open set in $B$ containing $b_{0}$ that is evenly covered by $p$; let $\left\{V_{\alpha}\right\}$ be a partition of $p^{-1}(U)$ into slices. Then $U \cap B_{0}$ is a neighborhood of $b_{0}$ in $B_{0}$, and the sets $V_{\alpha} \cap E_{0}$ are disjoint open sets in $E_{0}$ whose union is $p^{-1}\left(U \cap B_{0}\right)$, and each is mapped homeomorphically onto $U \cap B_{0}$ by $p$.

Theorem 53.3. It $p: E \rightarrow B$ and $p^{\prime}: E^{\prime} \rightarrow B^{\prime}$ are covering maps, then

$$
p \times p^{\prime}: E \times E^{\prime} \rightarrow B \times B^{\prime}
$$

is a covering map.

Proof. Given $b \in B$ and $b^{\prime} \in B^{\prime}$, let $U$ and $U^{\prime}$ be neighborhoods of $b$ and $b^{\prime}$, respectively, that are evenly covered by $p$ and $p^{\prime}$, respectively. Let $\left\{V_{\alpha}\right\}$ and $\left\{V_{\beta}^{\prime}\right\}$ be partitions of $p^{-1}(U)$ and $\left(p^{\prime}\right)^{-1}\left(U^{\prime}\right)$, respectively, into slices. Then the inverse image under $p \times p^{\prime}$ of the open set $U \times U^{\prime}$ is the union of all the sets $V_{\alpha} \times V_{\beta}^{\prime}$. These are disjoint open sets of $E \times E^{\prime}$, and each is mapped homeomorphically onto $U \times U^{\prime}$ by $p \times p^{\prime}$.

EXAMPle 4. Consider the space $T=S^{1} \times S^{1}$; it is called the torus. The product map

$$
p \times p: \mathbb{R} \times \mathbb{R} \longrightarrow S^{1} \times S^{1}
$$

is a covering of the torus by the plane $\mathbb{R}^{2}$, where $p$ denotes the covering map of Theorem 53.1. Each of the unit squares $[n, n+1] \times[m, m+1]$ gets wrapped by $p \times p$ entirely around the torus. See Figure 53.4.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-338.jpg?height=402&width=983&top_left_y=1392&top_left_x=555)

Figure 53.4

In this figure, we have pictured the torus not as the product $S^{1} \times S^{1}$, which is a subspace of $\mathbb{R}^{4}$ and thus difficult to visualize, but as the familiar doughnut-shaped surface $D$ in $\mathbb{R}^{3}$ obtained by rotating the circle $C_{1}$ in the $x z$-plane of radius $\frac{1}{3}$ centered at $(1,0,0)$ about the $z$-axis. It is not hard to see that $S^{1} \times S^{1}$ is homeomorphic with the surface $D$. Let $C_{2}$ be the circle of radius 1 in the $x y$-plane centered at the origin. Then let us map $C_{1} \times C_{2}$ into $D$ by defining $f(a \times b)$ to be that point into which $a$ is carried when one rotates the circle $C_{1}$ about the $z$-axis until its center hits the point $b$. See Figure 53.5. The map $f$ will be a homeomorphism of $C_{1} \times C_{2}$ with $D$, as you can check mentally. If you wish, you can write equations for $f$ and check continuity, injectivity, and surjectivity directly. (Continuity of $f^{-1}$ will follow from compactness of $C_{1} \times C_{2}$.)

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-339.jpg?height=583&width=766&top_left_y=375&top_left_x=813)

Figure 53.5

EXAMPLE 5. Consider the covering map $p \times p$ of the preceding example. Let $b_{0}$ denote the point $p(0)$ of $S^{1}$; and let $B_{0}$ denote the subspace

$$
B_{0}=\left(S^{1} \times b_{0}\right) \cup\left(b_{0} \times S^{1}\right)
$$

of $S^{1} \times S^{1}$. Then $B_{0}$ is the union of two circles that have a point in common; we sometimes call it the figure-eight space. The space $E_{0}=p^{-1}\left(B_{0}\right)$ is the "infinite grid"

$$
E_{0}=(\mathbb{R} \times \mathbb{Z}) \cup(\mathbb{Z} \times \mathbb{R})
$$

pictured in Figure 53.4. The map $p_{0}: E_{0} \rightarrow B_{0}$ obtained by restricting $p \times p$ is thus a covering map.

The infinite grid is but one covering space of the figure eight; we shall see others later on.

EXAMPLE 6. Consider the covering map

$$
p \times i: \mathbb{R} \times \mathbb{R}_{+} \longrightarrow S^{1} \times \mathbb{R}_{+}
$$

where $i$ is the identity map of $\mathbb{R}_{+}$and $p$ is the map of Theorem 53.1. If we take the standard homeomorphism of $S^{1} \times \mathbb{R}_{+}$with $\mathbb{R}^{2}-\mathbf{0}$, sending $x \times t$ to $t x$, the composite gives us a covering

$$
\mathbb{R} \times \mathbb{R}_{+} \longrightarrow \mathbb{R}^{2}-\mathbf{0}
$$

of the punctured plane by the open upper half-plane. It is pictured in Figure 53.6. This covering map appears in the study of complex variables as the Riemann surface corresponding to the complex logarithm function.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-340.jpg?height=498&width=1064&top_left_y=364&top_left_x=486)

Figure 53.6

## Exercises

1. Let $Y$ have the discrete topology. Show that if $p: X \times Y \rightarrow X$ is projection on the first coordinate, then $p$ is a covering map.
2. Let $p: E \rightarrow B$ be continuous and surjective. Suppose that $U$ is an open set of $B$ that is evenly covered by $p$. Show that if $U$ is connected, then the partition of $p^{-1}(U)$ into slices is unique.
3. Let $p: E \rightarrow B$ be a covering map; let $B$ be connected. Show that if $p^{-1}\left(b_{0}\right)$ has $k$ elements for some $b_{0} \in B$, then $p^{-1}(b)$ has $k$ elements for every $b \in B$. In such a case, $E$ is called a $\boldsymbol{k}$-fold covering of $B$.
4. Let $q: X \rightarrow Y$ and $r: Y \rightarrow Z$ be covering maps; let $p=r \circ q$. Show that if $r^{-1}(z)$ is finite for each $z \in Z$, then $p$ is a covering map.
5. Show that the map of Example 3 is a covering map. Generalize to the map $p(z)=z^{n}$.
6. Let $p: E \rightarrow B$ be a covering map.

(a) If $B$ is Hausdorff, regular, completely regular, or locally compact Hausdorff, then so is $E$. [Hint: If $\left\{V_{\alpha}\right\}$ is a partition of $p^{-1}(U)$ into slices, and $C$ is a closed set of $B$ such that $C \subset U$, then $p^{-1}(C) \cap V_{\alpha}$ is a closed set of $E$.]

(b) If $B$ is compact and $p^{-1}(b)$ is finite for each $b \in B$, then $E$ is compact.

## §54 The Fundamental Group of the Circle

The study of covering spaces of a space $X$ is intimately related to the study of the fundamental group of $X$. In this section, we establish the crucial links between the two concepts, and compute the fundamental group of the circle.

Definition. Let $p: E \rightarrow B$ be a map. If $f$ is a continuous mapping of some space $X$ into $B$, a lifting of $f$ is a map $\tilde{f}: X \rightarrow E$ such that $p \circ \tilde{f}=f$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-341.jpg?height=194&width=189&top_left_y=494&top_left_x=1057)

The existence of liftings when $p$ is a covering map is an important tool in studying covering spaces and the fundamental group. First, we show that for a covering space, paths can be lifted; then we show that path homotopies can be lifted as well. First, an example:

EXAMPLE 1. Consider the covering $p: \mathbb{R} \rightarrow S^{1}$ of Theorem 53.1. The path $f$ : $[0,1] \rightarrow S^{1}$ beginning at $b_{0}=(1,0)$ given by $f(s)=(\cos \pi s, \sin \pi s)$ lifts to the path $\tilde{f}(s)=s / 2$ beginning at 0 and ending at $\frac{1}{2}$. The path $g(s)=(\cos \pi s,-\sin \pi s)$ lifts to the path $\tilde{g}(s)=-s / 2$ beginning at 0 and ending at $-\frac{1}{2}$. The path $h(s)=(\cos 4 \pi s, \sin 4 \pi s)$ lifts to the path $\tilde{h}(s)=2 s$ beginning at 0 and ending at 2 . Intuitively, $h$ wraps the interval $[0,1]$ around the circle twice; this is reflected in the fact that the lifted path $\tilde{h}$ begins at zero and ends at the number 2. These paths are pictured in Figure 54.1.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-341.jpg?height=322&width=1118&top_left_y=1234&top_left_x=638)

Figure 54.1

Lemma 54.1. Let $p: E \rightarrow B$ be a covering map, let $p\left(e_{0}\right)=b_{0}$. Any path $f:[0,1] \rightarrow B$ beginning at $b_{0}$ has a unique lifting to a path $\tilde{f}$ in $E$ beginning at $e_{0}$.

Proof. Cover $B$ by open sets $U$ each of which is evenly covered by $p$. Find a subdivision of $[0,1]$, say $s_{0}, \ldots, s_{n}$, such that for each $i$ the set $f\left(\left[s_{i}, s_{i+1}\right]\right)$ lies in such an open set $U$. (Here we use the Lebesgue number lemma.) We define the lifting $\tilde{f}$ step by step.

First, define $\tilde{f}(0)=e_{0}$. Then, supposing $\tilde{f}(s)$ is defined for $0 \leq s \leq s_{i}$, we define $\tilde{f}$ on $\left[s_{i}, s_{i+1}\right]$ as follows: The set $f\left(\left[s_{i}, s_{i+1}\right]\right)$ lies in some open set $U$ that is evenly covered by $p$. Let $\left\{V_{\alpha}\right\}$ be a partition of $p^{-1}(U)$ into slices; each set $V_{\alpha}$ is mapped homeomorphically onto $U$ by $p$. Now $\tilde{f}\left(s_{i}\right)$ lies in one of these sets, say in $V_{0}$. Define $\tilde{f}(s)$ for $s \in\left[s_{i}, s_{i+1}\right]$ by the equation

$$
\tilde{f}(s)=\left(p \mid V_{0}\right)^{-1}(f(s)) .
$$

Because $p \mid V_{0}: V_{0} \rightarrow U$ is a homeomorphism, $\tilde{f}$ will be continuous on $\left[s_{i}, s_{i+1}\right]$.

Continuing in this way, we define $\tilde{f}$ on all of [0,1]. Continuity of $\tilde{f}$ follows from the pasting lemma; the fact that $p \circ \tilde{f}=f$ is immediate from the definition of $\tilde{f}$.

The uniqueness of $\tilde{f}$ is also proved step by step. Suppose that $\tilde{\tilde{f}}$ is another lifting of $f$ beginning at $e_{0}$. Then $\tilde{\tilde{f}}(0)=e_{0}=\tilde{f}(0)$. Suppose that $\tilde{\tilde{f}}(s)=\tilde{f}(s)$ for all $s$ such that $0 \leq s \leq s_{i}$. Let $V_{0}$ be as in the preceding paragraph; then for $s \in\left[s_{i}, s_{i+1}\right]$, $\tilde{f}(s)$ is defined as $\left(p \mid V_{0}\right)^{-1}(f(s))$. What can $\tilde{\tilde{f}}(s)$ equal? Since $\tilde{\tilde{f}}$ is a lifting of $f$, it must carry the interval $\left[s_{i}, s_{i+1}\right]$ into the set $p^{-1}(U)=\bigcup V_{\alpha}$. The slices $V_{\alpha}$ are open and disjoint; because the set $\tilde{\tilde{f}}\left(\left[s_{i}, s_{i+1}\right]\right)$ is connected, it must lie entirely in one of the sets $V_{\alpha}$. Because $\tilde{\tilde{f}}\left(s_{i}\right)=\tilde{f}\left(s_{i}\right)$, which is in $V_{0}, \tilde{\tilde{f}}$ must carry all of $\left[s_{i}, s_{i+1}\right]$ into the set $V_{0}$. Thus, for $s$ in $\left[s_{i}, s_{i+1}\right], \tilde{\tilde{f}}(s)$ must equal some point $y$ of $V_{0}$ lying in $p^{-1}(f(s))$. But there is only one such point $y$, namely, $\left(p \mid V_{0}\right)^{-1}(f(s))$. Hence $\tilde{f}(s)=\tilde{f}(s)$ for $s \in\left[s_{i}, s_{i+1}\right]$.

Lemma 54.2. Let $p: E \rightarrow B$ be a covering map; let $p\left(e_{0}\right)=b_{0}$. Let the map $F: I \times I \rightarrow B$ be continuous, with $F(0,0)=b_{0}$. There is a unique lifting of $F$ to a continuous map

$$
\tilde{F}: I \times I \rightarrow E
$$

such that $\tilde{F}(0,0)=e_{0}$. If $F$ is a path homotopy, then $\tilde{F}$ is a path homotopy.

Proof. Given $F$, we first define $\tilde{F}(0,0)=e_{0}$. Next, we use the preceding lemma to extend $\tilde{F}$ to the left-hand edge $0 \times I$ and the bottom edge $I \times 0$ of $I \times I$. Then we extend $\tilde{F}$ to all of $I \times I$ as follows:

Choose subdivisions

$$
\begin{aligned}
& s_{0}<s_{1}<\cdots<s_{m}, \\
& t_{0}<t_{1}<\cdots<t_{n}
\end{aligned}
$$

of $I$ fine enough that each rectangle

$$
I_{i} \times J_{j}=\left[s_{i-1}, s_{i}\right] \times\left[t_{j-1}, t_{j}\right]
$$

is mapped by $F$ into an open set of $B$ that is evenly covered by $p$. (Use the Lebesgue number lemma.) We define the lifting $\tilde{F}$ step by step, beginning with the rectangle $I_{1} \times J_{1}$, continuing with the other rectangles $I_{i} \times J_{1}$ in the "bottom row," then with the rectangles $I_{i} \times J_{2}$ in the next row, and so on.

In general, given $i_{0}$ and $j_{0}$, assume that $\tilde{F}$ is defined on the set $A$ which is the union of $0 \times I$ and $I \times 0$ and all the rectangles "previous" to $I_{i_{0}} \times J_{j_{0}}$ (those rectangles $I_{i} \times J_{j}$ for which $j<j_{0}$ and those for which $j=j_{0}$ and $i<i_{0}$ ). Assume also that $\tilde{F}$ is a continuous lifting of $F \mid A$. We define $\tilde{F}$ on $I_{i_{0}} \times J_{j_{0}}$. Choose an open set $U$ of $B$ that is evenly covered by $p$ and contains the set $F\left(I_{i_{0}} \times J_{j_{0}}\right)$. Let $\left\{V_{\alpha}\right\}$ be a partition of $p^{-1}(U)$ into slices; each set $V_{\alpha}$ is mapped homeomorphically onto $U$ by $p$. Now $\tilde{F}$ is already defined on the set $C=A \cap\left(I_{i_{0}} \times J_{j_{0}}\right)$. This set is the union of the left
and bottom edges of the rectangle $I_{i_{0}} \times J_{j_{0}}$, so it is connected. Therefore, $\tilde{F}(C)$ is connected and must lie entirely within one of the sets $V_{\alpha}$. Suppose it lies in $V_{0}$. Then, the situation is as pictured in Figure 54.2.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-343.jpg?height=514&width=984&top_left_y=552&top_left_x=706)

Figure 54.2

Let $p_{0}: V_{0} \rightarrow U$ denote the restriction of $p$ to $V_{0}$. Since $\tilde{F}$ is a lifting of $F \mid A$, we know that for $x \in C$,

$$
p_{0}(\tilde{F}(x))=p(\tilde{F}(x))=F(x),
$$

so that $\tilde{F}(x)=p_{0}^{-1}(F(x))$. Hence we may extend $\tilde{F}$ by defining

$$
\tilde{F}(x)=p_{0}^{-1}(F(x))
$$

for $x \in I_{i_{0}} \times J_{j_{0}}$. The extended map will be continuous by the pasting lemma.

Continuing in this way, we define $\tilde{F}$ on all of $I^{2}$.

To check uniqueness, note that at each step of the construction of $\tilde{F}$, as we extend $\tilde{F}$ first to the bottom and left edges of $I^{2}$, and then to the rectangles $I_{i} \times J_{j}$, one by one, there is only one way to extend $\tilde{F}$ continuously. Thus, once the value of $\tilde{F}$ at $(0,0)$ is specified, $\tilde{F}$ is completely determined.

Now suppose that $F$ is a path homotopy. We wish to show that $\tilde{F}$ is a path homotopy. The map $F$ carries the entire left edge $0 \times I$ of $I^{2}$ into a single point $b_{0}$ of $B$. Because $\tilde{F}$ is a lifting of $F$, it carries this edge into the set $p^{-1}\left(b_{0}\right)$. But this set has the discrete topology as a subspace of $E$. Since $0 \times I$ is connected and $\tilde{F}$ is continuous, $\tilde{F}(0 \times I)$ is connected and thus must equal a one-point set. Similarly, $\tilde{F}(1 \times I)$ must be a one-point set. Thus $\tilde{F}$ is a path homotopy.

Theorem 54.3. Let $p: E \rightarrow B$ be a covering map; let $p\left(e_{0}\right)=b_{0}$. Let $f$ and $g$ be two paths in $B$ from $b_{0}$ to $b_{1}$; let $\tilde{f}$ and $\tilde{g}$ be their respective liftings to paths in $E$ beginning at $e_{0}$. If $f$ and $g$ are path homotopic, then $\tilde{f}$ and $\tilde{g}$ end at the same point of $E$ and are path homotopic.

Proof. Let $F: I \times I \rightarrow B$ be the path homotopy between $f$ and $g$. Then $F(0,0)=$ $b_{0}$. Let $\tilde{F}: I \times I \rightarrow E$ be the lifting of $F$ to $E$ such that $\tilde{F}(0,0)=e_{0}$. By the preceding lemma, $\tilde{F}$ is a path homotopy, so that $\tilde{F}(0 \times I)=\left\{e_{0}\right\}$ and $\tilde{F}(1 \times I)$ is a one-point set $\left\{e_{1}\right\}$.

The restriction $\tilde{F} \mid I \times 0$ of $\tilde{F}$ to the bottom edge of $I \times I$ is a path on $E$ beginning at $e_{0}$ that is a lifting of $F \mid I \times 0$. By uniqueness of path liftings, we must have $\tilde{F}(s, 0)=$ $\tilde{f}(s)$. Similarly, $\tilde{F} \mid I \times 1$ is a path on $E$ that is a lifting of $F \mid I \times 1$, and it begins at $e_{0}$ because $\tilde{F}(0 \times I)=\left\{e_{0}\right\}$. By uniqueness of path liftings, $\tilde{F}(s, 1)=\tilde{g}(s)$. Therefore, both $\tilde{f}$ and $\tilde{g}$ end at $e_{1}$, and $\tilde{F}$ is a path homotopy between them.

Definition. Let $p: E \rightarrow B$ be a covering map; let $b_{0} \in B$. Choose $e_{0}$ so that $p\left(e_{0}\right)=b_{0}$. Given an element $[f]$ of $\pi_{1}\left(B, b_{0}\right)$, let $\tilde{f}$ be the lifting of $f$ to a path in $E$ that begins at $e_{0}$. Let $\phi([f])$ denote the end point $\tilde{f}(1)$ of $\tilde{f}$. Then $\phi$ is a well-defined set map

$$
\phi: \pi_{1}\left(B, b_{0}\right) \rightarrow p^{-1}\left(b_{0}\right) .
$$

We call $\phi$ the lifting correspondence derived from the covering map $p$. It depends of course on the choice of the point $e_{0}$.

Theorem 54.4. Let $p: E \rightarrow B$ be a covering map; let $p\left(e_{0}\right)=b_{0}$. If $E$ is path connected, then the lifting correspondence

$$
\phi: \pi_{1}\left(B, b_{0}\right) \rightarrow p^{-1}\left(b_{0}\right)
$$

is surjective. If $E$ is simply connected, it is bijective.

Proof. If $E$ is path connected, then, given $e_{1} \in p^{-1}\left(b_{0}\right)$, there is a path $\tilde{f}$ in $E$ from $e_{0}$ to $e_{1}$. Then $f=p \circ \tilde{f}$ is a loop in $B$ at $b_{0}$, and $\phi([f])=e_{1}$ by definition.

Suppose $E$ is simply connected. Let $[f]$ and $[g]$ be two elements of $\pi_{1}\left(B, b_{0}\right)$ such that $\phi([f])=\phi([g])$. Let $\tilde{f}$ and $\tilde{g}$ be the liftings of $f$ and $g$, respectively, to paths in $E$ that begin at $e_{0}$; then $\tilde{f}(1)=\tilde{g}(1)$. Since $E$ is simply connected, there is a path homotopy $\tilde{F}$ in $E$ between $\tilde{f}$ and $\tilde{g}$. Then $p \circ \tilde{F}$ is a path homotopy in $B$ between $f$ and $g$.

Theorem 54.5. The fundamental group of $S^{1}$ is isomorphic to the additive group of integers.

Proof. Let $p: \mathbb{R} \rightarrow S^{1}$ be the covering map of Theorem 53.1, let $e_{0}=0$, and let $b_{0}=p\left(e_{0}\right)$. Then $p^{-1}\left(b_{0}\right)$ is the set $\mathbb{Z}$ of integers. Since $\mathbb{R}$ is simply connected, the lifting correspondence

$$
\phi: \pi_{1}\left(S^{1}, b_{0}\right) \rightarrow \mathbb{Z}
$$

is bijective. We show that $\phi$ is a homomorphism, and the theorem is proved.

Given $[f]$ and $[g]$ in $\pi_{1}\left(B, b_{0}\right)$, let $\tilde{f}$ and $\tilde{g}$ be their respective liftings to paths on $\mathbb{R}$ beginning at 0 . Let $n=\tilde{f}(1)$ and $m=\tilde{g}(1)$; then $\phi([f])=n$ and $\phi([g])=m$, by definition. Let $\tilde{\tilde{g}}$ be the path

$$
\tilde{\tilde{g}}(s)=n+\tilde{g}(s)
$$

on $\mathbb{R}$. Because $p(n+x)=p(x)$ for all $x \in \mathbb{R}$, the path $\tilde{\tilde{g}}$ is a lifting of $g$; it begins at $n$. Then the product $\tilde{f} * \tilde{\tilde{g}}$ is defined, and it is the lifting of $f * g$ that begins at 0 , as you can check. The end point of this path is $\tilde{\tilde{g}}(1)=n+m$. Then by definition,

$$
\phi([f] *[g])=n+m=\phi([f])+\phi([g]) .
$$

Definition. Let $G$ be a group; let $x$ be an element of $G$. we denote the inverse of $x$ by $x^{-1}$. The symbol $x^{n}$ denotes the $n$-fold product of $x$ with itself, $x^{-n}$ denotes the $n$-fold product of $x^{-1}$ with itself, and $x^{0}$ denotes the identity element of $G$. If the set of all elements of the form $x^{m}$, for $m \in \mathbb{Z}$, equals $G$, then $G$ is said to be a cyclic group, and $x$ is said to be a generator of $G$.

The cardinality of a group is also called the order of the group. A group is cyclic of infinite order if and only if it is isomorphic to the additive group of integers; it is cyclic of order $k$ if and only if it is isomorphic to the group $\mathbb{Z} / k$ of integers modulo $k$. The preceding theorem implies that the fundamental group of the circle is infinite cyclic.

Note that if $x$ is a generator of the infinite cyclic group $G$, and if $y$ is an element of the arbitrary group $H$, then there is a unique homomorphism $h$ of $G$ into $H$ such that $h(x)=y$; it is defined by setting $h\left(x^{n}\right)=y^{n}$ for all $n$.

For later use, in $\S 65$ and in Chapters 13 and 14, we prove here a strengthened version of Theorem 54.4.

*Theorem 54.6. Let $p: E \rightarrow B$ be a covering map; let $p\left(e_{0}\right)=b_{0}$.

(a) The homomorphism $p_{*}: \pi_{1}\left(E, e_{0}\right) \rightarrow \pi_{1}\left(B, b_{0}\right)$ is a monomorphism.

(b) Let $H=p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)$. The lifting correspondence $\phi$ induces an injective map

$$
\Phi: \pi_{1}\left(B, b_{0}\right) / H \rightarrow p^{-1}\left(b_{0}\right)
$$

of the collection of right cosets of $H$ into $p^{-1}\left(b_{0}\right)$, which is bijective if $E$ is path connected.

(c) If $f$ is a loop in $B$ based at $b_{0}$, then $[f] \in H$ if and only if $f$ lifts to a loop in $E$ based at $e_{0}$.

Proof. (a) Suppose $\tilde{h}$ is a loop in $E$ at $e_{0}$, and $p_{*}([\tilde{h}])$ is the identity element. Let $F$ be a path homotopy between $p \circ \tilde{h}$ and the constant loop. If $\tilde{F}$ is the lifting of $F$ to $E$ such that $\tilde{F}(0,0)=e_{0}$, then $\tilde{F}$ is a path homotopy between $\tilde{h}$ and the constant loop at $e_{0}$.
(b) Given loops $f$ and $g$ in $B$, let $\tilde{f}$ and $\tilde{g}$ be liftings of them to $E$ that begin at $e_{0}$. Then $\phi([f])=\tilde{f}(1)$ and $\phi([g])=\tilde{g}(1)$. We show that $\phi([f])=\phi([g])$ if and only if $[f] \in H *[g]$.

First, suppose that $[f] \in H *[g]$. Then $[f]=[h * g]$, where $h=p \circ \tilde{h}$ for some loop $\tilde{h}$ in $E$ based at $e_{0}$. Now the product $\tilde{h} * \tilde{g}$ is defined, and it is a lifting of $h * g$. Because $[f]=[h * g]$, the liftings $\tilde{f}$ and $\tilde{h} * \tilde{g}$, which begin at $e_{0}$, must end at the same point of $E$. Then $\tilde{f}$ and $\tilde{g}$ end at the same point of $E$, so that $\phi([f])=\phi([g])$. See Figure 54.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-346.jpg?height=442&width=963&top_left_y=756&top_left_x=545)

Figure 54.3

Now suppose that $\phi([f])=\phi([g])$. Then $\tilde{f}$ and $\tilde{g}$ end at the same point of $E$. The product of $\tilde{f}$ and the reverse of $\tilde{g}$ is defined, and it is a loop $\tilde{h}$ in $E$ based at $e_{0}$. By direct computation, $[\tilde{h} * \tilde{g}]=[\tilde{f}]$. If $\tilde{F}$ is a path homotopy in $E$ between the loops $\tilde{h} * \tilde{g}$ and $\tilde{f}$, then $p \circ \tilde{F}$ is a path homotopy in $B$ between $h * g$ and $f$, where $h=p \circ \tilde{h}$. Thus $[f] \in H *[g]$, as desired.

If $E$ is path connected, then $\phi$ is surjective, so that $\Phi$ is surjective as well.

(c) Injectivity of $\Phi$ means that $\phi([f])=\phi([g])$ if and only if $[f] \in H *[g]$. Applying this result in the case where $g$ is the constant loop, we see that $\phi([f])=e_{0}$ if and only if $[f] \in H$. But $\phi([f])=e_{0}$ precisely when the lift of $f$ that begins at $e_{0}$ also ends at $e_{0}$.

## Exercises

1. What goes wrong with the "path-lifting lemma" (Lemma 54.1) for the local homeomorphism of Example 2 of $\S 53$ ?
2. In defining the map $\tilde{F}$ in the proof of Lemma 54.2 , why were we so careful about the order in which we considered the small rectangles?
3. Let $p: E \rightarrow B$ be a covering map. Let $\alpha$ and $\beta$ be paths in $B$ with $\alpha(1)=\beta(0)$; let $\tilde{\alpha}$ and $\tilde{\beta}$ be liftings of them such that $\tilde{\alpha}(1)=\tilde{\beta}(0)$. Show that $\tilde{\alpha} * \tilde{\beta}$ is a lifting of $\alpha * \beta$.
4. Consider the covering map $p: \mathbb{R} \times \mathbb{R}_{+} \rightarrow \mathbb{R}^{2}-\mathbf{0}$ of Example 6 of $\S 53$. Find liftings of the paths

$$
\begin{aligned}
& f(t)=(2-t, 0), \\
& g(t)=((1+t) \cos 2 \pi t,(1+t) \sin 2 \pi t) \\
& h(t)=f * g .
\end{aligned}
$$

Sketch these paths and their liftings.

5. Consider the covering map $p \times p: \mathbb{R} \times \mathbb{R} \rightarrow S^{1} \times S^{1}$ of Example 4 of $\S 53$. Consider the path

$$
f(t)=(\cos 2 \pi t, \sin 2 \pi t) \times(\cos 4 \pi t, \sin 4 \pi t)
$$

in $S^{1} \times S^{1}$. Sketch what $f$ looks like when $S^{1} \times S^{1}$ is identified with the doughnut surface $D$. Find a lifting $\tilde{f}$ of $f$ to $\mathbb{R} \times \mathbb{R}$, and sketch it.

6. Consider the maps $g, h: S^{1} \rightarrow S^{1}$ given $g(z)=z^{n}$ and $h(z)=1 / z^{n}$. (Here we represent $S^{1}$ as the set of complex numbers $z$ of absolute value 1.) Compute the induced homomorphisms $g_{*}, h_{*}$ of the infinite cyclic group $\pi_{1}\left(S^{1}, b_{0}\right)$ into itself. [Hint: Recall the equation $(\cos \theta+i \sin \theta)^{n}=\cos n \theta+i \sin n \theta$.]
7. Generalize the proof of Theorem 54.5 to show that the fundamental group of the torus is isomorphic to the group $\mathbb{Z} \times \mathbb{Z}$.
8. Let $p: E \rightarrow B$ be a covering map, with $E$ path connected. Show that if $B$ is simply connected, then $p$ is a homeomorphism.

## §55 Retractions and Fixed Points

We now prove several classical results of topology that follow from our knowledge of the fundamental group of $S^{1}$.

Definition. If $A \subset X$, a retraction of $X$ onto $A$ is a continuous map $r: X \rightarrow A$ such that $r \mid A$ is the identity map of $A$. If such a map $r$ exists, we say that $A$ is a retract of $X$.

Lemma 55.1. If $A$ is a retract of $X$, then the homomorphism of fundamental groups induced by inclusion $j: A \rightarrow X$ is injective.

Proof. If $r: X \rightarrow A$ is a retraction, then the composite map $r \circ j$ equals the identity map of $A$. It follows that $r_{*} \circ j_{*}$ is the identity map of $\pi_{1}(A, a)$, so that $j_{*}$ must be injective.

Theorem 55.2 (No-retraction theorem). There is no retraction of $B^{2}$ onto $S^{1}$.

Proof. If $S^{1}$ were a retract of $B^{2}$, then the homomorphism induced by inclusion $j: S^{1} \rightarrow B^{2}$ would be injective. But the fundamental group of $S^{1}$ is nontrivial and the fundamental group of $B^{2}$ is trivial.

Lemma 55.3. Let $h: S^{1} \rightarrow X$ be a continuous map. Then the following conditions are equivalent:

(1) $h$ is nulhomotopic.

(2) $h$ extends to a continuous map $k: B^{2} \rightarrow X$.

(3) $h_{*}$ is the trivial homomorphism of fundamental groups.

Proof. (1) $\Rightarrow$ (2). Let $H: S^{1} \times I \rightarrow X$ be a homotopy between $h$ and a constant map. Let $\pi: S^{1} \times I \rightarrow B^{2}$ be the map

$$
\pi(x, t)=(1-t) x .
$$

Then $\pi$ is continuous, closed and surjective, so it is a quotient map; it collapses $S^{1} \times 1$ to the point $\mathbf{0}$ and is otherwise injective. Because $H$ is constant on $S^{1} \times 1$, it induces, via the quotient map $\pi$, a continuous map $k: B^{2} \rightarrow X$ that is an extension of $h$. See Figure 55.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-348.jpg?height=408&width=1027&top_left_y=1056&top_left_x=505)

Figure 55.1

(2) $\Rightarrow$ (3). If $j: S^{1} \rightarrow B^{2}$ is the inclusion map, then $h$ equals the composite $k \circ j$. Hence $h_{*}=k_{*} \circ j_{*}$. But

$$
j_{*}: \pi_{1}\left(S^{1}, b_{0}\right) \rightarrow \pi_{1}\left(B^{2}, b_{0}\right)
$$

is trivial because the fundamental group of $B^{2}$ is trivial. Therefore $h_{*}$ is trivial.

(3) $\Rightarrow$ (1). Let $p: \mathbb{R} \rightarrow S^{1}$ be the standard covering map, and let $p_{0}: I \rightarrow S^{1}$ be its restriction to the unit interval. Then $\left[p_{0}\right]$ generates $\pi_{1}\left(S^{1}, b_{0}\right)$ because $p_{0}$ is a loop in $S^{1}$ whose lift to $\mathbb{R}$ begins at 0 and ends at 1 .

Let $x_{0}=h\left(b_{0}\right)$. Because $h_{*}$ is trivial, the loop $f=h \circ p_{0}$ represents the identity element of $\pi_{1}\left(X, x_{0}\right)$. Therefore, there is a path homotopy $F$ in $X$ between $f$ and the constant path at $x_{0}$. The map $p_{0} \times \mathrm{id}: I \times I \rightarrow S^{1} \times I$ is a quotient map, being continuous, closed, and surjective; it maps $0 \times t$ and $1 \times t$ to $b_{0} \times t$ for each $t$, but is otherwise injective. The path homotopy $F$ maps $0 \times I$ and $1 \times I$ and $I \times 1$ to the point $x_{0}$ of $X$, so it induces a continuous map $H: S^{1} \times I \rightarrow X$ that is a homotopy between $h$ and a constant map. See Figure 55.2.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-349.jpg?height=450&width=1069&top_left_y=366&top_left_x=662)

Figure 55.2

Corollary 55.4. The inclusion map $j: S^{1} \rightarrow R^{2}-\mathbf{0}$ is not nulhomotopic. The identity map $i: S^{1} \rightarrow S^{1}$ is not nulhomotopic.

Proof. There is a retraction of $\mathbb{R}-\mathbf{0}$ onto $S^{1}$ given by the equation $r(x)=x /\|x\|$. Therefore, $j_{*}$ is injective, and hence nontrivial. Similarly, $i_{*}$ is the identity homomorphism, and hence nontrivial.

Theorem 55.5. Given a nonvanishing vector field on $B^{2}$, there exists a point of $S^{1}$ where the vector field points directly inward and a point of $S^{1}$ where it points directly outward.

Proof. A vector field on $B^{2}$ is an ordered pair $(x, v(x))$, where $x$ is in $B^{2}$ and $v$ is a continuous map of $B^{2}$ into $\mathbb{R}^{2}$. In calculus, one often uses the notation

$$
\mathbf{v}(x)=v_{1}(x) \mathbf{i}+v_{2}(x) \mathbf{j}
$$

for the function $v$, where $\mathbf{i}$ and $\mathbf{j}$ are the standard unit basis vectors in $\mathbb{R}^{2}$. But we shall stick with simple functional notation. To say that a vector field is nonvanishing means that $v(x) \neq \mathbf{0}$ for every $x$; in such a case $v$ actually maps $B^{2}$ into $\mathbb{R}^{2}-\mathbf{0}$.

We suppose first that $v(x)$ does not point directly inward at any point $x$ of $S^{1}$ and derive a contradiction. Consider the map $v: B^{2} \rightarrow \mathbb{R}^{2}-\mathbf{0}$; let $w$ be its restriction to $S^{1}$. Because the map $w$ extends to a map of $B^{2}$ into $\mathbb{R}^{2}-\mathbf{0}$, it is nulhomotopic.

On the other hand, $w$ is homotopic to the inclusion map $j: S^{1} \rightarrow \mathbb{R}^{2}-\mathbf{0}$. Figure 55.3 illustrates the homotopy; one defines it formally by the equation

$$
F(x, t)=t x+(1-t) w(x)
$$

for $x \in S^{1}$. We must show that $F(x, t) \neq \mathbf{0}$. Clearly, $F(x, t) \neq \mathbf{0}$ for $t=0$ and $t=1$. If $F(x, t)=\mathbf{0}$ for some $t$ with $0<t<1$, then $t x+(1-t) w(x)=0$, so that $w(x)$ equals a negative scalar multiple of $x$. But this means that $w(x)$ points directly inward at $x$ ! Hence $F$ maps $S^{1} \times I$ into $\mathbb{R}^{2}-\mathbf{0}$, as desired.

It follows that $j$ is nulhomotopic, contradicting the preceding corollary.

To show that $v$ points directly outward at some point of $S^{1}$, we apply the result just proved to the vector field $(x,-v(x))$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-350.jpg?height=605&width=766&top_left_y=372&top_left_x=638)

Figure 55.3

We have already seen that every continuous map $f:[0,1] \rightarrow[0,1]$ has a fixed point (see Exercise 3 of §24). The same is true for the ball $B^{2}$, although the proof is deeper:

Theorem 55.6 (Brouwer fixed-point theorem for the disc). If $f: B^{2} \rightarrow B^{2}$ is continuous, then there exists a point $x \in B^{2}$ such that $f(x)=x$.

Proof. We proceed by contradiction. Suppose that $f(x) \neq x$ for every $x$ in $B^{2}$. Then defining $v(x)=f(x)-x$ gives us a nonvanishing vector field $(x, v(x))$ on $B^{2}$. But the vector field $v$ cannot point directly outward at any point $x$ of $S^{1}$, for that would mean

$$
f(x)-x=a x
$$

for some positive real number $a$, so that $f(x)=(1+a) x$ would lie outside the unit ball $B^{2}$. We thus arrive at a contradiction.

One might well wonder why fixed-point theorems are of interest in mathematics. It turns out that many problems, such as problems concerning existence of solutions for systems of equations, for instance, can be formulated as fixed-point problems. Here is one example, a classical theorem of Frobenius. We assume some knowledge of linear algebra at this point.

*Corollary 55.7. Let $A$ be a 3 by 3 matrix of positive real numbers. Then $A$ has a positive real eigenvalue (characteristic value).

Proof. Let $T: \mathbb{R}^{3} \rightarrow \mathbb{R}^{3}$ be the linear transformation whose matrix (relative to the standard basis for $\mathbb{R}^{3}$ ) is $A$. Let $B$ be the intersection of the 2 -sphere $S^{2}$ with the first
octant

$$
\left\{\left(x_{1}, x_{2}, x_{3}\right) \mid x_{1} \geq 0 \text { and } x_{2} \geq 0 \text { and } x_{3} \geq 0\right\}
$$

of $\mathbb{R}^{3}$. It is easy to show that $B$ is homeomorphic to the ball $B^{2}$, so that the fixed-point theorem holds for continuous maps of $B$ into itself.

Now if $x=\left(x_{1}, x_{2}, x_{3}\right)$ is in $B$, then all the components of $x$ are nonnegative and at least one is positive. Because all entries of $A$ are positive, the vector $T(x)$ is a vector all of whose components are positive. As a result, the map $x \rightarrow T(x) /\|T(x)\|$ is a continuous map of $B$ to itself, which therefore has a fixed point $x_{0}$. Then

$$
T\left(x_{0}\right)=\left\|T\left(x_{0}\right)\right\| x_{0},
$$

so that $T$ (and therefore the matrix $A$ ) has the positive real eigenvalue $\left\|T\left(x_{0}\right)\right\|$.

Finally, we prove a theorem that implies that the triangular region

$$
T=\{(x, y) \mid x \geq 0 \text { and } y \geq 0 \text { and } x+y \leq 1\}
$$

in $\mathbb{R}^{2}$ has topological dimension at least 2. (See $\S 50$.)

*Theorem 55.8. There is an $\epsilon>0$ such that for every open covering $\mathcal{A}$ of $T$ by sets of diameter less than $\epsilon$, some point of $T$ belongs to at least three elements of $\mathcal{A}$.

Proof. We use the fact that $T$ is homeomorphic to $B^{2}$, so that we can apply the results proved in this section to the space $T$.

Choose $\epsilon>0$ so that no set of diameter less than $\epsilon$ intersects all three edges of $T$. (In fact, $\epsilon=\frac{1}{2}$ will do.) We suppose that $\mathcal{A}=\left\{U_{1}, \ldots, U_{n}\right\}$ is an open covering of $T$ by sets of diameter less than $\epsilon$, such that no three elements of $\mathcal{A}$ intersect, and derive a contradiction.

For each $i=1, \ldots, n$, choose a vertex $v_{i}$ of $T$ as follows: If $U_{i}$ intersects two edges of $T$, let $v_{i}$ be the vertex common to these edges. If $U_{i}$ intersects only one edge of $T$, let $v_{i}$ be one of the end points of this edge. If $U_{i}$ intersects no edge of $T$, let $v_{i}$ be any vertex of $T$.

Now let $\left\{\phi_{i}\right\}$ be a partition of unity dominated by $\left\{U_{1}, \ldots, U_{n}\right\}$. (See $\S 36$.) Define $k: T \rightarrow \mathbb{R}^{2}$ by the equation

$$
k(x)=\sum_{i=1}^{n} \phi_{i}(x) v_{i}
$$

Then $k$ is continuous. Given a point $x$ of $T$, it lies in at most two elements of $\mathscr{A}$; hence at most two of the numbers $\phi_{i}(x)$ are nonzero. Then $k(x)=v_{i}$ if $x$ lies in only one open set $U_{i}$, and $k(x)=t v_{i}+(1-t) v_{j}$ for some $t$ with $0 \leq t \leq 1$ if $x$ lies in two open sets $U_{i}$ and $U_{j}$. In either case, $k(x)$ belongs to the union of the edges of $T$, which is Bd $T$. Thus $k$ maps $T$ into $\mathrm{Bd} T$.

Furthermore, $k$ maps each edge of $T$ into itself. For if $x$ belongs to the edge $v w$ of $T$, any open set $U_{i}$ containing $x$ intersects this edge, so that $v_{i}$ must equal either $v$ or $w$. The definition of $k$ then shows that $k(x)$ belongs to $v w$.

Let $h: \operatorname{Bd} T \rightarrow \operatorname{Bd} T$ be the restriction of $k$ to $\operatorname{Bd} T$. Since $h$ can be extended to the continuous map $k$, it is nulhomotopic. On the other hand, $h$ is homotopic to the identity map of Bd $T$ to itself; indeed, since $h$ maps each edge of $T$ into itself, the straight-line homotopy between $h$ and the identity map of $\operatorname{Bd} T$ is such a homotopy. But the identity map $i$ of $\mathrm{Bd} T$ is not nulhomotopic.

## Exercises

1. Show that if $A$ is a retract of $B^{2}$, then every continuous map $f: A \rightarrow A$ has a fixed point.
2. Show that if $h: S^{1} \rightarrow S^{1}$ is nulhomotopic, then $h$ has a fixed point and $h$ maps some point $x$ to its antipode $-x$.
3. Show that if $A$ is a nonsingular 3 by 3 matrix having nonnegative entries, then $A$ has a positive real eigenvalue.
4. Suppose that you are given the fact that for each $n$, there is no retraction $r$ : $B^{n+1} \rightarrow S^{n}$. (This result can be proved using more advanced techniques of algebraic topology.) Prove the following:

(a) The identity map $i: S^{n} \rightarrow S^{n}$ is not nulhomotopic.

(b) The inclusion map $j: S^{n} \rightarrow \mathbb{R}^{n+1}-\mathbf{0}$ is not nulhomotopic.

(c) Every nonvanishing vector field on $B^{n+1}$ points directly outward at some point of $S^{n}$, and directly inward at some point of $S^{n}$.

(d) Every continuous map $f: B^{n+1} \rightarrow B^{n+1}$ has a fixed point.

(e) Every $n+1$ by $n+1$ matrix with positive real entries has a positive eigenvalue.

(f) If $h: S^{n} \rightarrow S^{n}$ is nulhomotopic, then $h$ has a fixed point and $h$ maps some point $x$ to its antipode $-x$.

## *§56 The Fundamental Theorem of Algebra

It is a basic fact about the complex numbers that every polynomial equation

$$
x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}=0
$$

of degree $n$ with real or complex coefficients has $n$ roots (if the roots are counted according to their multiplicities). You probably first were told this fact in high school algebra, although it is doubtful that it was proved for you at that time.

The proof is, in fact, rather hard; the most difficult part is to prove that every polynomial equation of positive degree has at least one root. There are various ways
of doing this. One can use only techniques of algebra; this proof is long and arduous. Or one can develop the theory of analytic functions of a complex variable to the point where it becomes a trivial corollary of Liouville's theorem. Or one can prove it as a relatively easy corollary of our computation of the fundamental group of the circle; this we do now.

Theorem 56.1 (The fundamental theorem of algebra). A polynomial equation

$$
x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}=0
$$

of degree $n>0$ with real or complex coefficients has at least one (real or complex) root.

Proof. Step 1. Consider the map $f: S^{1} \rightarrow S^{1}$ given by $f(z)=z^{n}$, where $z$ is a complex number. We show that the induced homomorphism $f_{*}$ of fundamental groups is injective.

Let $p_{0}: I \rightarrow S^{1}$ be the standard loop in $S^{1}$,

$$
p_{0}(s)=e^{2 \pi i s}=(\cos 2 \pi s, \sin 2 \pi s) \text {. }
$$

Its image under $f_{*}$ is the loop

$$
f\left(p_{0}(s)\right)=\left(e^{2 \pi i s}\right)^{n}=(\cos 2 \pi n s, \sin 2 \pi n s) .
$$

This loop lifts to the path $s \rightarrow n s$ in the covering space $\mathbb{R}$. Therefore, the loop $f \circ p_{0}$ corresponds to the integer $n$ under the standard isomorphism of $\pi_{1}\left(S^{1}, b_{0}\right)$ with the integers, whereas $p_{0}$ corresponds to the number 1 . Thus $f_{*}$ is "multiplication by $n$ " in the fundamental group of $S^{1}$, so that in particular, $f_{*}$ is injective.

Step 2. We show that if $g: S^{1} \rightarrow \mathbb{R}^{2}-\mathbf{0}$ is the map $g(z)=z^{n}$, then $g$ is not nulhomotopic.

The map $g$ equals the map $f$ of Step 1 followed by the inclusion map $j: S^{1} \rightarrow$ $\mathbb{R}^{2}-\mathbf{0}$. Now $f_{*}$ is injective, and $j_{*}$ is injective because $S^{1}$ is a retract of $\mathbb{R}^{2}-\mathbf{0}$. Therefore, $g_{*}=j_{*} \circ f_{*}$ is injective. Thus $g$ cannot be nulhomotopic.

Step 3. Now we prove a special case of the theorem. Given a polynomial equation

$$
x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}=0,
$$

we assume that

$$
\left|a_{n-1}\right|+\cdots+\left|a_{1}\right|+\left|a_{0}\right|<1
$$

and show that the equation has a root lying in the unit ball $B^{2}$.

Assume it has no such root. Then we can define a map $k: B^{2} \rightarrow \mathbb{R}^{2}-\mathbf{0}$ by the equation

$$
k(z)=z^{n}+a_{n-1} z^{n-1}+\cdots+a_{1} z+a_{0} .
$$

Let $h$ be the restriction of $k$ to $S^{1}$. Because $h$ extends to a map of the unit ball into $\mathbb{R}^{2} \mathbf{- 0}$, the map $h$ is nulhomotopic.

On the other hand, we shall define a homotopy $F$ between $h$ and the map $g$ of Step 2; since $g$ is not nulhomotopic, we have a contradiction. We define $F: S^{1} \times I \rightarrow$ $\mathbb{R}^{2}-\mathbf{0}$ by the equation

$$
F(z, t)=z^{n}+t\left(a_{n-1} z^{n-1}+\cdots+a_{0}\right) .
$$

See Figure 56.1; $F(z, t)$ never equals $\mathbf{0}$ because

$$
\begin{aligned}
|F(z, t)| & \geq\left|z^{n}\right|-\left|t\left(a_{n-1} z^{n-1}+\cdots+a_{0}\right)\right| \\
& \geq 1-t\left(\left|a_{n-1} z^{n-1}\right|+\cdots+\left|a_{0}\right|\right) \\
& =1-t\left(\left|a_{n-1}\right|+\cdots+\left|a_{0}\right|\right)>0 .
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-354.jpg?height=484&width=1052&top_left_y=990&top_left_x=488)

Figure 56.1

Step 4. Now we prove the general case. Given a polynomial equation

$$
x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}=0,
$$

let us choose a real number $c>0$ and substitute $x=c y$. We obtain the equation

$$
(c y)^{n}+a_{n-1}(c y)^{n-1}+\cdots+a_{1}(c y)+a_{0}=0
$$

or

$$
y^{n}+\frac{a_{n-1}}{c} y^{n-1}+\cdots+\frac{a_{1}}{c^{n-1}} y+\frac{a_{0}}{c^{n}}=0 .
$$

If this equation has the root $y=y_{0}$, then the original equation has the root $x_{0}=c y_{0}$. So we need merely choose $c$ large enough that

$$
\left|\frac{a_{n-1}}{c}\right|+\left|\frac{a_{n-2}}{c^{2}}\right|+\cdots+\left|\frac{a_{1}}{c^{n-1}}\right|+\left|\frac{a_{0}}{c^{n}}\right|<1
$$

to reduce the theorem to the special case considered in Step 3.

## Exercises

1. Given a polynomial equation

$$
x^{n}+a_{n-1} x^{n-1}+\cdots+a_{1} x+a_{0}=0
$$

with real or complex coefficients. Show that if $\left|a_{n-1}\right|+\cdots+\left|a_{1}\right|+\left|a_{0}\right|<1$, then all the roots of the equation lie interior to the unit ball $B^{2}$. [Hint: Let $g(x)=1+a_{n-1} x+\cdots+a_{1} x^{n-1}+a_{0} x^{n}$, and show that $g(x) \neq 0$ for $x \in B^{2}$.]

2. Find a circle about the origin containing all the roots of the polynomial equation $x^{7}+x^{2}+1=0$.

## *§57 The Borsuk-Ulam Theorem

Here is a "brain-teaser" problem: Suppose you are given a bounded polygonal region $A$ in the plane $\mathbb{R}^{2}$. No matter what shape $A$ has, it is easy to show that there exists a straight line that bisects $A$, that is, one that cuts the area of $A$ in half. Simply take the horizontal line $y=c$, let $f(c)$ denote the area of that part of $A$ that lies beneath this line, note that $f$ is a continuous function of $c$, and use the intermediate-value theorem to find a value of $c$ for which $f(c)$ equals exactly half the area of $A$.

But now suppose instead that you are given two such regions $A_{1}$ and $A_{2}$, you are asked to find a single line that bisects them both. It is not obvious even that there exists such a line. Try to find one for an arbitrary pair of triangular regions if you have doubts!

In fact, such a line always exists. This result is a corollary of a well-known theorem called the Borsuk-Ulam theorem, to which we now turn.

Definition. If $x$ is a point of $S^{n}$, then its antipode is the point $-x$. A map $h: S^{n} \rightarrow$ $S^{m}$ is said to be antipode-preserving if $h(-x)=-h(x)$ for all $x \in S^{n}$.

Theorem 57.1. If $h: S^{1} \rightarrow S^{1}$ is continuous and antipode-preserving, then $h$ is not nulhomotopic.

Proof. Let $b_{0}$ be the point $(1,0)$ of $S^{1}$. Let $\rho: S^{1} \rightarrow S^{1}$ be a rotation of $S^{1}$ that maps $h\left(b_{0}\right)$ to $b_{0}$. Since $\rho$ preserves antipodes, so does the composite $\rho \circ h$. Furthermore, if $H$ were a homotopy between $h$ and a constant map, then $\rho \circ H$ would be a homotopy between $\rho \circ h$ and a constant map. Therefore, it suffices to prove the theorem under the additional hypothesis that $h\left(b_{0}\right)=b_{0}$.

Step 1. Let $q: S^{1} \rightarrow S^{1}$ be the map $q(z)=z^{2}$, where $z$ is a complex number. Or in real coordinates, $q(\cos \theta, \sin \theta)=(\cos 2 \theta, \sin 2 \theta)$. The map $q$ is a quotient map, being continuous, closed, and surjective. The inverse image under $q$ of any point of $S^{1}$ consists of two antipodal points $z$ and $-z$ of $S^{1}$. Because $h(-z)=-h(z)$, one has the
equation $q(h(-z))=q(h(z))$. Therefore, because $q$ is a quotient map, the map $q \circ h$ induces a continuous map $k: S^{1} \rightarrow S^{1}$ such that $k \circ q=q \circ h$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-356.jpg?height=203&width=219&top_left_y=487&top_left_x=912)

Note that $q\left(b_{0}\right)=h\left(b_{0}\right)=b_{0}$, so that $k\left(b_{0}\right)=b_{0}$ as well. Also, $h\left(-b_{0}\right)=-b_{0}$.

Step 2. We show that the homomorphism $k_{*}$ of $\pi_{1}\left(S^{1}, b_{0}\right)$ with itself is nontrivial.

For this purpose, we first show that $q$ is a covering map. (We gave this as an exercise in §53.) The proof is similar to the proof that the standard map $p: \mathbb{R} \rightarrow S^{1}$ is a covering map. If, for instance, $U$ is the subset of $S^{1}$ consisting of those points having positive second coordinate, then $p^{-1}(U)$ consist of those points of $S^{1}$ lying in the first and third quadrants of $\mathbb{R}^{2}$. The map $q$ carries each of these sets homeomorphically onto $U$. Similar arguments apply when $U$ is the intersection of $S^{1}$ with the open lower half-plane, or with the open right and left half-planes.

Second, we note that if $\tilde{f}$ is any path in $S^{1}$ from $b_{0}$ to $-b_{0}$, then the loop $f=q \circ \tilde{f}$ represents a nontrivial element of $\pi_{1}\left(S^{1}, b_{0}\right)$. For $\tilde{f}$ is a lifting of $f$ to $S^{1}$ that begins at $b_{0}$ and does not end at $b_{0}$.

Finally, we show $k_{*}$ is nontrivial. Let $\tilde{f}$ be a path in $S^{1}$ from $b_{0}$ to $-b_{0}$, and let $f$ be the loop $q \circ \tilde{f}$. Then $k_{*}[f]$ is not trivial, for $k_{*}[f]=[k \circ(q \circ \tilde{f})]=[q \circ(h \circ \tilde{f})]$; the latter is nontrivial because $h \circ \tilde{f}$ is a path in $S^{1}$ from $b_{0}$ to $-b_{0}$.

Step 3. Finally, we show that the homomorphism $h_{*}$ is nontrivial, so that $h$ cannot be nulhomotopic.

The homomorphism $k_{*}$ is injective, being a nontrivial homomorphism of an infinite cyclic group with itself. The homomorphism $q_{*}$ is also injective; indeed, $q_{*}$ corresponds to multiplication by two in the group of integers. It follows that $k_{*} \circ q_{*}$ is injective. Since $q_{*} \circ h_{*}=k_{*} \circ q_{*}$, the homomorphism $h_{*}$ must be injective as well.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-356.jpg?height=250&width=580&top_left_y=1679&top_left_x=729)

Figure 57.1

Theorem 57.2. There is no continuous antipode-preserving map $g: S^{2} \rightarrow S^{1}$.

Proof. Suppose $g: S^{2} \rightarrow S^{1}$ is continuous and antipode preserving. Let us take $S^{1}$ to be the equator of $S^{2}$. Then the restriction of $g$ to $S^{1}$ is a continuous antipode-preserving map $h$ of $S^{1}$ to itself. By the preceding theorem, $h$ is not nulhomotopic. But the upper hemisphere $E$ of $S^{2}$ is homeomorphic to the ball $B^{2}$, and $g$ is a continuous extension of $h$ to $E$ ! See Figure 57.1.

Theorem 57.3 (Borsuk-Ulam theorem for $\boldsymbol{S}^{\mathbf{2}}$ ). Given a continuous map $f: S^{2} \rightarrow$ $\mathbb{R}^{2}$, there is a point $x$ of $S^{2}$ such that $f(x)=f(-x)$.

Proof. Suppose that $f(x) \neq f(-x)$ for all $x \in S^{2}$. Then the map

$$
g(x)=[f(x)-f(-x)] /\|f(x)-f(-x)\|
$$

is a continuous map $g: S^{2} \rightarrow S^{1}$ such that $g(-x)=-g(x)$ for all $x$.

Theorem 57.4 (The bisection theorem). Given two bounded polygonal regions in $\mathbb{R}^{2}$, there exists a line in $\mathbb{R}^{2}$ that bisects each of them.

Proof. We take two bounded polygonal regions $A_{1}$ and $A_{2}$ in the plane $\mathbb{R}^{2} \times 1$ in $\mathbb{R}^{3}$, and show there is a line $L$ in this plane that bisects each of them.

Given a point $u$ of $S^{2}$, let us consider the plane $P$ in $\mathbb{R}^{3}$ passing through the origin that has $u$ as its unit normal vector. This plane divides $\mathbb{R}^{3}$ into two half-spaces; let $f_{i}(u)$ equal the area of that portion of $A_{i}$ that lies on the same side of $P$ as does the vector $u$.

If $u$ is the unit vector $\mathbf{k}$, then $f_{i}(u)=$ area $A_{i}$; and if $u=-\mathbf{k}$, then $f_{i}(u)=0$. Otherwise, the plane $P$ intersects the plane $\mathbb{R}^{2} \times 1$ in a line $L$ that splits $\mathbb{R}^{2} \times 1$ into two half-planes, and $f_{i}(u)$ is the area of that part of $A_{i}$ that lies on one side of this line. See Figure 57.2.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-357.jpg?height=435&width=672&top_left_y=1348&top_left_x=860)

Figure 57.2

Replacing $u$ by $-u$ gives us the same plane $P$, but the other half-space, so that $f_{i}(-u)$ is the area of that part of $A_{i}$ that lies on the other side of $P$ from $u$. It follows that

$$
f_{i}(u)+f_{i}(-u)=\operatorname{area} A_{i} .
$$

Now consider the map $F: S^{2} \rightarrow \mathbb{R}^{2}$ given by $F(u)=\left(f_{1}(u), f_{2}(u)\right)$. The Borsuk-Ulam theorem gives us a point $u$ of $S^{2}$ for which $F(u)=F(-u)$. Then $f_{i}(u)=f_{i}(-u)$ for $i=1,2$, that $f_{i}(u)=\frac{1}{2}$ area $A_{i}$, as desired.

We have proved the bisection theorem for bounded polygonal regions in the plane. However, all that was needed in the proof was the existence of an additive area function for $A_{1}$ and $A_{2}$. Thus, the theorem holds for any two sets $A_{1}$ and $A_{2}$ that are "Jordanmeasurable" in the sense used in analysis.

These theorems generalize to higher dimensions, but the proofs are considerably more sophisticated. The generalized version of the bisection theorem states that given $n$ Jordan-measurable sets in $\mathbb{R}^{n}$, there exists a plane of dimension $n-1$ that bisects them all. In the case $n=3$, this result goes by the pleasant name of the "ham sandwich theorem." If one considers a ham sandwich to consist of two pieces of bread and a slab of ham, then the bisection theorem says that one can divide each of them precisely in half with a single whack of a cleaver!

## Exercises

1. Prove the following "theorem of meteorology": At any given moment in time, there exists a pair of antipodal points on the surface of the earth at which both the temperature and the barometric pressure are equal.
2. Show that if $g: S^{2} \rightarrow S^{2}$ is continuous and $g(x) \neq g(-x)$ for all $x$, then $g$ is surjective. [Hint: If $p \in S^{2}$, then $S^{2}-\{p\}$ is homeomorphic to $\mathbb{R}^{2}$.]
3. Let $h: S^{1} \rightarrow S^{1}$ be continuous and antipode-preserving with $h\left(b_{0}\right)=b_{0}$. Show that $h_{*}$ carries a generator of $\pi_{1}\left(S^{1}, b_{0}\right)$ to an odd power of itself. [Hint: If $k$ is the map constructed in the proof of Theorem 57.1, show that $k_{*}$ does the same.]
4. Suppose you are given the fact that for each $n$, no continuous antipode-preserving map $h: S^{n} \rightarrow S^{n}$ is nulhomotopic. (This result can be proved using more advanced techniques of algebraic topology.) Prove the following:

(a) There is no retraction $r: B^{n+1} \rightarrow S^{n}$.

(b) There is no continuous antipode-preserving map $g: S^{n+1} \rightarrow S^{n}$.

(c) (Borsuk-Ulam theorem) Given a continuous map $f: S^{n+1} \rightarrow \mathbb{R}^{n+1}$, there is a point $x$ of $S^{n+1}$ such that $f(x)=f(-x)$.

(d) If $A_{1}, \ldots, A_{n+1}$ are bounded measurable sets in $\mathbb{R}^{n+1}$, there exists an $n$ plane in $\mathbb{R}^{n+1}$ that bisects each of them.

## §58 Deformation Retracts and Homotopy Type

As we have seen, one way of obtaining information about the fundamental group of a space $X$ is to study the covering spaces of $X$. Another is one we discuss in this section, which involves the notion of homotopy type. It provides a method for reducing the problem of computing the fundamental group of a space to that of computing the fundamental group of some other space-preferably, one that is more familiar.

We begin with a lemma.

Lemma 58.1. Let $h, k:\left(X, x_{0}\right) \rightarrow\left(Y, y_{0}\right)$ be continuous maps. If $h$ and $k$ are homotopic, and if the image of the base point $x_{0}$ of $X$ remains fixed at $y_{0}$ during the homotopy, then the homomorphisms $h_{*}$ and $k_{*}$ are equal.

Proof. The proof is immediate. By assumption, there is a homotopy $H: X \times I \rightarrow Y$ between $h$ and $k$ such that $H\left(x_{0}, t\right)=y_{0}$ for all $t$. It follows that if $f$ is a loop in $X$ based at $x_{0}$, then the composite

$$
I \times I \xrightarrow{f \times \mathrm{id}} X \times I \xrightarrow{H} Y
$$

is a homotopy between $h \circ f$ and $k \circ f$; it is a path homotopy because $f$ is a loop at $x_{0}$ and $H$ maps $x_{0} \times I$ to $y_{0}$.

Using this lemma, we generalize a result about the space $\mathbb{R}^{2}-\mathbf{0}$ proved earlier, proving that the homomorphism induced by inclusion $j: S^{1} \rightarrow \mathbb{R}^{2}-\mathbf{0}$ is not only injective but surjective as well. More generally, we prove the following:

Theorem 58.2. The inclusion map $j: S^{n} \rightarrow \mathbb{R}^{n+1}-\mathbf{0}$ induces an isomorphism of fundamental groups.

Proof. Let $X=\mathbb{R}^{n+1}-\mathbf{0}$; let $b_{0}=(1,0, \ldots, 0)$. Let $r: X \rightarrow S^{n}$ be the map $r(x)=x /\|x\|$. Then $r \circ j$ is the identity map of $S^{n}$, so that $r_{*} \circ j_{*}$ is the identity homomorphism of $\pi_{1}\left(S^{n}, b_{0}\right)$.

Now consider the composite $j \circ r$, which maps $X$ to itself;

$$
X \xrightarrow{r} S^{n} \xrightarrow{j} X .
$$

This map is not the identity map of $X$, but it is homotopic to the identity map. Indeed, the straight-line homotopy $H: X \times I \rightarrow X$, given by

$$
H(x, t)=(1-t) x+t x /\|x\|,
$$

is a homotopy between the identity map of $X$ and the map $j \circ r$. For $H(x, t)$ is never equal to $\mathbf{0}$, because $(1-t)+t /\|x\|$ is a number between 1 and $1 /\|x\|$. Note that the point $b_{0}$ remains fixed during the homotopy, since $\left\|b_{0}\right\|=1$. It follows from the preceding lemma that the homomorphism $(j \circ r)_{*}=j_{*} \circ r_{*}$ is the identity homomorphism of $\pi_{1}\left(X, b_{0}\right)$.

What made the preceding proof work? Roughly speaking, it worked because we had a natural way of deforming the identity map of $\mathbb{R}^{n+1}-\mathbf{0}$ to a map that collapsed all of $\mathbb{R}^{n+1}-\mathbf{0}$ onto $S^{n}$. The deformation $H$ gradually collapsed each radial line emanating from the origin to the point where it intersected $S^{n}$; each point of $S^{n}$ remained fixed during this deformation.

Figure 58.1 illustrates, in the case $n=1$, how the deformation $H$ gives rise to a path homotopy $H(f(s), t)$ between the loop $f$ in $\mathbb{R}^{2}-\mathbf{0}$ and the loop $g=f /\|f\|$ in $S^{1}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-360.jpg?height=791&width=683&top_left_y=371&top_left_x=680)

Figure 58.1

These comments lead us to formulate a more general situation in which the same procedure applies.

Definition. Let $A$ be a subspace of $X$. We say that $A$ is a deformation retract of $X$ if the identity map of $X$ is homotopic to a map that carries all of $X$ into $A$, such that each point of $A$ remains fixed during the homotopy. This means that there is a continuous map $H: X \times I \rightarrow X$ such that $H(x, 0)=x$ and $H(x, 1) \in A$ for all $x \in X$, and $H(a, t)=a$ for all $a \in A$. The homotopy $H$ is called a deformation retraction of $X$ onto $A$. The map $r: X \rightarrow A$ defined by the equation $r(x)=H(x, 1)$ is a retraction of $X$ onto $A$, and $H$ is a homotopy between the identity map of $X$ and the map $j \circ r$, where $j: A \rightarrow X$ is inclusion.

The proof of the preceding theorem generalizes immediately to prove the following:

Theorem 58.3. Let $A$ be a deformation retract of $X$; let $x_{0} \in A$. Then the inclusion map

$$
j:\left(A, x_{0}\right) \rightarrow\left(X, x_{0}\right)
$$

induces an isomorphism of fundamental groups.

EXAmple 1. Let $B$ denote the $z$-axis in $\mathbb{R}^{3}$. Consider the space $\mathbb{R}^{3}-B$. It has the punctured $x y$-plane $\left(\mathbb{R}^{2}-\mathbf{0}\right) \times 0$ as a deformation retract. The map $H$ defined by the equation

$$
H(x, y, z, t)=(x, y,(1-t) z)
$$

is a deformation retraction; it gradually collapses each line parallel to the $z$-axis into the point where the line intersects the $x y$-plane. We conclude that the space $\mathbb{R}^{3}-B$ has an infinite cyclic fundamental group.

EXAMPLE 2. Consider $\mathbb{R}^{2}-p-q$, the doubly punctured plane. We assert it has the "figure eight" space as a deformation retract. Rather than writing equations, we merely sketch the deformation retraction; it is the three-stage deformation indicated in Figure 58.2.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-361.jpg?height=646&width=1124&top_left_y=956&top_left_x=636)

Figure 58.2

EXAMPLE 3. Another deformation retract of $\mathbb{R}^{2}-p-q$ is the "theta space"

$$
\theta=S^{1} \cup(0 \times[-1,1])
$$

we leave it to you to sketch the maps involved. As a result, the figure eight and the theta space have isomorphic fundamental groups, even though neither is a deformation retract of the other.

Of course, we do not know anything about the fundamental group of the figure eight as yet. But we shall.

The example of the figure eight and the theta space suggests the possibility that there might be a more general way of showing two spaces have isomorphic fundamental groups than by showing that one is homeomorphic to a deformation retract of the other. We formulate such a notion now.

Definition. Let $f: X \rightarrow Y$ and $g: Y \rightarrow X$ be continuous maps. Suppose that the map $g \circ f: X \rightarrow X$ is homotopic to the identity map of $X$, and the map $f \circ g: Y \rightarrow Y$ is homotopic to the identity map of $Y$. Then the maps $f$ and $g$ are called homotopy equivalences, and each is said to be a homotopy inverse of the other.

It is straightforward to show that if $f: X \rightarrow Y$ is a homotopy equivalence of $X$ with $Y$ and $h: Y \rightarrow Z$ is a homotopy equivalence of $Y$ with $Z$, then $h \circ f: X \rightarrow Z$ is a homotopy equivalence of $X$ with $Z$. It follows that the relation of homotopy equivalence is an equivalence relation. Two spaces that are homotopy equivalent are said to have the same homotopy type.

Note that if $A$ is a deformation retract of $X$, then $A$ has the same homotopy type as $X$. For let $j: A \rightarrow X$ be the inclusion mapping and let $r: X \rightarrow A$ be the retraction mapping. Then the composite $r \circ j$ equals the identity map of $A$, and the composite $j \circ r$ is by hypothesis homotopic to the identity map of $X$ (and in fact each point of $A$ remains fixed during the homotopy).

We now show that two spaces having the same homotopy type have isomorphic fundamental groups. For this purpose, we need to study what happens when we have a homotopy between two continuous maps of $X$ into $Y$ such that the base point of $X$ does not remain fixed during the homotopy.

Lemma 58.4. Let $h, k: X \rightarrow Y$ be continuous maps; let $h\left(x_{0}\right)=y_{0}$ and $k\left(x_{0}\right)=y_{1}$. If $h$ and $k$ are homotopic, there is a path $\alpha$ in $Y$ from $y_{0}$ to $y_{1}$ such that $k_{*}=\hat{\alpha} \circ h_{*}$. Indeed, if $H: X \times I \rightarrow Y$ is the homotopy between $h$ and $k$, then $\alpha$ is the path $\alpha(t)=H\left(x_{0}, t\right)$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-362.jpg?height=211&width=408&top_left_y=1427&top_left_x=817)

Proof. Let $f: I \rightarrow X$ be a loop in $X$ based at $x_{0}$. We must show that

$$
k_{*}([f])=\hat{\alpha}\left(h_{*}([f]) .\right.
$$

This equation states that $[k \circ f]=[\bar{\alpha}] *[h \circ f] *[\alpha]$, or equivalently, that

$$
[\alpha] *[k \circ f]=[h \circ f] *[\alpha] .
$$

This is the equation we shall verify.

To begin, consider the loops $f_{0}$ and $f_{1}$ in the space $X \times I$ given by the equations

$$
f_{0}(s)=(f(s), 0) \quad \text { and } \quad f_{1}(s)=(f(s), 1) \text {. }
$$

Consider also the path $c$ in $X \times I$ given by the equation

$$
c(t)=\left(x_{0}, t\right) .
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-363.jpg?height=424&width=1077&top_left_y=371&top_left_x=658)

Figure 58.3

Then $H \circ f_{0}=h \circ f$ and $H \circ f_{1}=k \circ f$, while $H \circ c$ equals the path $\alpha$. See Figure 58.3.

Let $F: I \times I \rightarrow X \times I$ be the map $F(s, t)=(f(s), t)$. Consider the following paths in $I \times I$, which run along the four edges of $I \times I$ :

$$
\begin{array}{lll}
\beta_{0}(s)=(s, 0) & \text { and } & \beta_{1}(s)=(s, 1), \\
\gamma_{0}(t)=(0, t) & \text { and } & \gamma_{1}(t)=(1, t) .
\end{array}
$$

Then $F \circ \beta_{0}=f_{0}$ and $F \circ \beta_{1}=f_{1}$, while $F \circ \gamma_{0}=F \circ \gamma_{1}=c$.

The broken-line paths $\beta_{0} * \gamma_{1}$ and $\gamma_{0} * \beta_{1}$ are paths in $I \times I$ from $(0,0)$ to $(1,1)$; since $I \times I$ is convex, there is a path homotopy $G$ between them. Then $F \circ G$ is a path homotopy in $X \times I$ between $f_{0} * c$ and $c * f_{1}$. And $H \circ(F \circ G)$ is a path homotopy in $Y$ between

$$
\begin{aligned}
& \left(H \circ f_{0}\right) *(H \circ c)=(h \circ f) * \alpha \quad \text { and } \\
& (H \circ c) *\left(H \circ f_{1}\right)=\alpha *(k \circ f),
\end{aligned}
$$

as desired.

Corollary 58.5. Let $h, k: X \rightarrow Y$ be homotopic continuous maps; let $h\left(x_{0}\right)=y_{0}$ and $k\left(x_{0}\right)=y_{1}$. If $h_{*}$ is injective, or surjective, or trivial, so is $k_{*}$.

Corollary 58.6. Let $h: X \rightarrow Y$. If $h$ is nulhomotopic, then $h_{*}$ is the trivial homomorphism.

Proof. The constant map induces the trivial homomorphism.

Theorem 58.7. Let $f: X \rightarrow Y$ be continuous; let $f\left(x_{0}\right)=y_{0}$. If $f$ is a homotopy equivalence, then

$$
f_{*}: \pi_{1}\left(X, x_{0}\right) \longrightarrow \pi_{1}\left(Y, y_{0}\right)
$$

is an isomorphism.

Proof. Let $g: Y \rightarrow X$ be a homotopy inverse for $f$. Consider the maps

$$
\left(X, x_{0}\right) \xrightarrow{f}\left(Y, y_{0}\right) \xrightarrow{g}\left(X, x_{1}\right) \xrightarrow{f}\left(Y, y_{1}\right),
$$

where $x_{1}=g\left(y_{0}\right)$ and $y_{1}=f\left(x_{1}\right)$. We have the corresponding induced homomorphisms:

$$
\begin{aligned}
& \pi_{1}\left(X, x_{0}\right) \xrightarrow{\left(f_{x_{0}}\right)_{*}} \pi_{1}\left(Y, y_{0}\right) \\
& \pi_{1}\left(X, x_{1}\right) \xrightarrow{\left(f_{x_{1}}\right)_{*}} \pi_{1}\left(Y, y_{1}\right)
\end{aligned}
$$

[Here we have to distinguish between the homomorphisms induced by $f$ relative to two different base points.] Now

$$
g \circ f:\left(X, x_{0}\right) \longrightarrow\left(X, x_{1}\right)
$$

is by hypothesis homotopic to the identity map, so there is a path $\alpha$ in $X$ such that

$$
(g \circ f)_{*}=\hat{\alpha} \circ\left(i_{X}\right)_{*}=\hat{\alpha}
$$

It follows that $(g \circ f)_{*}=g_{*} \circ\left(f_{x_{0}}\right)_{*}$ is an isomorphism.

Similarly, because $f \circ g$ is homotopic to the identity map $i_{Y}$, the homomorphism $(f \circ g)_{*}=\left(f_{x_{1}}\right)_{*} \circ g_{*}$ is an isomorphism.

The first fact implies that $g_{*}$ is surjective, and the second implies that $g_{*}$ is injective. Therefore, $g_{*}$ is an isomorphism. Applying the first equation once again, we conclude that

$$
\left(f_{x_{0}}\right)_{*}=\left(g_{*}\right)^{-1} \circ \hat{\alpha},
$$

so that $\left(f_{x_{0}}\right)_{*}$ is also an isomorphism.

Note that although $g$ is a homotopy inverse for $f$, the homomorphism $g_{*}$ is not an inverse for the homomorphism $\left(f_{x_{0}}\right)_{*}$.

The relation of homotopy equivalence is clearly more general than the notion of deformation retraction. The theta space and the figure eight are both deformation retracts of the doubly punctured plane. Therefore, they are homotopy equivalent to the doubly punctured plane, and hence to each other. But neither is homeomorphic to a deformation retract of the other; in fact, neither of them can even be imbedded in the other.

It is a striking fact that the situation that occurs for these two spaces is the standard situation regarding homotopy equivalences. Martin Fuchs has proved a theorem to the effect that two spaces $X$ and $Y$ have the same homotopy type if and only if they are homeomorphic to deformation retracts of a single space $Z$. The proof, although it uses only elementary tools, is difficult [F].

## Exercises

1. Show that if $A$ is a deformation retract of $X$, and $B$ is a deformation retract of $A$, then $B$ is a deformation retract of $X$.
2. For each of the following spaces, the fundamental group is either trivial, infinite cyclic, or isomorphic to the fundamental group of the figure eight. Determine for each space which of the three alternatives holds.

(a) The "solid torus," $B^{2} \times S^{1}$.

(b) The torus $T$ with a point removed.

(c) The cylinder $S^{1} \times I$.

(d) The infinite cylinder $S^{1} \times \mathbb{R}$.

(e) $\mathbb{R}^{3}$ with the nonnegative $x$, $y$, and $z$ axes deleted.

The following subsets of $\mathbb{R}^{2}$ :

(f) $\{x \mid\|x\|>1\}$

(g) $\{x \mid\|x\| \geq 1\}$

(h) $\{x \mid\|x\|<1\}$

(i) $S^{1} \cup\left(\mathbb{R}_{+} \times 0\right)$

(j) $S^{1} \cup\left(\mathbb{R}_{+} \times \mathbb{R}\right)$

(k) $S^{1} \cup(\mathbb{R} \times 0)$

(l) $\mathbb{R}^{2}-\left(\mathbb{R}_{+} \times 0\right)$

3. Show that given a collection $\mathcal{C}$ of spaces, the relation of homotopy equivalence is an equivalence relation on $C$.
4. Let $X$ be the figure eight and let $Y$ be the theta space. Describe maps $f: X \rightarrow Y$ and $g: Y \rightarrow X$ that are homotopy inverse to each other.
5. Recall that a space $X$ is said to be contractible if the identity map of $X$ to itself is nulhomotopic. Show that $X$ is contractible if and only if $X$ has the homotopy type of a one-point space.
6. Show that a retract of a contractible space is contractible.
7. Let $A$ be a subspace of $X$; let $j: A \rightarrow X$ be the inclusion map, and let $f: X \rightarrow$ $A$ be a continuous map. Suppose there is a homotopy $H: X \times I \rightarrow X$ between the map $j \circ f$ and the identity map of $X$.

(a) Show that if $f$ is a retraction, then $j_{*}$ is an isomorphism.

(b) Show that if $H$ maps $A \times I$ into $A$, then $j_{*}$ is an isomorphism.

(c) Give an example in which $j_{*}$ is not an isomorphism.

*8. Find a space $X$ and a point $x_{0}$ of $X$ such that inclusion $\left\{x_{0}\right\} \rightarrow X$ is a homotopy equivalence, but $\left\{x_{0}\right\}$ is not a deformation retract of $X$. [Hint: Let $X$ be the subspace of $\mathbb{R}^{2}$ that is the union of the line segments $(1 / n) \times I$, for $n \in \mathbb{Z}_{+}$, the line segment $0 \times I$, and the line segment $I \times 0$; let $x_{0}$ be the point $(0,1)$. If $\left\{x_{0}\right\}$ is a deformation retract of $X$, show that for any neighborhood $U$ of $x_{0}$, the path component of $U$ containing $x_{0}$ contains a neighborhood of $x_{0}$.]

9. We define the degree of a continuous map $h: S^{1} \rightarrow S^{1}$ as follows:

Let $b_{0}$ be the point $(1,0)$ of $S^{1}$; choose a generator $\gamma$ for the infinite cyclic group $\pi_{1}\left(S^{1}, b_{0}\right)$. If $x_{0}$ is any point of $S^{1}$, choose a path $\alpha$ in $S^{1}$ from $b_{0}$ to $x_{0}$,
and define $\gamma\left(x_{0}\right)=\hat{\alpha}(\gamma)$. Then $\gamma\left(x_{0}\right)$ generates $\pi_{1}\left(S^{1}, x_{0}\right)$. The element $\gamma\left(x_{0}\right)$ is independent of the choice of the path $\alpha$, since the fundamental group of $S^{1}$ is abelian.

Now given $h: S^{1} \rightarrow S^{1}$, choose $x_{0} \in S^{1}$ and let $h\left(x_{0}\right)=x_{1}$. Consider the homomorphism

$$
h_{*}: \pi_{1}\left(S^{1}, x_{0}\right) \longrightarrow \pi_{1}\left(S^{1}, x_{1}\right) .
$$

Since both groups are infinite cyclic, we have

$$
\begin{equation*}
h_{*}\left(\gamma\left(x_{0}\right)\right)=d \cdot \gamma\left(x_{1}\right) \tag{*}
\end{equation*}
$$

for some integer $d$, if the group is written additively. The integer $d$ is called the degree of $h$ and is denoted by $\operatorname{deg} h$.

The degree of $h$ is independent of the choice of the generator $\gamma$; choosing the other generator would merely change the sign of both sides of $(*)$.

(a) Show that $d$ is independent of the choice of $x_{0}$.

(b) Show that if $h, k: S^{1} \rightarrow S^{1}$ are homotopic, they have the same degree.

(c) Show that $\operatorname{deg}(h \circ k)=(\operatorname{deg} h) \cdot(\operatorname{deg} k)$.

(d) Compute the degrees of the constant map, the identity map, the reflection map $\rho\left(x_{1}, x_{2}\right)=\left(x_{1},-x_{2}\right)$, and the map $h(z)=z^{n}$, where $z$ is a complex number.

*(e) Show that if $h, k: S^{1} \rightarrow S^{1}$ have the same degree, they are homotopic.

10. Suppose that to every map $h: S^{n} \rightarrow S^{n}$ we have assigned an integer, denoted by $\operatorname{deg} h$ and called the degree of $h$, such that:

(i) Homotopic maps have the same degree.

(ii) $\operatorname{deg}(h \circ k)=(\operatorname{deg} h) \cdot(\operatorname{deg} k)$.

(iii) The identity map has degree 1 , any constant map has degree 0 , and the reflection map $\rho\left(x_{1}, \ldots, x_{n+1}\right)=\left(x_{1}, \ldots, x_{n},-x_{n+1}\right)$ has degree -1 .

[One can construct such a function, using the tools of algebraic topology. Intuitively, $\operatorname{deg} h$ measures how many times $h$ wraps $S^{n}$ about itself; the sign tells you whether $h$ preserves orientation or not.] Prove the following:

(a) There is no retraction $r: B^{n+1} \rightarrow S^{n}$.

(b) If $h: S^{n} \rightarrow S^{n}$ has degree different from $(-1)^{n+1}$, then $h$ has a fixed point. [Hint: Show that if $h$ has no fixed point, then $h$ is homotopic to the antipodal $\operatorname{map} a(x)=-x$.]

(c) If $h: S^{n} \rightarrow S^{n}$ has degree different from 1, then $h$ maps some point $x$ to its antipode $-x$.

(d) If $S^{n}$ has a nonvanishing tangent vector field $v$, then $n$ is odd. [Hint: If $v$ exists, show the identity map is homotopic to the antipodal map.]

## §59 The Fundamental Group of $S^{n}$

Now we turn to a problem mentioned at the beginning of the chapter, the problem of showing that the sphere, torus, and double torus are surfaces that are topologically distinct. We begin with the sphere; we show that $S^{n}$ is simply connected for $n \geq 2$. The crucial result we need is stated in the following theorem.

Theorem 59.1. Suppose $X=U \cup V$, where $U$ and $V$ are open sets of $X$. Suppose that $U \cap V$ is path connected, and that $x_{0} \in U \cap V$. Let $i$ and $j$ be the inclusion mappings of $U$ and $V$, respectively, into $X$. Then the images of the induced homomorphisms

$$
i_{*}: \pi_{1}\left(U, x_{0}\right) \rightarrow \pi_{1}\left(X, x_{0}\right) \quad \text { and } \quad j_{*}: \pi_{1}\left(V, x_{0}\right) \rightarrow \pi_{1}\left(X, x_{0}\right)
$$

generate $\pi_{1}\left(X, x_{0}\right)$.

Proof. This theorem states that, given any loop $f$ in $X$ based at $x_{0}$, it is path homotopic to a product of the form $\left(g_{1} *\left(g_{2} *\left(\cdots * g_{n}\right)\right)\right.$, where each $g_{i}$ is a loop in $X$ based at $x_{0}$ that lies either in $U$ or in $V$.

Step 1. We show there is a subdivision $a_{0}<a_{1}<\cdots<a_{n}$ of the unit interval such that $f\left(a_{i}\right) \in U \cap V$ and $f\left(\left[a_{i-1}, a_{i}\right]\right)$ is contained either in $U$ or in $V$, for each $i$.

To begin, choose a subdivision $b_{0}, \ldots, b_{m}$ of $[0,1]$ such that for each $i$, the set $f\left(\left[b_{i-1}, b_{i}\right]\right)$ is contained in either $U$ or $V$. (Use the Lebesgue number lemma.) If $f\left(b_{i}\right)$ belongs to $U \cap V$ for each $i$, we are finished. If not, let $i$ be an index such that $f\left(b_{i}\right) \notin U \cap V$. Each of the sets $f\left(\left[b_{i-1}, b_{i}\right]\right)$ and $f\left(\left[b_{i}, b_{i+1}\right]\right)$ lies either in $U$ or in $V$. If $f\left(b_{i}\right) \in U$, then both of these sets must lie in $U$; and if $f\left(b_{i}\right) \in V$, both of them must lie in $V$. In either case, we may delete $b_{i}$, obtaining a new subdivision $c_{0}$, $\ldots, c_{m-1}$ that still satisfies the condition that $f\left(\left[c_{i-1}, c_{i}\right]\right)$ is contained either in $U$ or in $V$, for each $i$.

A finite number of repetitions of this process leads to the desired subdivision.

Step 2. We prove the theorem. Given $f$, let $a_{0}, \ldots, a_{n}$ be the subdivision constructed in Step 1. Define $f_{i}$ to be the path in $X$ that equals the positive linear map of $[0,1]$ onto $\left[a_{i-1}, a_{i}\right]$ followed by $f$. Then $f_{i}$ is a path that lies either in $U$ or in $V$, and by Theorem 51.3 ,

$$
[f]=\left[f_{1}\right] *\left[f_{2}\right] * \cdots *\left[f_{n}\right] .
$$

For each $i$, choose a path $\alpha_{i}$ in $U \cap V$ from $x_{0}$ to $f\left(a_{i}\right)$. (Here we use the fact that $U \cap V$ is path connected.) Since $f\left(a_{0}\right)=f\left(a_{n}\right)=x_{0}$, we can choose $\alpha_{0}$ and $\alpha_{n}$ to be the constant path at $x_{0}$. See Figure 59.1.

Now we set

$$
g_{i}=\left(\alpha_{i-1} * f_{i}\right) * \overline{\alpha_{i}}
$$

for each $i$. Then $g_{i}$ is a loop in $X$ based at $x_{0}$ whose image lies either in $U$ or in $V$. Direct computation shows that

$$
\left[g_{1}\right] *\left[g_{1}\right] * \cdots *\left[g_{n}\right]=\left[f_{1}\right] *\left[f_{2}\right] * \cdots *\left[f_{n}\right]
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-368.jpg?height=494&width=1050&top_left_y=366&top_left_x=502)

Figure 59.1

The preceding theorem is a special case of a famous theorem of topology called the Seifert-van Kampen theorem, which expresses the fundamental group of the space $X=U \cup V$ quite generally, when $U \cap V$ is path connected, in terms of the fundamental groups of $U$ and $V$. We shall study this theorem in Chapter 11.

Corollary 59.2. Suppose $X=U \cup V$, where $U$ and $V$ are open sets of $X$; suppose $U \cap V$ is nonempty and path connected. If $U$ and $V$ are simply connected, then $X$ is simply connected.

Theorem 59.3. If $n \geq 2$, the $n$-sphere $S^{n}$ is simply connected.

Proof. Let $p=(0, \ldots, 0,1) \in \mathbb{R}^{n+1}$ and $q=(0, \ldots, 0,-1)$ be the "north pole" and the "south pole" of $S^{n}$, respectively. to $\mathbb{R}^{n}$.

Step 1. We show that if $n \geq 1$, the punctured sphere $S^{n}-p$ is homeomorphic

Define $f:\left(S^{n}-p\right) \rightarrow \mathbb{R}^{n}$ by the equation

$$
f(x)=f\left(x_{1}, \ldots, x_{n+1}\right)=\frac{1}{1-x_{n+1}}\left(x_{1}, \ldots, x_{n}\right) .
$$

The map $f$ is called stereographic projection. (If one takes the straight line in $\mathbb{R}^{n+1}$ passing through the north pole $p$ and the point $x$ of $S^{n}-p$, then this line intersects the $n$-plane $\mathbb{R}^{n} \times 0 \subset \mathbb{R}^{n+1}$ in the point $f(x) \times 0$.) One checks that $f$ is a homeomorphism by showing that the map $g: \mathbb{R}^{n} \rightarrow\left(S^{n}-p\right)$ given by

$$
g(y)=g\left(y_{1}, \ldots, y_{n}\right)=\left(t(y) \cdot y_{1}, \ldots, t(y) \cdot y_{n}, 1-t(y)\right),
$$

where $t(y)=2 /\left(1+\|y\|^{2}\right)$, is a right and left inverse for $f$.

Note that the reflection map $\left(x_{1}, \ldots, x_{n+1}\right) \rightarrow\left(x_{1}, \ldots, x_{n},-x_{n+1}\right)$ defines a homeomorphism of $S^{n}-p$ with $S^{n}-q$, so the latter is also homeomorphic to $\mathbb{R}^{n}$.

Step 2. We prove the theorem. Let $U$ and $V$ be the open sets $U=S^{n}-p$ and $V=S^{n}-q$ of $S^{n}$.

Note first that for $n \geq 1$, the sphere $S^{n}$ is path connected. This follows from the fact that $U$ and $V$ are path connected (being homeomorphic to $\mathbb{R}^{n}$ ) and have the point $(1,0, \ldots, 0)$ of $S^{n}$ in common.

Now we show that for $n \geq 2$, the sphere $S^{n}$ is simply connected. The spaces $U$ and $V$ are simply connected, being homeomorphic to $\mathbb{R}^{n}$. Their intersection equals $S^{n}-p-q$, which is homeomorphic under stereographic projection to $\mathbb{R}^{n}-\mathbf{0}$. The latter space is path connected, for every point of $\mathbb{R}^{n}-\mathbf{0}$ can be joined to a point of $S^{n-1}$ by a straight-line path, and $S^{n-1}$ is path connected if $n \geq 2$. Then the preceding corollary applies.

## Exercises

1. Let $X$ be the union of two copies of $S^{2}$ having a point in common. What is the fundamental group of $X$ ? Prove that your answer is correct. [Be careful! The union of two simply connected spaces having a point in common is not necessarily simply connected. See [S], p. 59.]
2. Criticize the following "proof" that $S^{2}$ is simply connected: Let $f$ be a loop in $S^{2}$ based at $x_{0}$. Choose a point $p$ of $S^{2}$ not lying in the image of $f$. Since $S^{2}-p$ is homeomorphic with $\mathbb{R}^{2}$, and $\mathbb{R}^{2}$ is simply connected, the loop $f$ is path homotopic to the constant loop.
3. (a) Show that $\mathbb{R}^{1}$ and $\mathbb{R}^{n}$ are not homeomorphic if $n>1$.

(b) Show that $\mathbb{R}^{2}$ and $\mathbb{R}^{n}$ are not homeomorphic if $n>2$.

It is, in fact, true that $\mathbb{R}^{m}$ and $\mathbb{R}^{n}$ are not homeomorphic if $n \neq m$, but the proof requires more advanced tools of algebraic topology.

4. Assume the hypotheses of Theorem 59.1.

(a) What can you say about the fundamental group of $X$ if $j_{*}$ is the trivial homomorphism? If both $i_{*}$ and $j_{*}$ are trivial?

(b) Give an example where $i_{*}$ and $j_{*}$ are trivial but neither $U$ nor $V$ have trivial fundamental groups.

## $\$ 60$ Fundamental Groups of Some Surfaces

Recall that a surface is a Hausdorff space with a countable basis, each point of which has a neighborhood that is homeomorphic with an open subset of $\mathbb{R}^{2}$. Surfaces are of interest in various parts of mathematics, including geometry, topology, and complex analysis. We consider here several surfaces, including the torus and double torus, and show by comparing their fundamental groups that they are not homeomorphic. In a later chapter, we shall classify up to homeomorphism all compact surfaces.

First, we consider the torus. In an earlier exercise, we asked you to compute its fundamental group using the theory of covering spaces. Here, we compute its fundamental group by using a theorem about the fundamental group of a product space.

Recall that if $A$ and $B$ are groups with operation -, then the cartesian product $A \times B$ is given a group structure by using the operation

$$
(a \times b) \cdot\left(a^{\prime} \times b^{\prime}\right)=\left(a \cdot a^{\prime}\right) \times\left(b \cdot b^{\prime}\right) .
$$

Recall also that if $h: C \rightarrow A$ and $k: C \rightarrow B$ are group homomorphisms, then the map $\Phi: C \rightarrow A \times B$ defined by $\Phi(c)=h(c) \times k(c)$ is a group homomorphism.

Theorem 60.1. $\pi_{1}\left(X \times Y, x_{0} \times y_{0}\right)$ is isomorphic with $\pi_{1}\left(X, x_{0}\right) \times \pi_{1}\left(Y, y_{0}\right)$.

Proof. Let $p: X \times Y \rightarrow X$ and $q: X \times Y \rightarrow Y$ be the projection mappings. If we use the base points indicated in the statement of the theorem, we have induced homomorphisms

$$
\begin{gathered}
p_{*}: \pi_{1}\left(X \times Y, x_{0} \times y_{0}\right) \longrightarrow \pi_{1}\left(X, x_{0}\right), \\
q_{*}: \pi_{1}\left(X \times Y, x_{0} \times y_{0}\right) \longrightarrow \pi_{1}\left(Y, y_{0}\right) .
\end{gathered}
$$

We define a homomorphism

$$
\Phi: \pi_{1}\left(X \times Y, x_{0} \times y_{0}\right) \longrightarrow \pi_{1}\left(X, x_{0}\right) \times \pi_{1}\left(Y, y_{0}\right)
$$

by the equation

$$
\Phi([f])=p_{*}([f]) \times q_{*}([f])=[p \circ f] \times[q \circ f] .
$$

We shall show that $\Phi$ is an isomorphism.

The map $\Phi$ is surjective. Let $g: I \rightarrow X$ be a loop based at $x_{0}$; let $h: I \rightarrow Y$ be a loop based at $y_{0}$. We wish to show that the element $[g] \times[h]$ lies in the image of $\Phi$. Define $f: I \rightarrow X \times Y$ by the equation

$$
f(s)=g(s) \times h(s) .
$$

Then $f$ is a loop in $X \times Y$ based at $x_{0} \times y_{0}$, and

$$
\Phi([f])=[p \circ f] \times[q \circ f]=[g] \times[h],
$$

as desired.

The kernel of $\Phi$ vanishes. Suppose that $f: I \rightarrow X \times Y$ is a loop in $X \times Y$ based at $x_{0} \times y_{0}$ and $\Phi([f])=[p \circ f] \times[q \circ f]$ is the identity element. This means that $p \circ f \simeq_{p} e_{x_{0}}$ and $q \circ f \simeq_{p} e_{y_{0}}$; let $G$ and $H$ be the respective path homotopies. Then the map $F: I \times I \rightarrow X \times Y$ defined by

$$
F(s, t)=G(s, t) \times H(s, t)
$$

is a path homotopy between $f$ and the constant loop based at $x_{0} \times y_{0}$.

Corollary 60.2. The fundamental group of the torus $T=S^{1} \times S^{1}$ is isomorphic to the group $\mathbb{Z} \times \mathbb{Z}$.

Now we define a surface called the projective plane and compute its fundamental group.

Definition. The projective plane $P^{2}$ is the quotient space obtained from $S^{2}$ by identifying each point $x$ of $S^{2}$ with its antipodal point $-x$.

The projective plane may not be a space that is familiar to you; it cannot be imbedded in $\mathbb{R}^{3}$ and is thus difficult to visualize. It is, however, the fundamental object of study in projective geometry, just as the euclidean plane $\mathbb{R}^{2}$ is in ordinary euclidean geometry. Topologists are primarily interested in it as an example of a surface.

Theorem 60.3. The projective plane $P^{2}$ is a compact surface, and the quotient map $p: S^{2} \rightarrow P^{2}$ is a covering map.

Proof. First we show that $p$ is an open map. Let $U$ be open in $S^{2}$. Now the antipodal map $a: S^{2} \rightarrow S^{2}$ given by $a(x)=-x$ is a homeomorphism of $S^{2}$; hence $a(U)$ is open in $S^{2}$. Since

$$
p^{-1}(p(U))=U \cup a(U),
$$

this set also is open in $S^{2}$. Therefore, by definition, $p(U)$ is open in $P^{2}$. A similar proof shows that $p$ is a closed map.

Now we show that $p$ is a covering map. Given a point $y$ of $P^{2}$, choose $x \in p^{-1}(y)$. Then choose an $\epsilon$-neighborhood $U$ of $x$ in $S^{2}$ for some $\epsilon<1$, using the euclidean metric $d$ of $\mathbb{R}^{3}$. Then $U$ contains no pair $\{z, a(z)\}$ of antipodal points of $S^{2}$, since $d(z, a(z))=2$. As a result, the map

$$
p: U \longrightarrow p(U)
$$

is bijective. Being continuous and open, it is a homeomorphism. Similarly,

$$
p: a(U) \rightarrow p(a(U))=p(U)
$$

is a homeomorphism. The set $p^{-1}(p(U))$ is thus the union of the two disjoint open sets $U$ and $a(U)$, each of which is mapped homeomorphically by $p$ onto $p(U)$. Then $p(U)$ is a neighborhood of $p(x)=y$ that is evenly covered by $p$.

Since $S^{2}$ has a countable basis $\left\{U_{n}\right\}$, the space $P^{2}$ has a countable basis $\left\{p\left(U_{n}\right)\right\}$.

The fact that $P^{2}$ is Hausdorff follows from the fact that $S^{2}$ is normal and $p$ is a closed map. (See Exercise 6 of §31.) Alternatively, one can give a direct proof: Let $y_{1}$ and $y_{2}$ be two points of $P^{2}$. The set $p^{-1}\left(y_{1}\right) \cup p^{-1}\left(y_{2}\right)$ consists of four points; let $2 \epsilon$ be the minimum distance between them. Let $U_{1}$ be the $\epsilon$-neighborhood of one of the points of $p^{-1}\left(y_{1}\right)$, and let $U_{2}$ be the $\epsilon$-neighborhood of one of the points of $p^{-1}\left(y_{2}\right)$. Then

$$
U_{1} \cup a\left(U_{1}\right) \quad \text { and } \quad U_{2} \cup a\left(U_{2}\right)
$$

are disjoint. It follows that $p\left(U_{1}\right)$ and $p\left(U_{2}\right)$ are disjoint neighborhoods of $y_{1}$ and $y_{2}$, respectively, in $P^{2}$.

Since $S^{2}$ is a surface and every point of $P^{2}$ has a neighborhood homeomorphic with an open subset of $S^{2}$, the space $P^{2}$ is also a surface.

Corollary 60.4. $\pi_{1}\left(P^{2}, y\right)$ is a group of order 2 .

Proof. The projection $p: S^{2} \rightarrow P^{2}$ is a covering map. Since $S^{2}$ is simply connected, we can apply Theorem 54.4, which tells us there is a bijective correspondence between $\pi_{1}\left(P^{2}, y\right)$ and the set $p^{-1}(y)$. Since this set is a two-element set, $\pi_{1}\left(P^{2}, y\right)$ is a group of order 2 .

Any group of order 2 is isomorphic to $\mathbb{Z} / 2$, the integers $\bmod 2$, of course.

One can proceed similarly to define $P^{n}$, for any $n \in \mathbb{Z}_{+}$, as the space obtained from $S^{n}$ by identifying each point $x$ with its antipode $-x$; it is called projective $n$ space. The proof of Theorem 60.3 goes through without change to prove that the projection $p: S^{n} \rightarrow P^{n}$ is a covering map. Then because $S^{n}$ is simply connected for $n \geq 2$, it follows that $\pi_{1}\left(P^{n}, y\right)$ is a two-element group for $n \geq 2$. We leave it to you to figure out what happens when $n=1$.

Now we study the double torus. We begin with a lemma about the figure eight.

Lemma 60.5. The fundamental group of the figure eight is not abelian.

Proof. Let $X$ be the union of two circles $A$ and $B$ in $\mathbb{R}^{2}$ whose intersection consists of the single point $x_{0}$. We describe a certain covering space $E$ of $X$.

The space $E$ is the subspace of the plane consisting of the $x$-axis and the $y$-axis, along with tiny circles tangent to these axes, one circle tangent to the $x$-axis at each nonzero integer point and one circle tangent to the $y$-axis at each nonzero integer point.

The projection map $p: E \rightarrow X$ wraps the $x$-axis around the circle $A$ and wraps the $y$-axis around the other circle $B$; in each case the integer points are mapped by $p$ into the base point $x_{0}$. Each circle tangent to an integer point on the $x$-axis is mapped homeomorphically by $p$ onto $B$, while each circle tangent to an integer point on the $y$-axis is mapped homeomorphically onto $A$; in each case the point of tangency is mapped onto the point $x_{0}$. We leave it to you to check mentally that the map $p$ is indeed a covering map.

We could write this description down in equations if we wished, but the informal description seems to us easier to follow.

Now let $\tilde{f}: I \rightarrow E$ be the path $\tilde{f}(s)=s \times 0$, going along the $x$-axis from the origin to the point $1 \times 0$. Let $\tilde{g}: I \rightarrow E$ be the path $\tilde{g}(s)=0 \times s$, going along the $y$-axis from the origin to the point $0 \times 1$. Let $f=p \circ \tilde{f}$ and $g=p \circ \tilde{g}$; then $f$ and $g$ are loops in the figure eight based at $x_{0}$, going around the circles $A$ and $B$, respectively. See Figure 60.1.

We assert that $f * g$ and $g * f$ are not path homotopic, so that the fundamental group of the figure eight is not abelian.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-373.jpg?height=883&width=1110&top_left_y=369&top_left_x=641)

Figure 60.1

To prove this assertion, let us lift each of these to a path in $E$ beginning at the origin. The path $f * g$ lifts to a path that goes along the $x$-axis from the origin to $1 \times 0$ and then goes once around the circle tangent to the $x$-axis at $1 \times 0$. On the other hand, the path $g * f$ lifts to a path in $E$ that goes along the $y$-axis from the origin to $0 \times 1$, and then goes once around the circle tangent to the $y$-axis at $0 \times 1$. Since the lifted paths do not end at the same point, $f * g$ and $g * f$ cannot be path homotopic.

We shall prove later that the fundamental group of the figure eight is, in fact, the group that algebraists call the "free group on two generators."

Theorem 60.6. The fundamental group of the double torus is not abelian.

Proof. The double torus $T \# T$ is the surface obtained by taking two copies of the torus, deleting a small open disc from each of them, and pasting the remaining pieces together along their edges. We assert that the figure eight $X$ is a retract of $T \# T$. This fact implies that inclusion $j: X \rightarrow T \# T$ induces a monomorphism $j_{*}$, so that $\pi_{1}\left(T \# T, x_{0}\right)$ is not abelian.

One can write equations for the retraction $r: T \# T \rightarrow X$, but it is simpler to indicate it in pictures, as we have done in Figure 60.2. Let $Y$ be the union of two tori having a point in common. First one maps $T \# T$ onto $Y$ by a map that collapses the dotted circle to a point but is otherwise one-to-one; it defines a homeomorphism $h$ of

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-374.jpg?height=202&width=1119&top_left_y=371&top_left_x=459)

Figure 60.2

the figure eight in $T \# T$ with the figure eight in $Y$. Then one retracts $Y$ onto its figure eight by mapping each cross-sectional circle to the point where it intersects the figure eight. Then one maps the figure eight in $Y$ back onto the figure eight in $T \# T$ by the map $h^{-1}$.

Corollary 60.7. The 2-sphere, torus, projective plane, and double torus are topologically distinct.

## Exercises

1. Compute the fundamental groups of the "solid torus" $S^{1} \times B^{2}$ and the product space $S^{1} \times S^{2}$.
2. Let $X$ be the quotient space obtained from $B^{2}$ by identifying each point $x$ of $S^{1}$ with its antipode $-x$. Show that $X$ is homeomorphic to the projective plane $P^{2}$.
3. Let $p: E \rightarrow X$ be the map constructed in the proof of Lemma 60.5. Let $E^{\prime}$ be the subspace of $E$ that is the union of the $x$-axis and the $y$-axis. Show that $p \mid E^{\prime}$ is not a covering map.
4. The space $P^{1}$ and the covering map $p: S^{1} \rightarrow P^{1}$ are familiar ones. What are they?
5. Consider the covering map indicated in Figure 60.3. Here, $p$ wraps $A_{1}$ around $A$ twice and wraps $B_{1}$ around $B$ twice; $p$ maps $A_{0}$ and $B_{0}$ homeomorphically onto $A$ and $B$, respectively. Use this covering space to show that the fundamental group of the figure eight is not abelian.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-374.jpg?height=355&width=619&top_left_y=1818&top_left_x=712)

Figure 60.3

## Chapter 10

## Separation Theorems in the Plane

There are several difficult questions concerning the topology of the plane that arise quite naturally in the study of analysis. The answers to these questions seem geometrically quite obvious but turn out to be surprisingly hard to prove. They include the Jordan curve theorem, the Brouwer theorem on invariance of domain, and the classical theorem that the winding number of a simple closed curve is zero or $\pm 1$. We prove them in this chapter as consequences of our study of covering spaces and the fundamental group.

## §61 The Jordan Separation Theorem

We consider first one of the classical theorems of mathematics, the Jordan curve theorem. It states a fact that is geometrically quite believable, the fact that a simple closed curve in the plane always separates the plane into two pieces, its "inside" and its "outside." It was originally conjectured in 1892 by Camille Jordan, and several incorrect proofs were published, including one by Jordan himself. Eventually, a correct proof was provided by Oswald Veblen, in 1905. The early proofs were complicated, but over the years, simpler proofs have been found. If one uses the tools of modern algebraic topology, singular homology theory in particular, the proof is quite straightforward. The proof we give here is the simplest one we know that uses only results from the theory of covering spaces and the fundamental group.

Our proof of the Jordan curve theorem divides into three parts. The first, which we call the Jordan separation theorem, states that a simple closed curve in the plane separates it into at least two components. The second says that an arc in the plane does not separate the plane. And the third, the Jordan curve theorem proper, says that a simple closed curve $C$ in the plane separates it into precisely two components, of which $C$ is the common boundary. The first of these theorems will be treated in this section.

In dealing with separation theorems, it will often be convenient to formulate them as separation theorems for subsets of $S^{2}$ rather than $\mathbb{R}^{2}$. The separation theorems for $\mathbb{R}^{2}$ will follow. The connection between the two sets of theorems is provided by the following lemma.

Recall that if $b$ is any point of $S^{2}$, there is a homeomorphism $h$ of $S^{2}-b$ with $\mathbb{R}^{2}$; one simply takes a rotation of $S^{2}$ that carries $b$ to the north pole, and follows it by stereographic projection.

Lemma 61.1. Let $C$ be a compact subspace of $S^{2}$; let $b$ be a point of $S^{2}-C$; and let $h$ be a homeomorphism of $S^{2}-b$ with $\mathbb{R}^{2}$. Suppose $U$ is a component of $S^{2}-C$. If $U$ does not contain $b$, then $h(U)$ is a bounded component of $\mathbb{R}^{2}-h(C)$. If $U$ contains $b$, then $h(U-b)$ is the unbounded component of $\mathbb{R}^{2}-h(C)$.

In particular, if $S^{2}-C$ has $n$ components, then $\mathbb{R}^{2}-h(C)$ has $n$ components.

Proof. We show first that if $U$ is a component of $S^{2}-C$, then $U-b$ is connected. This result is trivial if $b \notin U$, so suppose that $b \in U$ and suppose the sets $A$ and $B$ form a separation of $U-b$. Choose a neighborhood $W$ of $b$ disjoint from $C$ such that $W$ is homeomorphic to an open ball of $\mathbb{R}^{2}$. Since $W$ is connected, it is contained in $U$; since $W-b$ is connected, it is contained entirely in $A$ or in $B$. Say $W-b \subset A$. Then $b$ is not a limit point of $B$, for $W$ is a neighborhood of $b$ disjoint from $B$. It follows that the sets $A \cup\{b\}$ and $B$ form a separation of $U$, contrary to hypothesis.

Let $\left\{U_{\alpha}\right\}$ be the set of components of $S^{2}-C$; let $V_{\alpha}=h\left(U_{\alpha}-b\right)$. Because $S^{2}-C$ is locally connected, the sets $U_{\alpha}$ are connected, disjoint, open subsets of $S^{2}$. Therefore, the sets $V_{\alpha}$ are connected, disjoint, open subsets of $\mathbb{R}^{2}-h(C)$, so the sets $V_{\alpha}$ are the components of $\mathbb{R}^{2}-h(C)$.

Now the homeomorphism $h$ of $S^{2}-b$ with $\mathbb{R}^{2}$ can be extended to a homeomorphism $H$ of $S^{2}$ with the one-point compactification $\mathbb{R}^{2} \cup\{\infty\}$ of $\mathbb{R}^{2}$, merely by setting $H(b)=\infty$. If $U_{\beta}$ is the component of $S^{2}-C$ containing $b$, then $H\left(U_{\beta}\right)$ is a neighborhood of $\infty$ in $\mathbb{R}^{2} \cup\{\infty\}$. Therefore $V_{\beta}$ is unbounded; since its complement $\mathbb{R}^{2}-V_{\beta}$ is compact, all the other components of $\mathbb{R}^{2}-h(C)$ are bounded. See Figure 61.1.

Lemma 61.2 (Nulhomotopy lemma). Let $a$ and $b$ be points of $S^{2}$. Let $A$ be a compact space, and let

$$
f: A \longrightarrow S^{2}-a-b
$$

be a continuous map. If $a$ and $b$ lie in the same component of $S^{2}-f(A)$, then $f$ is nulhomotopic.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-377.jpg?height=612&width=1064&top_left_y=372&top_left_x=665)

Figure 61.1

Proof. One can replace $S^{2}$ by the one-point compactification $\mathbb{R}^{2} \cup\{\infty\}$ of $\mathbb{R}^{2}$, letting $a$ and $b$ correspond to the points $\mathbf{0}$ and $\infty$. Then our lemma reduces to the following: Let $A$ be a compact space and let $g: A \rightarrow \mathbb{R}^{2}-\mathbf{0}$ be a continuous map. If $\mathbf{0}$ lies in the unbounded component of $\mathbb{R}^{2}-g(A)$, then $g$ is nulhomotopic.

This statement is easy to prove. Choose a ball $B$ centered at the origin, of sufficiently large radius that it contains the set $g(A)$. Choose a point $p$ of $\mathbb{R}^{2}$ lying outside $B$. Then $\mathbf{0}$ and $p$ both lie in the unbounded component of $\mathbb{R}^{2}-g(A)$.

Because $\mathbb{R}^{2}$ is locally path connected, so is the open set $\mathbb{R}^{2}-g(A)$. Therefore, the components and path components of $\mathbb{R}^{2}-g(A)$ are the same. Hence we can choose a path $\alpha$ in $\mathbb{R}^{2}-g(A)$ from $\mathbf{0}$ to $p$. We define a homotopy $G: A \times I \rightarrow \mathbb{R}^{2}-\mathbf{0}$ by the equation

$$
G(x, t)=g(x)-\alpha(t)
$$

it is pictured in Figure 61.2. The homotopy $G$ is a homotopy between the map $g$ and the map $k$ defined by $k(x)=g(x)-p$. Note that $G(x, t) \neq \mathbf{0}$ because the path $\alpha$ does not intersect the set $g(A)$.

Now we define a homotopy $H: A \times I \rightarrow \mathbb{R}^{2}-\mathbf{0}$ by the equation

$$
H(x, t)=\operatorname{tg}(x)-p .
$$

It is a homotopy between the map $k$ and a constant map. Note that $H(x, t) \neq \mathbf{0}$ because $\operatorname{tg}(x)$ lies inside the ball $B$ and $p$ does not.

Thus we have proved that $g$ is nulhomotopic.

Now we prove the Jordan separation theorem. In general, if $X$ is a connected space and $A \subset X$, we say that $A$ separates $X$ if $X-A$ is not connected; if $X-A$ has $n$ components, we say that $A$ separates $X$ into $n$ components.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-378.jpg?height=641&width=1074&top_left_y=362&top_left_x=484)

Figure 61.2

An $\operatorname{arc} A$ is a space homeomorphic to the unit interval [0,1]. The end points of $A$ are the two points $p$ and $q$ of $A$ such that $A-p$ and $A-q$ are connected; the other points of $A$ are called interior points of $A$.

A simple closed curve is a space homeomorphic to the unit circle $S^{1}$.

Theorem 61.3 (The Jordan separation theorem). Let $C$ be a simple closed curve in $S^{2}$. Then $C$ separates $S^{2}$.

Proof. Because $S^{2}-C$ is locally path connected, its components and path components are the same. We assume that $S^{2}-C$ is path connected and derive a contradiction.

Let us write $C$ as the union of two arcs $A_{1}$ and $A_{2}$ that intersect only in their end points $a$ and $b$. Let $X$ denote the space $S^{2}-a-b$. Let $U$ be the open set $S^{2}-A_{1}$ of $X$, and let $V$ be the open set $S^{2}-A_{2}$. Then $X$ is the union of the sets $U$ and $V$, and

$$
U \cap V=S^{2}-\left(A_{1} \cup A_{2}\right)=S^{2}-C,
$$

which by hypothesis is path connected. Thus the hypotheses of Theorem 59.1 are satisfied.

Let $x_{0}$ be a point of $U \cap V$. We will show that the inclusions

$$
i:\left(U, x_{0}\right) \longrightarrow\left(X, x_{0}\right) \quad \text { and } \quad j:\left(V, x_{0}\right) \longrightarrow\left(X, x_{0}\right)
$$

induce trivial homomorphisms of the fundamental groups involved. It then follows from Theorem 59.1 that the group $\pi_{1}\left(X, x_{0}\right)$ is trivial. But $X=S^{2}-a-b$, which is homeomorphic to the punctured plane $\mathbb{R}^{2}-\mathbf{0}$, so its fundamental group is not trivial.

Let us prove that $i_{*}$ is the trivial homomorphism; given a loop $f: I \rightarrow U$ based at $x_{0}$, we show that $i_{*}([f])$ is trivial. For this purpose, let $p: I \rightarrow S^{1}$ be the standard
loop generating $\pi_{1}\left(S^{1}, b_{0}\right)$. The map $f: I \rightarrow U$ induces a continuous map $h: S^{1} \rightarrow$ $U$ such that $h \circ p=f$. See Figure 61.3.

Consider the map $i \circ h: S^{1} \rightarrow S^{2}-a-b$. By hypothesis, the set $i\left(h\left(S^{1}\right)\right)=h\left(S^{1}\right)$ does not intersect the connected set $A_{1}$ containing $a$ and $b$. Therefore, $a$ and $b$ lie in the same component of $S^{2}-i\left(h\left(S^{1}\right)\right)$. By the preceding lemma, the map $i \circ h$ is nulhomotopic. It follows from Lemma 55.3 that $(i \circ h)_{*}$ is the trivial homomorphism of fundamental groups. But

$$
(i \circ h)_{*}([p])=[i \circ h \circ p]=[i \circ f]=i_{*}([f]) .
$$

Therefore, $i_{*}([f])$ is trivial, as desired.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-379.jpg?height=472&width=1097&top_left_y=869&top_left_x=645)

Figure 61.3

Let us examine the preceding proof. What facts did we use about the simple closed curve $C$ ? All we actually needed was the fact that $C$ could be written as the union of the two closed connected sets $A_{1}$ and $A_{2}$, whose intersection consisted of the two points $a$ and $b$. This remark leads to the following generalized version of the separation theorem, which will be useful later.

Theorem 61.4 (A general separation theorem). Let $A_{1}$ and $A_{2}$ be closed connected subsets of $S^{2}$ whose intersection consists of precisely two points $a$ and $b$. Then the set $C=A_{1} \cup A_{2}$ separates $S^{2}$.

Proof. We must show first that $C$ cannot equal all of $S^{2}$. That fact was obvious in the earlier proof. In the present case, we can see that $C \neq S^{2}$ because $S^{2}-a-b$ is connected and $C-a-b$ is not. (The sets $A_{i}-a-b$ form a separation of $C-a-b$.)

The remainder of the proof is a copy of the proof of the preceding theorem.

## Exercises

1. Give examples to show that a simple closed curve in the torus may or may not separate the torus.
2. Let $A$ be the subset of $\mathbb{R}^{2}$ consisting of the union of the topologist's sine curve and the broken-line path from $(0,-1)$ to $(0,-2)$ to $(1,-2)$ to $(1, \sin 1)$. See Figure 61.4. We call $A$ the closed topologist's sine curve. Show that if $C$ is a subspace of $S^{2}$ homeomorphic to the closed topologist's sine curve, then $C$ separates $S^{2}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-380.jpg?height=491&width=605&top_left_y=626&top_left_x=711)

Figure 61.4

## *\$62 Invariance of Domain ${ }^{\dagger}$

One of the theorems of topology that is truly fundamental, because it expresses an intrinsic property of euclidean space, is the theorem on "invariance of domain," proved by L. E. J. Brouwer in 1912. It states that for any open set $U$ of $\mathbb{R}^{n}$ and any continuous injective mapping $f: U \rightarrow \mathbb{R}^{n}$, the image set $f(U)$ is open in $\mathbb{R}^{n}$ and the inverse function is continuous. (The Inverse Function Theorem of analysis derives this result under the additional hypothesis that the map $f$ is continuously differentiable with nonsingular Jacobian matrix.) We shall prove this theorem in the case $n=2$.

Lemma 62.1 (Homotopy extension lemma). Let $X$ be a space such that $X \times I$ is normal. Let $A$ be a closed subspace of $X$, and let $f: A \rightarrow Y$ be a continuous map, where $Y$ is an open subspace of $\mathbb{R}^{n}$. If $f$ is nulhomotopic, then $f$ may be extended to a continuous map $g: X \rightarrow Y$ that is also nulhomotopic.

Proof. Let $F: A \times I \rightarrow Y$ be a homotopy between $f$ and a constant map. Then $F(a, 0)=f(a)$ and $F(a, 1)=y_{0}$ for all $a$. Extend $F$ to the space $X \times 1$ by setting $F(x, 1)=y_{0}$ for $x \in X$. Then $F$ is a continuous map of the closed subspace $(A \times$ I) $\cup(X \times 1)$ of $X \times I$ into $\mathbb{R}^{n}$; by the Tietze extension theorem, it may be extended to a continuous map $G: X \times I \rightarrow \mathbb{R}^{n}$.[^10]

Now the map $x \rightarrow G(x, 0)$ is an extension of $f$, but it maps $X$ into $\mathbb{R}^{n}$ rather than into the subspace $Y$. To obtain our desired map, we proceed as follows: Let $U$ be the open subset $U=G^{-1}(Y)$ of $X \times I$. Then $U$ contains $(A \times I) \cup(X \times 1)$. See Figure 62.1. Since $I$ is compact, the tube lemma implies that there is an open set $W$ of $X$ containing $A$ such that $W \times I \subset U$. Now the space $X$ is itself normal, being homeomorphic to the closed subspace $X \times 0$ of $X \times I$. Therefore, we may choose a continuous function $\phi: X \rightarrow[0,1]$ such that $\phi(x)=0$ for $x \in A$ and $\phi(x)=1$ for $x \in X-W$. The map $x \rightarrow x \times \phi(x)$ carries $X$ into the subspace $(W \times I) \cup(X \times 1)$ of $X \times I$, which lies in $U$. Then the continuous map $g(x)=G(x, \phi(x))$ carries $X$ into $Y$. And for $x \in A$, we have $\phi(x)=0$, so that $g(x)=G(x, 0)=f(x)$. Thus $g$ is the desired extension of $f$. The map $H: X \times I \rightarrow Y$ given by

$$
H(x, t)=G(x,(1-t) \phi(x)+t)
$$

is a homotopy between $g$ and a constant map.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-381.jpg?height=386&width=1136&top_left_y=1106&top_left_x=620)

Figure 62.1

The following lemma is a partial converse to the nulhomotopy lemma of the preceding section.

Lemma 62.2 (Borsuk lemma). Let $a$ and $b$ be points of $S^{2}$. Let $A$ be a compact space, and let $f: A \rightarrow S^{2}-a-b$ be a continuous injective map. If $f$ is nulhomotopic, then $a$ and $b$ lie in the same component of $S^{2}-f(A)$.

Proof. Because $A$ is compact and $S^{2}$ is Hausdorff, $f(A)$ is a compact subspace of $S^{2}$ that is homeomorphic to $A$. Because $f$ is nulhomotopic, so is the inclusion mapping of $f(A)$ into $S^{2}-a-b$. Hence it suffices to prove the lemma in the special case where $f$ is simply an inclusion map. Furthermore, we can replace $S^{2}$ by $\mathbb{R}^{2} \cup\{\infty\}$, letting $a$ correspond to $\mathbf{0}$, and $b$ to $\infty$. Then our lemma reduces to the following statement:

Let $A$ be a compact subspace of $\mathbb{R}^{2}-\mathbf{0}$. If the inclusion $j: A \rightarrow \mathbb{R}^{2}-\mathbf{0}$ is nulhomotopic, then $\mathbf{0}$ lies in the unbounded component of $\mathbb{R}^{2}-A$.

This we now prove. Let $C$ be the component of $\mathbb{R}^{2}-A$ containing $\mathbf{0}$; we suppose $C$ is bounded and derive a contradiction. Let $D$ be the union of the other components
of $\mathbb{R}^{2}-A$, including the unbounded component. Then $C$ and $D$ are disjoint open sets of $\mathbb{R}^{2}$, and $\mathbb{R}^{2}-A=C \cup D$. See Figure 62.2.

We define a continuous map $h: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}-\mathbf{0}$ that equals the identity outside $C$.

Begin with the inclusion map $j: A \rightarrow \mathbb{R}^{2}-\mathbf{0}$. Since $j$ is by hypothesis nulhomotopic, the preceding lemma implies that $j$ can be extended to a continuous map $k$ of $C \cup A$ into $\mathbb{R}^{2}-\mathbf{0}$. Then $k$ equals the identity at points of $A$. Extend $k$ to a map $h: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}-\mathbf{0}$ by setting $h(x)=x$ for $x \in D \cup A$; then $h$ is continuous by the pasting lemma.

Now we derive a contradiction. Let $B$ be the closed ball in $\mathbb{R}^{2}$ of radius $M$ centered at the origin, where $M$ is so large that $\operatorname{Int} B$ contains $C \cup A$. (Here, we use the fact that $C$ is bounded.) If we restrict $h$ to $B$, we obtain a map $g: B \rightarrow \mathbb{R}^{2}-\mathbf{0}$ such that $g(x)=x$ for $x \in \operatorname{Bd} B$. If we follow $g$ by the standard retraction $x \rightarrow M x /\|x\|$ of $\mathbb{R}^{2}-\mathbf{0}$ onto $\mathrm{Bd} B$, we obtain a retraction of $B$ onto $\mathrm{Bd} B$. Such a retraction does not exist.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-382.jpg?height=513&width=625&top_left_y=1048&top_left_x=709)

Figure 62.2

Theorem 62.3 (Invariance of domain). If $U$ is an open subset of $\mathbb{R}^{2}$ and $f: U \rightarrow$ $\mathbb{R}^{2}$ is continuous and injective, then $f(U)$ is open in $\mathbb{R}^{2}$ and the inverse function $f^{-1}: f(U) \rightarrow U$ is continuous.

Proof. As usual, we can replace $\mathbb{R}^{2}$ by $S^{2}$. We show that if $U$ is an open subset of $\mathbb{R}^{2}$ and $f: U \rightarrow S^{2}$ is continuous and injective, then $f(U)$ is open in $S^{2}$ and the inverse function is continuous.

Step 1. We show that if $B$ is any closed ball in $\mathbb{R}^{2}$ contained in $U$, then $f(B)$ does not separate $S^{2}$.

Let $a$ and $b$ be two points of $S^{2}-f(B)$. Because the identity map $i: B \rightarrow B$ is nulhomotopic, the map $h: B \rightarrow S^{2}-a-b$ obtained by restricting $f$ is nulhomotopic. The Borsuk lemma then implies that $a$ and $b$ lie in the same component of $S^{2}-h(B)=$ $S^{2}-f(B)$.

Step 2. We show that if $B$ is any closed ball of $\mathbb{R}^{2}$ lying in $U$, then $f(\operatorname{Int} B)$ is open in $S^{2}$.

The space $C=f(\operatorname{Bd} B)$ is a simple closed curve in $S^{2}$, so it separates $S^{2}$. Let $V$ be the component of $S^{2}-C$ that contains the connected set $f(\operatorname{Int} B)$, and let $W$ be the union of the others. Because $S^{2}$ is locally connected, $V$ and $W$ are open in $S^{2}$. We show $V=f(\operatorname{Int} B)$, and we are through.

We suppose $a$ is a point of $V$ that is not in $f(\operatorname{Int} B)$ and derive a contradiction. Let $b$ be a point of $W$. Since the set $D=f(B)$ does not separate $S^{2}$, the set $S^{2}-D$ is a connected set containing $a$ and $b$. This set is contained in $S^{2}-C$ (since $D \supset C$ ); it follows that $a$ and $b$ lie in the same component of $S^{2}-C$, contrary to construction. See Figure 62.3.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-383.jpg?height=448&width=902&top_left_y=880&top_left_x=745)

Figure 62.3

Step 3. We prove the theorem. Since, for any ball $B$ contained in $U$, the set $f(\operatorname{Int} B)$ is open in $S^{2}$, the map $f: U \rightarrow S^{2}$ is an open map. It follows that $f(U)$ is open in $S^{2}$ and $f^{-1}$ is continuous.

## Exercises

1. Give an example to show that the conclusion of the Borsuk lemma need not hold if $f$ is not injective.
2. Let $A$ be a compact contractible subspace of $S^{2}$. Show that $A$ does not separate $S^{2}$.
3. Let $X$ be a space such that $X \times I$ is normal. Let $A$ be a closed subspace of $X$; let $f: A \rightarrow Y$ be a continuous map, where $Y$ is an open subspace of $\mathbb{R}^{n}$. If $f$ is homotopic to a map that is extendable to a continuous map $h: X \rightarrow Y$, then $f$ itself is extendable to a continuous map $g: X \rightarrow Y$, such that $g \simeq h$.
4. Let $C$ be a simple closed curve in $\mathbb{R}^{2}-\mathbf{0}$; let $j: C \rightarrow \mathbb{R}^{2}-\mathbf{0}$ be the inclusion mapping. Show that $j_{*}$ is trivial if $\mathbf{0}$ lies in the unbounded component of $\mathbb{R}^{2}-C$, and is nontrivial otherwise. (In fact, $j_{*}$ is an isomorphism in the latter case, as we shall prove in $\S 65$.)
5. Theorem. Let $U$ be a simply connected open set in $\mathbb{R}^{2}$. If $C$ is a simple closed curve lying in $U$, then each bounded component of $\mathbb{R}^{2}-C$ also lies in $U$.

(This condition actually characterizes the simply connected open sets of $\mathbb{R}^{2}$. See $[\mathrm{RW}]$. The space $\mathbb{R}^{2}-C$ has, of course, only one bounded component, as we shall prove in the next section.)

6. Suppose you are given that there is no retraction of $B^{n}$ onto $S^{n-1}$.

(a) Show the Borsuk lemma holds for $S^{n}$.

(b) Show that no compact contractible subspace of $S^{n}$ separates $S^{n}$.

(c) Suppose you are given also that any subspace of $S^{n}$ homeomorphic to $S^{n-1}$ separates $S^{n}$. Prove the invariance of domain theorem in dimension $n$.

## §63 The Jordan Curve Theorem

The special case of the Seifert-van Kampen theorem that we used in proving the Jordan separation theorem tells us something about the fundamental group of the space $X=$ $U \cup V$ in the case where the intersection $U \cap V$ is path connected. In the next theorem, we examine what happens when $U \cap V$ is not path connected. This result will enable us to complete the proof of the Jordan curve theorem.

Theorem 63.1. Let $X$ be the union of two open sets $U$ and $V$, such that $U \cap V$ can be written as the union of two disjoint open sets $A$ and $B$. Assume that there is a path $\alpha$ in $U$ from a point $a$ of $A$ to a point $b$ of $B$, and that there is a path $\beta$ in $V$ from $b$ to $a$. Let $f$ be the loop $f=\alpha * \beta$.

(a) The path-homotopy class $[f]$ generates an infinite cyclic subgroup of $\pi_{1}(X, a)$.

*(b) If $\pi_{1}(X, a)$ is itself infinite cyclic, it is generated by $[f]$.

(c) Assume there is a path $\gamma$ in $U$ from a to the point $a^{\prime}$ of $A$, and that there is a path $\delta$ in $V$ from $a^{\prime}$ to $a$. Let $g$ be the loop $g=\gamma * \delta$. Then the subgroups of $\pi_{1}(X, a)$ generated by $[f]$ and $[g]$ intersect in the identity element alone.

Proof. The proof is in many ways an imitation of the proof in $\S 54$ that the fundamental group of the circle is infinite cyclic. As in that proof, the crucial step is to find an appropriate covering space $E$ for the space $X$.

Step 1. (Construction of $E$ ). We construct $E$ by pasting together copies of the subspaces $U$ and $V$. Let us take countably many copies of $U$ and countably many copies of $V$, all disjoint, say

$$
U \times(2 n) \quad \text { and } \quad V \times(2 n+1)
$$

for all $n \in \mathbb{Z}$, where $\mathbb{Z}$ denotes the integers. Let $Y$ denote the union of these spaces; $Y$ is a subspace of $X \times \mathbb{Z}$. Now we form a new space $E$ as a quotient space of $Y$ by[^11]identifying the points

$$
x \times(2 n) \quad \text { and } \quad x \times(2 n-1) \quad \text { for } x \in A
$$

and by identifying the points

$$
x \times(2 n) \quad \text { and } \quad x \times(2 n+1) \quad \text { for } x \in B \text {. }
$$

Let $\pi: Y \rightarrow E$ be the quotient map.

Now the map $\rho: Y \rightarrow X$ defined by $\rho(x \times m)=x$ induces a map $p: E \rightarrow X$; the map $p$ is continuous because $E$ has the quotient topology. The map $p$ is also surjective. We shall show that $p$ is a covering map. See Figure 63.1.

First let us show that the map $\pi$ is an open map. Since $Y$ is the union of the disjoint open sets $\{U \times(2 n)\}$ and $\{V \times(2 n+1)\}$, it will suffice to show that $\pi \mid(U \times 2 n)$ and $\pi \mid(V \times(2 n+1))$ are open maps. And this is easy. Take an open set in $U \times 2 n$, for example; it will be of the form $W \times 2 n$, where $W$ is open in $U$. Then

$$
\begin{gathered}
\pi^{-1}(\pi(W \times 2 n))=[W \times 2 n] \cup[(W \cap B) \times(2 n+1)] \\
\cup[(W \cap A) \times(2 n-1)]
\end{gathered}
$$

which is the union of three open sets of $Y$ and hence open in $Y$. By definition of the quotient topology, $\pi(W \times 2 n)$ is open in $E$, as desired.

Now we prove that $p$ is a covering map; we show that the open sets $U$ and $V$ are evenly covered by $p$. Consider $U$, for example. The set $p^{-1}(U)$ is the union of the disjoint sets $\pi(U \times 2 n)$ for $n \in \mathbb{Z}$. Each of these sets is open in $E$ because $\pi$ is an open map. Let $\pi_{2 n}$ denote the restriction of $\pi$ to the open set $U \times 2 n$, mapping it onto $\pi(U \times 2 n)$. It is a homeomorphism because it is bijective, continuous, and open. Then when restricted to $\pi(U \times 2 n)$, the map $p$ is just the composite of the two homeomorphisms

$$
\pi(U \times 2 n) \xrightarrow{\pi_{2 n}^{-1}} U \times 2 n \xrightarrow{\rho} U
$$

and is thus a homeomorphism. Therefore, $p \mid \pi(U \times 2 n)$ maps this set homeomorphically onto $U$, as desired.

Step 2. Now we define a family of liftings of the loop $f=\alpha * \beta$.

For each integer $n$, let $e_{n}$ be the point $\pi(a \times 2 n)$ of $E$. Then the points $e_{n}$ are distinct, and they constitute the set $p^{-1}(a)$. We define a lifting $\tilde{f}_{n}$ of $f$ that begins at $e_{n}$ and ends at $e_{n+1}$.

Since $\alpha$ and $\beta$ are paths in $U$ and $V$, respectively, we can define

$$
\begin{aligned}
& \tilde{\alpha}_{n}(s)=\pi(\alpha(s) \times 2 n), \\
& \tilde{\beta}_{n}(s)=\pi(\beta(s) \times(2 n+1))
\end{aligned}
$$

then $\tilde{\alpha}_{n}$ and $\tilde{\beta}_{n}$ are liftings of $\alpha$ and $\beta$, respectively. (The case $n=0$ is illustrated in Figure 63.1.) The product $\tilde{\alpha}_{n} * \tilde{\beta}_{n}$ is defined, since $\tilde{\alpha}_{n}$ ends at $\pi(b \times 2 n)$ and $\tilde{\beta}_{n}$ begins at

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-386.jpg?height=1318&width=1096&top_left_y=368&top_left_x=479)

Figure 63.1

$\pi(b \times(2 n+1))$. We set $\tilde{f}_{n}=\tilde{\alpha}_{n} * \tilde{\beta}_{n}$, and note that $\tilde{f}_{n}$ begins at $\tilde{\alpha}_{n}(0)=\pi(a \times 2 n)=e_{n}$ and ends at $\tilde{\beta}_{n}(1)=\pi(a \times(2 n+1))=\pi(a \times(2 n+2))=e_{n+1}$.

Step 3. We show that $[f]$ generates an infinite cyclic subgroup of $\pi_{1}(X, a)$. It suffices to show that if $m$ is a positive integer, then $[f]^{m}$ is not the identity element. But this is easy. For the product

$$
\tilde{h}=\tilde{f}_{0} *\left(\tilde{f}_{1} *\left(\cdots * \tilde{f}_{m-1}\right)\right)
$$

is defined and is a lifting of the $m$-fold product

$$
h=f *(f *(\cdots * f)) .
$$

Because $\tilde{h}$ begins at $e_{0}$ and ends at $e_{m}$, the class $[h]=[f]^{m}$ cannot be trivial.

*Step 4. Now we show that if $\pi_{1}(X, a)$ is infinite cyclic, it is generated by $[f]$. Consider the lifting correspondence $\phi: \pi_{1}(X, a) \rightarrow p^{-1}(a)$. We showed in Step 3 that for each positive integer $m$, the correspondence $\phi$ carries $[f]^{m}$ to the point $e_{m}$ of $p^{-1}(a)$. A similar argument shows that it carries $[f]^{-m}$ to $e_{-m}$. Thus $\phi$ is surjective. Now by Theorem 54.6, $\phi$ induces an injective map

$$
\Phi: \pi_{1}(X, a) / H \longrightarrow p^{-1}(a),
$$

where $H=p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)$; the map $\Phi$ is surjective because $\phi$ is surjective. It follows that $H$ is the trivial group, since the quotient of an infinite cyclic group by any nontrivial subgroup is finite. Then the lifting correspondence $\phi$ itself is bijective; since it maps the subgroup generated by $[f]$ onto $p^{-1}(a)$, this subgroup must equal all of $\pi_{1}(X, a)$.

Step 5. Now we prove (c). The picture in Figure 63.1 may mislead you into thinking that the element $[g]$ of $\pi_{1}(X, a)$ considered in part (c) is in fact trivial. But that figure is rather special. Figure 63.2 illustrates what can occur when $A$ is itself the union of two disjoint nonempty open sets. In this case (which will be useful to us shortly) both $[f]$ and $[g]$ generate infinite cyclic subgroups of $\pi_{1}(X, a)$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-387.jpg?height=658&width=980&top_left_y=1220&top_left_x=709)

Figure 63.2

Given $g=\gamma * \delta$, we define a lifting of $g$ to $E$ as follows: Since $\gamma$ is a path in $U$, we can define

$$
\tilde{\gamma}(s)=\pi(\gamma(s)) \times 0)
$$

since $\delta$ is a path in $V$, we can define

$$
\tilde{\delta}(s)=\pi(\delta(s) \times(-1)) .
$$

Then $\tilde{\gamma}$ and $\tilde{\delta}$ are liftings of $\gamma$ and $\delta$. The product $\tilde{\gamma}=\tilde{\gamma} * \tilde{\delta}$ is defined, since $\tilde{\gamma}$ ends at $\pi\left(a^{\prime} \times 0\right)$ and $\tilde{\delta}$ begins at $\pi\left(a^{\prime} \times(-1)\right)$; and it is a lifting of $g$. Note that $\tilde{g}$ is a loop in $E$, for it begins and ends at $\pi(a \times 0)=\pi(a \times(-1))=e_{0}$.

It follows that the subgroups generated by $[f]$ and $[g]$ have only the identity element in common. For the $m$-fold product of $f$ with itself lifts to a path that begins at $e_{0}$ and ends at $e_{m}$, while every product of $g$ with itself lifts to a path beginning and ending at $e_{0}$. Hence $[f]^{m} \neq[g]^{k}$ for every nonzero $m$ and $k$.

Theorem 63.2 (A nonseparation theorem). Let $D$ be an arc in $S^{2}$. Then $D$ does not separate $S^{2}$.

Proof. We give two proofs of this theorem. The first uses the results of the preceding section, and the second does not.

First proof. Because $D$ is contractible, the identity map $i: D \rightarrow D$ is nulhomotopic. Hence if $a$ and $b$ are any two points of $S^{2}$ not in $D$, the inclusion $j: D \rightarrow$ $S^{2}-a-b$ is nulhomotopic. The Borsuk lemma then implies that $a$ and $b$ lie in the same component of $S^{2}-D$.

Second Proof. Let us write $D$ as the union of two $\operatorname{arcs} D_{1}$ and $D_{2}$ that intersect in a single point $d$. Let $a$ and $b$ be points not in $D$. We show that if $a$ and $b$ can be joined by paths in $S^{2}-D_{1}$ and in $S^{2}-D_{2}$, then they can be joined by a path in $S^{2}-D$. Figure 63.3 illustrates the fact that this assertion is not entirely trivial.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-388.jpg?height=535&width=669&top_left_y=1309&top_left_x=687)

Figure 63.3

We suppose that $a$ and $b$ cannot be joined by a path in $S^{2}-D$ and derive a contradiction. We apply Theorem 63.1. Let $X$ be the space $S^{2}-d$. Let $U$ and $V$ be the open sets

$$
U=S^{2}-D_{1} \quad \text { and } \quad V=S^{2}-D_{2}
$$

Then $X=U \cup V$, and $U \cap V=S^{2}-D$. By hypothesis, $a$ and $b$ are points of $S^{2}-D$ that cannot be joined by a path in $S^{2}-D$. Therefore, $U \cap V$ is not path connected.

Let $A$ be the path component of $U \cap V$ containing $a$; let $B$ be the union of the other path components of $U \cap V$. Since $U \cap V$ is locally path connected (being open in $S^{2}$ ), the path components of $U \cap V$ are open; hence $A$ and $B$ are open in $X$. We are given that $a$ and $b$ can be joined by paths in $U=S^{2}-D_{1}$ and $V=S^{2}-D_{2}$. We conclude from Theorem 63.1 that $\pi_{1}(X, a)$ is not trivial. But $X=S^{2}-d$, so its fundamental group is trivial.

Now we prove the theorem. Given the $\operatorname{arc} D$ and the points $a$ and $b$ of $S^{2}-D$, we suppose that $a$ and $b$ cannot be joined by a path in $S^{2}-D$ and derive a contradiction. Choose a homeomorphism $h:[0,1] \rightarrow D$; let $D_{1}=h([0,1 / 2])$ and $D_{2}=h([1 / 2,1])$. The result of the preceding paragraph shows that since $a$ and $b$ cannot be joined by a path in $S^{2}-D$, they cannot be joined by paths in both $S^{2}-D_{1}$ and $S^{2}-D_{2}$. To be definite, suppose that $a$ and $b$ cannot be joined by a path in $S^{2}-D_{1}$.

Now repeat the argument, breaking $D_{1}$ up into two $\operatorname{arcs} E_{1}=h([0,1 / 4])$ and $E_{2}=h([1 / 4,1 / 2])$. We conclude, as before, that $a$ and $b$ cannot be joined by paths in both $S^{2}-E_{1}$ and $S^{2}-E_{2}$.

Continue similarly. In this way we define a sequence

$$
I \supset I_{1} \supset I_{2} \supset \cdots
$$

of closed intervals such that $I_{n}$ has length $(1 / 2)^{n}$ and such that for each $n$, the points $a$ and $b$ cannot be joined by a path in $S^{2}-h\left(I_{n}\right)$. Compactness of the unit interval guarantees there is a point $x$ in $\bigcap I_{n}$; since the lengths of the intervals converge to zero, there is only one such point.

Consider the space $S^{2}-h(x)$. Since this space is homeomorphic to $\mathbb{R}^{2}$, the points $a$ and $b$ can be joined by a path $\alpha$ in $S^{2}-h(x)$. Because $\alpha(I)$ is compact, it is closed, so some $\epsilon$-neighborhood of $h(x)$ is disjoint from $\alpha(I)$. Then because $h$ is continuous, there is some $m$ such that $h\left(I_{m}\right)$ lies in this $\epsilon$-neighborhood. It follows that $\alpha$ is a path in $S^{2}-h\left(I_{m}\right)$ joining $a$ and $b$, contrary to hypothesis.

Both proofs of this theorem are interesting. As we noted in $\S 62$, the first generalizes to show that no compact contractible subspace of $S^{2}$ separates $S^{2}$. The second generalizes in another direction. Let us examine this second proof, and ask ourselves what properties of the sets $D_{1}$ and $D_{2}$ made it work? One readily sees that all that was needed was the fact that $D_{1}$ and $D_{2}$ were closed subsets of $S^{2}$ and that $S^{2}-\left(D_{1} \cap D_{2}\right)$ was simply connected. Hence we have the following result, which we shall use later:

Theorem 63.3 (A general nonseparation theorem). Let $D_{1}$ and $D_{2}$ be closed subsets of $S^{2}$ such that $S^{2}-D_{1} \cap D_{2}$ is simply connected. If neither $D_{1}$ nor $D_{2}$ separates $S^{2}$, then $D_{1} \cup D_{2}$ does not separate $S^{2}$.

Now we prove the Jordan curve theorem.

Theorem 63.4 (The Jordan curve theorem). Let $C$ be a simple closed curve in $S^{2}$. Then $C$ separates $S^{2}$ into precisely two components $W_{1}$ and $W_{2}$. Each of the sets $W_{1}$ and $W_{2}$ has $C$ as its boundary; that is, $C=\bar{W}_{i}-W_{i}$ for $i=1,2$.

Proof. Step 1. We first prove that $S^{2}-C$ has precisely two components. Write $C$ as the union of two $\operatorname{arcs} C_{1}$ and $C_{2}$ that intersect in a two-point set $\{p, q\}$. Let $X$ be the space $S^{2}-p-q$, and let $U$ and $V$ be the open sets

$$
U=S^{2}-C_{1} \quad \text { and } \quad V=S^{2}-C_{2}
$$

Then $X=U \cup V$, and $U \cap V=S^{2}-C$. The space $U \cap V$ has at least two components, by the Jordan separation theorem.

We suppose that $U \cap V$ has more than two components and derive a contradiction. Let $A_{1}$ and $A_{2}$ be two of the components of $U \cap V$, and let $B$ be the union of the others. Because $S^{2}-C$ is locally connected, each of these sets is open. Let $a \in A_{1}$ and $a^{\prime} \in A_{2}$ and $b \in B$. Because the arcs $C_{1}$ and $C_{2}$ do not separate $S^{2}$, there are paths $\alpha$ and $\gamma$ in $U$ from $a$ to $b$ and from $a$ to $a^{\prime}$, respectively, and there are paths $\beta$ and $\delta$ in $V$ from $b$ to $a$ and from $a^{\prime}$ to $a$, respectively. Consider the loops $f=\alpha * \beta$ and $g=\gamma * \delta$. Writing $U \cap V$ as the union of the open sets $A_{1} \cup A_{2}$ and $B$, we see that Theorem 63.1 implies that $[f]$ is a nontrivial element of $\pi_{1}(X, a)$. Writing $U \cap V$ as the union of the disjoint open sets $A_{1}$ and $A_{2} \cup B$, we see that $[g]$ is also a nontrivial element of $\pi_{1}(X, a)$. Since $\pi_{1}(X, a)$ is infinite cyclic, we must have $[f]^{m}=[g]^{k}$ for some nonzero integers $m$ and $k$. This result contradicts (c) of Theorem 63.1.

Step 2. Now we show that $C$ is the common boundary of $W_{1}$ and $W_{2}$

Because $S^{2}$ is locally connected, each of the components $W_{1}$ and $W_{2}$ of $S^{2}-C$ is open in $S^{2}$. In particular, neither contains a limit point of the other, so that both the sets $\bar{W}_{1}-W_{1}$ and $\bar{W}_{2}-W_{2}$ must be contained in $C$.

To prove the reverse inclusion, we show that if $x$ is a point of $C$, every neighborhood $U$ of $x$ intersects the closed set $\bar{W}_{1}-W_{1}$. It follows that $x$ is in the set $\bar{W}_{1}-W_{1}$.

So let $U$ be a neighborhood of $x$. Because $C$ is homeomorphic to the circle $S^{1}$, we can break $C$ up into two arcs $C_{1}$ and $C_{2}$ that intersect in only their end points, such that $C_{1}$ is small enough that it lies inside $U$. See Figure 63.4.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-390.jpg?height=583&width=746&top_left_y=1626&top_left_x=643)

Figure 63.4

Let $a$ and $b$ be points of $W_{1}$ and $W_{2}$, respectively. Because $C_{2}$ does not separate $S^{2}$, we can find a path $\alpha$ in $S^{2}-C_{2}$ joining $a$ and $b$. The set $\alpha(I)$ must contain a point $y$ of the set $\bar{W}_{1}-W_{1}$, because otherwise $\alpha(I)$ would be a connected set lying in the union of the disjoint open sets $W_{1}$ and $S^{2}-\bar{W}_{1}$, and intersecting each of them. The point $y$ belongs to the closed curve $C$, since $\left(\bar{W}_{1}-W_{1}\right) \subset C$. Because the path $\alpha$ does not intersect the $\operatorname{arc} C_{2}$, the point $y$ must therefore lie in the $\operatorname{arc} C_{1}$, which in turn lies in the open set $U$. Thus, $U$ intersects $\bar{W}_{1}-W_{1}$ in the point $y$, as desired.

Just as with the earlier theorems, we now ask ourselves what made the proof of this theorem work. Examining Step 1 of the proof, we see that all we used were the facts that $C_{1}$ and $C_{2}$ were closed connected sets, that $C_{1} \cap C_{2}$ consisted of two points, and that neither $C_{1}$ nor $C_{2}$ separated $S^{2}$. The first two facts implied that $C_{1} \cup C_{2}$ separated $S^{2}$ into at least two components; the third implied that there were only two components. Hence one has, with no further effort, the following result:

Theorem 63.5. Let $C_{1}$ and $C_{2}$ be closed connected subsets of $S^{2}$ whose intersection consists of two points. If neither $C_{1}$ nor $C_{2}$ separates $S^{2}$, then $C_{1} \cup C_{2}$ separates $S^{2}$ into precisely two components.

EXAMPLE 1. The second half of the Jordan curve theorem, to the effect that $C$ is the common boundary of $W_{1}$ and $W_{2}$, may seem so obvious as hardly to require comment. But it depends crucially on the fact that $C$ is homeomorphic to $S^{1}$.

For instance, consider the space indicated in Figure 63.5. It is the union of two arcs whose intersection consists of two points, so it separates $S^{2}$ into two components $W_{1}$ and $W_{2}$ just as the circle does, by Theorem 63.5. But $C$ does not equal the common boundary of $W_{1}$ and $W_{2}$ in this case.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-391.jpg?height=406&width=678&top_left_y=1515&top_left_x=860)

Figure 63.5

There is a fourth theorem that is often considered along with these three separation theorems. It is called the Schoenflies theorem, and it states that if $C$ is a simple closed curve in $S^{2}$ and $U$ and $V$ are the components of $S^{2}-C$, then $\bar{U}$ and $\bar{V}$ are each homeomorphic to the closed unit ball $B^{2}$. A proof may be found in [H-S].

The separation theorems can be generalized to higher dimensions as follows:

(1) Any subspace $C$ of $S^{n}$ homeomorphic to $S^{n-1}$ separates $S^{n}$.

(2) No subspace $A$ of $S^{n}$ homeomorphic to [0,1] or to some ball $B^{m}$ separates $S^{n}$.

(3) Any subspace $C$ of $S^{n}$ homeomorphic to $S^{n-1}$ separates $S^{n}$ into two components, of which $C$ is the common boundary.

These theorems can be proved quite readily once one has studied singular homology groups in algebraic topology. (See $[\mathrm{Mu}]$, p. 202.) The Brouwer theorem on invariance of domain for $\mathbb{R}^{n}$ follows as a corollary.

The Schoenflies theorem, however, does not generalize to higher dimensions without some restrictions on the way the space $C$ is imbedded in $S^{n}$. This is shown by the famous example of the "Alexander horned sphere," a homeomorphic image of $S^{2}$ in $S^{3}$, one of whose complementary domains is not simply connected! (See [H-Y], p. 176.)

The separation theorems can be generalized even further than this. The definitive theorem along these lines is the famous Alexander-Pontryagin duality theorem, a rather deep theorem of algebraic topology, which we shall not attempt to state here. (See $[\mathrm{Mu}]$.$) It implies that if the closed subspace C$ separates $S^{n}$ into $k$ components, so does any subspace of $S^{n}$ that is homeomorphic to $C$ (or even homotopy equivalent to $C$ ). The separation theorems (1)-(3) are immediate corollaries.

## Exercises

1. Let $C_{1}$ and $C_{2}$ be disjoint simple closed curves in $S^{2}$.

(a) Show that $S^{2}-C_{1}-C_{2}$ has precisely three components. [Hint: If $W_{1}$ is the component of $S^{2}-C_{1}$ disjoint from $C_{2}$, and if $W_{2}$ is the component of $S^{2}-C_{2}$ disjoint from $C_{1}$, show that $\bar{W}_{1} \cup \bar{W}_{2}$ does not separate $S^{2}$.]

(b) Show that these three components have boundaries $C_{1}$ and $C_{2}$ and $C_{1} \cup C_{2}$, respectively.

2. Let $D$ be a closed connected subspace of $S^{2}$ that separates $S^{2}$ into $n$ components.

(a) If $A$ is an arc in $S^{2}$ whose intersection with $D$ consists of one of its end points, show that $D \cup A$ separates $S^{2}$ into $n$ components.

(b) If $A$ is an arc in $S^{2}$ whose intersection with $D$ consists of its end points, show that $D \cup A$ separates $S^{2}$ into $n+1$ components.

(c) If $C$ is a simple closed curve in $S^{2}$ that intersects $D$ in a single point, show $D \cup C$ separates $S^{2}$ into $n+1$ components.

*3. (a) Let $D$ be a subspace of $S^{2}$ homeomorphic to the topologist's sine curve $\bar{S}$. (See §24.) Show that $D$ does not separate $S^{2}$. [Hint: Let $h: \bar{S} \rightarrow D$ be the homeomorphism. Given $0<c<1$, let $\bar{S}_{c}$ equal the intersection of $\bar{S}$ with the set $\{(x, y) \mid x \leq c\}$. Show that given $a, b \in S^{2}-D$, there is, for some value of $c$, a path in $S^{2}-h\left(\bar{S}_{c}\right)$ from $a$ to $b$. Conclude that there is a path in $S^{2}-D$ from $a$ to $b$.]

(b) Let $C$ be a subspace of $S^{2}$ homeomorphic to the closed topologist's sine curve. Show that $C$ separates $S^{2}$ into precisely two components, of which $C$ is the common boundary. [Hint: Let $h$ be the homeomorphism of the closed topologist's sine curve with $C$. Let $C_{0}=h(0 \times[-1,1])$. Show first, using
the argument of Theorem 63.4, that each point of $C-C_{0}$ lies in the boundary of each component of $S^{2}-C$.]

## §64 Imbedding Graphs in the Plane

A (finite) linear graph $G$ is a Hausdorff space that is written as the union of finitely many arcs, each pair of which intersect in at most a common end point. The arcs are called the edges of the graph, and the end points of the arcs are called the vertices of the graph.

Linear graphs are used in mathematics to model many real-life phenomena; however, we shall look at them simply as interesting spaces that in some sense are generalizations of simple closed curves.

Note that any graph is determined completely (up to homeomorphism) by listing its vertices and specifying which pairs of vertices have an edge joining them.

EXAMPLE 1. If $G$ contains exactly $n$ vertices, and if for every pair of distinct vertices of $G$ there is an edge of $G$ joining them, then $G$ is called the complete graph on $\boldsymbol{n}$ vertices and is denoted $G_{n}$. Several such graphs are pictured in Figure 64.1. Note that the first three of these graphs are pictured as subspaces of $\mathbb{R}^{2}$, but the fourth is pictured instead as a subspace of $\mathbb{R}^{3}$. A little experimentation will convince you that this graph cannot in fact be imbedded in $\mathbb{R}^{2}$. We shall prove this result shortly.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-393.jpg?height=84&width=198&top_left_y=1440&top_left_x=645)

$\mathrm{G}_{2}$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-393.jpg?height=222&width=189&top_left_y=1418&top_left_x=905)

$\mathrm{G}_{3}$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-393.jpg?height=236&width=231&top_left_y=1381&top_left_x=1150)

$\mathrm{G}_{4}$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-393.jpg?height=328&width=336&top_left_y=1382&top_left_x=1414)

Figure 64.1

EXAMPLE 2. Another interesting graph arises in considering the classical puzzle: "Given three houses, $h_{1}, h_{2}$, and $h_{3}$, and three utilities, $g$ (for gas), $w$ (for water), and $e$ (for electricity), can you connect each utility to each house without letting any of the connecting lines cross?" Formulated mathematically, this is just the question whether the graph pictured in Figure 64.2, which is called the utilities graph, can be imbedded in $\mathbb{R}^{2}$. Again, a little experimentation will convince you that it cannot, a fact that we shall prove shortly.

Definition. A theta space $X$ is a Hausdorff space that is written as the union of three arcs $A, B$, and $C$, each pair of which intersect precisely in their end points. (The space $X$ is of course homeomorphic to the Greek letter theta.)

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-394.jpg?height=347&width=503&top_left_y=365&top_left_x=770)

Figure 64.2

Note that as it stands, a theta space $X$ is not a linear graph, for the arcs in question intersect in more than a common end point. One can write it as a graph, however, by breaking each of the $\operatorname{arcs} A, B$, and $C$ up into two arcs with an end point in common.

Lemma 64.1. Let $X$ be a theta space that is a subspace of $S^{2}$; let $A, B$, and $C$ be the arcs whose union is $X$. Then $X$ separates $S^{2}$ into three components, whose boundaries are $A \cup B, B \cup C$, and $A \cup C$, respectively. The component having $A \cup B$ as its boundary equals one of the components of $S^{2}-A \cup B$.

Proof. Let $a$ and $b$ be the end points of the arcs $A, B$, and $C$. Consider the simple closed curve $A \cup B$; it separates $S^{2}$ into two components $U$ and $U^{\prime}$, each of which is open in $S^{2}$ and has boundary $A \cup B$. See Figure 64.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-394.jpg?height=433&width=499&top_left_y=1391&top_left_x=772)

Figure 64.3

The space $C-a-b$ is connected, so it is contained in one of these components, say in $U^{\prime}$. Then consider the two spaces $\bar{U}=U \cup A \cup B$ and $C$; each is connected. Neither separates $S^{2}$, for $C$ is an arc, and the complement of $\bar{U}$ is the connected set $U^{\prime}$. Since the intersection of these two sets consists of the two points $a$ and $b$, their union separates $S^{2}$ into two components $V$ and $W$, by Theorem 63.5. It follows that $S^{2}-$ $(A \cup B \cup C)$ is the union of the three disjoint connected sets $U, V$, and $W$; because they are open in $S^{2}$, they are the components of $S^{2}-(A \cup B \cup C)$. The component $U$ has $A \cup B$ as its boundary. Symmetry implies that the other two have $B \cup C$ and
$A \cup C$ as their boundaries.

Theorem 64.2. Let $X$ be the utilities graph. Then $X$ cannot be imbedded in the plane.

Proof. If $X$ can be imbedded in the plane, then it can be imbedded in $S^{2}$. So suppose $X$ is a subspace of $S^{2}$. We derive a contradiction.

We use the notation of Example 2, where $g, w, e, h_{1}, h_{2}$, and $h_{3}$ are the vertices of $X$. Let $A, B$, and $C$ be the following arcs contained in $X$ :

$$
\begin{aligned}
& A=g h_{1} w \\
& B=g h_{2} w \\
& C=g h_{3} w .
\end{aligned}
$$

Each pair of these arcs intersect in their end points $g$ and $w$ alone; hence $Y=A \cup B \cup C$ is a theta space. The space $Y$ separates $S^{2}$ into three components $U, V$, and $W$, whose boundaries are $A \cup B, B \cup C$, and $A \cup C$, respectively. See Figure 64.4.

Now the vertex $e$ of $X$ lies in one of these three components, so that the arcs $e h_{1}$ and $e h_{2}$ and $e h_{3}$ of $X$ lie in the closure of that component. That component cannot be $U$, for $\bar{U}$ is contained in $U \cup A \cup B$, a set that does not contain the point $h_{3}$. Similarly, the component containing $e$ cannot be $V$ or $W$, because $\bar{V}$ does not contain $h_{1}$, and $\bar{W}$ does not contain $h_{2}$. Thus, we have reached a contradiction.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-395.jpg?height=336&width=481&top_left_y=1325&top_left_x=964)

Figure 64.4

Lemma 64.3. Let $X$ be a subspace of $S^{2}$ that is a complete graph on four vertices $a_{1}$, $a_{2}, a_{3}$, and $a_{4}$. Then $X$ separates $S^{2}$ into four components. The boundaries of these components are the sets $X_{1}, X_{2}, X_{3}$, and $X_{4}$, where $X_{i}$ is the union of those edges of $X$ that do not have $a_{i}$ as a vertex.

Proof. Let $Y$ be the union of all the arcs of $X$ different from the arc $a_{2} a_{4}$. Then we can write $Y$ as a theta space by setting

$$
\begin{aligned}
& A=a_{1} a_{2} a_{3}, \\
& B=a_{1} a_{3}, \\
& C=a_{1} a_{4} a_{3} .
\end{aligned}
$$

See Figure 64.5. The arcs $A, B$, and $C$ intersect in their end points $a_{1}$ and $a_{3}$ alone, and their union is $Y$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-396.jpg?height=499&width=621&top_left_y=497&top_left_x=708)

Figure 64.5

The space $Y$ separates $S^{2}$ into three components $U, V$, and $W$, whose boundaries are $A \cup B, B \cup C$, and $A \cup C$, respectively. The space $a_{2} a_{4}-a_{2}-a_{4}$, being connected, must lie in one of them. It cannot lie in $U$, because $A \cup B$ does not contain $a_{4}$. And it cannot lie in $V$ because $B \cup C$ does not contain $a_{2}$. Hence it must lie in $W$.

Now $\bar{U} \cup \bar{V}$ is connected because $\bar{U}$ and $\bar{V}$ are connected and have nonempty intersection $B$. Furthermore, the set $\bar{U} \cup \bar{V}$ does not separate $S^{2}$, because its complement is $W$. Similarly, the arc $a_{2} a_{4}$ is connected and does not separate $S^{2}$. And the sets $a_{2} a_{4}$ and $\bar{U} \cup \bar{V}$ intersect in the points $a_{2}$ and $a_{4}$ alone. It follows from Theorem 63.5 that $a_{2} a_{4} \cup \bar{U} \cup \bar{V}$ separates $S^{2}$ into two components $W_{1}$ and $W_{2}$. Then $S^{2}-Y$ is the union of the four disjoint connected sets $U, V, W_{1}$, and $W_{2}$. Since these sets are open, they are the components of $S^{2}-Y$.

Now one of these components, namely $U$, has the graph $A \cup B=X_{4}$ as its boundary. Symmetry implies that the other three have $X_{1}, X_{2}$, and $X_{3}$ as their respective boundaries.

Theorem 64.4. The complete graph on five vertices cannot be imbedded in the plane.

Proof. Suppose that $G$ is a subspace of $S^{2}$ that is a complete graph on the five vertices $a_{1}, a_{2}, a_{3}, a_{4}$, and $a_{5}$. Let $X$ be the union of those edges of $G$ that do not have $a_{5}$ as a vertex; then $X$ is a complete graph on four vertices. The space $X$ separates $S^{2}$ into four components, whose respective boundaries are the graphs $X_{1}, \ldots, X_{4}$, where $X_{i}$ consists of those edges of $X$ that do not have $a_{i}$ as a vertex. Now the point $a_{5}$ must lie in one of these four components. It follows that the connected space

$$
a_{1} a_{5} \cup a_{2} a_{5} \cup a_{3} a_{5} \cup a_{4} a_{5},
$$

which is the union of those edges of $G$ that have $a_{5}$ as a vertex, must lie in the closure of this component. Then all the vertices $a_{1}, \ldots, a_{4}$ lie in the boundary of this component.

But this is impossible, for none of the graphs $X_{i}$ contains all four vertices $a_{1}, \ldots, a_{4}$. Thus we reach a contradiction.

It follows from these theorems that if a graph $G$ contains a subgraph that is a utilities graph or a complete graph on five vertices, then $G$ cannot be imbedded in the plane. It is a remarkable theorem, due to Kuratowski, that the converse is also true! The proof is not easy.

## Exercise

1. Let $X$ be a space that is written as the union of finitely many arcs $A_{1}, \ldots, A_{n}$, each pair of which intersect in at most a common end point.

(a) Show that $X$ is Hausdorff if and only if each arc $A_{i}$ is closed in $X$.

(b) Give an example to show that $X$ need not be Hausdorff. [Hint: See Exercise 5 of $\S 36$.]

## §65 The Winding Number of a Simple Closed Curve

If $h: S^{1} \rightarrow \mathbb{R}^{2}-\mathbf{0}$ is a continuous map, then the induced homomorphism $h_{*}$ carries a generator of the fundamental group of $S^{1}$ to some integral power of a generator of the fundamental group of $\mathbb{R}^{2}-\mathbf{0}$. This integral power $n$ is called the winding number of $h$ with respect to $\mathbf{0}$. It measures how many times $h$ "wraps $S^{1}$ around the origin;" its sign depends of course on the choice of generators. See Figure 65.1. We will introduce it more formally in the next section.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-397.jpg?height=366&width=1076&top_left_y=1588&top_left_x=659)

Figure 65.1

For the present, we merely ask the question: What can one say about the winding number of $h$ if $h$ is injective, that is, if $h$ is a homeomorphism of $S^{1}$ with a simple closed curve $C$ in $\mathbb{R}^{2}-\mathbf{0}$ ? The illustrations in Figure 65.2 suggest the obvious conjecture: If $\mathbf{0}$ belongs to the unbounded component of $\mathbb{R}^{2}-C$, then $n=0$, while if $\mathbf{0}$ belongs to the bounded component, then $n= \pm 1$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-398.jpg?height=364&width=1106&top_left_y=373&top_left_x=468)

Figure 65.2

The first conjecture is easy to prove, for Lemma 61.2 tells us that $h$ is nulhomotopic if 0 belongs to the unbounded component of $\mathbb{R}^{2}-C$. On the other hand, the second conjecture is surprisingly difficult; it is in fact a rather deep result. We prove it in this section.

As usual, we shall replace $\mathbb{R}^{2} \cup\{\infty\}$ by $S^{2}$, letting $p$ be the point corresponding to $\mathbf{0}$ and $q$ be the point corresponding to $\infty$. Then our conjecture can be reformulated as follows: If $C$ is a simple closed curve in $S^{2}$, and if $p$ and $q$ belong to different components of $S^{2}-C$, then the inclusion mapping $j: C \rightarrow S^{2}-p-q$ induces an isomorphism of fundamental groups. This is what we shall prove.

First, we prove our result in the case where the simple closed curve $C$ is contained in a complete graph on four vertices. Then we prove the general case.

Lemma 65.1. Let $G$ be a subspace of $S^{2}$ that is a complete graph on four vertices $a_{1}, \ldots, a_{4}$. Let $C$ be the subgraph $a_{1} a_{2} a_{3} a_{4} a_{1}$, which is a simple closed curve. Let $p$ and $q$ be interior points of the edges $a_{1} a_{3}$ and $a_{2} a_{4}$, respectively. Then:

(a) The points $p$ and $q$ lie in different components of $S^{2}-C$.

(b) The inclusion $j: C \rightarrow S^{2}-p-q$ induces an isomorphism of fundamental groups.

Proof. (a) As in the proof of Lemma 64.3, the theta space $C \cup a_{1} a_{3}$ separates $S^{2}$ into three components $U, V$, and $W$. One of these, say $W$, has $C$ as its boundary; it is the only component whose boundary contains both $a_{2}$ and $a_{4}$. Therefore, $a_{2} a_{4}-a_{2}-a_{4}$ must lie in $W$, so that in particular, $q$ belongs to $W$. Of course, $p$ is not in $W$ because $p$ belongs to the theta space $C \cup a_{1} a_{3}$. Now Lemma 64.1 tells us that $W$ is one of the components of $S^{2}-C$; therefore, $p$ and $q$ belong to different components of $S^{2}-C$.

(b) Let $X=S^{2}-p-q$. The idea of the proof is the following: We choose a point $x$ interior to the $\operatorname{arc} a_{1} a_{2}$, and a point $y$ interior to the $\operatorname{arc} a_{3} a_{4}$. And we let $\alpha$ and $\beta$ be the broken-line paths

$$
\alpha=x a_{1} a_{4} y \quad \text { and } \quad \beta=y a_{3} a_{2} x \text {. }
$$

Then $\alpha * \beta$ is a loop lying in the simple closed curve $C$. We shall prove that $\alpha * \beta$ represents a generator of the fundamental group of $X$. It follows that the homomorphism
$j_{*}: \pi_{1}(C, x) \rightarrow \pi_{1}(X, x)$ is surjective, so that $j_{*}$ must be an isomorphism (since the groups involved are infinite cyclic). See Figure 65.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-399.jpg?height=530&width=611&top_left_y=498&top_left_x=885)

Figure 65.3

Let $D_{1}$ and $D_{2}$ be the arcs

$$
D_{1}=p a_{3} a_{2} q \quad \text { and } \quad D_{2}=q a_{4} a_{1} p
$$

and let $U=S^{2}-D_{1}$ and $V=S^{2}-D_{2}$. See Figure 65.4. Then $X=U \cup V$, and $U \cap V$ equals $S^{2}-D$, where $D$ is the simple closed curve $D=D_{1} \cup D_{2}$. Hence, $U \cap V$ has two components, by the Jordan curve theorem. Furthermore, since $D$ equals the simple closed curve $a_{1} a_{3} a_{2} a_{4} a_{1}$, the result of (a) implies that the points $x$ and $y$, which lie interior to the other two edges of the graph $G$, lie in different components of $S^{2}-D$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-399.jpg?height=520&width=1082&top_left_y=1564&top_left_x=654)

Figure 65.4

The hypotheses of Theorem 63.1 are thus satisfied. The path $\alpha$ is a path in $U$ from $x$ to $y$, while $\beta$ is a path in $V$ from $y$ to $x$. Because the fundamental group of $X$
is infinite cyclic, the loop $\alpha * \beta$ represents a generator of this group.

Now we prove our main theorem.

Theorem 65.2. Let $C$ be a simple closed curve in $S^{2}$; let $p$ and $q$ lie in different components of $S^{2}-C$. Then the inclusion mapping $j: C \rightarrow S^{2}-p-q$ induces an isomorphism of fundamental groups.

Proof. The proof involves constructing a complete graph on four vertices that contains $C$ as a subgraph.

Step 1. Let $a, b$, and $c$ be three distinct points of $\mathbb{R}^{2}$. If $A$ is an arc with end points points $a$ and $b$, and if $B$ is an arc with end points $b$ and $c$, then there exists an arc contained in $A \cup B$ with end points $a$ and $c$.

Choose paths $f: I \rightarrow A$ from $a$ to $b$, and $g: I \rightarrow B$ from $b$ to $c$, such that $f$ and $g$ are homeomorphisms. Let $t_{0}$ be a smallest point of $I$ such that $f\left(t_{0}\right) \in B$; and let $t_{1}$ be the point of $I$ such that $g\left(t_{1}\right)=f\left(t_{0}\right)$. Then the set $f\left(\left[0, t_{0}\right]\right) \cup g\left(\left[t_{1}, 1\right]\right)$ is the required arc. (If $t_{0}=0$ or $t_{1}=1$, one of these sets consists of a single point.) See Figure 65.5.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-400.jpg?height=288&width=449&top_left_y=1177&top_left_x=794)

Figure 65.5

Step 2. We show that if $U$ is an open set of $\mathbb{R}^{2}$, any two points of $U$ that can be connected by a path in $U$ are the end points of an arc lying in $U$.

If $x, y \in U$, set $x \sim y$ if $x=y$ or if there is an arc in $U$ with end points $x$ and $y$. The result of Step 1 shows that this is an equivalence relation. The equivalence classes are open, for if the $\epsilon$-neighborhood of $x$ lies in $U$, it consists of points equivalent to $x$. Since $U$ is connected, there is only one such equivalence class.

Step 3. Let $C$ be a simple closed curve in $\mathbb{R}^{2}$. We construct a subspace $G$ of $\mathbb{R}^{2}$ that is a complete graph on four vertices $a_{1}, \ldots, a_{4}$ such that $C$ equals the subgraph $a_{1} a_{2} a_{3} a_{4} a_{1}$.

For convenience, we assume that $\mathbf{0}$ lies in the bounded component of $\mathbb{R}^{2}-C$. Consider the $x$-axis $\mathbb{R} \times 0$ in $\mathbb{R}^{2}$; let $a_{1}$ be the largest point on the negative $x$-axis that lies in $C$, and let $a_{3}$ be the smallest point on the positive $x$-axis that lies in $C$. Then the line segment $a_{1} a_{3}$ lies in the closure of the bounded component of $\mathbb{R}^{2}-C$.

Let us write $C$ as the union of two $\operatorname{arcs} C_{1}$ and $C_{2}$ with end points $a_{1}$ and $a_{3}$. Let $a$ be a point of the unbounded component of $\mathbb{R}^{2}-C$. Since $C_{1}$ and $C_{2}$ do not separate $\mathbb{R}^{2}$, we can choose paths $\alpha: I \rightarrow \mathbb{R}^{2}-C_{1}$ and $\beta: I \rightarrow \mathbb{R}^{2}-C_{2}$ from $a$
to $\mathbf{0}$; in view of Step 2, we may assume that $\alpha$ and $\beta$ are injective. Let $a_{2}=\alpha\left(t_{0}\right)$, where $t_{0}$ is the smallest number such that $\alpha\left(t_{0}\right) \in C$; then $a_{2}$ is a point interior to $C_{2}$. Similarly, let $a_{4}=\beta\left(t_{1}\right)$, where $t_{1}$ is the smallest number such that $\beta\left(t_{1}\right) \in C$; then $a_{4}$ is an interior point of $C_{1}$. Then $\alpha\left(\left[0, t_{0}\right]\right)$ and $\beta\left(\left[0, t_{1}\right]\right)$ are arcs joining $a$ to $a_{2}$ and $a_{4}$, respectively; by Step 2, their union contains an arc with end points $a_{2}$ and $a_{4}$; this arc intersects $C$ only in these two points. This arc, along with the line segment $a_{1} a_{3}$ and the curve $C$, forms the desired graph. See Figure 65.6.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-401.jpg?height=672&width=900&top_left_y=727&top_left_x=749)

Figure 65.6

Step 4. It follows from the result of Step 3 and the preceding lemma that for some pair of points $p, q$ lying in different components of $S^{2}-C$, the inclusion $j: C \rightarrow$ $S^{2}-p-q$ induces an isomorphism of fundamental groups. To complete the proof, we need only show that the same holds for any pair $p, q$ of points lying in different components of $S^{2}-C$. For that purpose, it suffices to prove the following:

Let $D$ be a simple closed curve in $\mathbb{R}^{2}$; suppose $\mathbf{0}$ lies in the bounded component of $\mathbb{R}^{2}-D$. Let $p$ be another point of this component. If inclusion $j: D \rightarrow \mathbb{R}^{2}-\mathbf{0}$ induces an isomorphism of fundamental groups, then so does the inclusion $k: D \rightarrow \mathbb{R}^{2}-p$.

Let $f: \mathbb{R}^{2}-p \rightarrow \mathbb{R}^{2}-\mathbf{0}$ be the homeomorphism $f(x)=x-p$. It suffices to show that the map

$$
D \xrightarrow{k} \mathbb{R}^{2}-p \xrightarrow{f} \mathbb{R}^{2}-\mathbf{0}
$$

indices an isomorphism of fundamental groups. Let $\alpha$ be a path in $\mathbb{R}^{2}-D$ from $\mathbf{0}$ to $p$, and let $F: D \times I \rightarrow \mathbb{R}^{2}-\mathbf{0}$ be the map $F(x, t)=x-\alpha(t)$. Then $F$ is a homotopy between $j$ and $f \circ k$; since $j$ induces an isomorphism, so does $f \circ k$. (See Corollary 58.5).

This theorem is a special case of a rather deep theorem of algebraic topology, concerning the "linking number" of two disjoint subspaces of $S^{m+n+1}$, one homeomorphic to an $m$-sphere and the other homeomorphic to an $n$-sphere; it is related to the Alexander duality theorem. (See [Mu], p. 433.) The special case of our theorem is that of a 0 -sphere (i.e., a two-point space) and a 1-sphere (i.e., a simple closed curve) in $S^{2}$.

## §66 The Cauchy Integral Formula

One of the central theorems in the study of functions of a complex variable is the one concerning the Cauchy integral formula for analytic functions. For the classical version of this theorem, one needs to assume not only the Jordan curve theorem, but also the winding-number theorem of the last section. There is, however, a reformulation of the Cauchy integral theorem that avoids using these results; this version of the theorem, although it is rather less natural, is the one now commonly found in texts on the subject.

Since we have the Jordan curve theorem at our disposal, we shall set ourselves the task of deriving the Cauchy integral formula in its classical version from the reformulated version.

We begin by introducing the notion of "winding number" more formally.

Definition. Let $f$ be a loop in $\mathbb{R}^{2}$, and let $a$ be a point not in the image of $f$. Set

$$
g(s)=[f(s)-a] /\|f(s)-a\| ;
$$

then $g$ is a loop in $S^{1}$. Let $p: \mathbb{R} \rightarrow S^{1}$ be the standard covering map, and let $\tilde{g}$ be a lifting of $g$ to $S^{1}$. Because $g$ is a loop, the difference $\tilde{g}(1)-\tilde{g}(0)$ is an integer. This integer is called the winding number of $\boldsymbol{f}$ with respect to $\boldsymbol{a}$, and is denoted $n(f, a)$.

Note that $n(f, a)$ is independent of the choice of the lifting of $g$. For if $\tilde{g}$ is one lifting of $g$, then uniqueness of liftings implies that any other lifting of $g$ has the form $\tilde{g}(s)+m$ for some integer $m$.

Definition. Let $F: I \times I \rightarrow X$ be a continuous map such that $F(0, t)=F(1, t)$ for all $t$. Then for each $t$, the map $f_{t}(s)=F(s, t)$ is a loop in $X$. The map $F$ is called a free homotopy between the loops $f_{0}$ and $f_{1}$. It is a homotopy of loops in which the base point of the loop is allowed to move during the homotopy.

Lemma 66.1. Let $f$ be a loop in $\mathbb{R}^{2}-a$.

(a) If $\bar{f}$ is the reverse of $f$, then $n(\bar{f}, a)=-n(f, a)$.

(b) If $f$ is freely homotopic to $f^{\prime}$, through loops lying in $\mathbb{R}^{2}-a$, then $n(f, a)=$ $n\left(f^{\prime}, a\right)$.

(c) If $a$ and $b$ lie in the same component of $\mathbb{R}^{2}-f(I)$, then $n(f, a)=n(f, b)$.

Proof. (a) To compute $n(\bar{f}, a)$, one replace $s$ by $1-s$ throughout the definition. This has the effect of changing $\tilde{g}(1)-\tilde{g}(0)$ by a sign.

(b) Let $F$ be a free homotopy between $f$ and $f^{\prime}$. Define $G: I \times I \rightarrow S^{1}$ by the equation

$$
G(s, t)=[F(s, t)-a] /\|F(s, t)-a\| .
$$

Let $\tilde{G}$ be a lifting of $G$ to $\mathbb{R}$. Then $\tilde{G}(1, t)-\tilde{G}(0, t)$ is an integer for each $t$; being continuous, it is constant.

(c) Let $\alpha$ be a path in $\mathbb{R}^{2}-f(I)$ from $a$ to $b$. Note that by definition, $n(f, a)=$ $n(f-a, \mathbf{0})$. Since $f(s)-\alpha(t)$ is a free homotopy in $\mathbb{R}^{2}-\mathbf{0}$ between $f-a$ and $f-b$, our result follows.

Definition. Let $f$ be a loop in $X$. We call $f$ a simple loop provided $f(s)=f\left(s^{\prime}\right)$ only if $s=s^{\prime}$ or if one of the points $s, s^{\prime}$ is 0 and the other is 1 . If $f$ is a simple loop, its image set is a simple closed curve in $X$.

Theorem 66.2. Let $f$ be a simple loop in $\mathbb{R}^{2}$. If a lies in the unbounded component of $\mathbb{R}^{2}-f(I)$, then $n(f, a)=0$; while if $a$ lies in the bounded component, $n(f, a)= \pm 1$.

Proof. Since $n(f, a)=n(f-a, \mathbf{0})$, we may restrict ourselves to the case $a=\mathbf{0}$. Furthermore, we may assume that the base point of $f$ lies on the positive $x$-axis. For one can gradually rotate $\mathbb{R}^{2}-\mathbf{0}$ until the base point of $f$ is such a point; this modifies $f$ by a free homotopy, so it does not affect the conclusion of the theorem.

So let $f$ be a simple loop in $X=\mathbb{R}^{2}-\mathbf{0}$ based at a point $x_{0}$ of the positive $x$ axis. Let $C$ be the simple closed curve $f(I)$. We show that if $\mathbf{0}$ lies in the bounded component of $\mathbb{R}^{2}-C$, then $[f]$ generates $\pi_{1}\left(X, x_{0}\right)$, while if $\mathbf{0}$ lies in the unbounded component, $[f]$ is trivial.

The map $f$ induces, via the standard quotient map $p: I \rightarrow S^{1}$, a homeomorphism $h: S^{1} \rightarrow C$. The element $[p]$ generates the fundamental group of $S^{1}$, so $h_{*}[p]$ generates the fundamental group of $C$. If $\mathbf{0}$ lies in the bounded component of $\mathbb{R}^{2}-C$, Theorem 65.2 tells us that $j_{*} h_{*}[p]=[f]$ generates the fundamental group of $\mathbb{R}^{2}-\mathbf{0}$, where $j: C \rightarrow \mathbb{R}^{2}-\mathbf{0}$ is the inclusion. On the other hand, if $\mathbf{0}$ lies in the unbounded component of $\mathbb{R}^{2}-C$, then $j \circ h$ is nulhomotopic by Lemma 61.2, so that $[f]$ is trivial.

Now we show that if $[f]$ generates $\pi_{1}\left(X, x_{0}\right)$, then $n(f, \mathbf{0})= \pm 1$, while if $[f]$ is trivial, $n(f, \mathbf{0})=0$. Since the retraction $x \rightarrow x /\|x\|$ of $\mathbb{R}^{2}-\mathbf{0}$ onto $S^{1}$ induces an isomorphism of fundamental groups, the loop $g(s)=f(s) /\|f(s)\|$ represents a generator of $\pi_{1}\left(S^{1}, b_{0}\right)$ in the first case, and the identity element in the second case. If we examine the isomorphism $\phi: \pi_{1}\left(S^{1}, b_{0}\right) \rightarrow \mathbb{Z}$ constructed in the proof of Theorem 54.5, we see this means that when we lift $g$ to a path $\tilde{g}$ in $\mathbb{R}$ beginning at 0 , the path $\tilde{g}$ ends at $\pm 1$ in the first case, and at 0 in the second.

Definition. Let $f$ be a simple loop in $\mathbb{R}^{2}$. We say $f$ is a counterclockwise loop if $n(f, a)=+1$ for some $a$ (and hence for every $a$ ) in the bounded component of
$\mathbb{R}^{2}-f(I)$. We say it is a clockwise loop if $n(f, a)=-1$. The standard loop $p(s)=$ $(\cos 2 \pi s, \sin 2 \pi s)$ is thus a counterclockwise loop.

## Application to complex variables

We now relate winding numbers to complex line integrals.

Lemma 66.3. Let $f$ be a piecewise-differentiable loop in the complex plane; let $a$ be a point not in the image of $f$. Then

$$
n(f, a)=\frac{1}{2 \pi i} \int_{f} \frac{d z}{z-a}
$$

This equation is often used as the definition of the winding number of $f$.

Proof. The proof is a simple exercise in computation. Let $p: \mathbb{R} \rightarrow S^{1}$ be the standard covering map. Let $r(s)=\|f(s)-a\|$ and $g(s)=[f(s)-a] / r(s)$. Let $\tilde{g}$ be a lifting of $g$ to $\mathbb{R}$. Set $\theta(s)=2 \pi \tilde{g}(s)$. Then $f(s)-a=r(s) \exp (i \theta(s))$, so that

$$
\begin{aligned}
\int_{f} \frac{d z}{z-a} & =\int_{0}^{1}\left[\left(r^{\prime} e^{i \theta}+i r \theta^{\prime} e^{i \theta}\right) / r e^{i \theta}\right] d s \\
& =[\log r(s)+i \theta(s)]_{0}^{1} \\
& =i[\theta(1)-\theta(0)] \\
& =2 \pi i[\tilde{g}(1)-\tilde{g}(0)] .
\end{aligned}
$$

Theorem 66.4 (Cauchy integral formula-classical version). Let $C$ be a simple closed piecewise-differentiable curve in the complex plane. Let $B$ be the bounded component of $\mathbb{R}^{2}-C$. If $F(z)$ is analytic in an open set $\Omega$ that contains $B$ and $C$, then for each point $a$ of $B$,

$$
F(a)= \pm \frac{1}{2 \pi i} \int_{C} \frac{F(z)}{z-a} d z
$$

The sign is + if $C$ is oriented counterclockwise, and - otherwise.

Proof. We derive this formula from the version of it proved in Ahlfors [A], which is the following:

Let $F$ be analytic in a region $\Omega$. Let $f$ be a piecewise-differentiable loop in $\Omega$. Assume that $n(f, b)=0$ for each $b$ not in $\Omega$. If $a \in \Omega$ and $a$ is not in the image of $f$, then

$$
n(f, a) \cdot F(a)=\frac{1}{2 \pi i} \int_{f} \frac{F(z)}{z-a} d z
$$

We apply this result to a piecewise-differentiable parametrization $f$ of our simple closed curve $C$. The condition $n(f, b)=0$ holds for each $b$ not in $\Omega$, since any such $b$ lies in the unbounded component of $\mathbb{R}^{2}-C$. Furthermore, $n(f, a)= \pm 1$ whenever $a$ is in $B$, the sign depending on the orientation of $C$, by Theorem 66.2. The theorem follows.

Note that one cannot even state the classical version of the Cauchy integral theorem without knowing the Jordan curve theorem. To prove it requires even more, namely, knowledge of the winding number of a simple closed curve. It is of interest to note that this latter result can be proved (at least in the differentiable case) by an entirely different method, using the general version of Green's Theorem, proved in analysis. This proof is outlined in Exercise 2.

## Exercises

1. Let $f$ be a loop in $\mathbb{R}^{2}-a$; let $g(s)=[f(s)-a] /\|f(s)-a\|$ The map $g$ induces, via the standard quotient map $p: I \rightarrow S^{1}$, a continuous map $h: S^{1} \rightarrow S^{1}$. Show that $n(f, a)$ equals the degree of $h$, as defined in Exercise 9 of $\$ 58$.
2. This exercise assumes some familiarity with analysis on manifolds. Theorem. Let $C$ be a simple closed curve in $\mathbb{R}^{2}$ that is a smooth submanifold of $\mathbb{R}^{2}$; let $f: I \rightarrow C$ be a simple loop smoothly parameterizing $C$. If $\mathbf{0}$ is a point of the bounded component of $\mathbb{R}^{2}-C$, then $n(f, \mathbf{0})= \pm 1$.

Proof. Let $U$ be the bounded component of $\mathbb{R}^{2}-C$. Let $B$ be a closed $\epsilon$-ball centered at $\mathbf{0}$ that lies in $U$; let $S=\operatorname{Bd} B$. Let $M$ equal the closure of $U-B$.

(a) Show $M$ is a smooth 2-manifold with boundary $C \cup S$.

(b) Apply Green's theorem to show that $\int_{C} d z / z= \pm \int_{S} d z / z$, the sign depending on the orientations of $S$ and $C$. [Hint: Set $P=-y /\left(x^{2}+y^{2}\right)$ and $Q=x /\left(x^{2}+y^{2}\right)$.]

(c) Show that the second integral equals $\pm 2 \pi i$.

## Chapter 11

## The Seifert-van Kampen Theorem

## §67 Direct Sums of Abelian Groups

In this section, we shall consider only groups that are abelian. As is usual, we shall write such groups additively. Then 0 denotes the identity element of the group, $-x$ denotes the inverse of $x$, and $n x$ denotes the $n$-fold sum $x+\cdots+x$.

Suppose $G$ is an abelian group, and $\left\{G_{\alpha}\right\}_{\alpha \in J}$ is an indexed family of subgroups of $G$. We say that the groups $G_{\alpha}$ generate $G$ if every element $x$ of $G$ can be written as a finite sum of elements of the groups $G_{\alpha}$. Since $G$ is abelian, we can always rearrange such a sum to group together terms that belong to a single $G_{\alpha}$; hence we can always write $x$ in the form

$$
x=x_{\alpha_{1}}+\cdots+x_{\alpha_{n}},
$$

where the indices $\alpha_{i}$ are distinct. In this case, we often write $x$ as the formal sum $x=\sum_{\alpha \in J} x_{\alpha}$, where it is understood that $x_{\alpha}=0$ if $\alpha$ is not one of the indices $\alpha_{1}$, $\ldots, \alpha_{n}$.

If the groups $G_{\alpha}$ generate $G$, we often say that $G$ is the sum of the groups $G_{\alpha}$, writing $G=\sum_{\alpha \in J} G_{\alpha}$ in general, or $G=G_{1}+\cdots+G_{n}$ in the case of the finite index set $\{1, \ldots, n\}$.

Now suppose that the groups $G_{\alpha}$ generate $G$, and that for each $x \in G$, the expression $x=\sum x_{\alpha}$ for $x$ is unique. That is, suppose that for each $x \in G$, there is only one
$J$-tuple $\left(x_{\alpha}\right)_{\alpha \in J}$ with $x_{\alpha}=0$ for all but finitely many $\alpha$ such that $x=\sum x_{\alpha}$. Then $G$ is said to be the direct sum of the groups $G_{\alpha}$, and we write

$$
G=\bigoplus_{\alpha \in J} G_{\alpha}
$$

or in the finite case, $G=G_{1} \oplus \cdots \oplus G_{n}$.

EXAMPLE 1. The cartesian product $\mathbb{R}^{\omega}$ is an abelian group under the operation of coordinate-wise addition. The set $G_{n}$ consisting of those tuples $\left(x_{i}\right)$ such that $x_{i}=0$ for $i \neq n$ is a subgroup isomorphic to $\mathbb{R}$. The groups $G_{n}$ generate the subgroup $\mathbb{R}^{\infty}$ of $\mathbb{R}^{\omega}$; indeed, $\mathbb{R}^{\infty}$ is their direct sum.

A useful characterization of direct sums is given in the following lemma; we call it the extension condition for direct sums:

Lemma 67.1. Let $G$ be an abelian group; let $\left\{G_{\alpha}\right\}$ be a family of subgroups of $G$. If $G$ is the direct sum of the groups $G_{\alpha}$, then $G$ satisfies the following condition:

Given any abelian group $H$ and any family of homomorphisms $h_{\alpha}: G_{\alpha} \rightarrow H$, there exists a homomorphism $h: G \rightarrow H$ whose restriction to $G_{\alpha}$ equals $h_{\alpha}$, for each $\alpha$.

Furthermore, $h$ is unique. Conversely, if the groups $G_{\alpha}$ generate $G$ and the extension condition (*) holds, then $G$ is the direct sum of the groups $G_{\alpha}$.

Proof. We show first that if $G$ has the stated extension property, then $G$ is the direct sum of the $G_{\alpha}$. Suppose $x=\sum x_{\alpha}=\sum y_{\alpha}$; we show that for any particular index $\beta$, we have $x_{\beta}=y_{\beta}$. Let $H$ denote the group $G_{\beta}$; and let $h_{\alpha}: G_{\alpha} \rightarrow H$ be the trivial homomorphism for $\alpha \neq \beta$, and the identity homomorphism for $\alpha=\beta$. Let $h: G \rightarrow H$ be the hypothesized extension of the homomorphisms $h_{\alpha}$. Then

$$
\begin{aligned}
& h(x)=\sum h_{\alpha}\left(x_{\alpha}\right)=x_{\beta}, \\
& h(x)=\sum h_{\alpha}\left(y_{\alpha}\right)=y_{\beta},
\end{aligned}
$$

so that $x_{\beta}=y_{\beta}$.

Now we show that if $G$ is the direct sum of the $G_{\alpha}$, then the extension condition holds. Given homomorphisms $h_{\alpha}$, we define $h(x)$ as follows: If $x=\sum x_{\alpha}$, set $h(x)=$ $\sum h_{\alpha}\left(x_{\alpha}\right)$. Because this sum is finite, it makes sense; because the expression for $x$ is unique, $h$ is well-defined. One checks readily that $h$ is the desired homomorphism. Uniqueness follows by noting that $h$ must satisfy this equation if it is a homomorphism that equals $h_{\alpha}$ on $G_{\alpha}$ for each $\alpha$.

This lemma makes a number of results about direct sums quite easy to prove:

Corollary 67.2. Let $G=G_{1} \oplus G_{2}$. Suppose $G_{1}$ is the direct sum of subgroups $H_{\alpha}$ for $\alpha \in J$, and $G_{2}$ is the direct sum of subgroups $H_{\beta}$ for $\beta \in K$, where the index sets $J$ and $K$ are disjoint. Then $G$ is the direct sum of the subgroups $H_{\gamma}$, for $\gamma \in J \cup K$.

Proof. If $h_{\alpha}: H_{\alpha} \rightarrow H$ and $h_{\beta}: H_{\beta} \rightarrow H$ are families of homomorphisms, they extend to homomorphisms $h_{1}: G_{1} \rightarrow H$ and $h_{2}: G_{2} \rightarrow H$ by the preceding lemma. Then $h_{1}$ and $h_{2}$ extend to a homomorphism $h: G \rightarrow H$.

This corollary implies, for example, that

$$
\left(G_{1} \oplus G_{2}\right) \oplus G_{3}=G_{1} \oplus G_{2} \oplus G_{3}=G_{1} \oplus\left(G_{2} \oplus G_{3}\right)
$$

Corollary 67.3. If $G=G_{1} \oplus G_{2}$, then $G / G_{2}$ is isomorphic to $G_{1}$.

Proof. Let $H=G_{1}$, let $h_{1}: G_{1} \rightarrow H$ be the identity homomorphism, and let $h_{2}: G_{2} \rightarrow H$ be the trivial homomorphism. Let $h: G \rightarrow H$ be their extension to $G$. Then $h$ is surjective with kernel $G_{2}$.

In many situations, one is given a family of abelian groups $\left\{G_{\alpha}\right\}$ and one wishes to find a group $G$ that contains subgroups $G_{\alpha}^{\prime}$ isomorphic to the groups $G_{\alpha}$, such that $G$ is the direct sum of these subgroups. This can in fact always be done; it leads to a notion called the external direct sum.

Definition. Let $\left\{G_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of abelian groups. Suppose that $G$ is an abelian group, and that $i_{\alpha}: G_{\alpha} \rightarrow G$ is a family of monomorphisms, such that $G$ is the direct sum of the groups $i_{\alpha}\left(G_{\alpha}\right)$. Then we say that $G$ is the external direct sum of the groups $G_{\alpha}$, relative to the monomorphisms $i_{\alpha}$.

The group $G$ is not unique, of course; we show later that it is unique up to isomorphism. Here is one way of constructing $G$ :

Theorem 67.4. Given a family of abelian groups $\left\{G_{\alpha}\right\}_{\alpha \in J}$, there exists an abelian group $G$ and a family of monomorphisms $i_{\alpha}: G_{\alpha} \rightarrow G$ such that $G$ is the direct sum of the groups $i_{\alpha}\left(G_{\alpha}\right)$.

Proof. Consider first the cartesian product

$$
\prod_{\alpha \in J} G_{\alpha}
$$

it is an abelian group if we add two $J$-tuples by adding them coordinate-wise. Let $G$ denote the subgroup of the cartesian product consisting of those tuples $\left(x_{\alpha}\right)_{\alpha \in J}$ such that $x_{\alpha}=0_{\alpha}$, the identity element of $G_{\alpha}$, for all but finitely many values of $\alpha$. Given an index $\beta$, define $i_{\beta}: G_{\beta} \rightarrow G$ by letting $i_{\beta}(x)$ be the tuple that has $x$ as its $\beta$ th coordinate and $0_{\alpha}$ as its $\alpha$ th coordinate for all $\alpha \neq \beta$. It is immediate that $i_{\beta}$ is a monomorphism. It is also immediate that since each element $\mathbf{x}$ of $G$ has only finitely many nonzero coordinates, $\mathbf{x}$ can be written uniquely as a finite sum of elements from the groups $i_{\beta}\left(G_{\beta}\right)$.

The extension condition that characterizes ordinary direct sums translates immediately into an extension condition for external direct sums:

Lemma 67.5. Let $\left\{G_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of abelian groups; let $G$ be an abelian group; let $i_{\alpha}: G_{\alpha} \rightarrow G$ be a family of homomorphisms. If each $i_{\alpha}$ is a monomorphism and $G$ is the direct sum of the groups $i_{\alpha}\left(G_{\alpha}\right)$, then $G$ satisfies the following extension condition:

Given any abelian group $H$ and any family of homomorphisms $h_{\alpha}$ : $G_{\alpha} \rightarrow H$, there exists a homomorphism $h: G \rightarrow H$ such that $h \circ i_{\alpha}=h_{\alpha}$ for each $\alpha$.

Furthermore, $h$ is unique. Conversely, suppose the groups $i_{\alpha}\left(G_{\alpha}\right)$ generate $G$ and the extension condition (*) holds. Then each $i_{\alpha}$ is a monomorphism, and $G$ is the direct sum of the groups $i_{\alpha}\left(G_{\alpha}\right)$.

Proof. The only part that requires proof is the statement that if the extension condition holds, then each $i_{\alpha}$ is a monomorphism. That is proved as follows. Given an index $\beta$, set $H=G_{\beta}$ and let $h_{\alpha}: G_{\alpha} \rightarrow H$ be the identity homomorphism if $\alpha=\beta$, and the trivial homomorphism if $\alpha \neq \beta$. Let $h: G \rightarrow H$ be the hypothesized extension. Then in particular, $h \circ i_{\beta}=h_{\beta}$; it follows that $i_{\beta}$ is injective.

An immediate consequence is a uniqueness theorem for direct sums:

Theorem 67.6 (Uniqueness of direct sums). Let $\left\{G_{\alpha}\right\}_{\alpha \in J}$ be a family of abelian groups. Suppose $G$ and $G^{\prime}$ are abelian groups and $i_{\alpha}: G_{\alpha} \rightarrow G$ and $i_{\alpha}^{\prime}: G_{\alpha} \rightarrow G^{\prime}$ are families of monomorphisms, such that $G$ is the direct sum of the groups $i_{\alpha}\left(G_{\alpha}\right)$ and $G^{\prime}$ is the direct sum of the groups $i_{\alpha}^{\prime}\left(G_{\alpha}\right)$. Then there is a unique isomorphism $\phi: G \rightarrow G^{\prime}$ such that $\phi \circ i_{\alpha}=i_{\alpha}^{\prime}$ for each $\alpha$.

Proof. We apply the preceding lemma (four times!). Since $G$ is the external direct sum of the $G_{\alpha}$ and $\left\{i_{\alpha}^{\prime}\right\}$ is a family of homomorphisms, there exists a unique homomorphism $\phi: G \rightarrow G^{\prime}$ such that $\phi \circ i_{\alpha}=i_{\alpha}^{\prime}$ for each $\alpha$. Similarly, since $G^{\prime}$ is the external direct sum of the $G_{\alpha}$ and $\left\{i_{\alpha}\right\}$ is a family of homomorphisms, there exists a unique homomorphism $\psi: G^{\prime} \rightarrow G$ such that $\psi \circ i_{\alpha}^{\prime}=i_{\alpha}$ for each $\alpha$. Now $\psi \circ \phi: G \rightarrow G$ has the property that $\psi \circ \phi \circ i_{\alpha}=i_{\alpha}$ for each $\alpha$; since the identity map of $G$ has the same property, the uniqueness part of the lemma shows that $\psi \circ \phi$ must equal the identity map of $G$. Similarly, $\phi \circ \psi$ must equal the identity map of $G^{\prime}$.

If $G$ is the external direct sum of the groups $G_{\alpha}$, relative to the monomorphisms $i_{\alpha}$, we sometimes abuse notation and write $G=\bigoplus G_{\alpha}$, even though the groups $G_{\alpha}$ are not subgroups of $G$. That is, we identify each group $G_{\alpha}$ with its image under $i_{\alpha}$, and treat $G$ as an ordinary direct sum rather than an external direct sum. In each case, the context will make the meaning clear.

Now we discuss free abelian groups.

Definition. Let $G$ be an abelian group and let $\left\{a_{\alpha}\right\}$ be an indexed family of elements of $G$; let $G_{\alpha}$ be the subgroup of $G$ generated by $a_{\alpha}$. If the groups $G_{\alpha}$ generate $G$, we also say that the elements $a_{\alpha}$ generate $G$. If each group $G_{\alpha}$ is infinite cyclic, and if $G$ is the direct sum of the groups $G_{\alpha}$, then $G$ is said to be a free abelian group having the elements $\left\{a_{\alpha}\right\}$ as a basis.

The extension condition for direct sums implies the following extension condition for free abelian groups:

Lemma 67.7. Let $G$ be an abelian group; let $\left\{a_{\alpha}\right\}_{\alpha \in J}$ be a family of elements of $G$ that generates $G$. Then $G$ is a free abelian group with basis $\left\{a_{\alpha}\right\}$ if and only if for any abelian group $H$ and any family $\left\{y_{\alpha}\right\}$ of elements of $H$, there is a homomorphism $h$ of $G$ into $H$ such that $h\left(a_{\alpha}\right)=y_{\alpha}$ for each $\alpha$. In such case, $h$ is unique.

Proof. Let $G_{\alpha}$ denote the subgroup of $G$ generated by $a_{\alpha}$. Suppose first that the extension property holds. We show first that each group $G_{\alpha}$ is infinite cyclic. Suppose that for some index $\beta$, the element $a_{\beta}$ generates a finite cyclic subgroup of $G$. Then if we set $H=\mathbb{Z}$, there is no homomorphism $h: G \rightarrow H$ that maps each $a_{\alpha}$ to the number 1. For $a_{\beta}$ has finite order and 1 does not! To show that $G$ is the direct sum of the groups $G_{\alpha}$, we merely apply Lemma 67.1.

Conversely, if $G$ is free abelian with basis $\left\{a_{\alpha}\right\}$, then given the elements $\left\{y_{\alpha}\right\}$ of $H$, there are homomorphisms $h_{\alpha}: G_{\alpha} \rightarrow H$ such that $h_{\alpha}\left(a_{\alpha}\right)=y_{\alpha}$ (because $G_{\alpha}$ is infinite cyclic). Then Lemma 67.1 applies.

Theorem 67.8. If $G$ is a free abelian group with basis $\left\{a_{1}, \ldots, a_{n}\right\}$, then $n$ is uniquely determined by $G$.

Proof. The group $G$ is isomorphic to the $n$-fold product $\mathbb{Z} \times \cdots \times \mathbb{Z}$; the subgroup $2 G$ corresponds to the product $(2 \mathbb{Z}) \times \cdots \times(2 \mathbb{Z})$. Then the quotient group $G / 2 G$ is in bijective correspondence with the set $(\mathbb{Z} / 2 \mathbb{Z}) \times \cdots \times(\mathbb{Z} / 2 \mathbb{Z})$, so that $G / 2 G$ has cardinality $2^{n}$. Thus $n$ is uniquely determined by $G$.

If $G$ is a free abelian group with a finite basis, the number of elements in a basis for $G$ is called the rank of $G$.

## Exercises

1. Suppose that $G=\sum G_{\alpha}$. Show this sum is direct if and only if the equation

$$
x_{\alpha_{1}}+\cdots+x_{\alpha_{n}}=0
$$

implies that each $x_{\alpha_{i}}$ equals 0 . (Here $x_{\alpha_{i}} \in G_{\alpha_{i}}$ and the indices $\alpha_{i}$ are distinct.)

2. Show that if $G_{1}$ is a subgroup of $G$, there may be no subgroup $G_{2}$ of $G$ such that $G=G_{1} \oplus G_{2}$. [Hint: Set $G=\mathbb{Z}$ and $G_{1}=2 \mathbb{Z}$.]
3. If $G$ is free abelian with basis $\{x, y\}$, show that $\{2 x+3 y, x-y\}$ is also a basis for $G$.
4. The order of an element $a$ of an abelian group $G$ is the smallest positive integer $m$ such that $m a=0$, if such exists; otherwise, the order of $a$ is said to be infinite. The order of $a$ thus equals the order of the subgroup generated by $a$.

(a) Show the elements of finite order in $G$ form a subgroup of $G$, called its torsion subgroup.

(b) Show that if $G$ is free abelian, it has no elements of finite order.

(c) Show the additive group of rationals has no elements of finite order, but is not free abelian. [Hint: If $\left\{a_{\alpha}\right\}$ is a basis, express $\frac{1}{2} a_{\alpha}$ in terms of this basis.]

5. Give an example of a free abelian group $G$ of rank $n$ having a subgroup $H$ of rank $n$ for which $H \neq G$.
6. Prove the following:

Theorem. If $A$ is a free abelian group of rank $n$, then any subgroup $B$ of $A$ is a free abelian group of rank at most $n$.

Proof. We can assume $A=\mathbb{Z}^{n}$, the $n$-fold cartesian product of $\mathbb{Z}$ with itself. Let $\pi_{i}: \mathbb{Z}^{n} \rightarrow \mathbb{Z}$ be projection on the $i$ th coordinate. Given $m \leq n$, let $B_{m}$ consist of all elements $\mathbf{x}$ of $B$ such that $\pi_{i}(\mathbf{x})=0$ for $i>m$. Then $B_{m}$ is a subgroup of $B$.

Consider the subgroup $\pi_{m}\left(B_{m}\right)$ of $\mathbb{Z}$. If this subgroup is nontrivial, choose $\mathbf{x}_{m} \in B_{m}$ so that $\pi_{m}\left(\mathbf{x}_{m}\right)$ is a generator of this subgroup. Otherwise, set $\mathbf{x}_{m}=\mathbf{0}$.

(a) Show $\left\{\mathbf{x}_{1}, \ldots, \mathbf{x}_{m}\right\}$ generates $B_{m}$, for each $m$.

(b) Show the nonzero elements of $\left\{\mathbf{x}_{1}, \ldots, \mathbf{x}_{m}\right\}$ form a basis for $B_{m}$, for each $m$.

(c) Show that $B_{n}=B$ is free abelian with rank at most $n$.

## $\S 68$ Free Products of Groups

We now consider groups $G$ that are not necessarily abelian. In this case, we write $G$ multiplicatively. We denote the identity element of $G$ by 1 , and the inverse of the element $x$ by $x^{-1}$. The symbol $x^{n}$ denotes the $n$-fold product of $x$ with itself, $x^{-n}$ denotes the $n$-fold product of $x^{-1}$ with itself, and $x^{0}$ denotes 1 .

In this section, we study a concept that plays a role for arbitrary groups similar to that played by the direct sum for abelian groups. It is called the free product of groups.

Let $G$ be a group. If $\left\{G_{\alpha}\right\}_{\alpha \in J}$ is a family of subgroups of $G$, we say (as before) that these groups generate $G$ if every element $x$ of $G$ can be written as a finite product of elements of the groups $G_{\alpha}$. This means that there is a finite sequence $\left(x_{1}, \ldots, x_{n}\right)$ of elements of the groups $G_{\alpha}$ such that $x=x_{1} \cdots x_{n}$. Such a sequence is called a word (of length $n$ ) in the groups $G_{\alpha}$; it is said to represent the element $x$ of $G$.

Note that because we lack commutativity, we cannot rearrange the factors in the expression for $x$ so as to group together factors that belong to a single one of the groups $G_{\alpha}$. However, if $x_{i}$ and $x_{i+1}$ both belong to the same group $G_{\alpha}$, we can group them
together, thereby obtaining the word

$$
\left(x_{1}, \ldots, x_{i-1}, x_{i} x_{i+1}, x_{i+2}, \ldots, x_{n}\right),
$$

of length $n-1$, which also represents $x$. Furthermore, if any $x_{i}$ equals 1 , we can delete $x_{i}$ from the sequence, again obtaining a shorter word that represents $x$.

Applying these reduction operations repeatedly, one can in general obtain a word representing $x$ of the form $\left(y_{1}, \ldots, y_{m}\right)$, where no group $G_{\alpha}$ contains both $y_{i}$ and $y_{i+1}$, and where $y_{i} \neq 1$ for all $i$. Such a word is called a reduced word. This discussion does not apply, however, if $x$ is the identity element of $G$. For in that case, one might represent $x$ by a word such as $\left(a, a^{-1}\right)$, which reduces successively to the word $\left(a a^{-1}\right)$ of length one, and then disappears altogether! Accordingly, we make the convention that the empty set is considered to be a reduced word (of length zero) that represents the identity element of $G$. With this convention, it is true that if the groups $G_{\alpha}$ generate $G$, then every element of $G$ can be represented by a reduced word in the elements of the groups $G_{\alpha}$.

Note that if $\left(x_{1}, \ldots, x_{n}\right)$ and $\left(y_{1}, \ldots, y_{m}\right)$ are words representing $x$ and $y$, respectively, then $\left(x_{1}, \ldots, x_{n}, y_{1}, \ldots, y_{m}\right)$ is a word representing $x y$. Even if the first two words are reduced words, however, the third will not be a reduced word unless none of the groups $G_{\alpha}$ contains both $x_{n}$ and $y_{1}$.

Definition. Let $G$ be a group, let $\left\{G_{\alpha}\right\}_{\alpha \in J}$ be a family of subgroups of $G$ that generates $G$. Suppose that $G_{\alpha} \cap G_{\beta}$ consists of the identity element alone whenever $\alpha \neq \beta$. We say that $G$ is the free product of the groups $G_{\alpha}$ if for each $x \in G$, there is only one reduced word in the groups $G_{\alpha}$ that represents $x$. In this case, we write

$$
G=\prod_{\alpha \in J}^{*} G_{\alpha}
$$

or in the finite case, $G=G_{1} * \cdots * G_{n}$.

Let $G$ be the free product of the groups $G_{\alpha}$, and let $\left(x_{1}, \ldots, x_{n}\right)$ be a word in the groups $G_{\alpha}$ satisfying the condition $x_{i} \neq 1$ for all $i$. Then, for each $i$, there is a unique index $\alpha_{i}$ such that $x_{i} \in G_{\alpha_{i}}$; to say the word is a reduced word is to say simply that $\alpha_{i} \neq \alpha_{i+1}$ for each $i$.

Suppose the groups $G_{\alpha}$ generate $G$, where $G_{\alpha} \cap G_{\beta}=\{1\}$ for $\alpha \neq \beta$. In order for $G$ to be the free product of these groups, it suffices to know that the representation of 1 by the empty word is unique. For suppose this weaker condition holds, and suppose that $\left(x_{1}, \ldots, x_{n}\right)$ and $\left(y_{1}, \ldots, y_{m}\right)$ are two reduced words that represent the same element $x$ of $G$. Let $\alpha_{i}$ and $\beta_{i}$ be the indices such that $x_{i} \in G_{\alpha_{i}}$ and $y_{i} \in G_{\beta_{i}}$. Since

$$
x_{1} \cdots x_{n}=x=y_{1} \cdots y_{m}
$$

the word

$$
\left(y_{m}^{-1}, \ldots, y_{1}^{-1}, x_{1}, \ldots, x_{n}\right)
$$

represents 1 . It must be possible to reduce this word, so we must have $\alpha_{1}=\beta_{1}$; the word then reduces to the word

$$
\left(y_{m}^{-1}, \ldots, y_{1}^{-1} x_{1}, \ldots, x_{n}\right) .
$$

Again, it must be possible to reduce this word, so we must have $y_{1}^{-1} x_{1}=1$. Then $x_{1}=y_{1}$, so that 1 is represented by the word

$$
\left(y_{m}^{-1}, \ldots, y_{2}^{-1}, x_{2}, \ldots, x_{n}\right) .
$$

The argument continues similarly. One concludes finally that $m=n$ and $x_{i}=y_{i}$ for all $i$.

EXAmple 1. Consider the group $P$ of bijections of the set $\{0,1,2\}$ with itself. For $i=1,2$, define an element $\pi_{i}$ of $P$ by setting $\pi_{i}(i)=i-1$ and $\pi_{i}(i-1)=i$ and $\pi_{i}(j)=j$ otherwise. Then $\pi_{i}$ generates a subgroup $G_{i}$ of $P$ of order 2 . The groups $G_{1}$ and $G_{2}$ generate $P$, as you can check. But $P$ is not their free product. The reduced words $\left(\pi_{1}, \pi_{2}, \pi_{1}\right)$ and $\left(\pi_{2}, \pi_{1}, \pi_{2}\right)$, for instance, represent the same element of $P$.

The free product satisfies an extension condition analogous to that satisfied by the direct sum:

Lemma 68.1. Let $G$ be a group; let $\left\{G_{\alpha}\right\}$ be a family of subgroups of $G$. If $G$ is the free product of the groups $G_{\alpha}$, then $G$ satisfies the following condition:

Given any group $H$ and any family of homomorphisms $h_{\alpha}: G_{\alpha} \rightarrow$ $H$, there exists a homomorphism $h: G \rightarrow H$ whose restriction to $G_{\alpha}$ equals $h_{\alpha}$, for each $\alpha$.

Furthermore, $h$ is unique.

The converse of this lemma holds, but the proof is not as easy as it was for direct sums. We postpone it until later.

Proof. Given $x \in G$ with $x \neq 1$, let $\left(x_{1}, \ldots, x_{n}\right)$ be the reduced word that represents $x$. If $h$ exists, it must satisfy the equation

$$
\begin{equation*}
h(x)=h\left(x_{1}\right) \cdots h\left(x_{n}\right)=h_{\alpha_{1}}\left(x_{1}\right) \cdots h_{\alpha_{n}}\left(x_{n}\right) \tag{*}
\end{equation*}
$$

where $\alpha_{i}$ is the index such that $x_{i} \in G_{\alpha_{i}}$. Hence $h$ is unique.

To show $h$ exists, we define it by equation $(*)$ if $x \neq 1$, and we set $h(1)=1$. Because the representation of $x$ by a reduced word is unique, $h$ is well-defined. We must show it is a homomorphism.

We first prove a preliminary result. Given a word $w=\left(x_{1}, \ldots, x_{n}\right)$ of positive length in the elements of the groups $G_{\alpha}$, let us define $\phi(w)$ to be the element of $H$ given by the equation

$$
\begin{equation*}
\phi(w)=h_{\alpha_{1}}\left(x_{1}\right) \cdots h_{\alpha_{n}}\left(x_{n}\right), \tag{**}
\end{equation*}
$$

where $\alpha_{i}$ is any index such that $x_{i} \in G_{\alpha_{i}}$. Now $\alpha_{i}$ is unique unless $x_{i}=1$; hence $\phi$ is well-defined. If $w$ is the empty word, let $\phi(w)$ equal the identity element of $H$. We show that if $w^{\prime}$ is a word obtained from $w$ by applying one of our reduction operations, $\phi\left(w^{\prime}\right)=\phi(w)$.

Suppose first that $w^{\prime}$ is obtained by deleting $x_{i}=1$ from the word $w$. Then the equation $\phi\left(w^{\prime}\right)=\phi(w)$ follows from the fact that $h_{\alpha_{i}}\left(x_{i}\right)=1$. Second, suppose that $\alpha_{i}=\alpha_{i+1}$ and that

$$
w^{\prime}=\left(x_{1}, \ldots, x_{i} x_{i+1}, \ldots, x_{n}\right)
$$

The fact that

$$
h_{\alpha}\left(x_{i}\right) h_{\alpha}\left(x_{i+1}\right)=h_{\alpha}\left(x_{i} x_{i+1}\right) \text {, }
$$

where $\alpha=\alpha_{i}=\alpha_{i+1}$, implies that $\phi(w)=\phi\left(w^{\prime}\right)$.

It follows at once that if $w$ is any word in the groups $G_{\alpha}$ that represents $x$, then $h(x)=\phi(w)$. For by definition of $h$, this equation holds for any reduced word $w$; and the process of reduction does not change the value of $\phi$.

Now we show that $h$ is a homomorphism. Suppose that $w=\left(x_{1}, \ldots, x_{n}\right)$ and $w^{\prime}=\left(y_{1}, \ldots, y_{m}\right)$ are words representing $x$ and $y$, respectively. Let $\left(w, w^{\prime}\right)$ denote the word $\left(x_{1}, \ldots, x_{n}, y_{1}, \ldots, y_{m}\right)$, which represents $x y$. It follows from equation $(* *)$ that $\phi\left(w, w^{\prime}\right)=\phi(w) \phi\left(w^{\prime}\right)$. Then $h(x y)=h(x) h(y)$.

We now consider the problem of taking an arbitrary family of groups $\left\{G_{\alpha}\right\}$ and finding a group $G$ that contains subgroups $G_{\alpha}^{\prime}$ isomorphic to the groups $G_{\alpha}$, such that $G$ is the free product of the groups $G_{\alpha}^{\prime}$. This can, in fact, be done; it leads to the notion of external free product.

Definition. Let $\left\{G_{\alpha}\right\}_{\alpha \in J}$ be an indexed family of groups. Suppose that $G$ is a group, and that $i_{\alpha}: G_{\alpha} \rightarrow G$ is a family of monomorphisms, such that $G$ is the free product of the groups $i_{\alpha}\left(G_{\alpha}\right)$. Then we say that $G$ is the external free product of the groups $G_{\alpha}$, relative to the monomorphisms $i_{\alpha}$.

The group $G$ is not unique, of course; we show later that it is unique up to isomorphism. Constructing $G$ is much more difficult than constructing the external direct sum was:

Theorem 68.2. Given a family $\left\{G_{\alpha}\right\}_{\alpha \in J}$ of groups, there exists a group $G$ and a family of monomorphisms $i_{\alpha}: G_{\alpha} \rightarrow G$ such that $G$ is the free product of the groups $i_{\alpha}\left(G_{\alpha}\right)$.

Proof. For convenience, we assume that the groups $G_{\alpha}$ are disjoint as sets. (This can be accomplished by replacing $G_{\alpha}$ by $G_{\alpha} \times\{\alpha\}$ for each index $\alpha$, if necessary.)

Then as before, we define a word (of length $n$ ) in the elements of the groups $G_{\alpha}$ to be an $n$-tuple $w=\left(x_{1}, \ldots, x_{n}\right)$ of elements of $\bigcup G_{\alpha}$. It is called a reduced word if $\alpha_{i} \neq \alpha_{i+1}$ for all $i$, where $\alpha_{i}$ is the index such that $x_{i} \in G_{\alpha_{i}}$, and if for each $i, x_{i}$
is not the identity element of $G_{\alpha_{i}}$. We define the empty set to be the unique reduced word of length zero. Note that we are not given a group $G$ that contains all the $G_{\alpha}$ as subgroups, so we cannot speak of a word "representing" an element of $G$.

Let $W$ denote the set of all reduced words in the elements of the groups $G_{\alpha}$. Let $P(W)$ denote the set of all bijective functions $\pi: W \rightarrow W$. Then $P(W)$ is itself a group, with composition of functions as the group operation. We shall obtain our desired group $G$ as a subgroup of $P(W)$.

Step 1. For each index $\alpha$ and each $x \in G_{\alpha}$, we define a set map $\pi_{x}: W \rightarrow W$. It will satisfy the following conditions:

(1) If $x=1_{\alpha}$, the identity element of $G_{\alpha}$, then $\pi_{x}$ is the identity map of $W$.

(2) If $x, y \in G_{\alpha}$ and $z=x y$, then $\pi_{z}=\pi_{x} \circ \pi_{y}$.

We proceed as follows: Let $x \in G_{\alpha}$. For notational purposes, let $w=\left(x_{1}, \ldots, x_{n}\right)$ denote the general nonempty element of $W$, and let $\alpha_{1}$ denote the index such that $x_{1} \in G_{\alpha_{1}}$. If $x \neq 1_{\alpha}$, define $\pi_{x}$ as follows:

$$
\begin{array}{ll}
\pi_{x}(\varnothing)=(x), & \\
\pi_{x}(w)=\left(x, x_{1}, \ldots, x_{n}\right) & \text { if } \alpha_{1} \neq \alpha, \\
\pi_{x}(w)=\left(x x_{1}, \ldots, x_{n}\right) & \text { if } \alpha_{1}=\alpha \text { and } x_{1} \neq x^{-1}, \\
\pi_{x}(w)=\left(x_{2}, \ldots, x_{n}\right) & \text { if } \alpha_{1}=\alpha \text { and } x_{1}=x^{-1} . \tag{iv}
\end{array}
$$

If $x=1_{\alpha}$, define $\pi_{x}$ to be the identity map of $W$.

Note that the value of $\pi_{x}$ is in each case a reduced word, that is, an element of $W$. In cases (i) and (ii), the action of $\pi_{x}$ increases the length of the word; in case (iii) it leaves the length unchanged, and in case (iv) it reduces the length of the word. When case (iv) applies to a word $w$ of length one, it maps $w$ to the empty word.

Step 2. We show that if $x, y \in G_{\alpha}$ and $z=x y$, then $\pi_{z}=\pi_{x} \circ \pi_{y}$.

The result is trivial if either $x$ or $y$ equals $1_{\alpha}$, since in that case $\pi_{x}$ or $\pi_{y}$ is the identity map. So let us assume henceforth that $x \neq 1_{\alpha}$ and $y \neq 1_{\alpha}$. We compute the values of $\pi_{z}$ and of $\pi_{x} \circ \pi_{y}$ on the reduced word $w$. There are four cases to consider.

(i) Suppose $w$ is the empty word. We have $\pi_{y}(\varnothing)=(y)$. If $z=1_{\alpha}$, then $y=x^{-1}$ and $\pi_{x} \pi_{y}(\varnothing)=\varnothing$ by (iv), while $\pi_{z}(\varnothing)$ equals the same thing because $\pi_{z}$ is the identity map. If $z \neq 1_{\alpha}$, then

$$
\pi_{x} \pi_{y}(\varnothing)=(x y)=(z)=\pi_{z}(\varnothing) .
$$

In the remaining cases, we assume $w=\left(x_{1} \ldots, x_{n}\right)$, with $x_{1} \in G_{\alpha_{1}}$.

(ii) Suppose $\alpha \neq \alpha_{1}$. Then $\pi_{y}(w)=\left(y, x_{1}, \ldots, x_{n}\right)$. If $z=1_{\alpha}$, then $y=x^{-1}$ and $\pi_{x} \pi_{y}(w)=\left(x_{1}, \ldots, x_{n}\right)$ by (iv), while $\pi_{z}(w)$ equals the same because $\pi_{z}$ is the identity map. If $z \neq 1_{\alpha}$, then

$$
\begin{aligned}
\pi_{x} \pi_{y}(w) & =\left(x y, x_{1}, \ldots, x_{n}\right) \\
& =\left(z, x_{1}, \ldots, x_{n}\right)=\pi_{z}(w)
\end{aligned}
$$

(iii) Suppose $\alpha=\alpha_{1}$ and $y x_{1} \neq 1_{\alpha}$. Then $\pi_{y}(w)=\left(y x_{1}, x_{2}, \ldots, x_{n}\right)$. If $x y x_{1}=$ $1_{\alpha}$, then $\pi_{x} \pi_{y}(w)=\left(x_{2}, \ldots, x_{n}\right)$, while $\pi_{z}(w)$ equals the same thing because $z x_{1}=$ $x y x_{1}=1_{\alpha}$. If $x y x_{1} \neq 1_{\alpha}$, then

$$
\begin{aligned}
\pi_{x} \pi_{y}(w) & =\left(x y x_{1}, x_{2}, \ldots, x_{n}\right) \\
& =\left(z x_{1}, x_{2}, \ldots, x_{n}\right)=\pi_{z}(w) .
\end{aligned}
$$

(iv) Finally, suppose $\alpha=\alpha_{1}$ and $y x_{1}=1_{\alpha}$. Then $\pi_{y}(w)=\left(x_{2}, \ldots, x_{n}\right)$, which is empty if $n=1$. We compute

$$
\begin{aligned}
\pi_{x} \pi_{y}(w) & =\left(x, x_{2}, \ldots, x_{n}\right) \\
& =\left(x\left(y x_{1}\right), x_{2}, \ldots, x_{n}\right) \\
& =\left(z x_{1}, x_{2}, \ldots, x_{n}\right)=\pi_{z}(w) .
\end{aligned}
$$

Step 3. The map $\pi_{x}$ is an element of $p(W)$, and the map $i_{\alpha}: G_{\alpha} \rightarrow P(W)$ defined by $i_{\alpha}(x)=\pi_{x}$ is a monomorphism.

To show that $\pi_{x}$ is bijective, we note that if $y=x^{-1}$, then conditions (1) and (2) imply that $\pi_{y} \circ \pi_{x}$ and $\pi_{x} \circ \pi_{y}$ equal the identity map of $W$. Hence $\pi_{x}$ belongs to $P(W)$. The fact that $i_{\alpha}$ is a homomorphism is a consequence of condition (2). To show that $i_{\alpha}$ is a monomorphism, we note that if $x \neq 1_{\alpha}$, then $\pi_{x}(\varnothing)=(x)$, so that $\pi_{x}$ is not the identity map of $W$.

Step 4. Let $G$ be the subgroup of $P(W)$ generated by the groups $G_{\alpha}^{\prime}=i_{\alpha}\left(G_{\alpha}\right)$. We show that $G$ is the free product of the groups $G_{\alpha}^{\prime}$.

First, we show that $G_{\alpha}^{\prime} \cap G_{\beta}^{\prime}$ consists of the identity alone if $\alpha \neq \beta$. Let $x \in G_{\alpha}$ and $y \in G_{\beta}$; we suppose that neither $\pi_{x}$ nor $\pi_{y}$ is the identity map of $W$ and show that $\pi_{x} \neq \pi_{y}$. But this is easy, for $\pi_{x}(\varnothing)=(x)$ and $\pi_{y}(\varnothing)=(y)$, and these are different words.

Second, we show that no nonempty reduced word

$$
w^{\prime}=\left(\pi_{x_{1}}, \ldots, \pi_{x_{n}}\right)
$$

in the groups $G_{\alpha}^{\prime}$ represents the identity element of $G$. Let $\alpha_{i}$ be the index such that $x_{i} \in G_{\alpha_{i}}$; then $\alpha_{i} \neq \alpha_{i+1}$ and $x_{i} \neq 1_{\alpha_{i}}$ for each $i$. We compute

$$
\pi_{x_{1}}\left(\pi_{x_{2}}\left(\cdots\left(\pi_{x_{n}}(\varnothing)\right)\right)\right)=\left(x_{1}, \ldots, x_{n}\right),
$$

so the element of $G$ represented by $w^{\prime}$ is not the identity element of $P(W)$.

Although this proof of the existence of free products is certainly correct, it has the disadvantage that it doesn't provide us with a convenient way of thinking about the elements of the free product. For many purposes this doesn't matter, for the extension condition is the crucial property that is used in the applications. Nevertheless, one would be more comfortable having a more concrete model for the free product.

For the external direct sum, one had such a model. The external direct sum of the abelian groups $G_{\alpha}$ consisted of those elements $\left(x_{\alpha}\right)$ of the cartesian product $\prod G_{\alpha}$
such that $x_{\alpha}=0_{\alpha}$ for all but finitely many $\alpha$. And each group $G_{\beta}$ was isomorphic to the subgroup $G_{\beta}^{\prime}$ consisting of those $\left(x_{\alpha}\right)$ such that $x_{\alpha}=0_{\alpha}$ for all $\alpha \neq \beta$.

Is there a similar simple model for the free product? Yes. In the last step of the preceding proof, we showed that if $\left(\pi_{x_{1}}, \ldots, \pi_{x_{n}}\right)$ is a reduced word in the groups $G_{\alpha}^{\prime}$, then

$$
\pi_{x_{1}}\left(\pi_{x_{2}}\left(\cdots\left(\pi_{x_{n}}(\varnothing)\right)\right)\right)=\left(x_{1}, \ldots, x_{n}\right) .
$$

This equation implies that if $\pi$ is any element of $P(W)$ belonging to the free product $G$, then the assignment $\pi \rightarrow \pi(\varnothing)$ defines a bijective correspondence between $G$ and the set $W$ itself! Furthermore, if $\pi$ and $\pi^{\prime}$ are two elements of $G$ such that

$$
\pi(\varnothing)=\left(x_{1}, \ldots, x_{n}\right) \quad \text { and } \quad \pi^{\prime}(\varnothing)=\left(y_{1}, \ldots, y_{k}\right)
$$

then $\pi\left(\pi^{\prime}(\varnothing)\right)$ is the word obtained by taking the word $\left(x_{1}, \ldots, x_{n}, y_{1}, \ldots, y_{k}\right)$ and reducing it!

This gives us a way of thinking about the group $G$. One can think of $G$ as being simply the set $W$ itself, with the product of two words obtained by juxtaposing them and reducing the result. The identity element corresponds to the empty word. And each group $G_{\beta}$ corresponds to the subset of $W$ consisting of the empty set and all words of length 1 of the form $(x)$, for $x \in G_{\beta}$ and $x \neq 1_{\beta}$.

An immediate question arises: Why didn't we use this notion as our definition of the free product? It certainly seems simpler than going by way of the group $P(W)$ of permutations of $W$. The answer is this: Verification of the group axioms is very difficult if one uses this as the definition; associativity in particular is horrendous. The preceding proof of the existence of free products is a model of simplicity and elegance by comparison!

The extension condition for ordinary free products translates immediately into an extension condition for external free products:

Lemma 68.3. Let $\left\{G_{\alpha}\right\}$ be a family of groups; let $G$ be a group; let $i_{\alpha}: G_{\alpha} \rightarrow G$ be a family of homomorphisms. If each $i_{\alpha}$ is a monomorphism and $G$ is the free product of the groups $i_{\alpha}\left(G_{\alpha}\right)$, then $G$ satisfies the following condition:

Given a group $H$ and a family of homomorphisms $h_{\alpha}: G_{\alpha} \rightarrow H$, there exists a homomorphism $h: G \rightarrow H$ such that $h \circ i_{\alpha}=h_{\alpha}$ for each $\alpha$.

Furthermore, $h$ is unique.

An immediate consequence is a uniqueness theorem for free products; the proof is very similar to the corresponding proof for direct sums and is left to the reader.

Theorem 68.4 (Uniqueness of free products). Let $\left\{G_{\alpha}\right\}_{\alpha \in J}$ be a family of groups. Suppose $G$ and $G^{\prime}$ are groups and $i_{\alpha}: G_{\alpha} \rightarrow G$ and $i_{\alpha}^{\prime}: G_{\alpha} \rightarrow G^{\prime}$ are families of monomorphisms, such that the families $\left\{i_{\alpha}\left(G_{\alpha}\right)\right\}$ and $\left\{i_{\alpha}^{\prime}\left(G_{\alpha}\right)\right\}$ generate $G$ and $G^{\prime}$, respectively. If both $G$ and $G^{\prime}$ have the extension property stated in the preceding lemma, then there is a unique isomorphism $\phi: G \rightarrow G^{\prime}$ such that $\phi \circ i_{\alpha}=i_{\alpha}^{\prime}$ for all $\alpha$.

Now, finally, we can prove that the extension condition characterizes free products, proving the converses of Lemmas 68.1 and 68.3.

Lemma 68.5. Let $\left\{G_{\alpha}\right\}_{\alpha \in J}$ be a family of groups; let $G$ be a group; let $i_{\alpha}: G_{\alpha} \rightarrow G$ be a family of homomorphisms. If the extension condition of Lemma 68.3 holds, then each $i_{\alpha}$ is a monomorphism and $G$ is the free product of the groups $i_{\alpha}\left(G_{\alpha}\right)$.

Proof. We first show that each $i_{\alpha}$ is a monomorphism. Given an index $\beta$, let us set $H=G_{\beta}$. Let $h_{\alpha}: G_{\alpha} \rightarrow H$ be the identity if $\alpha=\beta$, and the trivial homomorphism if $\alpha \neq \beta$. Let $h: G \rightarrow H$ be the homomorphism given by the extension condition. Then $h \circ i_{\beta}=h_{\beta}$, so that $i_{\beta}$ is injective.

By Theorem 68.2, there exists a group $G^{\prime}$ and a family $i_{\alpha}^{\prime}: G_{\alpha} \rightarrow G^{\prime}$ of monomorphisms such that $G^{\prime}$ is the free product of the groups $i_{\alpha}^{\prime}\left(G_{\alpha}\right)$. Both $G$ and $G^{\prime}$ have the extension property of Lemma 68.3. The preceding theorem then implies that there is an isomorphism $\phi: G \rightarrow G^{\prime}$ such that $\phi \circ i_{\alpha}=i_{\alpha}^{\prime}$. It follows at once that $G$ is the free product of the groups $i_{\alpha}\left(G_{\alpha}\right)$.

We now prove two results analogous to Corollaries 67.2 and 67.3 .

Corollary 68.6. Let $G=G_{1} * G_{2}$, where $G_{1}$ is the free product of the subgroups $\left\{H_{\alpha}\right\}_{\alpha \in J}$ and $G_{2}$ is the free product of the subgroups $\left\{H_{\beta}\right\}_{\beta \in K}$. If the index sets $J$ and $K$ are disjoint, then $G$ is the free product of the subgroups $\left\{H_{\gamma}\right\}_{\gamma \in J \cup K}$.

Proof. The proof is almost a copy of the proof of Corollary 67.2.

This result implies in particular that

$$
G_{1} * G_{2} * G_{3}=G_{1} *\left(G_{2} * G_{3}\right)=\left(G_{1} * G_{2}\right) * G_{3}
$$

In order to state the next theorem, we must recall some terminology from group theory. If $x$ and $y$ are elements of a group $G$, we say that $y$ is conjugate to $x$ if $y=$ $c x c^{-1}$ for some $c \in G$. A normal subgroup of $G$ is one that contains all conjugates of its elements.

If $S$ is a subset of $G$, one can consider the intersection $N$ of all normal subgroups of $G$ that contain $S$. It is easy to see that $N$ is itself a normal subgroup of $G$; it is called the least normal subgroup of $G$ that contains $S$.

Theorem 68.7. Let $G=G_{1} * G_{2}$. Let $N_{i}$ be a normal subgroup of $G_{i}$, for $i=1,2$. If $N$ is the least normal subgroup of $G$ that contains $N_{1}$ and $N_{2}$, then

$$
G / N \cong\left(G_{1} / N_{1}\right) *\left(G_{2} / N_{2}\right) .
$$

Proof. The composite of the inclusion and projection homomorphisms

$$
G_{1} \longrightarrow G_{1} * G_{2} \longrightarrow\left(G_{1} * G_{2}\right) / N
$$

carries $N_{1}$ to the identity element, so that it induces a homomorphism

$$
i_{1}: G_{1} / N_{1} \longrightarrow\left(G_{1} * G_{2}\right) / N
$$

Similarly, the composite of the inclusion and projection homomorphisms induces a homomorphism

$$
i_{2}: G_{2} / N_{2} \longrightarrow\left(G_{1} * G_{2}\right) / N
$$

We show that the extension condition of Lemma 68.5 holds with respect to $i_{1}$ and $i_{2}$; it follows that $i_{1}$ and $i_{2}$ are monomorphisms and that $\left(G_{1} * G_{2}\right) / N$ is the external free product of $G_{1} / N_{1}$ and $G_{2} / N_{2}$ relative to these monomorphisms.

So let $h_{1}: G_{1} / N_{1} \rightarrow H$ and $h_{2}: G_{2} / N_{2} \rightarrow H$ be arbitrary homomorphisms. The extension condition for $G_{1} * G_{2}$ implies that there is a homomorphism of $G_{1} * G_{2}$ into $H$ that equals the composite

$$
G_{i} \longrightarrow G_{i} / N_{i} \longrightarrow H
$$

of the projection map and $h_{i}$ on $G_{i}$, for $i=1,2$. This homomorphism carries the elements of $N_{1}$ and $N_{2}$ to the identity element, so its kernel contains $N$. Therefore it induces a homomorphism $h:\left(G_{1} * G_{2}\right) / N \rightarrow H$ that satisfies the conditions $h_{1}=h \circ i_{1}$ and $h_{2}=h \circ i_{2}$.

Corollary 68.8. If $N$ is the least normal subgroup of $G_{1} * G_{2}$ that contains $G_{1}$, then $\left(G_{1} * G_{2}\right) / N \cong G_{2}$.

The notion of "least normal subgroup" is a concept that will appear frequently as we proceed. Obviously, if $N$ is the least normal subgroup of $G$ containing the subset $S$ of $G$, then $N$ contains $S$ and all conjugates of elements of $S$. For later use, we now verify that these elements actually generate $N$.

Lemma 68.9. Let $S$ be a subset of the group $G$. If $N$ is the least normal subgroup of $G$ containing $S$, then $N$ is generated by all conjugates of elements of $S$.

Proof. Let $N^{\prime}$ be the subgroup of $G$ generated by all conjugates of elements of $S$. We know that $N^{\prime} \subset N$; to verify the reverse inclusion, we need merely show that $N^{\prime}$ is normal in $G$. Given $x \in N^{\prime}$ and $c \in G$, we show that $c x c^{-1} \in N^{\prime}$.

We can write $x$ in the form $x=x_{1} x_{2} \cdots x_{n}$, where each $x_{i}$ is conjugate to an element $s_{i}$ of $S$. Then $c x_{i} c^{-1}$ is also conjugate to $s_{i}$. Because

$$
c x c^{-1}=\left(c x_{1} c^{-1}\right)\left(c x_{2} c^{-1}\right) \cdots\left(c x_{n} c^{-1}\right)
$$

$c x c^{-1}$ is a product of conjugates of elements of $S$, so that $c x c^{-1} \in N^{\prime}$, as desired.

## Exercises

1. Check the details of Example 1.
2. Let $G=G_{1} * G_{2}$, where $G_{1}$ and $G_{2}$ are nontrivial groups.

(a) Show $G$ is not abelian.

(b) If $x \in G$, define the length of $x$ to be the length of the unique reduced word in the elements of $G_{1}$ and $G_{2}$ that represents $x$. Show that if $x$ has even length (at least 2), then $x$ does not have finite order. Show that if $x$ has odd length, then $x$ is conjugate to an element of shorter length.

(c) Show that the only elements of $G$ that have finite order are the elements of $G_{1}$ and $G_{2}$ that have finite order, and their conjugates.

3. Let $G=G_{1} * G_{2}$. Given $c \in G$, let $c G_{1} c^{-1}$ denote the set of all elements of the form $c x c^{-1}$, for $x \in G_{1}$. It is a subgroup of $G$; show that its intersection with $G_{2}$ consists of the identity alone.
4. Prove Theorem 68.4 .

## §69 Free Groups

Let $G$ be a group; let $\left\{a_{\alpha}\right\}$ be a family of elements of $G$, for $\alpha \in J$. We say the elements $\left\{a_{\alpha}\right\}$ generate $G$ if every element of $G$ can be written as a product of powers of the elements $a_{\alpha}$. If the family $\left\{a_{\alpha}\right\}$ is finite, we say $G$ is finitely generated.

Definition. Let $\left\{a_{\alpha}\right\}$ be a family of elements of a group $G$. Suppose each $a_{\alpha}$ generates an infinite cyclic subgroup $G_{\alpha}$ of $G$. If $G$ is the free product of the groups $\left\{G_{\alpha}\right\}$, then $G$ is said to be a free group, and the family $\left\{a_{\alpha}\right\}$ is called a system of free generators for $G$.

In this case, for each element $x$ of $G$, there is a unique reduced word in the elements of the groups $G_{\alpha}$ that represents $x$. This says that if $x \neq 1$, then $x$ can be written uniquely in the form

$$
x=\left(a_{\alpha_{1}}\right)^{n_{1}} \cdots\left(a_{\alpha_{k}}\right)^{n_{k}}
$$

where $\alpha_{i} \neq \alpha_{i+1}$ and $n_{i} \neq 0$ for each $i$. (Of course, $n_{i}$ may be negative.)

Free groups are characterized by the following extension property:

Lemma 69.1. Let $G$ be a group; let $\left\{a_{\alpha}\right\}_{\alpha \in J}$ be a family of elements of $G$. If $G$ is a free group with system of free generators $\left\{a_{\alpha}\right\}$, then $G$ satisfies the following condition:

Given any group $H$ and any family $\left\{y_{\alpha}\right\}$ of elements of $H$, there is a homomorphism $h: G \rightarrow H$ such that $h\left(a_{\alpha}\right)=y_{\alpha}$ for each $\alpha$.

Furthermore, $h$ is unique. Conversely, if the extension condition (*) holds, then $G$ is a free group with system of free generators $\left\{a_{\alpha}\right\}$.

Proof. If $G$ is free, then for each $\alpha$, the group $G_{\alpha}$ generated by $a_{\alpha}$ is infinite cyclic, so there is a homomorphism $h_{\alpha}: G_{\alpha} \rightarrow H$ with $h_{\alpha}\left(a_{\alpha}\right)=y_{\alpha}$. Then Lemma 68.1 applies. To prove the converse, let $\beta$ be a fixed index. By hypothesis, there exists a homomorphism $h: G \rightarrow \mathbb{Z}$ such that $h\left(a_{\beta}\right)=1$ and $h\left(a_{\alpha}\right)=0$ for $\alpha \neq \beta$. It follows that the group $G_{\beta}$ is infinite cyclic. Then Lemma 68.5 applies. lowing:

The results of the preceding section (in particular, Corollary 68.6) imply the fol-

Theorem 69.2. Let $G=G_{1} * G_{2}$, where $G_{1}$ and $G_{2}$ are free groups with $\left\{a_{\alpha}\right\}_{\alpha \in J}$ and $\left\{a_{\alpha}\right\}_{\alpha \in K}$ as respective systems of free generators. If $J$ and $K$ are disjoint, then $G$ is a free group with $\left\{a_{\alpha}\right\}_{\alpha \in J \cup K}$ as a system of free generators.

Definition. Let $\left\{a_{\alpha}\right\}_{\alpha \in J}$ be an arbitrary indexed family. Let $G_{\alpha}$ denote the set of all symbols of the form $a_{\alpha}^{n}$ for $n \in \mathbb{Z}$. We make $G_{\alpha}$ into a group by defining

$$
a_{\alpha}^{n} \cdot a_{\alpha}^{m}=a_{\alpha}^{n+m} .
$$

Then $a_{\alpha}^{0}$ is the identity element of $G_{\alpha}$, and $a_{\alpha}^{-n}$ is the inverse of $a_{\alpha}^{n}$. We denote $a_{\alpha}^{1}$ simply by $a_{\alpha}$. The external free product of the groups $\left\{G_{\alpha}\right\}$ is called the free group on the elements $a_{\alpha}$.

If $G$ is the free group on the elements $a_{\alpha}$, we normally abuse notation and identify the elements of the group $G_{\alpha}$ with their images under the monomorphism $i_{\alpha}: G_{\alpha} \rightarrow$ $G$ involved in the construction of the external free product. Then each $a_{\alpha}$ is treated as an element of $G$, and the family $\left\{a_{\alpha}\right\}$ forms a system of free generators for $G$.

There is an important connection between free groups and free abelian groups. In order to describe it, we must recall the notion of commutator subgroup from algebra.

Definition. Let $G$ be a group. If $x, y \in G$, we denote by $[x, y]$ the element

$$
[x, y]=x y x^{-1} y^{-1}
$$

of $G$; it is called the commutator of $x$ and $y$. The subgroup of $G$ generated by the set of all commutators in $G$ is called the commutator subgroup of $G$ and denoted $[G, G]$.

The following result may be familiar; we provide a proof, for completeness:

Lemma 69.3. Given $G$, the subgroup $[G, G]$ is a normal subgroup of $G$ and the quotient group $G /[G, G]$ is abelian. If $h: G \rightarrow H$ is any homomorphism from $G$ to an abelian group $H$, then the kernel of $h$ contains $[G, G]$, so $h$ induces a homomorphism $k: G /[G, G] \rightarrow H$.

Proof. Step 1. First we show that any conjugate of a commutator is in $[G, G]$. We compute as follows:

$$
\begin{aligned}
g[x, y] g^{-1} & =g\left(x y x^{-1} y^{-1}\right) g^{-1} \\
& =\left(g x y x^{-1}\right)(1)\left(y^{-1} g^{-1}\right) \\
& =\left(g x y x^{-1}\right)\left(g^{-1} y^{-1} y g\right)\left(y^{-1} g^{-1}\right) \\
& =\left((g x) y(g x)^{-1} y^{-1}\right)\left(y g y^{-1} g^{-1}\right) \\
& =[g x, y] \cdot[y, g],
\end{aligned}
$$

which is in $[G, G]$, as desired.

Step 2. We show that $[G, G]$ is a normal subgroup of $G$. Let $z$ be an arbitrary element of $[G, G]$; we show that any conjugate $g z g^{-1}$ of $z$ is also in $[G, G]$. The element $z$ is a product of commutators and their inverses. Because

$$
[x, y]^{-1}=\left(x y x^{-1} y^{-1}\right)^{-1}=[y, x],
$$

$z$ actually equals a product of commutators. Let $z=z_{1} \cdots z_{n}$, where each $z_{i}$ is a commutator. Then

$$
g z g^{-1}=\left(g z_{1} g^{-1}\right)\left(g z_{2} g^{-1}\right) \cdots\left(g z_{n} g^{-1}\right),
$$

which is a product of elements of $[G, G]$ by Step 1 and hence belongs to $[G, G]$.

Step 3. We show that $G /[G, G]$ is abelian. Let $G^{\prime}=[G, G]$; we wish to show that

$$
\left(a G^{\prime}\right)\left(b G^{\prime}\right)=\left(b G^{\prime}\right)\left(a G^{\prime}\right),
$$

that is, $a b G^{\prime}=b a G^{\prime}$. This is equivalent to the equation

$$
a^{-1} b^{-1} a b G^{\prime}=G^{\prime}
$$

and this equation follows from the fact that $a^{-1} b^{-1} a b=\left[a^{-1}, b^{-1}\right]$, which is an element of $G^{\prime}$.

Step 4. To complete the proof, we note that because $H$ is abelian, $h$ carries each commutator to the identity element of $H$. Hence the kernel of $h$ contains $[G, G]$, so that $h$ induces the desired homomorphism $k$.

Theorem 69.4. If $G$ is a free group with free generators $a_{\alpha}$, then $G /[G, G]$ is a free abelian group with basis $\left[a_{\alpha}\right]$, where $\left[a_{\alpha}\right]$ denotes the coset of $a_{\alpha}$ in $G /[G, G]$.

Proof. We apply Lemma 67.7. Given any family $\left\{y_{\alpha}\right\}$ of elements of the abelian group $H$, there exists a homomorphism $h: G \rightarrow H$ such that $h\left(a_{\alpha}\right)=y_{\alpha}$ for each $\alpha$. Because $H$ is abelian, the kernel of $h$ contains $[G, G]$; therefore $h$ induces a homomorphism $k: G /[G, G] \rightarrow H$ that carries $\left[a_{\alpha}\right]$ to $y_{\alpha}$.

Corollary 69.5. If $G$ is a free group with $n$ free generators, then any system of free generators for $G$ has $n$ elements.

Proof. The free abelian group $G /[G, G]$ has rank $n$.

The properties of free groups are in many ways similar to those of free abelian groups. For instance, if $H$ is a subgroup of a free abelian group $G$, then $H$ itself is a free abelian group. (The proof in the case where $G$ has finite rank is outlined in Exercise 6 of $\S 67$; the proof in the general case is similar.) The analogous result holds for free groups, but the proof is considerably more difficult. We shall give a proof in Chapter 14 that is based on the theory of covering spaces.

In other ways, free groups are very different from free abelian groups. Given a free abelian group of rank $n$, the rank of any subgroup is at most $n$; but the analogous result for free groups does not hold. If $G$ is a free group with a system of $n$ free generators, then the cardinality of a system of free generators for a subgroup of $G$ may be greater than $n$; it may even be infinite! We shall explore this situation later.

## Generators and relations

A basic problem in group theory is to determine, for two given groups, whether or not they are isomorphic. For free abelian groups, the problem is solved; two such groups are isomorphic if and only if they have bases with the same cardinality. Similarly, two free groups are isomorphic if and only if their systems of free generators have the same cardinality. (We have proved these facts in the case of finite cardinality.)

For arbitrary groups, however the answer is not so simple. Only in the case of an abelian group that is finitely generated is there a clear-cut answer.

If $G$ is abelian and finitely generated, then there is a fundamental theorem to the effect that $G$ is the direct sum of two subgroups, $G=H \oplus T$, where $H$ is free abelian of finite rank, and $T$ is the subgroup of $G$ consisting of all elements of finite order. (We call $T$ the torsion subgroup of $G$.) The rank of $H$ is uniquely determined by $G$, since it equals the rank of the quotient of $G$ by its torsion subgroup. This number is often called the betti number of $G$. Furthermore, the subgroup $T$ is itself a direct sum; it is the direct sum of a finite number of finite cyclic groups whose orders are powers of primes. The orders of these groups are uniquely determined by $T$ (and hence by $G$ ), and are called the elementary divisors of $G$. Thus the isomorphism class of $G$ is completely determined by specifying its betti number and its elementary divisors.

If $G$ is not abelian, matters are not nearly so satisfactory, even if $G$ is finitely generated. What can we specify that will determine $G$ ? The best we can do is the following:

Given $G$, suppose we are given a family $\left\{a_{\alpha}\right\}_{\alpha \in J}$ of generators for $G$. Let $F$ be the free group on the elements $\left\{a_{\alpha}\right\}$. Then the obvious map $h\left(a_{\alpha}\right)=a_{\alpha}$ of these elements into $G$ extends to a homomorphism $h: F \rightarrow G$ that is surjective. If $N$ equals the kernel of $h$, then $F / N \cong G$. So one way of specifying $G$ is to give a family $\left\{a_{\alpha}\right\}$ of generators for $G$, and somehow to specify the subgroup $N$. Each element of $N$ is called a relation on $F$, and $N$ is called the relations subgroup. We can specify $N$ by giving a set of generators for $N$. But since $N$ is normal in $F$, we can also specify $N$ by a smaller set. Specifically, we can specify $N$ by giving a family $\left\{r_{\beta}\right\}$ of elements of $F$ such that these elements and their conjugates generate $N$, that is, such that $N$ is
the least normal subgroup of $F$ that contains the elements $r_{\beta}$. In this case, we call the family $\left\{r_{\beta}\right\}$ a complete set of relations for $G$.

Each element of $N$ belongs to $F$, so it can of course be represented uniquely by a reduced word in powers of the generators $\left\{a_{\alpha}\right\}$. When we speak of a relation on the generators of $G$, we sometimes refer to this reduced word, rather than to the element of $N$ it represents. The context will make the meaning clear.

Definition. If $G$ is a group, a presentation of $G$ consists of a family $\left\{a_{\alpha}\right\}$ of generators for $G$, along with a complete set $\left\{r_{\beta}\right\}$ of relations for $G$, where each $r_{\beta}$ is an element of the free group on the set $\left\{a_{\alpha}\right\}$. If the family $\left\{a_{\alpha}\right\}$ is finite, then $G$ is finitely generated, of course. If both the families $\left\{a_{\alpha}\right\}$ and $\left\{r_{\beta}\right\}$ are finite, then $G$ is said to be finitely presented, and these families form what is called a finite presentation for $G$.

This procedure for specifying $G$ is far from satisfactory. A presentation for $G$ does determine $G$ uniquely, up to isomorphism; but two completely different presentations can lead to groups that are isomorphic. Furthermore, even in the finite case there is no effective procedure for determining, from two different presentations, whether or not the groups they determine are isomorphic. This result is known as the "unsolvability of the isomorphism problem" for groups.

Unsatisfactory as it is, this is the best we can do!

## Exercises

1. If $G=G_{1} * G_{2}$, show that

$$
G /[G, G] \cong\left(G_{1} /\left[G_{1}, G_{1}\right]\right) \oplus\left(G_{2} /\left[G_{2}, G_{2}\right]\right) .
$$

[Hint: Use the extension condition for direct sums and free products to define homomorphisms

$$
G /[G, G] \rightleftarrows\left(G_{1} /\left[G_{1}, G_{1}\right]\right) \oplus\left(G_{2} /\left[G_{2}, G_{2}\right]\right)
$$

that are inverse to each other.]

2. Generalize the result of Exercise 1 to arbitrary free products.
3. Prove the following:

Theorem. Let $G=G_{1} * G_{1}$, where $G_{1}$ and $G_{2}$ are cyclic of orders $m$ and $n$, respectively. Then $m$ and $n$ are uniquely determined by $G$.

Proof.

(a) Show $G /[G, G]$ has order $m n$.

(b) Determine the largest integer $k$ such that $G$ has an element of order $k$. (See Exercise 2 of $\S 68$.)

(c) Prove the theorem.

4. Show that if $G=G_{1} \oplus G_{2}$, where $G_{1}$ and $G_{2}$ are cyclic of orders $m$ and $n$, respectively, then $m$ and $n$ are not uniquely determined by $G$ in general. [Hint: If $m$ and $n$ are relatively prime, show that $G$ is cyclic of order $m n$.]

## §70 The Seifert-van Kampen Theorem

We now return to the problem of determining the fundamental group of a space $X$ that is written as the union of two open subsets $U$ and $V$ having path-connected intersection. We showed in $\S 59$ that, if $x_{0} \in U \cap V$, the images of the two groups $\pi_{1}\left(U, x_{0}\right)$ and $\pi_{1}\left(V, x_{0}\right)$ in $\pi_{1}\left(X, x_{0}\right)$, under the homomorphisms induced by inclusion, generate the latter group. In this section, we show that $\pi_{1}\left(X, x_{0}\right)$ is, in fact, completely determined by these two groups, the group $\pi_{1}\left(U \cap V, x_{0}\right)$, and the various homomorphisms of these groups induced by inclusion. This is a basic result about fundamental groups. It will enable us to compute the fundamental groups of a number of spaces, including the compact 2-manifolds.

Theorem 70.1 (Seifert-van Kampen theorem). Let $X=U \cup V$, where $U$ and $V$ are open in $X$; assume $U, V$, and $U \cap V$ are path connected; let $x_{0} \in U \cap V$. Let $H$ be a group, and let

$$
\phi_{1}: \pi_{1}\left(U, x_{0}\right) \longrightarrow H \quad \text { and } \quad \phi_{2}: \pi_{1}\left(V, x_{0}\right) \longrightarrow H
$$

be homomorphisms. Let $i_{1}, i_{2}, j_{1}, j_{2}$ be the homomorphisms indicated in the following diagram, each induced by inclusion.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-425.jpg?height=314&width=622&top_left_y=1192&top_left_x=885)

If $\phi_{1} \circ i_{1}=\phi_{2} \circ i_{2}$, then there is a unique homomorphism $\Phi: \pi_{1}\left(X, x_{0}\right) \rightarrow H$ such that $\Phi \circ j_{1}=\phi_{1}$ and $\Phi \circ j_{2}=\phi_{2}$.

This theorem says that if $\phi_{1}$ and $\phi_{2}$ are arbitrary homomorphisms that are "compatible on $U \cap V$," then they induce a homomorphism of $\pi_{1}\left(X, x_{0}\right)$ into $H$.

Proof. Uniqueness is easy. Theorem 59.1 tells us that $\pi_{1}\left(X, x_{0}\right)$ is generated by the images of $j_{1}$ and $j_{2}$. The value of $\Phi$ on the generator $j_{1}\left(g_{1}\right)$ must equal $\phi_{1}\left(g_{1}\right)$, and its value on $j_{2}\left(g_{2}\right)$ must equal $\phi_{2}\left(g_{2}\right)$. Hence $\Phi$ is completely determined by $\phi_{1}$ and $\phi_{2}$. To show $\Phi$ exists is another matter!

For convenience, we introduce the following notation: Given a path $f$ in $X$, we shall use $[f]$ to denote its path-homotopy class in $X$. If $f$ happens to lie in $U$, then $[f]_{U}$ is used to denote its path-homotopy class in $U$. The notations $[f]_{V}$ and $[f]_{U \cap V}$ are defined similarly.

Step 1. We begin by defining a set map $\rho$ that assigns, to each loop $f$ based at $x_{0}$ that lies in $U$ or in $V$, an element of the group $H$. We define

$$
\begin{array}{ll}
\rho(f)=\phi_{1}\left([f]_{U}\right) & \text { if } f \text { lies in } U \\
\rho(f)=\phi_{2}\left([f]_{V}\right) & \text { if } f \text { lies in } V .
\end{array}
$$

Then $\rho$ is well-defined, for if $f$ lies in both $U$ and $V$,

$$
\phi_{1}\left([f]_{U}\right)=\phi_{1} i_{1}\left([f]_{U \cap V}\right) \quad \text { and } \quad \phi_{2}\left([f]_{V}\right)=\phi_{2} i_{2}\left([f]_{U \cap V}\right)
$$

and these two elements of $H$ are equal by hypothesis. The set map $\rho$ satisfies the following conditions:

(1) If $[f]_{U}=[g]_{U}$, or if $[f]_{V}=[g]_{V}$, then $\rho(f)=\rho(g)$.

(2) If both $f$ and $g$ lie in $U$, or if both lie in $V$, then $\rho(f * g)=\rho(f) \cdot \rho(g)$.

The first holds by definition, and the second holds because $\phi_{1}$ and $\phi_{2}$ are homomorphisms.

Step 2. We now extend $\rho$ to a set map $\sigma$ that assigns, to each path $f$ lying in $U$ or $V$, an element of $H$, such that the map $\sigma$ satisfies condition (1) of Step 1, and satisfies (2) when $f * g$ is defined.

To begin, we choose, for each $x$ in $X$, a path $\alpha_{x}$ from $x_{0}$ to $x$, as follows: If $x=x_{0}$, let $\alpha_{x}$ be the constant path at $x_{0}$. If $x \in U \cap V$, let $\alpha_{x}$ be a path in $U \cap V$. And if $x$ is in $U$ or $V$ but not in $U \cap V$, let $\alpha_{x}$ be a path in $U$ or $V$, respectively.

Then, for any path $f$ in $U$ or in $V$, we define a loop $L(f)$ in $U$ or $V$, respectively, based at $x_{0}$, by the equation

$$
L(f)=\alpha_{x} *\left(f * \bar{\alpha}_{y}\right)
$$

where $x$ is the initial point of $f$ and $y$ is the final point of $f$. See Figure 70.1. Finally, we define

$$
\sigma(f)=\rho(L(f)) .
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-426.jpg?height=605&width=847&top_left_y=1610&top_left_x=598)

Figure 70.1

First, we show that $\sigma$ is an extension of $\rho$. If $f$ is a loop based at $x_{0}$ lying in either $U$ or $V$, then

$$
L(f)=e_{x_{0}} *\left(f * e_{x_{0}}\right)
$$

because $\alpha_{x_{0}}$ is the constant path at $x_{0}$. Then $L(f)$ is path homotopic to $f$ in either $U$ or $V$, so that $\rho(L(f))=\rho(f)$ by condition (1) for $\rho$. Hence $\sigma(f)=\rho(f)$.

To check condition (1), let $f$ and $g$ be paths that are path homotopic in $U$ or in $V$. Then the loops $L(f)$ and $L(g)$ are also path homotopic either in $U$ or in $V$, so condition (1) for $\rho$ applies. To check (2), let $f$ and $g$ be arbitrary paths in $U$ or in $V$ such that $f(1)=g(0)$. We have

$$
L(f) * L(g)=\left(\alpha_{x} *\left(f * \bar{\alpha}_{y}\right)\right) *\left(\alpha_{y} *\left(g * \bar{\alpha}_{z}\right)\right)
$$

for appropriate points $x, y$, and $z$; this loop is path homotopic in $U$ or $V$ to $L(f * g)$. Then

$$
\rho(L(f * g))=\rho(L(f) * L(g))=\rho(L(f)) \cdot \rho(L(g))
$$

by conditions (1) and (2) for $\rho$. Hence $\sigma(f * g)=\sigma(f) \cdot \sigma(g)$.

Step 3. Finally, we extend $\sigma$ to a set map $\tau$ that assigns, to an arbitrary path $f$ of $X$, an element of $H$. It will satisfy the following conditions:

(1) If $[f]=[g]$, then $\tau(f)=\tau(g)$.

(2) $\tau(f * g)=\tau(f) \cdot \tau(g)$ if $f * g$ is defined.

Given $f$, choose a subdivision $s_{0}<\cdots<s_{n}$ of [0,1] such that $f$ maps each of the subintervals $\left[s_{i-1}, s_{i}\right]$ into $U$ or $V$. Let $f_{i}$ denote the positive linear map of $[0,1]$ onto $\left[s_{i-1}, s_{i}\right]$, followed by $f$. Then $f_{i}$ is a path in $U$ or in $V$, and

$$
[f]=\left[f_{1}\right] * \cdots *\left[f_{n}\right] .
$$

If $\tau$ is to be an extension of $\sigma$ and satisfy (1) and (2), we must have

$$
\begin{equation*}
\tau(f)=\sigma\left(f_{1}\right) \cdot \sigma\left(f_{2}\right) \cdots \sigma\left(f_{n}\right) . \tag{*}
\end{equation*}
$$

So we shall use this equation as our definition of $\tau$.

We show that this definition is independent of the choice of subdivision. It suffices to show that the value of $\tau(f)$ remains unchanged if we adjoin a single additional point $p$ to the subdivision. Let $i$ be the index such that $s_{i-1}<p<s_{i}$. If we compute $\tau(f)$ using this new subdivision, the only change in formula $(*)$ is that the factor $\sigma\left(f_{i}\right)$ disappears and is replaced by the product $\sigma\left(f_{i}^{\prime}\right) \cdot \sigma\left(f_{i}^{\prime \prime}\right)$, where $f_{i}^{\prime}$ and $f_{i}^{\prime \prime}$ equal the positive linear maps of $[0,1]$ to $\left[s_{i-1}, p\right]$ and to $\left[p, s_{i}\right]$, respectively, followed by $f$. But $f_{i}$ is path homotopic to $f_{i}^{\prime} * f_{i}^{\prime \prime}$ in $U$ or $V$, so that $\sigma\left(f_{i}\right)=\sigma\left(f_{i}^{\prime}\right) \cdot \sigma\left(f_{i}^{\prime \prime}\right)$, by conditions (1) and (2) for $\sigma$. Thus $\tau$ is well-defined.

It follows that $\tau$ is an extension of $\sigma$. For if $f$ already lies in $U$ or $V$, we can use the trivial partition of $[0,1]$ to define $\tau(f)$; then $\tau(f)=\sigma(f)$ by definition.

Step 4. We prove condition (1) for the set map $\tau$. This part of the proof requires some care.

We first verify this condition in a special case. Let $f$ and $g$ be paths in $X$ from $x$ to $y$, say, and let $F$ be a path homotopy between them. Let us assume the additional hypothesis that there exists a subdivision $s_{0}, \ldots, s_{n}$ of $[0,1]$ such that $F$ carries each rectangle $R_{i}=\left[s_{i-1}, s_{i}\right] \times I$ into either $U$ or $V$. We show in this case that $\tau(f)=$ $\tau(g)$.

Given $i$, consider the positive linear map of $[0,1]$ onto $\left[s_{i-1}, s_{i}\right]$ followed by $f$ or by $g$; and call these two paths $f_{i}$ and $g_{i}$, respectively. The restriction of $F$ to the rectangle $R_{i}$ gives us a homotopy between $f_{i}$ and $g_{i}$ that takes place in either $U$ or $V$, but it is not a path homotopy because the end points of the paths may move during the homotopy. Let us consider the paths traced out by these end points during the homotopy. We define $\beta_{i}$ to be the path $\beta_{i}(t)=F\left(s_{i}, t\right)$. Then $\beta_{i}$ is a path in $X$ from $f\left(s_{i}\right)$ to $g\left(s_{i}\right)$. The paths $\beta_{0}$ and $\beta_{n}$ are the constant paths at $x$ and $y$, respectively. See Figure 70.2. We show that for each $i$,

$$
f_{i} * \beta_{i} \simeq{ }_{p} \beta_{i-1} * g_{i},
$$

with the path homotopy taking place in $U$ or in $V$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-428.jpg?height=475&width=1156&top_left_y=1172&top_left_x=441)

Figure 70.2

In the rectangle $R_{i}$, take the broken-line path that runs along the bottom and right edges of $R_{i}$, from $s_{i-1} \times 0$ to $s_{i} \times 0$ to $s_{i} \times 1$; if we follow this path by the map $F$, we obtain the path $f_{i} * \beta_{i}$. Similarly, if we take the broken-line path along the left and top edges of $R_{i}$ and follow it by $F$, we obtain the path $\beta_{i-1} * g_{i}$. Because $R_{i}$ is convex, there is a path homotopy in $R_{i}$ between these two broken-line paths; if we follow by $F$, we obtain a path homotopy between $f_{i} * \beta_{i}$ and $\beta_{i-1} * g_{i}$ that takes place in either $U$ or $V$, as desired.

It follows from conditions (1) and (2) for $\sigma$ that

$$
\sigma\left(f_{i}\right) \cdot \sigma\left(\beta_{i}\right)=\sigma\left(\beta_{i-1}\right) \cdot \sigma\left(g_{i}\right),
$$

so that

$$
\begin{equation*}
\sigma\left(f_{i}\right)=\sigma\left(\beta_{i-1}\right) \cdot \sigma\left(g_{i}\right) \cdot \sigma\left(\beta_{i}\right)^{-1} \tag{**}
\end{equation*}
$$

It follows similarly that since $\beta_{0}$ and $\beta_{n}$ are constant paths, $\sigma\left(\beta_{0}\right)=\sigma\left(\beta_{n}\right)=1$. (For the fact that $\beta_{0} * \beta_{0}=\beta_{0}$ implies that $\sigma\left(\beta_{0}\right) \cdot \sigma\left(\beta_{0}\right)=\sigma\left(\beta_{0}\right)$.)

We now compute as follows:

$$
\tau(f)=\sigma\left(f_{1}\right) \cdot \sigma\left(f_{2}\right) \cdots \sigma\left(f_{n}\right) .
$$

Substituting $(* *)$ in this equation and simplifying, we have the equation

$$
\begin{aligned}
\tau(f) & =\sigma\left(g_{1}\right) \cdot \sigma\left(g_{2}\right) \cdots \sigma\left(g_{n}\right) \\
& =\tau(g)
\end{aligned}
$$

Thus, we have proved condition (1) in our special case.

Now we prove condition (1) in the general case. Given $f$ and $g$ and a path homotopy $F$ between them, let us choose subdivisions $s_{0}, \ldots, s_{n}$ and $t_{0}, \ldots, t_{m}$ of $[0,1]$ such that $F$ maps each subrectangle $\left[s_{i-1}, s_{i}\right] \times\left[t_{j-1}, t_{j}\right]$ into either $U$ or $V$. Let $f_{j}$ be the path $f_{j}(s)=F\left(s, t_{j}\right)$; then $f_{0}=f$ and $f_{m}=g$. The pair of paths $f_{j-1}$ and $f_{j}$ satisfy the requirements of our special case, so that $\tau\left(f_{j-1}\right)=\tau\left(f_{j}\right)$ for each $j$. It follows that $\tau(f)=\tau(g)$, as desired.

Step 5. Now we prove condition (2) for the set map $\tau$. Given a path $f * g$ in $X$, let us choose a subdivision $s_{0}<\cdots<s_{n}$ of [0,1] containing the point $1 / 2$ as a subdivision point, such that $f * g$ carries each subinterval into either $U$ or $V$. Let $k$ be the index such that $s_{k}=1 / 2$.

For $i=1, \ldots, k$, the positive linear map of $[0,1]$ to $\left[s_{i-1}, s_{i}\right]$, followed by $f * g$, is the same as the positive linear map of $[0,1]$ to $\left[2 s_{i-1}, 2 s_{i}\right]$ followed by $f$; call this map $f_{i}$. Similarly, for $i=k+1, \ldots, n$, the positive linear map of $[0,1]$ to $\left[s_{i-1}, s_{i}\right]$, followed by $f * g$, is the same as the positive linear map of $[0,1]$ to $\left[2 s_{i-1}-1,2 s_{i}-1\right]$ followed by $g$; call this map $g_{i-k}$. Using the subdivision $s_{0}, \ldots, s_{n}$ for the domain of the path $f * g$, we have

$$
\tau(f * g)=\sigma\left(f_{1}\right) \cdots \sigma\left(f_{k}\right) \cdot \sigma\left(g_{1}\right) \cdots \sigma\left(g_{n-k}\right) .
$$

Using the subdivision $2 s_{0}, \ldots, 2 s_{k}$ for the path $f$, we have

$$
\tau(f)=\sigma\left(f_{1}\right) \cdots \sigma\left(f_{k}\right) .
$$

And using the subdivision $2 s_{k}-1, \ldots, 2 s_{n}-1$ for the path $g$, we have

$$
\tau(g)=\sigma\left(g_{1}\right) \cdots \sigma\left(g_{n-k}\right) .
$$

Thus (2) holds trivially.

Step 6. The theorem follows. For each loop $f$ in $X$ based at $x_{0}$, we define

$$
\Phi([f])=\tau(f)
$$

Conditions (1) and (2) show that $\Phi$ is a well-defined homomorphism.

Let us show that $\Phi \circ j_{1}=\phi_{1}$. If $f$ is a loop in $U$, then

$$
\begin{aligned}
\Phi\left(j_{1}\left([f]_{U}\right)\right) & =\Phi([f]) \\
& =\tau(f) \\
& =\rho(f)=\phi_{1}\left([f]_{U}\right)
\end{aligned}
$$

as desired. The proof that $\Phi \circ j_{2}=\phi_{2}$ is similar.

The preceding theorem is the modern formulation of the Seifert-van Kampen theorem. We now turn to the classical version, which involves the free product of two groups. Recall that if $G$ is the external free product $G=G_{1} * G_{2}$, we often treat $G_{1}$ and $G_{2}$ as if they were subgroups of $G$, for simplicity of notation.

Theorem 70.2 (Seifert-van Kampen theorem, classical version). Assume the hypotheses of the preceding theorem. Let

$$
j: \pi_{1}\left(U, x_{0}\right) * \pi_{1}\left(V, x_{0}\right) \longrightarrow \pi_{1}\left(X, x_{0}\right)
$$

be the homomorphism of the free product that extends the homomorphisms $j_{1}$ and $j_{2}$ induced by inclusion. Then $j$ is surjective, and its kernel is the least normal subgroup $N$ of the free product that contains all elements represented by words of the form

$$
\left(i_{1}(g)^{-1}, i_{2}(g)\right) \text {, }
$$

for $g \in \pi_{1}\left(U \cap V, x_{0}\right)$.

Said differently, the kernel of $j$ is generated by all elements of the free product of the form $i_{1}(g)^{-1} i_{2}(g)$, and their conjugates.

Proof. The fact that $\pi_{1}\left(X, x_{0}\right)$ is generated by the images of $j_{1}$ and $j_{2}$ implies that $j$ is surjective.

We show that $N \subset \operatorname{ker} j$. Since ker $j$ is normal, it is enough to show that $i_{1}(g)^{-1} i_{2}(g)$ belongs to ker $j$ for each $g \in \pi_{1}\left(U \cap V, x_{0}\right)$. If $i: U \cap V \rightarrow X$ is the inclusion mapping, then

$$
j i_{1}(g)=j_{1} i_{1}(g)=i_{*}(g)=j_{2} i_{2}(g)=j i_{2}(g) .
$$

Then $i_{1}(g)^{-1} i_{2}(g)$ belongs to the kernel of $j$.

It follows that $j$ induces an epimorphism

$$
k: \pi_{1}\left(U, x_{0}\right) * \pi_{1}\left(V, x_{0}\right) / N \longrightarrow \pi_{1}\left(X, x_{0}\right) .
$$

We show that $N$ equals ker $j$ by showing that $k$ is injective. It suffices to show that $k$ has a left inverse.

Let $H$ denote the group $\pi_{1}\left(U, x_{0}\right) * \pi_{1}\left(V, x_{0}\right) / N$. Let $\phi_{1}: \pi_{1}\left(U, x_{0}\right) \rightarrow H$ equal the inclusion of $\pi_{1}\left(U, x_{0}\right)$ into the free product followed by projection of the free product onto its quotient by $N$. Let $\phi_{2}: \pi_{1}\left(V, x_{0}\right) \rightarrow H$ be defined similarly. Consider the diagram

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-430.jpg?height=316&width=619&top_left_y=1971&top_left_x=712)

It is easy to see that $\phi_{1} \circ i_{1}=\phi_{2} \circ i_{2}$. For if $g \in \pi_{1}\left(U \cap V, x_{0}\right)$, then $\phi_{1}\left(i_{1}(g)\right)$ is the coset $i_{1}(g) N$ in $H$, and $\phi_{2}\left(i_{2}(g)\right)$ is the coset $i_{2}(g) N$. Because $i_{1}(g)^{-1} i_{2}(g) \in N$, these cosets are equal.

It follows from Theorem 70.1 that there is a homomorphism $\Phi: \pi_{1}\left(X, x_{0}\right) \rightarrow H$ such that $\Phi \circ j_{1}=\phi_{1}$ and $\Phi \circ j_{2}=\phi_{2}$. We show that $\Phi$ is a left inverse for $k$. It suffices to show that $\Phi \circ k$ acts as the identity on any generator of $H$, that is, on any coset of the form $g N$, where $g$ is in $\pi_{1}\left(U, x_{0}\right)$ or $\pi_{1}\left(V, x_{0}\right)$. But if $g \in \pi_{1}\left(U, x_{0}\right)$, we have

$$
k(g N)=j(g)=j_{1}(g)
$$

so that

$$
\Phi(k(g N))=\Phi\left(j_{1}(g)\right)=\phi_{1}(g)=g N,
$$

as desired. A similar remark applies if $g \in \pi_{1}\left(V, x_{0}\right)$.

Corollary 70.3. Assume the hypotheses of the Seifert-van Kampen theorem. If $U \cap V$ is simply connected, then there is an isomorphism

$$
k: \pi_{1}\left(U, x_{0}\right) * \pi_{1}\left(V, x_{0}\right) \longrightarrow \pi_{1}\left(X, x_{0}\right) .
$$

Corollary 70.4. Assume the hypotheses of the Seifert-van Kampen theorem. If $V$ is simply connected, there is an isomorphism

$$
k: \pi_{1}\left(U, x_{0}\right) / N \longrightarrow \pi_{1}\left(X, x_{0}\right),
$$

where $N$ is the least normal subgroup of $\pi_{1}\left(U, x_{0}\right)$ containing the image of the homomorphism

$$
i_{1}: \pi_{1}\left(U \cap V, x_{0}\right) \rightarrow \pi_{1}\left(U, x_{0}\right) .
$$

EXAmple 1. Let $X$ be a theta-space. Then $X$ is a Hausdorff space that is the union of three $\operatorname{arcs} A, B$, and $C$, each pair of which intersect precisely in their end points $p$ and $q$. We showed earlier that the fundamental group of $X$ is not abelian. We show here that this group is in fact a free group on two generators.

Let $a$ be an interior point of $A$ and let $b$ be an interior point of $B$. Write $X$ as the union of the open sets $U=X-a$ and $V=X-b$. See Figure 70.3. The space $U \cap V=X-a-b$ is simply connected because it is contractible. Furthermore, $U$ and $V$ have infinite cyclic fundamental groups, because $U$ has the homotopy type of $B \cup C$ and $V$ has the homotopy type of $A \cup C$. Therefore, the fundamental group of $X$ is the free product of two infinite cyclic groups, that is, it is a free group on two generators.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-432.jpg?height=469&width=461&top_left_y=371&top_left_x=791)

Figure 70.3

## Exercises

In the following exercises, assume the hypotheses of the Seifert-van Kampen theorem.

1. Suppose that the homomorphism $i_{*}$ induced by inclusion $i: U \cap V \rightarrow X$ is trivial.

(a) Show that $j_{1}$ and $j_{2}$ induce an epimorphism

$$
h:\left(\pi_{1}\left(U, x_{0}\right) / N_{1}\right) *\left(\pi_{1}\left(V, x_{0}\right) / N_{2}\right) \longrightarrow \pi_{1}\left(X, x_{0}\right),
$$

where $N_{1}$ is the least normal subgroup of $\pi_{1}\left(U, x_{0}\right)$ containing image $i_{1}$, and $N_{2}$ is the least normal subgroup of $\pi_{1}\left(V, x_{0}\right)$ containing image $i_{2}$.

(b) Show that $h$ is an isomorphism. [Hint: Use Theorem 70.1 to define a left inverse for $h$.]

2. Suppose that $i_{2}$ is surjective.

(a) Show that $j_{1}$ induces an epimorphism

$$
h: \pi_{1}\left(U, x_{0}\right) / M \longrightarrow \pi_{1}\left(X, x_{0}\right),
$$

where $M$ is the least normal subgroup of $\pi_{1}\left(U, x_{0}\right)$ containing $i_{1}\left(\operatorname{ker} i_{2}\right)$. [Hint: Show $j_{1}$ is surjective.]

(b) Show that $h$ is an isomorphism. [Hint: Let $H=\pi_{1}\left(U, x_{0}\right) / M$. Let $\phi_{1}$ : $\pi_{1}\left(U, x_{0}\right) \rightarrow H$ be the projection. Use the fact that $\pi_{1}\left(U \cap V, x_{0}\right) /$ ker $i_{2}$ is isomorphic to $\pi_{1}\left(V, x_{0}\right)$ to define a homomorphism $\phi_{2}: \pi_{1}\left(V, x_{0}\right) \rightarrow H$. Use Theorem 70.1 to define a left inverse for $h$.]

3. (a) Show that if $G_{1}$ and $G_{2}$ have finite presentations, so does $G_{1} * G_{2}$.

(b) Show that if $\pi_{1}\left(U \cap V, x_{0}\right)$ is finitely generated and $\pi_{1}\left(U, x_{0}\right)$ and $\pi_{1}\left(V, x_{0}\right)$ have finite presentations, then $\pi_{1}\left(X, x_{0}\right)$ has a finite presentation. [Hint: If $N^{\prime}$ is a normal subgroup of $\pi_{1}\left(U, x_{0}\right) * \pi_{1}\left(V, x_{0}\right)$ that contains the elements $i_{1}\left(g_{i}\right)^{-1} i_{2}\left(g_{i}\right)$ where $g_{i}$ runs over a set of generators for $\pi_{1}\left(U \cap V, x_{0}\right)$, then $N^{\prime}$ contains $i_{1}(g)^{-1} i_{2}(g)$ for arbitrary $g$.]

## §71 The Fundamental Group of a Wedge of Circles

In this section, we define what we mean by a wedge of circles, and we compute its fundamental group.

Definition. Let $X$ be a Hausdorff space that is the union of the subspaces $S_{1}, \ldots, S_{n}$, each of which is homeomorphic to the unit circle $S^{1}$. Assume that there is a point $p$ of $X$ such that $S_{i} \cap S_{j}=\{p\}$ whenever $i \neq j$. Then $X$ is called the wedge of the circles $S_{1}, \ldots, S_{n}$.

Note that each space $S_{i}$, being compact, is closed in $X$. Note also that $X$ can be imbedded in the plane; if $C_{i}$ denotes the circle of radius $i$ in $\mathbb{R}^{2}$ with center at $(i, 0)$, then $X$ is homeomorphic to $C_{1} \cup \cdots \cup C_{n}$.

Theorem 71.1. Let $X$ be the wedge of the circles $S_{1}, \ldots, S_{n}$; let $p$ be the common point of these circles. Then $\pi_{1}(X, p)$ is a free group. If $f_{i}$ is a loop in $S_{i}$ that represents a generator of $\pi_{1}\left(S_{i}, p\right)$, then the loops $f_{1}, \ldots, f_{n}$ represent a system of free generators for $\pi_{1}(X, p)$.

Proof. The result is immediate if $n=1$. We proceed by induction on $n$. The proof is similar to the one given in Example 1 of the preceding section.

Let $X$ be the wedge of the circles $S_{1}, \ldots, S_{n}$, with $p$ the common point of these circles. Choose a point $q_{i}$ of $S_{i}$ different from $p$, for each $i$. Set $W_{i}=S_{i}-q_{i}$, and let

$$
U=S_{1} \cup W_{2} \cup \cdots \cup W_{n} \quad \text { and } \quad V=W_{1} \cup S_{2} \cup \cdots \cup S_{n} \text {. }
$$

Then $U \cap V=W_{1} \cup \cdots \cup W_{n}$. See Figure 71.1. Each of the spaces $U, V$, and $U \cap V$ is path connected, being the union of path-connected spaces having a point in common.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-433.jpg?height=252&width=313&top_left_y=1617&top_left_x=665)

U

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-433.jpg?height=267&width=310&top_left_y=1601&top_left_x=1044)

$U \cap V$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-433.jpg?height=250&width=314&top_left_y=1618&top_left_x=1414)

V

Figure 71.1

The space $W_{i}$ is homeomorphic to an open interval, so it has the point $p$ as a deformation retract; let $F_{i}: W_{i} \times I \rightarrow W_{i}$ be the deformation retraction. The maps $F_{i}$ fit together to define a map $F:(U \cap V) \times I \rightarrow U \cap V$ that is a deformation retraction of $U \cap V$ onto $p$. (To show that $F$ is continuous, we note that because $S_{i}$ is a closed subspace of $X$, the space $W_{i}=S_{i}-q_{i}$ is a closed subspace of $U \cap V$, so that $W_{i} \times I$
is a closed subspace of $(U \cap V) \times I$. Then the pasting lemma applies.) It follows that $U \cap V$ is simply connected, so that $\pi_{1}(X, p)$ is the free product of the groups $\pi_{1}(U, p)$ and $\pi_{1}(V, p)$, relative to the monomorphisms induced by inclusion.

A similar argument shows that $S_{1}$ is a deformation retract of $U$ and $S_{2} \cup \cdots \cup S_{n}$ is a deformation retract of $V$. It follows that $\pi_{1}(U, p)$ is infinite cyclic, and the loop $f_{1}$ represents a generator. It also follows, using the induction hypothesis, that $\pi_{1}(V, p)$ is a free group, with the loops $f_{2}, \ldots, f_{n}$ representing a system of free generators. Our theorem now follows from Theorem 69.2.

We generalize this result to a space $X$ that is the union of infinitely many circles having a point in common. Here we must be careful about the topology of $X$.

Definition. Let $X$ be a space that is the union of the subspaces $X_{\alpha}$, for $\alpha \in J$. The topology of $X$ is said to be coherent with the subspaces $X_{\alpha}$ provided a subset $C$ of $X$ is closed in $X$ if $C \cap X_{\alpha}$ is closed in $X_{\alpha}$ for each $\alpha$. An equivalent condition is that a set be open in $X$ if its intersection with each $X_{\alpha}$ is open in $X_{\alpha}$.

If $X$ is the union of finitely many closed subspaces $X_{1}, \ldots, X_{n}$, then the topology of $X$ is automatically coherent with these subspaces, since if $C \cap X_{i}$ is closed in $X_{i}$, it is closed in $X$, and $C$ is the finite union of the sets $C \cap X_{i}$.

Definition. Let $X$ be a space that is the union of the subspaces $S_{\alpha}$, for $\alpha \in J$, each of which is homeomorphic to the unit circle. Assume there is a point $p$ of $X$ such that $S_{\alpha} \cap S_{\beta}=\{p\}$ whenever $\alpha \neq \beta$. If the topology of $X$ is coherent with the subspaces $S_{\alpha}$, then $X$ is called the wedge of the circles $S_{\alpha}$.

In the finite case, the definition involved the Hausdorff condition instead of the coherence condition; in that case the coherence condition followed. In the infinite case, this would no longer be true, so we included the coherence condition as part of the definition. We would include the Hausdorff condition as well, but that is no longer necessary, for it follows from the coherence condition:

Lemma 71.2. Let $X$ be the wedge of the circles $S_{\alpha}$, for $\alpha \in J$. Then $X$ is normal. Furthermore, any compact subspace of $X$ is contained in the union of finitely many circles $S_{\alpha}$.

Proof. It is clear that one-point sets are closed in $X$. Let $A$ and $B$ be disjoint closed subsets of $X$; assume that $B$ does not contain $p$. Choose disjoint subsets $U_{\alpha}$ and $V_{\alpha}$ of $S_{\alpha}$ that are open in $S_{\alpha}$ and contain $\{p\} \cup\left(A \cap S_{\alpha}\right)$ and $B \cap S_{\alpha}$, respectively. Let $U=\bigcup U_{\alpha}$ and $V=\bigcup V_{\alpha}$; then $U$ and $V$ are disjoint. Now $U \cap S_{\alpha}=U_{\alpha}$ because all the sets $U_{\alpha}$ contain $p$, and $V \cap S_{\alpha}=V_{\alpha}$ because no set $V_{\alpha}$ contains $p$. Hence $U$ and $V$ are open in $X$, as desired. Thus $X$ is normal.

Now let $C$ be a compact subspace of $X$. For each $\alpha$ for which it is possible, choose a point $x_{\alpha}$ of $C \cap\left(S_{\alpha}-p\right)$. The set $D=\left\{x_{\alpha}\right\}$ is closed in $X$, because its intersection with each space $S_{\alpha}$ is a one-point set or is empty. For the same reason, each subset
of $D$ is closed in $X$. Thus $D$ is a closed discrete subspace of $X$ contained in $C$; since $C$ is limit point compact, $D$ must be finite.

Theorem 71.3. Let $X$ be the wedge of the circles $S_{\alpha}$, for $\alpha \in J$; let $p$ be the common point of these circles. Then $\pi_{1}(X, p)$ is a free group. If $f_{\alpha}$ is a loop in $S_{\alpha}$ representing a generator of $\pi_{1}\left(S_{\alpha}, p\right)$, then the loops $\left\{f_{\alpha}\right\}$ represent a system of free generators for $\pi_{1}(X, p)$.

Proof. Let $i_{\alpha}: \pi_{1}\left(S_{\alpha}, p\right) \rightarrow \pi_{1}(X, p)$ be the homomorphism induced by inclusion; let $G_{\alpha}$ be the image of $i_{\alpha}$.

Note that if $f$ is any loop in $X$ based at $p$, then the image set of $f$ is compact, so that $f$ lies in some finite union of subspaces $S_{\alpha}$. Furthermore, if $f$ and $g$ are two loops that are path homotopic in $X$, then they are actually path homotopic in some finite union of the subspaces $S_{\alpha}$.

It follows that the groups $\left\{G_{\alpha}\right\}$ generate $\pi_{1}(X, p)$. For if $f$ is a loop in $X$, then $f$ lies in $S_{\alpha_{1}} \cup \cdots \cup S_{\alpha_{n}}$ for some finite set of indices; then Theorem 71.1 implies that $[f]$ is a product of elements of the groups $G_{\alpha_{1}}, \ldots, G_{\alpha_{n}}$. Similarly, it follows that $i_{\beta}$ is a monomorphism. For if $f$ is a loop in $S_{\beta}$ that is path homotopic in $X$ to a constant, then $f$ is path homotopic to a constant in some finite union of spaces $S_{\alpha}$, so that Theorem 71.1 implies that $f$ is path homotopic to a constant in $S_{\beta}$.

Finally, suppose there is a reduced nonempty word

$$
w=\left(g_{\alpha_{1}} \ldots, g_{\alpha_{n}}\right)
$$

in the elements of the groups $G_{\alpha}$ that represents the identity element of $\pi_{1}(X, p)$. Let $f$ be a loop in $X$ whose path-homotopy class is represented by $w$. Then $f$ is path homotopic to a constant in $X$, so it is path homotopic to a constant in some finite union of subspaces $S_{\alpha}$. This contradicts Theorem 71.1.

The preceding theorem depended on the fact that the topology of $X$ was coherent with the subspaces $S_{\alpha}$. Consider the following example:

EXAMPLE 1. Let $C_{n}$ be the circle of radius $1 / n$ in $\mathbb{R}^{2}$ with center at the point $(1 / n, 0)$. Let $X$ be the subspace of $\mathbb{R}^{2}$ that is the union of these circles; then $X$ is the union of a countably infinite collection of circles, each pair of which intersect in the origin $p$. However, $X$ is not the wedge of the circles $C_{n}$; we call $X$ (for convenience) the infinite earring.

One can verify directly that $X$ does not have the topology coherent with the subspaces $C_{n}$; the intersection of the positive $x$-axis with $X$ contains exactly one point from each circle $C_{n}$, but it is not closed in $X$. Alternatively, for each $n$, let $f_{n}$ be a loop in $C_{n}$ that represents a generator of $\pi_{1}\left(C_{n}, p\right)$; we show that $\pi_{1}(X, p)$ is not a free group with $\left\{\left[f_{n}\right]\right\}$ as a system of free generators. Indeed, we show the elements $\left[f_{i}\right]$ do not even generate the group $\pi_{1}(X, p)$.

Consider the loop $g$ in $X$ defined as follows: For each $n$, define $g$ on the interval $[1 /(n+1), 1 / n]$ to be the positive linear map of this interval onto $[0,1]$ followed by $f_{n}$. This specifies $g$ on $(0,1]$; define $g(0)=p$. Because $X$ has the subspace topology derived from $\mathbb{R}^{2}$, it is easy to see that $g$ is continuous. See Figure 71.2. We show that given $n$, the element $[g]$ does not belong to the subgroup $G_{n}$ of $\pi_{1}(X, p)$ generated by $\left[f_{1}\right], \ldots,\left[f_{n}\right]$.

Choose $N>n$, and consider the map $h: X \rightarrow C_{N}$ defined by setting $h(x)=x$ for $x \in C_{N}$ and $h(x)=p$ otherwise. Then $h$ is continuous, and the induced homomorphism $h_{*}: \pi_{1}(X, p) \rightarrow \pi_{l}\left(C_{N}, p\right)$ carries each element of $G_{n}$ to the identity element. On the other hand, $h \circ g$ is the loop in $C_{N}$ that is constant outside $[1 /(N+1), 1 / N]$ and on this interval equals the positive linear map of this interval onto $[0,1]$ followed by $f_{N}$. Therefore, $h_{*}([g])=\left[f_{N}\right]$, which generates $\pi_{1}\left(C_{N}, p\right)$ ! Thus $[g] \notin G_{n}$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-436.jpg?height=502&width=1070&top_left_y=665&top_left_x=486)

Figure 71.2

In the preceding theorem, we calculated the fundamental group of a space that is an infinite wedge of circles. For later use, we now show that such spaces do exist! (We shall use this result in Chapter 14.)

* Lemma 71.4. Given an index set $J$, there exists a space $X$ that is a wedge of circles $S_{\alpha}$ for $\alpha \in J$.

Proof. Give the set $J$ the discrete topology, and let $E$ be the product space $S^{1} \times J$. Choose a point $b_{0} \in S^{1}$, and let $X$ be the quotient space obtained from $E$ by collapsing the closed set $P=b_{0} \times J$ to a point $p$. Let $\pi: E \rightarrow X$ be the quotient map; let $S_{\alpha}=\pi\left(S^{1} \times \alpha\right)$. We show that each $S_{\alpha}$ is homeomorphic to $S^{1}$ and $X$ is the wedge of the circles $S_{\alpha}$.

Note that if $C$ is closed in $S^{1} \times \alpha$, then $\pi(C)$ is closed in $X$. For $\pi^{-1} \pi(C)=C$ if the point $b_{0} \times \alpha$ is not in $C$, and $\pi^{-1} \pi(C)=C \cup P$ otherwise. In either case, $\pi^{-1} \pi(C)$ is closed in $S^{1} \times J$, so that $\pi(C)$ is closed in $X$.

It follows that $S_{\alpha}$ is itself closed in $X$, since $S^{1} \times \alpha$ is closed in $S^{1} \times J$, and that $\pi$ maps $S^{1} \times \alpha$ homeomorphically onto $S_{\alpha}$. Let $\pi_{\alpha}$ be this homeomorphism.

To show that $X$ has the topology coherent with the subspaces $S_{\alpha}$, let $D \subset X$ and suppose that $D \cap S_{\alpha}$ is closed in $S_{\alpha}$ for each $\alpha$. Now

$$
\pi^{-1}(D) \cap\left(S^{1} \times \alpha\right)=\pi_{\alpha}^{-1}\left(D \cap S_{\alpha}\right)
$$

the latter set is closed in $S^{1} \times \alpha$ because $\pi_{\alpha}$ is continuous. Then $\pi^{-1}(D)$ is closed in $S^{1} \times J$, so that $D$ is closed in $X$ by definition of the quotient topology.

## Exercises

1. Let $X$ be a space that is the union of subspaces $S_{1}, \ldots, S_{n}$, each of which is homeomorphic to the unit circle. Assume there is a point $p$ of $X$ such that $S_{i} \cap S_{j}=\{p\}$ for $i \neq j$.

(a) Show that $X$ is Hausdorff if and only if each space $S_{i}$ is closed in $X$.

(b) Show that $X$ is Hausdorff if and only if the topology of $X$ is coherent with the subspaces $S_{i}$.

(c) Give an example to show that $X$ need not be Hausdorff. [Hint: See Exercises 5 of $\S 36$.]

2. Suppose $X$ is a space that is the union of the closed subspaces $X_{1}, \ldots, X_{n}$; assume there is a point $p$ of $X$ such that $X_{i} \cap X_{j}=\{p\}$ for $i \neq j$. Then we call $X$ the wedge of the spaces $X_{1}, \ldots, X_{n}$, and write $X=X_{1} \vee \cdots \vee X_{n}$. Show that if for each $i$, the point $p$ is a deformation retract of an open set $W_{i}$ of $X_{i}$, then $\pi_{1}(X, p)$ is the external free product of the groups $\pi_{1}\left(X_{i}, p\right)$ relative to the monomorphisms induced by inclusion.
3. What can you say about the fundamental group of $X \vee Y$ if $X$ is homeomorphic to $S^{1}$ and $Y$ is homeomorphic to $S^{2}$ ?
4. Show that if $X$ is an infinite wedge of circles, then $X$ does not satisfy the first countability axiom.
5. Let $S_{n}$ be the circle of radius $n$ in $\mathbb{R}^{2}$ whose center is at the point $(n, 0)$. Let $Y$ be the subspace of $\mathbb{R}^{2}$ that is the union of these circles; let $p$ be their common point.

(a) Show that $Y$ is not homeomorphic to a countably infinite wedge $X$ of circles, nor to the bouquet of circles of Example 1.

(b) Show, however, that $\pi_{1}(Y, p)$ is a free group with $\left\{\left[f_{n}\right]\right\}$ as a system of free generators, where $f_{n}$ is a loop representing a generator of $\pi_{1}\left(S_{n}, p\right)$.

## \$72 Adjoining a Two-cell

We have computed the fundamental group of the torus $T=S^{1} \times S^{1}$ in two ways. One involved considering the standard covering map $p \times p: \mathbb{R} \times \mathbb{R} \rightarrow S^{1} \times S^{1}$ and using the lifting correspondence. Another involved a basic theorem about the fundamental group of a product space. Now we compute the fundamental group of the torus in yet another way.

If one restricts the covering map $p \times p$ to the unit square, one obtains a quotient map $\pi: I^{2} \rightarrow T$. It maps Bd $I^{2}$ onto the subspace $A=\left(S^{1} \times b_{0}\right) \cup\left(b_{0} \times S^{1}\right)$, which is the wedge of two circles, and it maps the rest of $I^{2}$ bijectively onto $T-A$. Thus, $T$ can be thought of as the space obtained by pasting the edges of the square $I^{2}$ onto the space $A$.

The process of constructing a space by pasting the edges of a polygonal region in the plane onto another space is quite useful. We show here how to compute the fundamental group of such a space. The applications will be many and fruitful.

Theorem 72.1. Let $X$ be a Hausdorff space; let $A$ be a closed path-connected subspace of $X$. Suppose that there is a continuous map $h: B^{2} \rightarrow X$ that maps $\operatorname{Int} B^{2}$ bijectively onto $X-A$ and maps $S^{1}=\operatorname{Bd} B^{2}$ into $A$. Let $p \in S^{1}$ and let $a=h(p)$; let $k:\left(S^{1}, p\right) \rightarrow(A, a)$ be the map obtained by restricting $h$. Then the homomorphism

$$
i_{*}: \pi_{1}(A, a) \longrightarrow \pi_{1}(X, a)
$$

induced by inclusion is surjective, and its kernel is the least normal subgroup of $\pi_{1}(A, a)$ containing the image of $k_{*}: \pi_{1}\left(S^{1}, p\right) \rightarrow \pi_{1}(A, a)$.

We sometimes say that the fundamental group of $X$ is obtained from the fundamental group of $A$ by "killing off" the class $k_{*}[f]$, where $[f]$ generates $\pi_{1}\left(S^{1}, p\right)$.

Proof. Step 1. The origin $\mathbf{0}$ is the center point of $B^{2} ;$ let $x_{0}$ be the point $h(\mathbf{0})$ of $X$. If $U$ is the open set $U=X-x_{0}$ of $X$, we show that $A$ is a deformation retract of $U$. See Figure 72.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-438.jpg?height=525&width=1075&top_left_y=1217&top_left_x=484)

Figure 72.1

Let $C=h\left(B^{2}\right)$, and let $\pi: B^{2} \rightarrow C$ be the map obtained by restricting the range of $h$. Consider the map

$$
\pi \times \mathrm{id}: B^{2} \times I \longrightarrow C \times I \text {; }
$$

it is a closed map because $B^{2} \times I$ is compact and $C \times I$ is Hausdorff; therefore, it is a quotient map. Its restriction

$$
\pi^{\prime}:\left(B^{2}-\mathbf{0}\right) \times I \longrightarrow\left(C-x_{0}\right) \times I
$$

is also a quotient map, since its domain is open in $B^{2} \times I$ and is saturated with respect to $\pi \times$ id. There is a deformation retraction of $B^{2}-\mathbf{0}$ onto $S^{1}$; it induces, via the
quotient map $\pi^{\prime}$, a deformation retraction of $C-x_{0}$ onto $\pi\left(S^{1}\right)$. We extend this deformation retraction to all of $U \times I$ by letting it keep each point of $A$ fixed during the deformation. Thus $A$ is a deformation retract of $U$.

It follows that the inclusion of $A$ into $U$ induces an isomorphism of fundamental groups. Our theorem then reduces to proving the following statement:

Let $f$ be a loop whose class generates $\pi_{1}\left(S^{1}, p\right)$. Then the inclusion of $U$ into $X$ induces an epimorphism

$$
\pi_{1}(U, a) \longrightarrow \pi_{1}(X, a)
$$

whose kernel is the least normal subgroup containing the class of the loop $g=h \circ f$.

Step 2. In order to prove this result, it is convenient to consider first the homomorphism $\pi_{1}(U, b) \rightarrow \pi_{1}(X, b)$ induced by inclusion relative to a base point $b$ that does not belong to $A$.

Let $b$ be any point of $U-A$. Write $X$ as the union of the open sets $U$ and $V=X-A=\pi\left(\operatorname{Int} B^{2}\right)$. Now $U$ is path connected, since it has $A$ as a deformation retract. Because $\pi$ is a quotient map, its restriction to $\operatorname{Int} B^{2}$ is also a quotient map and hence a homeomorphism; thus $V$ is simply connected. The set $U \cap V=V-x_{0}$ is homeomorphic to Int $B^{2} \mathbf{- 0}$, so it is path connected and its fundamental group is infinite cyclic. Since $b$ is a point of $U \cap V$, Corollary 70.4 implies that the homomorphism

$$
\pi_{1}(U, b) \longrightarrow \pi_{1}(X, b)
$$

induced by inclusion is surjective, and its kernel is the least normal subgroup containing the image of the infinite cyclic group $\pi_{1}(U \cap V, b)$.

Step 3. Now we change the base point back to $a$, proving the theorem.

Let $q$ be the point of $B^{2}$ that is the midpoint of the line segment from $\mathbf{0}$ to $p$, and let $b=h(q)$; then $b$ is a point of $U \cap V$. Let $f_{0}$ be a loop in Int $B^{2}-\mathbf{0}$ based at $q$ that represents a generator of the fundamental group of this space; then $g_{0}=h \circ f_{0}$ is a loop in $U \cap V$ based at $b$ that represents a generator of the fundamental group of $U \cap V$. See Figure 72.2.

Step 2 tells us that the homomorphism $\pi_{1}(U, b) \rightarrow \pi_{1}(X, b)$ induced by inclusion is surjective and its kernel is the least normal subgroup containing the class of the loop $g_{0}=h \circ f_{0}$. To obtain the analogous result with base point $a$ we proceed as follows:

Let $\gamma$ be the straight-line path in $B^{2}$ from $q$ to $p$; let $\delta$ be the path $\delta=h \circ \gamma$ in $U$ from $b$ to $a$. The isomorphisms induced by the path $\delta$ (both of which we denote by $\hat{\delta}$ ) commute with the homomorphisms induced by inclusion in the following diagram:

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-439.jpg?height=186&width=396&top_left_y=1989&top_left_x=1001)

Therefore, the homomorphism of $\pi_{1}(U, a)$ into $\pi_{1}(X, a)$ induced by inclusion is surjective, and its kernel is the least normal subgroup containing the element $\hat{\delta}\left(\left[g_{0}\right]\right)$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-440.jpg?height=500&width=564&top_left_y=369&top_left_x=734)

Figure 72.2

The loop $f_{0}$ represents a generator of the fundamental group of $\operatorname{Int} B^{2}-\mathbf{0}$ based at $q$. Then the loop $\bar{\gamma} *\left(f_{0} * \gamma\right)$ represents a generator of the fundamental group of $B^{2}-\mathbf{0}$ based at $p$. Therefore, it is path homotopic either to $f$ or its reverse; suppose the former. Following this path homotopy by the map $h$, we see that $\bar{\delta} *\left(g_{0} * \delta\right)$ is path homotopic in $U$ to $g$. Then $\hat{\delta}\left(\left[g_{0}\right]\right)=[g]$, and the theorem follows.

There is nothing special in this theorem about the unit ball $B^{2}$. The same result holds if we replace $B^{2}$ by any space $B$ homeomorphic to $B^{2}$, if we denote by $B d B$ the subspace corresponding to $S^{1}$ under the homeomorphism. Such a space $B$ is called a 2cell. The space $X$ of this theorem is thought of as having been obtained by "adjoining a 2-cell" to $A$. We shall treat this situation more formally later.

## Exercises

1. Let $X$ be a Hausdorff space; let $A$ be a closed path-connected subspace. Suppose that $h: B^{n} \rightarrow X$ is a continuous map that maps $S^{n-1}$ into $A$ and maps $\operatorname{Int} B^{n}$ bijectively onto $X-A$. Let $a$ be a point of $h\left(S^{n-1}\right)$. If $n>2$, what can you say about the homomorphism of $\pi_{1}(A, a)$ into $\pi_{1}(X, a)$ induced by inclusion?
2. Let $X$ be the adjunction space formed from the disjoint union of the normal, path-connected space $A$ and the unit ball $B^{2}$ by means of a continuous map $f: S^{1} \rightarrow A$. (See Exercise 8 of §35.) Show that $X$ satisfies the hypotheses of Theorem 72.1. Where do you use the fact that $A$ is normal?
3. Let $G$ be a group; let $x$ be an element of $G$; let $N$ be the least normal subgroup of $G$ containing $x$. Show that if there is a normal, path-connected space whose fundamental group is isomorphic to $G$, then there is a normal, path-connected space whose fundamental group is isomorphic to $G / N$.

## $\$ 73$ The Fundamental Groups of the Torus and the Dunce Cap

We now apply the results of the preceding section to compute two fundamental groups, one of which we already know and the other of which we do not. The techniques involved will be important later.

Theorem 73.1. The fundamental group of the torus has a presentation consisting of two generators $\alpha, \beta$ and a single relation $\alpha \beta \alpha^{-1} \beta^{-1}$.

Proof. Let $X=S^{1} \times S^{1}$ be the torus, and let $h: I^{2} \rightarrow X$ be obtained by restricting the standard covering map $p \times p: \mathbb{R} \times \mathbb{R} \rightarrow S^{1} \times S^{1}$. Let $p$ be the point $(0,0)$ of $\operatorname{Bd} I^{2}$, let $a=h(p)$, and let $A=h\left(\operatorname{Bd} I^{2}\right)$. Then the hypotheses of Theorem 72.1 are satisfied.

The space $A$ is the wedge of two circles, so the fundamental group of $A$ is free. Indeed, if we let $a_{0}$ be the path $a_{0}(t)=(t, 0)$ and $b_{0}$ be the path $b_{0}(t)=(0, t)$ in $\operatorname{Bd} I^{2}$, then the paths $\alpha=h \circ a_{0}$ and $\beta=h \circ b_{0}$ are loops in $A$ such that $[\alpha]$ and $[\beta]$ form a system of free generators for $\pi_{1}(A, a)$. See Figure 73.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-441.jpg?height=345&width=946&top_left_y=1193&top_left_x=723)

Figure 73.1

Now let $a_{1}$ and $b_{1}$ be the paths $a_{1}(t)=(t, 1)$ and $b_{1}(t)=(1, t)$ in $\operatorname{Bd} I^{2}$. Consider the loop $f$ in $\mathrm{Bd} I^{2}$ defined by the equation

$$
f=a_{0} *\left(b_{1} *\left(\bar{a}_{1} * \bar{b}_{0}\right)\right)
$$

Then $f$ represents a generator of $\pi_{1}\left(\mathrm{Bd} I^{2}, p\right)$; and the loop $g=h \circ f$ equals the product $\alpha *(\beta *(\bar{\alpha} * \bar{\beta}))$. Theorem 72.1 tells us that $\pi_{1}(X, a)$ is the quotient of the free group on the free generators $[\alpha]$ and $[\beta]$ by the least normal subgroup containing the element $[\alpha][\beta][\alpha]^{-1}[\beta]^{-1}$.

Corollary 73.2. The fundamental group of the torus is a free abelian group of rank 2 .

Proof. Let $G$ be the free group on generators $\alpha, \beta$; and let $N$ be the least normal subgroup containing the element $\alpha \beta \alpha^{-1} \beta^{-1}$. Because this element is a commutator, $N$ is contained in the commutator subgroup $[G, G]$ of $G$. On the other hand, $G / N$
is abelian; for it is generated by the cosets $\alpha N$ and $\beta N$, and these elements of $G / N$ commute. Therefore $N$ contains the commutator subgroup of $G$.

It follows from Theorem 69.4 that $G / N$ is a free abelian group of rank 2 .

Definition. Let $n$ be a positive integer with $n>1$. Let $r: S^{1} \rightarrow S^{1}$ be rotation through the angle $2 \pi / n$, mapping the point $(\cos \theta, \sin \theta)$ to the point $(\cos (\theta+$ $2 \pi / n), \sin (\theta+2 \pi / n)$ ). Form a quotient space $X$ from the unit ball $B^{2}$ by identifying each point $x$ of $S^{1}$ with the points $r(x), r^{2}(x), \ldots, r^{n-1}(x)$. We shall show that $X$ is a compact Hausdorff space; we call it the $\boldsymbol{n}$-fold dunce cap.

Let $\pi: B^{2} \rightarrow X$ be the quotient map; we show that $\pi$ is a closed map. In order to do this, we must show that if $C$ is a closed set of $B^{2}$, then $\pi^{-1} \pi(C)$ is also closed in $B^{2}$; it then will follow from the definition of the quotient topology that $\pi(C)$ is closed in $X$. Let $C_{0}=C \cap S^{1}$; it is closed in $B^{2}$. The set $\pi^{-1} \pi(C)$ equals the union of $C$ and the sets $r\left(C_{0}\right), r^{2}\left(C_{0}\right), \ldots, r^{n-1}\left(C_{0}\right)$, all of which are closed in $B^{2}$ because $r$ is a homeomorphism. Hence $\pi^{-1} \pi(C)$ is closed in $B^{2}$, as desired.

Because $\pi$ is continuous, $X$ is compact. The fact that $X$ is Hausdorff is a consequence of the following lemma, which was given as an exercise in $\S 31$.

Lemma 73.3. Let $\pi: E \rightarrow X$ be a closed quotient map. If $E$ is normal, then so is $X$.

Proof. Assume $E$ is normal. One-point sets are closed in $X$ because one-point sets are closed in $E$. Now let $A$ and $B$ be disjoint closed sets of $X$. Then $\pi^{-1}(A)$ and $\pi^{-1}(B)$ are disjoint closed sets of $E$. Choose disjoint open sets $U$ and $V$ of $E$ containing $\pi^{-1}(A)$ and $\pi^{-1}(B)$, respectively. It is tempting to assume that $\pi(U)$ and $\pi(V)$ are the open sets about $A$ and $B$ that we are seeking. But they are not. For they need not be open ( $\pi$ is not necessarily an open map), and they need not be disjoint! See Figure 73.2.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-442.jpg?height=408&width=707&top_left_y=1633&top_left_x=668)

Figure 73.2

So we proceed as follows: Let $C=E-U$ and let $D=E-V$. Because $C$ and $D$ are closed sets of $E$, the sets $\pi(C)$ and $\pi(D)$ are closed in $X$. Because $C$ contains no point of $\pi^{-1}(A)$, the set $\pi(C)$ is disjoint from $A$. Then $U_{0}=X-\pi(C)$ is an open
set of $X$ containing $A$. Similarly, $V_{0}=X-\pi(D)$ is an open set of $X$ containing $B$. Furthermore, $U_{0}$ and $V_{0}$ are disjoint. For if $x \in U_{0}$, then $\pi^{-1}(x)$ is disjoint from $C$, so that it is contained in $U$. Similarly, if $x \in V_{0}$, then $\pi^{-1}(x)$ is contained in $V$. Since $U$ and $V$ are disjoint, so are $U_{0}$ and $V_{0}$.

Let us note that the 2-fold dunce cap is a space we have seen before; it is homeomorphic to the projective plane $P^{2}$. To verify this fact, recall that $P^{2}$ was defined to be the quotient space obtained from $S^{2}$ by identifying $x$ with $-x$ for each $x$. Let $p: S^{2} \rightarrow P^{2}$ be the quotient map. Let us take the standard homeomorphism $i$ of $B^{2}$ with the upper hemisphere of $S^{2}$, given by the equation

$$
i(x, y)=\left(x, y,\left(1-x^{2}-y^{2}\right)^{1 / 2}\right)
$$

and follow it by the map $p$. We obtain a map $\pi: B^{2} \rightarrow P^{2}$ that is continuous, closed, and surjective. On Int $B$ it is injective, and for each $x \in S^{1}$, it maps $x$ and $-x$ to the same point. Hence it induces a homeomorphism of the 2 -fold dunce cap with $P^{2}$.

The fundamental group of the $n$-fold dunce cap is just what you might expect from our computation for $P^{2}$.

Theorem 73.4. The fundamental group of the $n$-fold dunce cap is a cyclic group of order $n$.

Proof. Let $h: B^{2} \rightarrow X$ be the quotient map, where $X$ is the $n$-fold dunce cap. Set $A=h\left(S^{1}\right)$. Let $p=(1,0) \in S^{1}$ and let $a=h(p)$. Then $h$ maps the $\operatorname{arc} C$ of $S^{1}$ running from $p$ to $r(p)$ onto $A$; it identifies the end points of $C$ but is otherwise injective. Therefore, $A$ is homeomorphic to a circle, so its fundamental group is infinite cyclic. Indeed, if $\gamma$ is the path

$$
\gamma(t)=(\cos (2 \pi t / n), \sin (2 \pi t / n))
$$

in $S^{1}$ from $p$ to $r(p)$, then $\alpha=h \circ \gamma$ represents a generator of $\pi_{1}(A, a)$. See Figure 73.3.

Now the class of the loop

$$
f=\gamma *\left((r \circ \gamma) *\left(\left(r^{2} \circ \gamma\right) * \cdots *\left(r^{n-1} \circ \gamma\right)\right)\right)
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-443.jpg?height=372&width=722&top_left_y=1840&top_left_x=838)

Figure 73.3
generates $\pi_{1}\left(S^{1}, p\right)$. Since $h\left(r^{m}(x)\right)=h(x)$ for all $x$ and $m$, the loop $h \circ f$ equals the $n$-fold product $\alpha *(\alpha *(\cdots * \alpha))$. The theorem follows.

## Exercises

1. Find spaces whose fundamental groups are isomorphic to the following groups. (Here $\mathbb{Z} / n$ denotes the additive group of integers modulo $n$.)

(a) $\mathbb{Z} / n \times \mathbb{Z} / m$.

(b) $\mathbb{Z} / n_{1} \times \mathbb{Z} / n_{2} \times \cdots \times \mathbb{Z} / n_{k}$.

(c) $\mathbb{Z} / n * \mathbb{Z} / m$. (See Exercise 2 of $\S 71$.)

(d) $\mathbb{Z} / n_{1} * \mathbb{Z} / n_{2} * \cdots * \mathbb{Z} / n_{k}$.

2. Prove the following:

Theorem. If $G$ is a finitely presented group, then there is a compact Hausdorff space $X$ whose fundamental group is isomorphic to $G$.

Proof. Suppose $G$ has a presentation consisting of $n$ generators and $m$ relations. Let $A$ be the wedge of $n$ circles; form an adjunction space $X$ from the union of $A$ and $m$ copies $B_{1}, \ldots, B_{m}$ of the unit ball by means of a continuous map $f: \bigcup \mathrm{Bd} B_{i} \rightarrow A$.

(a) Show that $X$ is Hausdorff.

(b) Prove the theorem in the case $m=1$.

(c) Proceed by induction on $m$, using the algebraic result stated in the following exercise.

The construction outlined in this exercise is a standard one in algebraic topology; the space $X$ is called a two-dimensional $C W$ complex.

3. Lemma. Let $f: G \rightarrow H$ and $g: H \rightarrow K$ be homomorphisms; assume $f$ is surjective. If $x_{0} \in G$, and if ker $g$ is the least normal subgroup of $H$ containing $f\left(x_{0}\right)$, then $\operatorname{ker}(g \circ f)$ is the least normal subgroup $N$ of $G$ containing $\operatorname{ker} f$ and $x_{0}$.

Proof. Show that $f(N)$ is normal; conclude that $\operatorname{ker}(g \circ f)=f^{-1}(\operatorname{ker} g) \subset$ $f^{-1} f(N)=N$.

4. Show that the space constructed in Exercise 2 is in fact metrizable. [Hint: The quotient map is a perfect map.]

This page intentionally left blank

## Chapter 13

## Classification of Covering Spaces

Up to this point, we have used covering spaces primarily as a tool for computing fundamental groups. Now we turn things around and use the fundamental group as a tool for studying covering spaces.

To do this in any reasonable way, we must restrict ourselves to the case where $B$ is locally path connected. Once we have done this, we may as well require $B$ to be path connected as well, since $B$ breaks up into the disjoint open sets $B_{\alpha}$ that are its path components, and the maps $p^{-1}\left(B_{\alpha}\right) \rightarrow B_{\alpha}$ obtained by restricting $p$ are covering maps, by Theorem 53.2. We may as well assume also that $E$ is path connected. For if $E_{\alpha}$ is a path component of $p^{-1}\left(B_{\alpha}\right)$, then the map $E_{\alpha} \rightarrow B_{\alpha}$ obtained by restricting $p$ is also a covering map. (See Lemma 80.1.) Therefore, one can determine all coverings of the locally path-connected space $B$ merely by determining all path-connected coverings of each path component of $B$ !

For this reason, we make the following:

Convention. Throughout this chapter, the statement that $p: E \rightarrow B$ is a covering map will include the assumption that $E$ and $B$ are locally path connected and path connected, unless specifically stated otherwise.

With this convention, we now describe the connection between covering spaces of $B$ and the fundamental group of $B$.

If $p: E \rightarrow B$ is a covering map, with $p\left(e_{0}\right)=b_{0}$, then the induced homomorphism $p_{*}$ is injective, by Theorem 54.6, so that

$$
H_{0}=p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)
$$

is a subgroup of $\pi_{1}\left(B, b_{0}\right)$ isomorphic to $\pi_{1}\left(E, e_{0}\right)$. It turns out that the subgroup $H_{0}$ determines the covering $p$ completely, up to a suitable notion of equivalence of coverings. This we shall prove in $\S 79$. Furthermore, under a (fairly mild) additional "local niceness" condition on $B$, there exists, for each subgroup $H_{0}$ of $\pi_{1}\left(B, b_{0}\right)$, a covering $p: E \rightarrow B$ of $B$ whose corresponding subgroup is $H_{0}$. This we shall prove in $\S 82$.

Roughly speaking, these results show that one can determine all covering spaces of $B$ merely by examining the collection of all subgroups of $\pi_{1}\left(B, b_{0}\right)$. This is the classical procedure of algebraic topology; one "solves" a problem of topology by reducing it to a problem of algebra, hopefully one that is more tractable.

Throughout the chapter, we assume the general lifting correspondence theorem, Theorem 54.6.

## \$79 Equivalence of Covering Spaces

In this section, we show that the subgroup $H_{0}$ of $\pi_{1}\left(B, b_{0}\right)$ determines the covering $p: E \rightarrow B$ completely, up to a suitable notion of equivalence of coverings.

Definition. Let $p: E \rightarrow B$ and $p^{\prime}: E^{\prime} \rightarrow B$ be covering maps. They are said to be equivalent if there exists a homeomorphism $h: E \rightarrow E^{\prime}$ such that $p=p^{\prime} \circ h$. The homeomorphism $h$ is called an equivalence of covering maps or an equivalence of covering spaces.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-447.jpg?height=183&width=311&top_left_y=1568&top_left_x=1041)

Given two covering maps $p: E \rightarrow B$ and $p^{\prime}: E^{\prime} \rightarrow B$ whose corresponding subgroups $H_{0}$ and $H_{0}^{\prime}$ are equal, we shall prove that there exists an equivalence $h$ : $E \rightarrow E^{\prime}$. For this purpose, we need to generalize the lifting lemmas of $\S 54$.

Lemma 79.1 (The general lifting lemma). Let $p: E \rightarrow B$ be a covering map; let $p\left(e_{0}\right)=b_{0}$. Let $f: Y \rightarrow B$ be a continuous map, with $f\left(y_{0}\right)=b_{0}$. Suppose $Y$ is path connected and locally path connected. The map $f$ can be lifted to a map $\tilde{f}: Y \rightarrow E$ such that $\tilde{f}\left(y_{0}\right)=e_{0}$ if and only if

$$
f_{*}\left(\pi_{1}\left(Y, y_{0}\right)\right) \subset p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right) .
$$

Furthermore, if such a lifting exists, it is unique.

Proof. If the lifting $\tilde{f}$ exists, then

$$
f_{*}\left(\pi_{1}\left(Y, Y_{0}\right)\right)=p_{*}\left(\tilde{f}_{*}\left(\pi_{1}\left(Y, y_{0}\right)\right)\right) \subset p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right) .
$$

This proves the "only if" part of the theorem.

Now we prove that if $\tilde{f}$ exists, it is unique. Given $y_{1} \in Y$, choose a path $\alpha$ in $Y$ from $y_{0}$ to $y_{1}$. Take the path $f \circ \alpha$ in $B$ and lift it to a path $\gamma$ in $E$ beginning at $e_{0}$. If a lifting $\tilde{f}$ of $f$ exists, then $\tilde{f}\left(y_{1}\right)$ must equal the end point $\gamma(1)$ of $\gamma$, for $\tilde{f} \circ \alpha$ is a lifting of $f \circ \alpha$ that begins at $e_{0}$, and path liftings are unique.

Finally, we prove the "if" part of the theorem. The uniqueness part of the proof gives us a clue how to proceed. Given $y_{1} \in Y$, choose a path $\alpha$ in $Y$ from $y_{0}$ to $y_{1}$. Lift the path $f \circ \alpha$ to a path $\gamma$ in $E$ beginning at $e_{0}$, and define $\tilde{f}\left(y_{1}\right)=\gamma(1)$. See Figure 79.1. It is a certain amount of work to show that $\tilde{f}$ is well-defined, independent of the choice of $\alpha$. Once we prove that, continuity of $\tilde{f}$ is proved easily, as we now show.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-448.jpg?height=588&width=1155&top_left_y=1019&top_left_x=444)

Figure 79.1

To prove continuity of $\tilde{f}$ at the point $y_{1}$ of $Y$, we show that, given a neighborhood $N$ of $\tilde{f}\left(y_{1}\right)$, there is a neighborhood $W$ of $y_{1}$ such that $\tilde{f}(W) \subset N$. To begin, choose a path-connected neighborhood $U$ of $f\left(y_{1}\right)$ that is evenly covered by $p$. Break $p^{-1}(U)$ up into slices, and let $V_{0}$ be the slice that contains the point $\tilde{f}\left(y_{1}\right)$. Replacing $U$ by a smaller neighborhood of $f\left(y_{1}\right)$ if necessary, we can assume that $V_{0} \subset N$. Let $p_{0}: V_{0} \rightarrow U$ be obtained by restricting $p$; then $p_{0}$ is a homeomorphism. Because $f$ is continuous at $y_{1}$ and $Y$ is locally path connected, we can find a path-connected neighborhood $W$ of $y_{1}$ such that $f(W) \subset U$. We shall show that $\tilde{f}(W) \subset V_{0}$; then our result is proved.

Given $y \in W$, choose a path $\beta$ in $W$ from $y_{1}$ to $y$. Since $\tilde{f}$ is well defined, $\tilde{f}(y)$ can be obtained by taking the path $\alpha * \beta$ from $y_{0}$ to $y$, lifting the path $f \circ(\alpha * \beta)$ to a path in $E$ beginning at $e_{0}$, and letting $\tilde{f}(y)$ be the end point of this lifted path. Now $\gamma$ is a lifting of $\alpha$ that begins at $e_{0}$. Since the path $f \circ \beta$ lies in $U$, the path $\delta=p_{0}^{-1} \circ f \circ \beta$
is a lifting of it that begins at $\tilde{f}\left(y_{1}\right)$. Then $\gamma * \delta$ is a lifting of $f \circ(\alpha * \beta)$ that begins at $e_{0}$; it ends at the point $\delta(1)$ of $V_{0}$. Hence $\tilde{f}(W) \subset V_{0}$, as desired.

Finally, we show $\tilde{f}$ is well defined. Let $\alpha$ and $\beta$ be two paths in $Y$ from $y_{0}$ to $y_{1}$. We must show that if we lift $f \circ \alpha$ and $f \circ \beta$ to paths in $E$ beginning at $e_{0}$, then these lifted paths end at the same point of $E$.

First, we lift $f \circ \alpha$ to a path $\gamma$ in $E$ beginning at $e_{0}$; then we lift $f \circ \bar{\beta}$ to a path $\delta$ in $E$ beginning at the end point $\gamma(1)$ of $\gamma$. Then $\gamma * \delta$ is a lifting of the loop $f \circ(\alpha * \bar{\beta})$. Now by hypothesis,

$$
f_{*}\left(\pi_{1}\left(Y, y_{0}\right)\right) \subset p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)
$$

Hence $[f \circ(\alpha * \bar{\beta})]$ belongs to the image of $p_{*}$. Theorem 54.6 now implies that its lift $\gamma * \delta$ is a loop in $E$.

It follows that $\tilde{f}$ is well defined. For $\bar{\delta}$ is a lifting of $f \circ \beta$ that begins at $e_{0}$, and $\gamma$ is a lifting of $f \circ \alpha$ that begins at $e_{0}$, and both liftings end at the same point of $E$.

Theorem 79.2. Let $p: E \rightarrow B$ and $p^{\prime}: E^{\prime} \rightarrow B$ be covering maps; let $p\left(e_{0}\right)=$ $p^{\prime}\left(e_{0}^{\prime}\right)=b_{0}$. There is an equivalence $h: E \rightarrow E^{\prime}$ such that $h\left(e_{0}\right)=e_{0}^{\prime}$ if and only if the groups

$$
H_{0}=p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right) \quad \text { and } \quad H_{0}^{\prime}=p_{*}^{\prime}\left(\pi_{1}\left(E^{\prime}, e_{0}^{\prime}\right)\right)
$$

are equal. If $h$ exists, it is unique.

Proof. We prove the "only if" part of the theorem. Given $h$, the fact that $h$ is a homeomorphism implies that

$$
h_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)=\pi_{1}\left(E^{\prime}, e_{0}^{\prime}\right) .
$$

Since $p^{\prime} \circ h=p$, we have $H_{0}=H_{0}^{\prime}$.

Now we prove the "if" part of the theorem; we assume that $H_{0}=H_{0}^{\prime}$ and show that $h$ exists. We shall apply the preceding lemma (four times!). Consider the maps

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-449.jpg?height=174&width=209&top_left_y=1706&top_left_x=1089)

Because $p^{\prime}$ is a covering map and $E$ is path connected and locally path connected, there exists a map $h: E \rightarrow E^{\prime}$ with $h\left(e_{0}\right)=e_{0}^{\prime}$ that is a lifting of $p$ (that is, such that $\left.p^{\prime} \circ h=p\right)$. Reversing the roles of $E$ and $E^{\prime}$ in this argument, we see there is a map $k: E^{\prime} \rightarrow E$ with $k\left(e_{0}^{\prime}\right)=e_{0}$ such that $p \circ k=p^{\prime}$. Now consider the maps

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-449.jpg?height=175&width=192&top_left_y=2116&top_left_x=1103)

The map $k \circ h: E \rightarrow E$ is a lifting of $p$ (since $p \circ k \circ h=p^{\prime} \circ h=p$ ), with $p\left(e_{0}\right)=e_{0}$. The identity map $i_{E}$ of $E$ is another such lifting. The uniqueness part of the preceding lemma implies that $k \circ h=i_{E}$. A similar argument shows that $h \circ k$ equals the identity map of $E^{\prime}$.

We seem to have solved our equivalence problem. But there is a somewhat subtle point we have overlooked. We have obtained a necessary and sufficient condition for there to exist an equivalence $h: E \rightarrow E^{\prime}$ that carries the point $e_{0}$ to the point $e_{0}^{\prime}$. But we have not yet determined under what conditions there exists an equivalence in general. It is possible that there may be no equivalence carrying $e_{0}$ to $e_{0}^{\prime}$ but that there is an equivalence carrying $e_{0}$ to some other point $e_{1}^{\prime}$ of $\left(p^{\prime}\right)^{-1}\left(b_{0}\right)$. Can we determine whether this is the case merely by examining the subgroups $H_{0}$ and $H_{0}^{\prime}$ ? We consider this problem now.

If $H_{1}$ and $H_{2}$ are subgroups of a group $G$, you may recall from algebra that they are said to be conjugate subgroups if $H_{2}=\alpha \cdot H_{1} \cdot \alpha^{-1}$ for some element $\alpha$ of $G$. Said differently, they are conjugate if the isomorphism of $G$ with itself that maps $x$ to $\alpha \cdot x \cdot \alpha^{-1}$ carries the group $H_{1}$ onto the group $H_{2}$. It is easy to check that conjugacy is an equivalence relation on the collection of subgroups of $G$. The equivalence class of the subgroup $H$ is called the conjugacy class of $H$.

Lemma 79.3. Let $p: E \rightarrow B$ be a covering map. Let $e_{0}$ and $e_{1}$ be points of $p^{-1}\left(b_{0}\right)$, and let $H_{i}=p_{*}\left(\pi_{1}\left(E, e_{i}\right)\right)$.

(a) If $\gamma$ is a path in $E$ from $e_{0}$ to $e_{1}$, and $\alpha$ is the loop $p \circ \gamma$ in $B$, then the equation $[\alpha] * H_{1} *[\alpha]^{-1}=H_{0}$ holds; hence $H_{0}$ and $H_{1}$ are conjugate.

(b) Conversely, given $e_{0}$, and given a subgroup $H$ of $\pi_{1}\left(B, b_{0}\right)$ conjugate to $H_{0}$, there exists a point $e_{1}$ of $p^{-1}\left(b_{0}\right)$ such that $H_{1}=H$.

Proof. (a) First, we show that $[\alpha] * H_{1} *[\alpha]^{-1} \subset H_{0}$. Given an element $[h]$ of $H_{1}$, we have $[h]=p_{*}([\tilde{h}])$ for some loop $\tilde{h}$ in $E$ based at $e_{1}$. Let $\tilde{k}$ be the path $\tilde{k}=(\gamma * \tilde{h}) * \bar{\gamma}$; it is a loop in $E$ based at $e_{0}$, and

$$
p_{*}([\tilde{k}])=[(\alpha * h) * \bar{\alpha}]=[\alpha] *[h] *[\alpha]^{-1},
$$

so the latter element belongs to $p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)=H_{0}$, as desired. See Figure 79.2.

Now we show that $[\alpha] * H_{1} *[\alpha]^{-1} \supset H_{0}$. Note that $\bar{\gamma}$ is a path from $e_{1}$ to $e_{0}$ and $\bar{\alpha}$ equals the loop $p \circ \bar{\gamma}$. By the result just proved, we have

$$
[\bar{\alpha}] * H_{0} *[\bar{\alpha}]^{-1} \subset H_{1}
$$

which implies out desired result.

(b) To prove the converse, let $e_{0}$ be given and let $H$ be conjugate to $H_{0}$. Then $H_{0}=[\alpha] * H *[\alpha]^{-1}$ for some loop $\alpha$ in $B$ based at $b_{0}$. Let $\gamma$ be the lifting of $\alpha$ to a path in $E$ beginning at $e_{0}$, and let $e_{1}=\gamma(1)$. Then (a) implies that $H_{0}=[\alpha] * H_{1} *[\alpha]^{-1}$. We conclude that $H=H_{1}$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-451.jpg?height=582&width=1020&top_left_y=368&top_left_x=686)

Figure 79.2

Theorem 79.4. Let $p: E \rightarrow B$ and $p^{\prime}: E^{\prime} \rightarrow B$ be covering maps; let $p\left(e_{0}\right)=$ $p^{\prime}\left(e_{0}^{\prime}\right)=b_{0}$. The covering maps $p$ and $p^{\prime}$ are equivalent if and only if the subgroups

$$
H_{0}=p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right) \quad \text { and } \quad H_{0}^{\prime}=p_{*}^{\prime}\left(\pi_{1}\left(E^{\prime}, e_{0}^{\prime}\right)\right)
$$

of $\pi_{1}\left(B, b_{0}\right)$ are conjugate.

Proof. If $h: E \rightarrow E^{\prime}$ is an equivalence, let $e_{1}^{\prime}=h\left(e_{0}\right)$, and let $H_{1}^{\prime}=p_{*}\left(\pi_{1}\left(E^{\prime}, e_{1}^{\prime}\right)\right)$. Theorem 79.2 implies that $H_{0}=H_{1}^{\prime}$, while the preceding lemma tells us that $H_{1}^{\prime}$ is conjugate to $H_{0}^{\prime}$.

Conversely, if the groups $H_{0}$ and $H_{0}^{\prime}$ are conjugate, the preceding lemma implies there is a point $e_{1}^{\prime}$ of $E^{\prime}$ such that $H_{1}^{\prime}=H_{0}$. Theorem 79.2 then gives us an equivalence $h: E \rightarrow E^{\prime}$ such that $h\left(e_{0}\right)=e_{1}^{\prime}$.

EXAmple 1. Consider covering spaces of the circle $B=S^{1}$. Because $\pi_{1}\left(B, b_{0}\right)$ is abelian, two subgroups of $\pi_{1}\left(B, b_{0}\right)$ are conjugate if and only if they are equal. Therefore two coverings of $B$ are equivalent if and only if they correspond to the same subgroup of $\pi_{1}\left(B, b_{0}\right)$.

Now $\pi_{1}\left(B, b_{0}\right)$ is isomorphic to the integers $\mathbb{Z}$. What are the subgroups of $\mathbb{Z}$ ? It is standard theorem of modern algebra that, given a nontrivial subgroup of $\mathbb{Z}$, it must be the group $G_{n}$ consisting of all multiples of $n$, for some $n \in \mathbb{Z}_{+}$.

We have studied one covering space of the circle, the covering $p: \mathbb{R} \rightarrow S^{1}$. It must correspond to the trivial subgroup of $\pi_{1}\left(S^{1}, b_{0}\right)$, because $\mathbb{R}$ is simply connected. We have also considered the covering $p: S^{1} \rightarrow S^{1}$ defined by $p(z)=z^{n}$, where $z$ is a complex number. In this case, the map $p_{*}$ carries a generator of $\pi_{1}\left(S^{1}, b_{0}\right)$ into $n$ times itself. Therefore, the group $p_{*}\left(\pi_{1}\left(S^{1}, b_{0}\right)\right)$ corresponds to the subgroup $G_{n}$ of $\mathbb{Z}$ under the standard isomorphism of $\pi_{1}\left(S^{1}, b_{0}\right)$ with $\mathbb{Z}$.

We conclude from the preceding theorem that every path-connected covering space of $S^{1}$ is equivalent to one of these coverings.

## Exercises

1. Show that if $n>1$, every continuous map $f: S^{n} \rightarrow S^{1}$ is nulhomotopic. [Hint: Use the lifting lemma.]
2. (a) Show that every continuous map $f: P^{2} \rightarrow S^{1}$ is nulhomotopic.

(b) Find a continuous map of the torus into $S^{1}$ that is not nulhomotopic.

3. Let $p: E \rightarrow B$ be a covering map; let $p\left(e_{0}\right)=b_{0}$. Show that $H_{0}=$ $p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)$ is a normal subgroup of $\pi_{1}\left(B, b_{0}\right)$ if and only if for every pair of points $e_{1}, e_{2}$ of $p^{-1}\left(b_{0}\right)$, there is an equivalence $h: E \rightarrow E$ with $h\left(e_{1}\right)=e_{2}$.
4. Let $T=S^{1} \times S^{1}$, the torus. There is an isomorphism of $\pi_{1}\left(T, b_{0} \times b_{0}\right)$ with $\mathbb{Z} \times \mathbb{Z}$ induced by projections of $T$ onto its two factors.

(a) Find a covering space of $T$ corresponding to the subgroup of $\mathbb{Z} \times \mathbb{Z}$ generated by the element $m \times 0$, where $m$ is a positive integer.

(b) Find a covering space of $T$ corresponding to the trivial subgroup of $\mathbb{Z} \times \mathbb{Z}$.

(c) Find a covering space of $T$ corresponding to the subgroup of $\mathbb{Z} \times \mathbb{Z}$ generated by $m \times 0$ and $0 \times n$, where $m$ and $n$ are positive integers.

*5. Let $T=S^{1} \times S^{1}$ be the torus; let $x_{0}=b_{0} \times b_{0}$.

(a) Prove the following:

Theorem. Every isomorphism of $\pi_{1}\left(T, x_{0}\right)$ with itself is induced by a homeomorphism of $T$ with itself that maps $x_{0}$ to $x_{0}$.

[Hint: Let $p: \mathbb{R}^{2} \rightarrow T$ be the usual covering map. If $A$ is a $2 \times 2$ matrix with integer entries, the linear map $T_{A}: \mathbb{R}^{2} \rightarrow \mathbb{R}^{2}$ with matrix $A$ induces a continuous map $f: T \rightarrow T$. Furthermore, $f$ is a homeomorphism if $A$ is invertible over the integers.]

(b) Prove the following:

Theorem. If $E$ is a covering space of $T$, then $E$ is homeomorphic either to $\mathbb{R}^{2}$, or to $S^{1} \times \mathbb{R}$, or to $T$.

[Hint: You may use the following result from algebra: If $F$ is a free abelian group of rank 2 and $N$ is a nontrivial subgroup, then there is a basis $a_{1}, a_{2}$ for $F$ such that either (1) $m a_{1}$ is a basis for $N$, for some positive integer $m$, or (2) $m a_{1}, n a_{2}$ is a basis for $N$, where $m$ and $n$ are positive integers.]

*6. Prove the following:

Theorem. Let $G$ be a topological group with multiplication operation $m: G \times$ $G \rightarrow G$ and identity element $e$. Assume $p: \tilde{G} \rightarrow G$ is a covering map. Given $\tilde{e}$ with $p(\tilde{e})=e$, there is a unique multiplication operation on $\tilde{G}$ that makes it into a topological group such that $\tilde{e}$ is the identity element and $p$ is a homomorphism. Proof. Recall that, by our convention, $G$ and $\tilde{G}$ are path connected and locally path connected.

(a) Let $I: G \rightarrow G$ be the map $I(g)=g^{-1}$. Show there exist unique maps $\tilde{m}: \tilde{G} \times \tilde{G} \rightarrow \tilde{G}$ and $\tilde{I}: \tilde{G} \rightarrow \tilde{G}$ with $\tilde{m}(\tilde{e} \times \tilde{e})=\tilde{e}$ and $\tilde{I}(\tilde{e})=\tilde{e}$ such that $p \circ \tilde{m}=m \circ(p \times p)$ and $p \circ \tilde{I}=I \circ p$.

(b) Show the maps $\tilde{G} \rightarrow \tilde{G}$ given by $\tilde{g} \rightarrow \tilde{m}(\tilde{e} \times \tilde{g})$ and $\tilde{g} \rightarrow \tilde{m}(\tilde{g} \times \tilde{e})$ equal the identity map of $\tilde{G}$. [Hint: Use the uniqueness part of Lemma 79.1.]
(c) Show the maps $\tilde{G} \rightarrow \tilde{G}$ given by $\tilde{g} \rightarrow \tilde{m}(\tilde{g} \times \tilde{I}(\tilde{g}))$ and $\tilde{g} \rightarrow \tilde{m}(\tilde{I}(\tilde{g}) \times \tilde{g})$ $\operatorname{map} \tilde{G}$ to $\tilde{e}$.

(d) Show the maps $\tilde{G} \times \tilde{G} \times \tilde{G} \rightarrow \tilde{G}$ given by

$$
\begin{aligned}
& \tilde{g} \times \tilde{g}^{\prime} \times \tilde{g}^{\prime \prime} \rightarrow \tilde{m}\left(\tilde{g} \times \tilde{m}\left(\tilde{g}^{\prime} \times \tilde{g}^{\prime \prime}\right)\right) \\
& \tilde{g} \times \tilde{g}^{\prime} \times \tilde{g}^{\prime \prime} \rightarrow \tilde{m}\left(\tilde{m}\left(\tilde{g} \times \tilde{g}^{\prime}\right) \times \tilde{g}^{\prime \prime}\right)
\end{aligned}
$$

are equal.

(e) Complete the proof.

7. Let $p: \tilde{G} \rightarrow G$ be a homomorphism of topological groups that is a covering map. Show that if $G$ is abelian, so is $\tilde{G}$.

## §80 The Universal Covering Space

Suppose $p: E \rightarrow B$ is a covering map, with $p\left(e_{0}\right)=b_{0}$. If $E$ is simply connected, then $E$ is called a universal covering space of $B$. Since $\pi_{1}\left(E, e_{0}\right)$ is trivial, this covering space corresponds to the trivial subgroup of $\pi_{1}\left(B, b_{0}\right)$ under the correspondence defined in the preceding section. Theorem 79.4 thus implies that any two universal covering spaces of $B$ are equivalent. For this reason, we often speak of "the" universal covering space of a given space $B$. Not every space has a universal covering space, as we shall see. For the moment, we shall simply assume that B has a universal covering space and derive some consequences of this assumption.

We prove two preliminary lemmas:

Lemma 80.1. Let $B$ be path connected and locally path connected. Let $p: E \rightarrow B$ be a covering map in the former sense (so that $E$ is not required to be path connected). If $E_{0}$ is a path component of $E$, then the map $p_{0}: E_{0} \rightarrow B$ obtained by restricting $p$ is a covering map.

Proof. We first show $p_{0}$ is surjective. Since the space $E$ is locally homeomorphic to $B$, it is locally path connected. Therefore $E_{0}$ is open in $E$. It follows that $p\left(E_{0}\right)$ is open in $B$. We show that $p\left(E_{0}\right)$ is also closed in $B$, so that $p\left(E_{0}\right)=B$.

Let $x$ be a point of $B$ belonging to the closure of $p\left(E_{0}\right)$. Let $U$ be a path-connected neighborhood of $x$ that is evenly covered by $p$. Since $U$ contains a point of $p\left(E_{0}\right)$, some slice $V_{\alpha}$ of $p^{-1}(U)$ must intersect $E_{0}$. Since $V_{\alpha}$ is homeomorphic to $U$, it is path connected; therefore it must be contained in $E_{0}$. Then $p\left(V_{\alpha}\right)=U$ is contained in $p\left(E_{0}\right)$, so that in particular, $x \in p\left(E_{0}\right)$.

Now we show $p_{0}: E_{0} \rightarrow B$ is a covering map. Given $x \in B$, choose a neighborhood $U$ of $x$ as before. If $V_{\alpha}$ is a slice of $p^{-1}(U)$, then $V_{\alpha}$ is path connected; if it intersects $E_{0}$, it lies in $E_{0}$. Therefore, $p_{0}^{-1}(U)$ equals the union of those slices $V_{\alpha}$ of $p^{-1}(U)$ that intersect $E_{0}$; each of these is open in $E_{0}$ and is mapped homeomorphically by $p_{0}$ onto $U$. Thus $U$ is evenly covered by $p_{0}$.

Lemma 80.2. Let $p, q$, and $r$ be continuous maps with $p=r \circ q$, as in the following diagram:

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-454.jpg?height=153&width=186&top_left_y=498&top_left_x=926)

(a) If $p$ and $r$ are covering maps, so is $q$.

*(b) If $p$ and $q$ are covering maps, so is $r$.

Proof. By our convention, $X, Y$, and $Z$ are path connected and locally path connected. Let $x_{0} \in X$; set $y_{0}=q\left(x_{0}\right)$ and $z_{0}=p\left(x_{0}\right)$.

(a) Assume that $p$ and $r$ are covering maps. We show first that $q$ is surjective. Given $y \in Y$, choose a path $\tilde{\alpha}$ in $Y$ from $y_{0}$ to $y$. Then $\alpha=r \circ \tilde{\alpha}$ is a path in $Z$ beginning at $z_{0}$; let $\tilde{\tilde{\alpha}}$ be a lifting of $\alpha$ to a path in $X$ beginning at $x_{0}$. Then $q \circ \tilde{\tilde{\alpha}}$ is a lifting of $\alpha$ to $Y$ that begins at $y_{0}$. By uniqueness of path liftings, $\tilde{\alpha}=q \circ \tilde{\tilde{\alpha}}$. Then $q$ maps the end point of $\tilde{\tilde{\alpha}}$ to the end point $y$ of $\tilde{\alpha}$. Thus $q$ is surjective.

Given $y \in Y$, we find a neighborhood of $y$ that is evenly covered by $q$. Let $z=$ $r(y)$. Since $p$ and $r$ are covering maps, we can find a path-connected neighborhood $U$ of $z$ that is evenly covered by both $p$ and $r$. Let $V$ be the slice of $r^{-1}(U)$ that contains the point $y$; we show $V$ is evenly covered by $q$. Let $\left\{U_{\alpha}\right\}$ be the collection of slices of $p^{-1}(U)$. Now $q$ maps each set $U_{\alpha}$ into the set $r^{-1}(U)$; because $U_{\alpha}$ is connected, it must be mapped by $q$ into a single one of the slices of $r^{-1}(U)$. Therefore, $q^{-1}(V)$ equals the union of those slices $U_{\alpha}$ that are mapped by $q$ into $V$. It is easy to see that each such $U_{\alpha}$ is mapped homeomorphically onto $V$ by $q$. For let $p_{0}, q_{0}, r_{0}$ be the maps obtained by restricting $p, q$, and $r$, respectively, as indicated in the following diagram:

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-454.jpg?height=158&width=219&top_left_y=1525&top_left_x=912)

Because $p_{0}$ and $r_{0}$ are homeomorphisms, so is $q_{0}=r_{0}^{-1} \circ p_{0}$.

*(b) We shall use this result only in the exercises. Assume that $p$ and $q$ are covering maps. Because $p=r \circ q$ and $p$ is surjective, $r$ is also surjective.

Given $z \in Z$, let $U$ be a path-connected neighborhood of $z$ that is evenly covered by $p$. We show that $U$ is also evenly covered by $r$. Let $\left\{V_{\beta}\right\}$ be the collection of path components of $r^{-1}(U)$; these sets are disjoint and open in $Y$. We show that for each $\beta$, the map $r$ carries $V_{\beta}$ homeomorphically onto $U$.

Let $\left\{U_{\alpha}\right\}$ be the collection of slices of $p^{-1}(U)$; they are disjoint, open, and path connected, so they are the path components of $p^{-1}(U)$. Now $q$ maps each $U_{\alpha}$ into the set $r^{-1}(U)$; because $U_{\alpha}$ is connected, it must be mapped by $q$ into one of the sets $V_{\beta}$. Therefore $q^{-1}\left(V_{\beta}\right)$ equals the union of a subcollection of the collection $\left\{U_{\alpha}\right\}$. Theorem 53.2 and Lemma 80.1 together imply that if $U_{\alpha_{0}}$ is any one of the path components of $q^{-1}\left(V_{\beta}\right)$ then the map $q_{0}: U_{\alpha_{0}} \rightarrow V_{\beta}$ obtained by restricting $q$ is a covering map.

In particular, $q_{0}$ is surjective. Hence $q_{0}$ is a homeomorphism, being continuous, open, and injective as well. Consider the maps

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-455.jpg?height=161&width=222&top_left_y=511&top_left_x=1085)

obtained by restricting $p, q$, and $r$. Because $p_{0}$ and $q_{0}$ are homeomorphisms, so is $r_{0}$.

Theorem 80.3. Let $p: E \rightarrow B$ be a covering map, with $E$ simply connected. Given any covering map $r: Y \rightarrow B$, there is a covering map $q: E \rightarrow Y$ such that $r \circ q=p$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-455.jpg?height=147&width=186&top_left_y=987&top_left_x=1106)

This theorem shows why $E$ is called a universal covering space of $B$; it covers every other covering space of $B$.

Proof. Let $b_{0} \in B$; choose $e_{0}$ and $y_{0}$ so that $p\left(e_{0}\right)=b_{0}$ and $r\left(y_{0}\right)=b_{0}$. We apply Lemma 79.1 to construct $q$. The map $r$ is a covering map, and the condition

$$
p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right) \subset r_{*}\left(\pi_{1}\left(Y, y_{0}\right)\right)
$$

is satisfied trivially because $E$ is simply connected. Therefore, there is a map $q: E \rightarrow$ $Y$ such that $r \circ q=p$ and $q\left(e_{0}\right)=y_{0}$. It follows from the preceding lemma that $q$ is a covering map.

Now we give an example of a space that has no universal covering space. We need the following lemma.

Lemma 80.4. Let $p: E \rightarrow B$ be a covering map; let $p\left(e_{0}\right)=b_{0}$. If $E$ is simply connected, then $b_{0}$ has a neighborhood $U$ such that inclusion $i: U \rightarrow B$ induces the trivial homomorphism

$$
i_{*}: \pi_{1}\left(U, b_{0}\right) \longrightarrow \pi_{1}\left(B, b_{0}\right) .
$$

Proof. Let $U$ be a neighborhood of $b_{0}$ that is evenly covered by $p$; break $p^{-1}(U)$ up into slices; let $U_{\alpha}$ be the slice containing $e_{0}$. Let $f$ be a loop in $U$ based at $b_{0}$. Because $p$ defines a homeomorphism of $U_{\alpha}$ with $U$, the loop $f$ lifts to a loop $\tilde{f}$ in $U_{\alpha}$ based at $e_{0}$. Since $E$ is simply connected, there is a path homotopy $\tilde{F}$ in $E$ between $\tilde{f}$ and a constant loop. Then $p \circ \tilde{F}$ is a path homotopy in $B$ between $f$ and a constant loop.

EXAMPLE 1. Let $X$ be our familiar "infinite earring" in the plane; if $C_{n}$ is the circle of radius $1 / n$ in the plane with center at the point $(1 / n, 0)$, then $X$ is the union of the circles $C_{n}$. Let $b_{0}$ be the origin; we show that if $U$ is any neighborhood of $b_{0}$ in $X$, then the homomorphism of fundamental groups induced by inclusion $i: U \rightarrow X$ is not trivial.

Given $n$, there is a retraction $r: X \rightarrow C_{n}$ obtained by letting $r$ map each circle $C_{i}$ for $i \neq n$ to the point $b_{0}$. Choose $n$ large enough that $C_{n}$ lies in $U$. Then in the following diagram of homomorphisms induced by inclusion, $j_{*}$ is injective; hence $i_{*}$ cannot be trivial.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-456.jpg?height=197&width=503&top_left_y=673&top_left_x=770)

It follows that even though $X$ is path connected and locally path connected, it has no universal covering space.

## Exercise

1. Let $q: X \rightarrow Y$ and $r: Y \rightarrow Z$ be maps; let $p=r \circ q$.

(a) Let $q$ and $r$ be covering maps. Show that if $Z$ has a universal covering space, then $p$ is a covering map. Compare Exercise 4 of $\S 53$.

*(b) Give an example where $q$ and $r$ are covering maps but $p$ is not.

## *\$81 Covering Transformations

Given a covering map $p: E \rightarrow B$, it is of some interest to consider the set of all equivalences of this covering space with itself. Such an equivalence is called a covering transformation. Composites and inverses of covering transformations are covering transformations, so this set forms a group; it is called the group of covering transformations and denoted $\mathcal{C}(E, p, B)$.

Throughout this section, we shall assume that $p: E \rightarrow B$ is a covering map with $p\left(e_{0}\right)=b_{0}$; and we shall let $H_{0}=p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)$. We shall show that the group $\mathcal{C}(E, p, B)$ is completely determined by the group $\pi_{1}\left(B, b_{0}\right)$ and the subgroup $H_{0}$. Specifically, we shall show that if $N\left(H_{0}\right)$ is the largest subgroup of $\pi_{1}\left(B, b_{0}\right)$ of which $H_{0}$ is a normal subgroup, then $\mathcal{C}(E, p, B)$ is isomorphic to $N\left(H_{0}\right) / H_{0}$.

We define $N\left(H_{0}\right)$ formally as follows:

Definition. If $H$ is a subgroup of the group $G$, then the normalizer of $H$ in $G$ is the subset of $G$ defined by the equation

$$
N(H)=\left\{g \mid g H g^{-1}=H\right\}
$$

It is easy to see that $N(H)$ is a subgroup of $G$. It follows from the definition that it contains $H$ as a normal subgroup and is the largest such subgroup of $G$.

The correspondence between the groups $N\left(H_{0}\right) / H_{0}$ and $\mathcal{C}(E, p, B)$ is established by using the lifting correspondence of $\S 54$ and the results about the existence of equivalences proved in $\S 79$. We make the following definition:

Definition. Given $p: E \rightarrow B$ with $p\left(e_{0}\right)=b_{0}$, let $F$ be the set $F=p^{-1}\left(e_{0}\right)$. Let

$$
\Phi: \pi_{1}\left(B, b_{0}\right) / H_{0} \rightarrow F
$$

be the lifting correspondence of Theorem 54.6; it is a bijection. Define also a correspondence

$$
\Psi: \mathcal{C}(E, p, B) \rightarrow F
$$

by setting $\Psi(h)=h\left(e_{0}\right)$ for each covering transformation $h: E \rightarrow E$. Since $h$ is uniquely determined once its value at $e_{0}$ is known, the correspondence $\Psi$ is injective.

Lemma 81.1. The image of the map $\Psi$ equals the image under $\Phi$ of the subgroup $N\left(H_{0}\right) / H_{0}$ of $\pi_{1}\left(B, b_{0}\right) / H_{0}$.

Proof. Recall that the lifting correspondence $\phi: \pi_{1}\left(B, b_{0}\right) \rightarrow F$ is defined as follows: Given a loop $\alpha$ in $B$ at $b_{0}$, let $\gamma$ be its lift to $E$ beginning at $e_{0}$; let $e_{1}=\gamma(1)$; and define $\phi$ by setting $\phi([\alpha])=e_{1}$. To prove the lemma, we need to show that there is a covering transformation $h: E \rightarrow E$ with $h\left(e_{0}\right)=e_{1}$ if and only if $[\alpha] \in N\left(H_{0}\right)$.

This is easy. Lemma 79.1 tells us that $h$ exists if and only if $H_{0}=H_{1}$, where $H_{1}=p_{*}\left(\pi_{1}\left(E, e_{1}\right)\right)$. And Lemma 79.3 tells us that $[\alpha] * H_{1} *[\alpha]^{-1}=H_{0}$. Hence $h$ exists if and only if $[\alpha] * H_{0} *[\alpha]^{-1}=H_{0}$, which is simply the statement that $[\alpha] \in$ $N\left(H_{0}\right)$.

## Theorem 81.2. The bijection

$$
\Phi^{-1} \circ \Psi: \mathcal{C}(E, p, B) \rightarrow N\left(H_{0}\right) / H_{0}
$$

is an isomorphism of groups.

Proof. We need only show that $\Phi^{-1} \circ \Psi$ is a homomorphism. Let $h, k: E \rightarrow E$ be covering transformations. Let $h\left(e_{0}\right)=e_{1}$ and $k\left(e_{0}\right)=e_{2}$; then

$$
\Psi(h)=e_{1} \quad \text { and } \quad \Psi(k)=e_{2},
$$

by definition. Choose paths $\gamma$ and $\delta$ in $E$ from $e_{0}$ to $e_{1}$ and $e_{2}$, respectively. If $\alpha=p \circ \gamma$ and $\beta=p \circ \delta$, then

$$
\Phi\left([\alpha] H_{0}\right)=e_{1} \quad \text { and } \quad \Phi\left([\beta] H_{0}\right)=e_{2} \text {, }
$$

by definition. Let $e_{3}=h\left(k\left(e_{0}\right)\right)$; then $\Psi(h \circ k)=e_{3}$. We show that

$$
\Phi\left([\alpha * \beta] H_{0}\right)=e_{3},
$$

and the proof is complete.

Since $\delta$ is a path from $e_{0}$ to $e_{2}$, the path $h \circ \delta$ is a path from $h\left(e_{0}\right)=e_{1}$ to $h\left(e_{2}\right)=h\left(k\left(e_{0}\right)\right)=e_{3}$. See Figure 81.1. Then the product $\gamma *(h \circ \delta)$ is defined and is a path from $e_{0}$ to $e_{3}$. It is a lifting of $\alpha * \beta$, since $p \circ \gamma=\alpha$ and $p \circ h \circ \delta=p \circ \delta=\beta$. Therefore $\Phi\left([\alpha * \beta] H_{0}\right)=e_{3}$, as desired.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-458.jpg?height=510&width=810&top_left_y=666&top_left_x=616)

Figure 81.1

Corollary 81.3. The group $H_{0}$ is a normal subgroup of $\pi_{1}\left(B, b_{0}\right)$ if and only if for every pair of points $e_{1}$ and $e_{2}$ of $p^{-1}\left(b_{0}\right)$, there is a covering transformation $h: E \rightarrow$ $E$ with $h\left(e_{1}\right)=e_{2}$. In this case, there is an isomorphism

$$
\Phi^{-1} \circ \Psi: \mathcal{C}(E, p, B) \rightarrow \pi_{1}\left(B, b_{0}\right) / H_{0}
$$

Corollary 81.4. Let $p: E \rightarrow B$ be a covering map. If $E$ is simply connected, then

$$
\mathcal{C}(E, p, B) \cong \pi_{1}\left(B, b_{0}\right) .
$$

If $H_{0}$ is a normal subgroup of $\pi_{1}\left(B, b_{0}\right)$, then $p: E \rightarrow B$ is called a regular covering map. (Here is another example of the overuse of familiar terms. The words "normal" and "regular" have already been used to mean quite different things!)

EXAMPLE 1. Because the fundamental group of the circle is abelian, every covering of $S^{1}$ is regular. If $p: \mathbb{R} \rightarrow S^{1}$ is the standard covering map, for instance, the covering transformations are the homeomorphisms $x \rightarrow x+n$. The group of such transformations is isomorphic to $\mathbb{Z}$.

EXAMPLE 2. For an example at the other extreme, consider the covering space of the figure eight indicated in Figure 81.2. (We considered this covering earlier, in §60. The $x$-axis is wrapped around the circle $A$ and the $y$-axis is wrapped around $B$. The circles $A_{i}$ and $B_{i}$ are mapped homeomorphically onto $A$ and $B$, respectively.) In this case, we show that the group $\mathcal{C}(E, p, B)$ is trivial.

In general, if $h: E \rightarrow E$ is a covering transformation, then any loop in the base space that lifts to a loop in $E$ at $e_{0}$ also lifts to a loop when the lift begins at $h\left(e_{0}\right)$. In the present case, a loop that generates the fundamental group of $A$ lifts to a non-loop when the lift is based at $e_{0}$ and lifts to a loop when it is based at any other point of $p^{-1}\left(b_{0}\right)$ lying on the $y$-axis. Similarly, a loop that generates the fundamental group of $B$ lifts to a non-loop beginning at $e_{0}$ and to a loop beginning at any other point of $p^{-1}\left(b_{0}\right)$ lying on the $x$-axis. It follows that $h\left(e_{0}\right)=e_{0}$, so that $h$ is the identity map.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-459.jpg?height=644&width=1082&top_left_y=691&top_left_x=658)

Figure 81.2

There is a method for constructing covering spaces that automatically leads to a covering that is regular; and in fact every regular covering space can be constructed by this method. It involves the action of a group $G$ on a space $X$.

Definition. Let $X$ be a space, and let $G$ be a subgroup of the group of homeomorphisms of $X$ with itself. The orbit space $X / G$ is defined to be the quotient space obtained from $X$ by means of the equivalence relation $x \sim g(x)$ for all $x \in X$ and all $g \in G$. The equivalence class of $x$ is called the orbit of $x$.

Definition. If $G$ is a group of homeomorphisms of $X$, the action of $G$ on $X$ is said to be properly discontinuous if for every $x \in X$ there is a neighborhood $U$ of $x$ such that $g(U)$ is disjoint from $U$ whenever $g \neq e$. (Here $e$ is the identity element of $G$.) It follows that $g_{0}(U)$ and $g_{1}(U)$ are disjoint whenever $g_{0} \neq g_{1}$, for otherwise $U$ and $g_{0}^{-1} g_{1}(U)$ would not be disjoint.

Theorem 81.5. Let $X$ be path connected and locally path connected; let $G$ be a group of homeomorphisms of $X$. The quotient map $\pi: X \rightarrow X / G$ is a covering map if and only if the action of $G$ is properly discontinuous. In this case, the covering map $\pi$ is regular and $G$ is its group of covering transformations.

Proof. We show $\pi$ is an open map. If $U$ is open in $X$, then $\pi^{-1} \pi(U)$ is the union of the open sets $g(U)$ of $X$, for $g \in G$. Hence $\pi^{-1} \pi(U)$ is open in $X$, so that $\pi(U)$ is open in $X / G$ by definition. Thus $\pi$ is open.

Step 1. We suppose that the action of $G$ is properly discontinuous and show that $\pi$ is a covering map. Given $x \in X$, let $U$ be a neighborhood of $x$ such that $g_{0}(U)$ and $g_{1}(U)$ are disjoint whenever $g_{0} \neq g_{1}$. Then $\pi(U)$ is evenly covered by $\pi$. Indeed, $\pi^{-1} \pi(U)$ equals the union of the disjoint open sets $g(U)$, for $g \in G$, each of which contains at most one point of each orbit. Therefore, the map $g(U) \rightarrow \pi(U)$ obtained by restricting $\pi$ is bijective; being continuous and open, it is a homeomorphism. The sets $g(U)$, for $g \in G$, thus form a partition of $\pi^{-1} \pi(U)$ into slices.

Step 2. We suppose now that $\pi$ is a covering map and show that the action of $G$ is properly discontinuous. Given $x \in X$, let $V$ be a neighborhood of $\pi(x)$ that is evenly covered by $\pi$. Partition $\pi^{-1}(V)$ into slices; let $U_{\alpha}$ be the slice containing $x$. Given $g \in G$ with $g \neq e$, the set $g\left(U_{\alpha}\right)$ must be disjoint from $U_{\alpha}$, for otherwise, two points of $U_{\alpha}$ would belong to the same orbit and the restriction of $\pi$ to $U_{\alpha}$ would not be injective. It follows that the action of $G$ is properly discontinuous.

Step 3. We show that if $\pi$ is a covering map, then $G$ is its group of covering transformations and $\pi$ is regular. Certainly any $g \in G$ is a covering transformation, for $\pi \circ g=\pi$ because the orbit of $g(x)$ equals the orbit of $x$. On the other hand, let $h$ be a covering transformation with $h\left(x_{1}\right)=x_{2}$, say. Because $\pi \circ h=\pi$, the points $x_{1}$ and $x_{2}$ map to the same point under $\pi$; therefore there is an element $g \in G$ such that $\mathrm{g}\left(x_{1}\right)=x_{2}$. The uniqueness part of Theorem 79.2 then implies that $h=g$.

It follows that $\pi$ is regular. Indeed, for any two points $x_{1}$ and $x_{2}$ lying in the same orbit, there is an element $g \in G$ such that $g\left(x_{1}\right)=x_{2}$. Then Corollary 81.3 applies.

Theorem 81.6. If $p: X \rightarrow B$ is a regular covering map and $G$ is its group of covering transformations, then there is a homeomorphism $k: X / G \rightarrow B$ such that $p=k \circ \pi$, where $\pi: X \rightarrow X / G$ is the projection.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-460.jpg?height=183&width=236&top_left_y=1657&top_left_x=903)

Proof. If $g$ is a covering transformation, then $p(g(x))=p(x)$ by definition. Hence $p$ is constant on each orbit, so it induces a continuous map $k$ of the quotient space $X / G$ into $B$. On the other hand, $p$ is a quotient map because it is continuous, surjective, and open. Because $p$ is regular, any two points of $p^{-1}(b)$ belong to the same orbit under the action of $G$. Therefore, $\pi$ induces a continuous map $B \rightarrow X / G$ that is an inverse for $k$.

EXAMPle 3. Let $X$ be the cylinder $S^{1} \times I$; let $h: X \rightarrow X$ be the homeomorphism $h(x, t)=(-x, t)$; and let $k: X \rightarrow X$ be the homeomorphism $k(x, t)=(-x, 1-t)$. The groups $G_{1}=\{e, h\}$ and $G_{2}=\{e, k\}$ are isomorphic to the integers modulo 2; both
act properly discontinuously on $X$. But $X / G_{1}$ is homeomorphic to $X$, while $X / G_{2}$ is homeomorphic to the Möbius band, as you can check. See Figure 81.3.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-461.jpg?height=118&width=1084&top_left_y=510&top_left_x=655)

Figure 81.3

## Exercises

1. (a) Find a group $G$ of homeomorphisms of the torus $T$ having order 2 such that $T / G$ is homeomorphic to the torus.

(b) Find a group $G$ of homeomorphisms of $T$ having order 2 that $T / G$ is homeomorphic to the Klein bottle.

2. Let $X=A \vee B$ be the wedge of two circles.

(a) Let $E$ be the space pictured in Figure 81.4; let $p: E \rightarrow X$ wrap each arc $A_{1}$ and $A_{2}$ around $A$ and map $B_{1}$ and $B_{2}$ homeomorphically onto $B$. Show $p$ is a regular covering map.

(b) Determine the group of covering transformations of the covering of $X$ indicated in Figure 81.5. Is this covering regular?

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-461.jpg?height=286&width=1080&top_left_y=1395&top_left_x=659)

Figure 81.4

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-461.jpg?height=311&width=802&top_left_y=1837&top_left_x=798)

Figure 81.5
(c) Repeat (b) for the covering pictured in Figure 81.6.

(d) Repeat (b) for the covering pictured in Figure 81.7.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-462.jpg?height=373&width=1111&top_left_y=513&top_left_x=466)

Figure 81.6

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-462.jpg?height=274&width=1083&top_left_y=1037&top_left_x=480)

Figure 81.7

3. Let $p: X \rightarrow B$ be a covering map (not necessarily regular); let $G$ be its group of covering transformations.

(a) Show that the action of $G$ on $X$ is properly discontinuous.

(b) Let $\pi: X \rightarrow X / G$ be the projection map. Show there is a covering map $k: X / G \rightarrow B$ such that $k \circ \pi=p$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-462.jpg?height=155&width=247&top_left_y=1688&top_left_x=970)

4. Let $G$ be a group of homeomorphisms of $X$. The action of $G$ on $X$ is said to be fixed-point free if no element of $G$ other than the identity $e$ has a fixed point. Show that if $X$ is Hausdorff, and if $G$ is a finite group of homeomorphisms of $X$ whose action is fixed-point free, then the action of $G$ is properly discontinuous.
5. Consider $S^{3}$ as the space of all pairs of complex numbers $\left(z_{1}, z_{2}\right)$ satisfying the equation $\left|z_{1}\right|^{2}+\left|z_{2}\right|^{2}=1$. Given relatively prime positive integers $n$ and $k$, define $h: S^{3} \rightarrow S^{3}$ by the equation

$$
h\left(z_{1}, z_{2}\right)=\left(z_{1} e^{2 \pi i / n}, z_{2} e^{2 \pi i k / n}\right) .
$$

(a) Show that $h$ generates a subgroup $G$ of the homeomorphism group of $S^{3}$ that is cyclic of order $n$, and that only the identity element of $G$ has a fixed point. The orbit space $S^{3} / G$ is called the lens space $L(n, k)$.

(b) Show that if $L(n, k)$ and $L\left(n^{\prime}, k^{\prime}\right)$ are homeomorphic, then $n=n^{\prime}$. [It is a theorem that $L(n, k)$ and $L\left(n^{\prime}, k^{\prime}\right)$ are homeomorphic if and only if $n=n^{\prime}$ and either $k \equiv k^{\prime}(\bmod n)$ or $k k^{\prime} \equiv 1(\bmod n)$. The proof is decidedly nontrivial.]

(c) Show that $L(n, k)$ is a compact 3-manifold.

6. Prove the following:

Theorem. Let $X$ be a locally compact Hausdorff space; let $G$ be a group of homeomorphisms of $X$ such that the action of $G$ is fixed-point free. Suppose that for each compact subspace $C$ of $X$, there are only finitely many elements $g$ of $G$ such that the intersection $C \cap g(C)$ is nonempty. Then the action of $G$ is properly discontinuous, and $X / G$ is locally compact Hausdorff.

Proof.

(a) For each compact subspace $C$ of $X$, show that the union of the sets $g(C)$, for $g \in G$, is closed in $X$. [Hint: If $U$ is a neighborhood of $x$ with $\bar{U}$ compact, then $\bar{U} \cup C$ intersects $g(\bar{U} \cup C)$ for only finitely many $g$.]

(b) Show $X / G$ is Hausdorff.

(c) Show the action of $G$ is properly discontinuous.

(d) Show $X / G$ is locally compact.

## $\$ 82$ Existence of Covering Spaces

We have shown that corresponding to each covering map $p: E \rightarrow B$ is a conjugacy class of subgroups of $\pi_{1}\left(B, b_{0}\right)$, and that two such covering maps are equivalent if and only if they correspond to the same such class. Thus, we have an injective correspondence from equivalence classes of coverings of $B$ to conjugacy classes of subgroups of $\pi_{1}\left(B, b_{0}\right)$. Now we ask the question whether this correspondence is surjective, that is, whether for every conjugacy class of subgroups of $\pi_{1}\left(B, b_{0}\right)$, there exists a covering of $B$ that corresponds to this class.

The answer to this question is "no," in general. In $\S 80$, we gave an example of a path-connected, locally path-connected space $B$ that had no simply connected covering space, that is, that had no covering space corresponding to the class of the trivial subgroup. This example relied on Lemma 80.4, which gave a condition that any space having a simply connected covering space must satisfy. We now introduce this condition formally.

Definition. A space $B$ is said to be semilocally simply connected if for each $b \in B$, there is a neighborhood $U$ of $b$ such that the homomorphism

$$
i_{*}: \pi_{1}(U, b) \rightarrow \pi_{1}(B, b)
$$

induced by inclusion is trivial.

Note that if $U$ satisfies this condition, then so does any smaller neighborhood of $b$, so that $b$ has "arbitrarily small" neighborhoods satisfying this condition. Note also that this condition is weaker than true local simple connectedness, which would require that within each neighborhood of $b$ there should exist a neighborhood $U$ of $b$ that is itself simply connected.

Semilocal simple connectedness of $B$ is both necessary and sufficient for there to exist, for every conjugacy class of subgroups of $\pi_{1}\left(B, b_{0}\right)$, a corresponding covering space of $B$. Necessity was proved in Lemma 80.4 ; sufficiency is proved in this section.

Theorem 82.1. Let $B$ be path connected, locally path connected, and semilocally simply connected. Let $b_{0} \in B$. Given a subgroup $H$ of $\pi_{1}\left(B, b_{0}\right)$, there exists a covering map $p: E \rightarrow B$ and a point $e_{0} \in p^{-1}\left(b_{0}\right)$ such that

$$
p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)=H
$$

Proof. Step 1. Construction of $E$. The procedure for constructing $E$ is reminiscent of the procedure used in complex analysis for constructing Riemann surfaces. Let $\mathcal{P}$ denote the set of all paths in $B$ beginning at $b_{0}$. Define an equivalence relation on $\mathcal{P}$ by setting $\alpha \sim \beta$ if $\alpha$ and $\beta$ end at the same point of $B$ and

$$
[\alpha * \bar{\beta}] \in H
$$

This relation is easily seen to be an equivalence relation. We will denote the equivalence class of the path $\alpha$ by $\alpha^{\#}$.

Let $E$ denote the collection of equivalence classes, and define $p: E \rightarrow B$ by the equation

$$
p\left(\alpha^{\#}\right)=\alpha(1) \text {. }
$$

Since $B$ is path connected, $p$ is surjective. We shall topologize $E$ so that $p$ is a covering map.

We first note two facts:

(1) If $[\alpha]=[\beta]$, then $\alpha^{\#}=\beta^{\#}$.

(2) If $\alpha^{\#}=\beta^{\#}$, then $(\alpha * \delta)^{\#}=(\beta * \delta)^{\#}$ for any path $\delta$ in $B$ beginning at $\alpha(1)$.

The first follows by noting that if $[\alpha]=[\beta]$, then $[\alpha * \bar{\beta}]$ is the identity element, which belongs to $H$. The second follows by noting that $\alpha * \delta$ and $\beta * \delta$ end at the same point of $B$, and

$$
[(\alpha * \delta) * \overline{(\beta * \delta)}]=[(\alpha * \delta) *(\bar{\delta} * \bar{\beta})]=[\alpha * \bar{\beta}]
$$

which belongs to $H$ by hypothesis.

Step 2. Topologizing $E$. One way to topologize $E$ is to give $\mathcal{P}$ the compact-open topology (see Chapter 7) and $E$ the corresponding quotient topology. But we can topologize $E$ directly as follows:

Let $\alpha$ be any element of $\mathcal{P}$, and let $U$ be any path-connected neighborhood of $\alpha(1)$. Define

$$
B(U, \alpha)=\left\{(\alpha * \delta)^{\#} \mid \delta \text { is a path in } U \text { beginning at } \alpha(1)\right\} \text {. }
$$

Note that $\alpha^{\#}$ is an element of $B(U, \alpha)$, since if $b=\alpha(1)$, then $\alpha^{\#}=\left(\alpha * e_{b}\right)^{\#}$; this element belongs to $B(U, \alpha)$ by definition. We assert that the sets $B(U, \alpha)$ form a basis for a topology on $E$.

First, we show that if $\beta^{\#} \in B(U, \alpha)$, then $\alpha^{\#} \in B(U, \beta)$ and $B(U, \alpha)=B(U, \beta)$. If $\beta^{\#} \in B(U, \alpha)$, then $\beta^{\#}=(\alpha * \delta)^{\#}$ for some path $\delta$ in $U$. Then

$$
\begin{aligned}
(\beta * \bar{\delta})^{\#} & =((\alpha * \delta) * \bar{\delta})^{\#} & & \text { by (2) } \\
& =\alpha^{\#} & & \text { by (1) }
\end{aligned}
$$

so that $\alpha^{\#} \in B(U, \beta)$ by definition. See Figure 82.1. We show first that $B(U, \beta) \subset$ $B(U, \alpha)$. Note that the general element of $B(U, \beta)$ is of the form $(\beta * \gamma)^{\#}$, where $\gamma$ is a path in $U$. Then note that

$$
\begin{aligned}
(\beta * \gamma)^{\#} & =((\alpha * \delta) * \gamma)^{\#} \\
& =(\alpha *(\delta * \gamma))^{\#}
\end{aligned}
$$

which belongs to $B(U, \alpha)$ by definition. Symmetry gives the inclusion $B(U, \alpha) \subset$ $B(U, \beta)$ as well.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-465.jpg?height=749&width=782&top_left_y=1338&top_left_x=797)

Figure 82.1

Now we show the sets $B(U, \alpha)$ form a basis. If $\beta^{\#}$ belongs to the intersection $B\left(U_{1}, \alpha_{1}\right) \cap B\left(U_{2}, \alpha_{2}\right)$, we need merely choose a path-connected neighborhood $V$
of $\beta(1)$ contained in $U_{1} \cap U_{2}$. The inclusion

$$
B(V, \beta) \subset B\left(U_{1}, \beta\right) \cap B\left(U_{2}, \beta\right)
$$

follows from the definition of these sets, and the right side of the equation equals $B\left(U_{1}, \alpha_{1}\right) \cap B\left(U_{2}, a_{2}\right)$ by the result just proved.

Step 3. The map $p$ is continuous and open. It is easy to see that $p$ is open, for the image of the basis element $B(U, \alpha)$ is the open subset $U$ of $B$ : Given $x \in U$, we choose a path $\delta$ in $U$ from $\alpha(1)$ to $x$; then $(\alpha * \delta)^{\#}$ is in $B(U, \alpha)$ and $p\left((\alpha * \delta)^{\#}\right)=x$.

To show that $p$ is continuous, let us take an element $\alpha^{\#}$ of $E$ and a neighborhood $W$ of $p\left(\alpha^{\#}\right)$. Choose a path-connected neighborhood $U$ of the point $p\left(\alpha^{\#}\right)=\alpha(1)$ lying in $W$. Then $B(U, \alpha)$ is a neighborhood of $\alpha^{\#}$ that $p$ maps into $W$. Thus $p$ is continuous at $\alpha^{\#}$.

Step 4. Every point of $B$ has a neighborhood that is evenly covered by $p$. Given $b_{1} \in B$, choose $U$ to be a path-connected neighborhood of $b_{1}$ that satisfies the further condition that the homomorphism $\pi_{1}\left(U, b_{1}\right) \rightarrow \pi_{1}\left(B, b_{1}\right)$ induced by inclusion is trivial. We assert that $U$ is evenly covered by $p$.

First, we show that $p^{-1}(U)$ equals the union of the sets $B(U, \alpha)$, as $\alpha$ ranges over all paths in $B$ from $b_{0}$ to $b_{1}$. Since $p$ maps each set $B(U, \alpha)$ onto $U$, it is clear that $p^{-1}(U)$ contains this union. On the other hand, if $\beta^{\#}$ belongs to $p^{-1}(U)$, then $\beta(1) \in U$. Choose a path $\delta$ in $U$ from $b_{1}$ to $\beta(1)$ and let $\alpha$ be the path $\beta * \bar{\delta}$ from $b_{0}$ to $b_{1}$. Then $[\beta]=[\alpha * \delta]$, so that $\beta^{\#}=(\alpha * \delta)^{\#}$, which belongs to $B(U, \alpha)$. Thus $p^{-1}(U)$ is contained in the union of the sets $B(U, \alpha)$.

Second, note that distinct sets $B(U, \alpha)$ are disjoint. For if $\beta^{\#}$ belongs to $B\left(U, \alpha_{1}\right) \cap$ $B\left(U, \alpha_{2}\right)$, then $B\left(U, \alpha_{1}\right)=B(U, \beta)=B\left(U, \alpha_{2}\right)$, by Step 2 .

Third, we show that $p$ defines a bijective map of $B(U, \alpha)$ with $U$. It follows that $p \mid B(U, \alpha)$ is a homeomorphism, being bijective and continuous and open. We already know that $p$ maps $B(U, \alpha)$ onto $U$. To prove injectivity, suppose that

$$
p\left(\left(\alpha * \delta_{1}\right)^{\#}\right)=p\left(\left(\alpha * \delta_{2}\right)^{\#}\right)
$$

where $\delta_{1}$ and $\delta_{2}$ are paths in $U$. Then $\delta_{1}(1)=\delta_{2}(1)$. Because the homomorphism $\pi_{1}\left(U, b_{1}\right) \rightarrow \pi_{1}\left(B, b_{1}\right)$ induced by inclusion is trivial, $\delta_{1} * \bar{\delta}_{2}$ is path homotopic in $B$ to the constant loop. Then $\left[\alpha * \delta_{1}\right]=\left[\alpha * \delta_{2}\right]$, so that $\left(\alpha * \delta_{1}\right)^{\#}=\left(\alpha * \delta_{2}\right)^{\#}$, as desired.

It follows that $p: E \rightarrow B$ is a covering map in the sense used in earlier chapters. To show it is a covering map in the sense used in this chapter, we must show $E$ is path connected. This we shall do shortly.

Step 5. Lifting a path in $B$. Let $e_{0}$ denote the equivalence class of the constant path at $b_{0}$; then $p\left(e_{0}\right)=b_{0}$ by definition. Given a path $\alpha$ in $B$ beginning at $b_{0}$, we calculate its lift to a path in $E$ beginning at $e_{0}$ and show that this lift ends at $\alpha^{\#}$.

To begin, given $c \in[0,1]$, let $\alpha_{c}: I \rightarrow B$ denote the path defined by the equation

$$
\alpha_{c}(t)=\alpha(t c) \quad \text { for } \quad 0 \leq t \leq 1
$$

Then $\alpha_{c}$ is the "portion" of $\alpha$ that runs from $\alpha(0)$ to $\alpha(c)$. In particular, $\alpha_{0}$ is the constant path at $b_{0}$, and $\alpha_{1}$ is the path $\alpha$ itself. We define $\tilde{\alpha}: I \rightarrow E$ by the equation

$$
\tilde{\alpha}(c)=\left(\alpha_{c}\right)^{\#}
$$

and show that $\tilde{\alpha}$ is continuous. Then $\tilde{\alpha}$ is a lift of $\alpha$, since $p(\tilde{\alpha}(c))=\alpha_{c}(1)=\alpha(c)$; furthermore, $\tilde{\alpha}$ begins at $\left(\alpha_{0}\right)^{\#}=e_{0}$ and ends at $\left(\alpha_{1}\right)^{\#}=\alpha^{\#}$.

To verify continuity, we introduce the following notation. Given $0 \leq c<d \leq 1$, let $\delta_{c, d}$ denote the path that equals the positive linear map of $I$ onto $[c, d]$ followed by $\alpha$. Note that the paths $\alpha_{d}$ and $\alpha_{c} * \delta_{c, d}$ are path homotopic because one is just a reparametrization of the other. See Figure 82.2.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-467.jpg?height=370&width=841&top_left_y=692&top_left_x=776)

Figure 82.2

We now verify continuity of $\tilde{\alpha}$ at the point $c$ of [0,1]. Let $W$ be a basis element in $E$ about the point $\tilde{\alpha}(c)$. Then $W$ equals $B\left(U, \alpha_{c}\right)$ for some path-connected neighborhood $U$ of $\alpha(c)$. Choose $\epsilon>0$ so that for $|c-t|<\epsilon$, the point $\alpha(t)$ lies in $U$. We show that if $d$ is a point of [0,1] with $|c-d|<\epsilon$, then $\tilde{\alpha}(d) \in W$; this proves continuity of $\tilde{\alpha}$ at $c$.

So suppose $|c-d|<\epsilon$. Take first the case where $d>c$. Set $\delta=\delta_{c, d}$; then since $\left[\alpha_{d}\right]=\left[\alpha_{c} * \delta\right]$, we have

$$
\tilde{\alpha}(d)=\left(\alpha_{d}\right)^{\#}=\left(\alpha_{c} * \delta\right)^{\#}
$$

Since $\delta$ lies in $U$, we have $\tilde{\alpha}(d) \in B\left(U, \alpha_{c}\right)$, as desired. If $d<c$, set $\delta=\delta_{d, c}$ and proceed similarly.

Step 6. The map $p: E \rightarrow B$ is a covering map. We need only verify that $E$ is path connected, and this is easy. For if $\alpha^{\#}$ is any point of $E$, then the lift $\tilde{\alpha}$ of the path $\alpha$ is a path in $E$ from $e_{0}$ to $\alpha^{\#}$.

Step 7. Finally, $H=p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right.$. Let $\alpha$ be a loop in $B$ at $b_{0}$. Let $\tilde{\alpha}$ be its lift to $E$ beginning at $e_{0}$. Theorem 54.6 tells us that $[\alpha] \in p_{*}\left(\pi_{1}\left(E, e_{0}\right)\right)$ if and only if $\tilde{\alpha}$ is a loop in $E$. Now the final point of $\tilde{\alpha}$ is the point $\alpha^{\#}$, and $\alpha^{\#}=e_{0}$ if and only if $\alpha$ is equivalent to the constant path at $b_{0}$, i.e., if and only if $\left[\alpha * \bar{e}_{b_{0}}\right] \in H$. This occurs precisely when $[\alpha] \in H$.

Corollary 82.2. The space $B$ has a universal covering space if and only if $B$ is path connected, locally path connected, and semilocally simply connected.

## Exercises

1. Show that a simply connected space is semilocally simply connected.
2. Let $X$ be the infinite earring in $\mathbb{R}^{2}$. (See Example 1 of $\S 80$.) Let $C(X)$ be the subspace of $\mathbb{R}^{3}$ that is the union of all line segments joining points of $X \times 0$ to the point $p=(0,0,1)$. It is called the cone on $X$. Show that $C(X)$ is simply connected, but is not locally simply connected at the origin.

## *Supplementary Exercises: Topological Properties and $\pi_{1}$

The results of the preceding section tell us that the appropriate hypotheses for classifying the covering spaces of $B$ are that $B$ is path connected, locally path connected, and semilocally simply connected. We now show that they are also the correct hypotheses for studying the relation between various topological properties of $B$ and the fundamental group of $B$.

1. Let $X$ be a space; let $\mathcal{A}$ be an open covering of $X$. Under what conditions does there exist an open covering $\mathscr{B}$ of $X$ refining $\mathcal{A}$ such that for each pair $B, B^{\prime}$ of elements of $\mathscr{B}$ that have nonempty intersection, the union $B \cup B^{\prime}$ lies in an element of $\mathcal{A}$ ?

(a) Show that such a covering $\mathscr{B}$ exists if $X$ is metrizable. [Hint: Choose $\epsilon(x)$ so $B(x, 3 \epsilon(x))$ lies in an element of $\mathcal{A}$. Let $\mathscr{B}$ consist of the open sets $B(x, \epsilon(x))$.]

(b) Show that such a covering exists if $X$ is compact Hausdorff. [Hint: Let $A_{1}, \ldots, A_{n}$ be a finite subcollection of $\mathcal{A}$ that covers $X$. Choose an open covering $C_{1}, \ldots, C_{n}$ of $X$ such that $\bar{C}_{i} \subset A_{i}$ for each $i$. For each nonempty subset $J$ of $\{1, \ldots, n\}$, consider the set

$$
\left.B_{J}=\bigcap_{j \in J} A_{j}-\bigcup_{j \notin J} \bar{C}_{j} \cdot\right]
$$

2. Prove the following:

Theorem. Let $X$ be a space that is path connected, locally path connected, and semilocally simply connected. If $X$ is regular with a countable basis, then $\pi_{1}\left(X, x_{0}\right)$ is countable.

Proof. Let $\mathcal{A}$ be a covering of $X$ by path-connected open sets $A$ such that for each $A \in \mathcal{A}$ and each $a \in A$, the homomorphism $\pi_{1}(A, a) \rightarrow \pi_{1}(X, a)$ induced by inclusion is trivial. Let $\mathscr{B}$ be a countable open covering of $X$ by nonempty path-connected sets that satisfies the conditions of Exercise 1. Choose a point $p(B) \in B$ for each $B \in \mathcal{B}$. For each pair $B, B^{\prime}$ of elements of $\mathcal{B}$ for which $B \cap B^{\prime} \neq \varnothing$, choose a path $g\left(B, B^{\prime}\right)$ in $B \cup B^{\prime}$ from $p(B)$ to $p\left(B^{\prime}\right)$. We call the path $g\left(B, B^{\prime}\right)$ a select path.

Let $B_{0}$ be a fixed element of $\mathscr{B}$; let $x_{0}=p\left(B_{0}\right)$. Show that if $f$ is a loop in $X$ based at $x_{0}$, then $f$ is path homotopic to a product of select paths, as follows:

(a) Show that there is a subdivision

$$
0=t_{0}<\cdots<t_{n}=1
$$

of $[0,1]$ such that $f$ maps $\left[t_{n-1}, t_{n}\right]$ into $B_{0}$, and for each $i=1, \ldots, n-1$, $f$ maps $\left[t_{i-1}, t_{i}\right]$ into an element $B_{i}$ of $\mathscr{B}$. Set $B_{n}=B_{0}$.

(b) Let $f_{i}$ be the positive linear map of $[0,1]$ onto $\left[t_{i-1}, t_{i}\right]$ followed by $f$. Let $g_{i}=g\left(B_{i-1}, B_{i}\right)$. Choose a path $\alpha_{i}$ in $B_{i}$ from $f\left(t_{i}\right)$ to $p\left(B_{i}\right)$; if $i=0$ or $n$, let $\alpha_{i}$ be the constant path at $x_{0}$. Show that

$$
\left[f_{i}\right] *\left[\alpha_{i}\right]=\left[\alpha_{i-1}\right] *\left[g_{i}\right] .
$$

(c) Show that $[f]=\left[g_{1}\right] * \cdots *\left[g_{n}\right]$.

3. Let $p: E \rightarrow X$ be a covering map such that $\pi_{1}\left(X, x_{0}\right)$ is countable. Show that if $X$ is regular with a countable basis, so is $E$. [Hint: Let $\mathscr{B}$ be a countable basis for $X$ consisting of path-connected sets. Let $C$ be the collection of path components of $p^{-1}(B)$, for $B \in \mathcal{B}$. Compare Exercise 6 of §53.]
4. Prove the following:

Theorem. Let $X$ be a space that is path connected, locally path connected, and semilocally simply connected. If $X$ is compact Hausdorff, then $\pi_{1}\left(X, x_{0}\right)$ is finitely generated, and hence countable.

Proof. Repeat the proof outlined in Exercise 2, choosing $\mathscr{B}$ to be finite. One has the equation

$$
[f]=\left[g_{1}\right] * \cdots *\left[g_{n}\right]
$$

as before. Choose, for each $x \in X$, a path $\beta_{x}$ from $x_{0}$ to $x$; let $\beta_{x_{0}}$ be the constant path. If $g=g\left(B, B^{\prime}\right)$, define

$$
L(g)=\beta_{x} *\left(g * \bar{\beta}_{y}\right),
$$

where $x=p(B)$ and $y=p\left(B^{\prime}\right)$. Show that

$$
[f]=\left[L\left(g_{1}\right)\right] * \cdots *\left[L\left(g_{n}\right)\right] .
$$

5. Let $X$ be the infinite earring (see Example 1 of $\S 80$ ). Show that $X$ is a compact Hausdorff space with a countable basis whose fundamental group is uncountable. [Hint: Let $r_{n}: X \rightarrow C_{n}$ be a retraction. Given a sequence $a_{1}, a_{2}, \ldots$ of zeros and ones, show there exists a loop $f$ in $X$ such that, for each $n$, the element $\left(r_{n}\right)_{*}[f]$ is trivial if and only if $a_{n}=0$. $]$

This page intentionally left blank

## Chapter 12

## Classification of Surfaces

One of the earliest successes of algebraic topology was its role in solving the problem of classifying compact surfaces up to homeomorphism. "Solving" this problem means giving a list of compact surfaces such that no two surfaces on the list are homeomorphic, and such that every compact surface is homeomorphic to one of them. This is the problem we tackle in this chapter.

## \$74 Fundamental Groups of Surfaces

In this section, we show how to construct a number of compact connected surfaces, and we compute their fundamental groups. We shall construct each of these surfaces as the quotient space obtained from a polygonal region in the plane by "pasting its edges together."

To treat this pasting process formally requires some care. First, let us define precisely what we shall mean by a "polygonal region in the plane." Given a point $c$ of $\mathbb{R}^{2}$, and given $a>0$, consider the circle of radius $a$ in $\mathbb{R}^{2}$ with center at $c$. Given a finite sequence $\theta_{0}<\theta_{1}<\cdots<\theta_{n}$ of real numbers, where $n \geq 3$ and $\theta_{n}=\theta_{0}+2 \pi$, consider the points $p_{i}=c+a\left(\cos \theta_{i}, \sin \theta_{i}\right)$, which lie on this circle. They are numbered in counterclockwise order around the circle, and $p_{n}=p_{0}$. The line through $p_{i-1}$ and $p_{i}$ splits the plane into two closed half-planes; let $H_{i}$ be the one that contains all the
points $p_{k}$. Then the space

$$
P=H_{1} \cap \cdots \cap H_{n}
$$

is called the polygonal region determined by the points $p_{i}$. The points $p_{i}$ are called the vertices of $P$; the line segment joining $p_{i-1}$ and $p_{i}$ is called an edge of $P$; the union of the edges of $P$ is denoted $\mathrm{Bd} P$; and $P-\mathrm{Bd} P$ is denoted $\operatorname{Int} P$. It is not hard to show that if $p$ is any point of Int $P$, then $P$ is the union of all line segments joining $p$ and points of $\mathrm{Bd} P$, and that two such line segments intersect only in the point $p$.

Given a line segment $L$ in $\mathbb{R}^{2}$, an orientation of $L$ is simply an ordering of its end points; the first, say $a$, is called the initial point, and the second, say $b$, is called the final point, of the oriented line segment. We often say that $L$ is oriented from a to $\boldsymbol{b}$; and we picture the orientation by drawing an arrow on $L$ that points from $a$ towards $b$. If $L^{\prime}$ is another line segment, oriented from $c$ to $d$, then the positive linear map of $L$ onto $L^{\prime}$ is the homeomorphism $h$ that carries the point $x=(1-s) a+s b$ of $L$ to the point $h(x)=(1-s) c+s d$ of $L^{\prime}$.

If two polygonal regions $P$ and $Q$ have the same number of vertices, $p_{0}, \ldots, p_{n}$ and $q_{0}, \ldots, q_{n}$, respectively, with $p_{0}=p_{n}$ and $q_{0}=q_{n}$, then there is an obvious homeomorphism $h$ of $\operatorname{Bd} P$ with $\operatorname{Bd} Q$ that carries the line segment from $p_{i-1}$ to $p_{i}$ by a positive linear map onto the line segment from $q_{i-1}$ to $q_{i}$. If $p$ and $q$ are fixed points of Int $P$ and Int $Q$, respectively, then this homeomorphism may be extended to a homeomorphism of $P$ with $Q$ by letting it map the line segment from $p$ to the point $x$ of $\mathrm{Bd} P$ linearly onto the line segment from $q$ to $h(x)$. See Figure 74.1.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-472.jpg?height=458&width=1024&top_left_y=1396&top_left_x=508)

Figure 74.1

Definition. Let $P$ be a polygonal region in the plane. A labelling of the edges of $P$ is a map from the set of edges of $P$ to a set $S$ called the set of labels. Given an orientation of each edge of $P$, and given a labelling of the edges of $P$, we define an equivalence relation on the points of $P$ as follows: Each point of $\operatorname{Int} P$ is equivalent only to itself. Given any two edges of $P$ that have the same label, let $h$ be the positive linear map of one onto the other, and define each point $x$ of the first edge to be equivalent to
the point $h(x)$ of the second edge. This relation generates an equivalence relation on $P$. The quotient space $X$ obtained from this equivalence relation is said to have been obtained by pasting the edges of $\boldsymbol{P}$ together according to the given orientations and labelling.

EXAMPLE 1. Consider the orientations and labelling of the edges of the triangular region pictured in Figure 74.2. The figure indicates how one can show that the resulting quotient space is homeomorphic to the unit ball.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-473.jpg?height=304&width=1074&top_left_y=758&top_left_x=661)

Figure 74.2

EXAMPLE 2. The orientations and labelling of the edges of the square pictured in Figure 74.3 give rise to a space that is homeomorphic to the sphere $S^{2}$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-473.jpg?height=342&width=1080&top_left_y=1320&top_left_x=656)

Figure 74.3

We now describe a convenient method for specifying orientations and labels for the edges of a polygonal region, a method that does not involve drawing a picture.

Definition. Let $P$ be a polygonal region with successive vertices $p_{0}, \ldots, p_{n}$, where $p_{0}=p_{n}$. Given orientations and a labelling of the edges of $P$, let $a_{1}, \ldots, a_{m}$ be the distinct labels that are assigned to the edges of $P$. For each $k$, let $a_{i_{k}}$ be the label assigned to the edge $p_{k-1} p_{k}$, and let $\epsilon_{k}=+1$ or -1 according as the orientation assigned to this edge goes from $p_{k-1}$ to $p_{k}$ or the reverse. Then the number of edges of $P$, the orientations of the edges, and the labelling are completely specified by the symbol

$$
w=\left(a_{i_{1}}\right)^{\epsilon_{1}}\left(a_{i_{2}}\right)^{\epsilon_{2}} \cdots\left(a_{i_{n}}\right)^{\epsilon_{n}} .
$$

We call this symbol a labelling scheme of length $\boldsymbol{n}$ for the edges of $P$; it is simply a sequence of labels with exponents +1 or -1 .

We normally omit the exponents that equal +1 when giving a labelling scheme. Then the orientations and labelling of Example 1 can be specified by the labelling scheme $a^{-1} b a$, if we take $p_{0}$ to be the top vertex of the triangle. If we take one of the other vertices to be $p_{0}$, then we obtain one of the labelling schemes $b a a^{-1}$ or $a a^{-1} b$.

Similarly, the orientations and labelling indicated in Example 2 can be specified (if we begin at the lower left corner of the square) by the symbol $a a^{-1} b b^{-1}$.

It is clear that a cyclic permutation of the terms in a labelling scheme will change the space $X$ formed by using the scheme only up to homeomorphism. Later we will consider other modifications one can make to a labelling scheme that will leave the space $X$ unchanged up to homeomorphism.

EXAMPLE 3. We have already showed how the torus can be expressed as a quotient space of the unit square by means of the quotient map $p \times p: I \times I \rightarrow S^{1} \times S^{1}$. This same quotient space can be specified by the orientations and labelling of the edges of the square indicated in Figure 74.4. It can be specified also by the scheme $a b a^{-1} b^{-1}$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-474.jpg?height=300&width=1077&top_left_y=1182&top_left_x=483)

Figure 74.4

EXAMPLE 4. The projective plane $P^{2}$ is homeomorphic to the quotient space of the unit ball $B^{2}$ obtained by identifying $x$ with $-x$ for each $x \in S^{1}$. Because the unit square is homeomorphic to the unit ball, this space can also be specified by the orientations and labelling of the edges of the unit square indicated in Figure 74.5. It can be specified by the scheme $a b a b$.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-474.jpg?height=322&width=986&top_left_y=1879&top_left_x=525)

Figure 74.5

Now there is no reason to restrict oneself to a single polygonal region when forming a space by pasting edges together. Given a finite number $P_{1}, \ldots, P_{k}$ of disjoint polygonal regions, along with orientations and a labelling of their edges, one can form a quotient space $X$ in exactly the same way as for a single region, by pasting the edges of these regions together. Also, one specifies orientations and a labelling in a similar way, by means of $k$ labelling schemes. Depending on the particular schemes, the space $X$ one obtains may or may not be connected.

EXAMPLE 5. Figure 74.6 indicates a labelling of the edges of two squares for which the resulting quotient space is connected; it is the space called the Möbius band. Of course, this space could also be obtained from a single square by using the labelling scheme $a b a c$, as you can check.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-475.jpg?height=284&width=1078&top_left_y=914&top_left_x=659)

Figure 74.6

EXAMPLE 6. Figure 74.7 indicates a labelling scheme for the edges of two squares for which the resulting quotient space is not connected.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-475.jpg?height=290&width=1076&top_left_y=1464&top_left_x=658)

Figure 74.7

Theorem 74.1. Let $X$ be the space obtained from a finite collection of polygonal regions by pasting edges together according to some labelling scheme. Then $X$ is a compact Hausdorff space.

Proof. For simplicity, we treat the case where $X$ is formed from a single polygonal region. The general case is similar.

It is immediate that $X$ is compact, since the quotient map is continuous. To show $X$ is Hausdorff, it suffices to show that the quotient map $\pi$ is a closed map. (See Lemma 73.3.) For this purpose, we must show that for each closed set $C$ of $P$,
the set $\pi^{-1} \pi(C)$ is closed in $P$. Now $\pi^{-1} \pi(C)$ consists of the points of $C$ and all points of $P$ that are pasted to points of $C$ by the map $\pi$. These points are easy to determine. For each edge $e$ of $P$, let $C_{e}$ denote the compact subspace $C \cap e$ of $P$. If $e_{i}$ is an edge of $P$ that is pasted to $e$, and if $h_{i}: e_{i} \rightarrow e$ is the pasting homeomorphism, then the set $D_{e}=\pi^{-1} \pi(C) \cap e$ contains the space $h_{i}\left(C_{e_{i}}\right)$. Indeed, $D_{e}$ equals the union of $C_{e}$ and the spaces $h_{i}\left(C_{e_{i}}\right)$, as $e_{i}$ ranges over all edges of $P$ that are pasted to $e$. This union is compact; therefore, it is closed in $e$ and in $P$.

Since $\pi^{-1} \pi(C)$ is the union of the set $C$ and the sets $D_{e}$, as $e$ ranges over all edges of $P$, it is closed in $P$, as desired.

Now we note that if $X$ is obtained by pasting the edges of a polygonal region together, the quotient map $\pi$ may map all the vertices of the polygonal region to a single point of $X$, or it may not. In the case of the torus of Example 3, the quotient map does satisfy this condition, while in the case of the ball and sphere of Examples 1 and 2 , it does not. We are especially happy when $\pi$ satisfies this condition, for in this case one can readily compute the fundamental group of $X$ :

Theorem 74.2. Let $P$ be a polygonal region; let

$$
w=\left(a_{i_{1}}\right)^{\epsilon_{1}} \cdots\left(a_{i_{n}}\right)^{\epsilon_{n}}
$$

be a labelling scheme for the edges of $P$. Let $X$ be the resulting quotient space; let $\pi: P \rightarrow X$ be the quotient map. If $\pi$ maps all the vertices of $P$ to a single point $x_{0}$ of $X$, and if $a_{1}, \ldots, a_{k}$ are the distinct labels that appear in the labelling scheme, then $\pi_{1}\left(X, x_{0}\right)$ is isomorphic to the quotient of the free group on $k$ generators $\alpha_{1}, \ldots, \alpha_{k}$ by the least normal subgroup containing the element

$$
\left(\alpha_{i_{1}}\right)^{\epsilon_{1}} \cdots\left(\alpha_{i_{n}}\right)^{\epsilon_{n}} .
$$

Proof. The proof is similar to the proof we gave for the torus in $\S 73$. Because $\pi$ maps all vertices of $P$ to a single point of $X$, the space $A=\pi(\mathrm{Bd} P)$ is a wedge of $k$ circles. For each $i$, choose an edge of $P$ that is labelled $a_{i}$; let $f_{i}$ be the positive linear map of $I$ onto this edge oriented counterclockwise; and let $g_{i}=\pi \circ f_{i}$. Then the loops $g_{1}, \ldots, g_{k}$ represent a set of free generators for $\pi_{1}\left(A, x_{0}\right)$. The loop $f$ running around $\mathrm{Bd} P$ once in the counterclockwise direction generates the fundamental group of $\mathrm{Bd} P$, and the loop $\pi \circ f$ equals the loop

$$
\left(g_{i_{1}}\right)^{\epsilon_{1}} * \cdots *\left(g_{i_{n}}\right)^{\epsilon_{n}}
$$

The theorem now follows from Theorem 72.1.

Definition. Consider the space obtained from a $4 n$-sided polygonal region $P$ by means of the labelling scheme

$$
\left(a_{1} b_{1} a_{1}^{-1} b_{1}^{-1}\right)\left(a_{2} b_{2} a_{2}^{-1} b_{2}^{-1}\right) \cdots\left(a_{n} b_{n} a_{n}^{-1} b_{n}^{-1}\right)
$$

This space is called the $\boldsymbol{n}$-fold connected sum of tori, or simply the $\boldsymbol{n}$-fold torus, and denoted $T \# \cdots \# T$.

The 2-fold torus is pictured in Figure 74.8. If we split the polygonal region $P$ along the indicated line $c$, each of the resulting pieces represents a torus with an open disc removed. If we paste these pieces together along the curve $c$, we obtain the space we introduced in $\S 60$ and called there the double torus. A similar argument shows that the 3-fold torus $T \# T \# T$ can be pictured as the surface in Figure 74.9.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-477.jpg?height=291&width=1076&top_left_y=637&top_left_x=661)

Figure 74.8

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-477.jpg?height=197&width=1024&top_left_y=1073&top_left_x=687)

Figure 74.9

Theorem 74.3. Let $X$ denote the $n$-fold torus. Then $\pi_{1}\left(X, x_{0}\right)$ is isomorphic to the quotient of the free group on the $2 n$ generators $\alpha_{1}, \beta_{1}, \ldots, \alpha_{n}, \beta_{n}$ by the least normal subgroup containing the element

$$
\left[\alpha_{1}, \beta_{1}\right]\left[\alpha_{2}, \beta_{2}\right] \cdots\left[\alpha_{n}, \beta_{n}\right]
$$

where $[\alpha, \beta]=\alpha \beta \alpha^{-1} \beta^{-1}$, as usual.

Proof. In order to apply Theorem 74.2, one must show that under the labelling scheme for $X$, all the vertices of the polygonal region belong to the same equivalence class. We leave this to you to check.

Definition. Let $m>1$. Consider the space obtained from a $2 m$-sided polygonal region $P$ in the plane by means of the labelling scheme

$$
\left(a_{1} a_{1}\right)\left(a_{2} a_{2}\right) \cdots\left(a_{m} a_{m}\right)
$$

This space is called the $\boldsymbol{m}$-fold connected sum of projective planes, or simply the m-fold projective plane, and denoted $P^{2} \# \ldots \# P^{2}$.

The 2-fold projective plane $P^{2} \# P^{2}$ is pictured in Figure 74.10. The figure indicates how this space can be obtained from two copies of the projective plane by
deleting an open disc from each and pasting the resulting spaces together along the boundaries of the deleted discs. As with $P^{2}$ itself, we have no convenient way for picturing the $m$-fold projective plane as a surface in $\mathbb{R}^{3}$, for in fact it cannot be imbedded in $\mathbb{R}^{3}$. Sometimes, however, we can picture it in $\mathbb{R}^{3}$ as a surface that intersects itself. (We then speak of an immersed surface rather than an imbedded one.) We explore this topic in the exercises.
![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-478.jpg?height=320&width=1074&top_left_y=684&top_left_x=482)

Figure 74.10

Theorem 74.4. Let $X$ denote the $m$-fold projective plane. Then $\pi_{1}\left(X, x_{0}\right)$ is isomorphic to the quotient of the free group on $m$ generators $\alpha_{1}, \ldots, \alpha_{m}$ by the least normal subgroup containing the element

$$
\left(\alpha_{1}\right)^{2}\left(\alpha_{2}\right)^{2} \cdots\left(\alpha_{m}\right)^{2} .
$$

Proof. One needs only to check that under the labelling scheme for $X$, all the vertices of the polygonal region belong to the same equivalence class. This we leave to you.

There exist many other ways to form compact surfaces. One can for instance delete an open disc from each of the spaces $P^{2}$ and $T$, and paste the resulting spaces together along the boundaries of the deleted discs. You can check that this space can be obtained from a 6-sided polygonal region by means of the labelling scheme $a a b c b^{-1} c^{-1}$. But we shall stop at this point. For it turns out that we have already obtained a complete list of the compact connected surfaces. This is the basic classification theorem for surfaces, which we shall consider shortly.

## Exercises

1. Find a presentation for the fundamental group of $P^{2} \# T$.
2. Consider the space $X$ obtained from a seven-sided polygonal region by means of the labelling scheme $a$ aaaab ${ }^{-1} a^{-1}$. Show that the fundamental group of $X$ is the free product of two cyclic groups. [Hint: See Theorem 68.7.]
3. The Klein bottle $K$ is the space obtained from a square by means of the labelling scheme $a b a^{-1} b$. Figure 74.11 indicates how $K$ can be pictured as an immersed surface in $\mathbb{R}^{3}$.

(a) Find a presentation for the fundamental group of $K$.

(b) Find a double covering map $p: T \rightarrow K$, where $T$ is the torus. Describe the induced homomorphism of fundamental groups.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-479.jpg?height=366&width=1074&top_left_y=697&top_left_x=662)

Figure 74.11

4. (a) Show that the Klein bottle is homeomorphic to $P^{2} \# P^{2}$. [Hint: Split the square in Figure 74.11 along a diagonal, flip one of the resulting triangular pieces over, and paste the two pieces together along the edge labelled $b$.]

(b) Show how to picture the 4-fold projective plane as an immersed surface in $\mathbb{R}^{3}$.

5. The Möbius band $M$ is not a surface, but what is called a "surface with boundary". Show that $M$ is homeomorphic to the space obtained by deleting an open disc from $P^{2}$.
6. If $n>1$, show that the fundamental group of the $n$-fold torus is not abelian. [Hint: Let $G$ be the free group on the set $\left\{\alpha_{1}, \beta_{1}, \ldots, \alpha_{n}, \beta_{n}\right\}$; let $F$ be the free group on the set $\{\gamma, \delta\}$. Consider the homomorphism of $G$ onto $F$ that sends $\alpha_{1}$ and $\beta_{1}$ to $\gamma$ and all other $\alpha_{i}$ and $\beta_{i}$ to $\delta$.]
7. If $m>1$, show the fundamental group of the $m$-fold projective plane is not abelian. [Hint: There is a homomorphism mapping this group onto the group $\mathbb{Z} / 2 * \mathbb{Z} / 2$.]

## §75 Homology of Surfaces

Although we have succeeded in obtaining presentations for the fundamental groups of a number of surfaces, we now pause to ask ourselves what we have actually accomplished. Can we conclude from our computations, for instance, that the double torus and the triple torus are topologically distinct? Not immediately. For, as we know, we lack an effective procedure for determining from the presentations for two groups
whether or not these groups are isomorphic. Matters are much more satisfactory if we pass to the abelian group $\pi_{1} /\left[\pi_{1}, \pi_{1}\right]$, where $\pi_{1}=\pi_{1}\left(X, x_{0}\right)$. For then we have some known invariants to work with. We explore this situation in this section.

We know that if $X$ is a path-connected space, and if $\alpha$ is a path in $X$ from $x_{0}$ to $x_{1}$, then there is an isomorphism $\hat{\alpha}$ of the fundamental group based at $x_{0}$ with the fundamental group based at $x_{1}$, but the isomorphism depends on the choice of the path $\alpha$. A stronger result holds for the group $\pi_{1} /\left[\pi_{1}, \pi_{1}\right]$. In this case, the isomorphism of the "abelianized fundamental group" based at $x_{0}$ with the one based at $x_{1}$, induced by $\alpha$, is in fact independent of the choice of the path $\alpha$.

To verify this fact, it suffices to show that if $\alpha$ and $\beta$ are two paths from $x_{0}$ to $x_{1}$, then the path $g=\alpha * \bar{\beta}$ induces the identity isomorphism of $\pi_{1} /\left[\pi_{1}, \pi_{1}\right]$ with itself. And this is easy. If $[f] \in \pi_{1}\left(X, x_{0}\right)$, we have

$$
\hat{g}[f]=[\bar{g} * f * g]=[g]^{-1} *[f] *[g] .
$$

When we pass to the cosets in the abelian group $\pi_{1} /\left[\pi_{1}, \pi_{1}\right]$, we see that $\hat{g}$ induces the identity map.

Definition. If $X$ is a path-connected space, let

$$
H_{1}(X)=\pi_{1}\left(X, x_{0}\right) /\left[\pi_{1}\left(X, x_{0}\right), \pi_{1}\left(X, x_{0}\right)\right] .
$$

We call $H_{1}(X)$ the first homology group of $X$. We omit the base point from the notation because there is a unique path-induced isomorphism between the abelianized fundamental groups based at two different points.

If you study algebraic topology further, you will see an entirely different definition of $H_{1}(X)$. In fact, you will see groups $H_{n}(X)$ called the homology groups of $X$ that are defined for all $n \geq 0$. These are abelian groups that are topological invariants of $X$; they are of fundamental importance in applying results of algebra to problems of topology. A theorem due to W. Hurewicz establishes a connection between these groups and the homotopy groups of $X$. It implies in particular that for a path-connected space $X$, the first homology group $H_{1}(X)$ of $X$ is isomorphic to the abelianized fundamental group of $X$. This theorem motivates our choice of notation for the abelianized fundamental group.

To compute $H_{1}(X)$ for the surfaces considered earlier, we need the following result:

Theorem 75.1. Let $F$ be a group; let $N$ be a normal subgroup of $F$; let $q: F \rightarrow F / N$ be the projection. The projection homomorphism

$$
p: F \rightarrow F /[F, F]
$$

induces an isomorphism

$$
\phi: q(F) /[q(F), q(F)] \rightarrow p(F) / p(N) .
$$

This theorem states, roughly speaking, that if one divides $F$ by $N$ and then abelianizes the quotient, one obtains the same result as if one first abelianizes $F$ and then divides by the image of $N$ in this abelianization.

Proof. One has projection homomorphisms $p, q, r, s$, as in the following diagram, where $q(F)=F / N$ and $p(F)=F /[F, F]$.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-481.jpg?height=228&width=719&top_left_y=641&top_left_x=837)

Because $r \circ p$ maps $N$ to 1 , it induces a homomorphism $u: q(F) \rightarrow p(F) / p(N)$. Then because $p(F) / p(N)$ is abelian, the homomorphism $u$ induces a homomorphism $\phi$ of $q(F) /[q(F), q(F)]$. On the other hand, because $s \circ q$ maps $F$ into an abelian group, it induces a homomorphism $v: p(F) \rightarrow q(F) /[q(F), q(F)]$. Because $s \circ q$ carries $N$ to 1 , so does $v \circ p$; hence $v$ induces a homomorphism $\psi$ of $p(F) / p(N)$.

The homomorphism $\phi$ can be described as follows: Given an element $y$ of the group $q(F) /[q(F), q(F)]$, choose an element $x$ of $F$ such that $s(q(x))=y$; then $\phi(y)=r(p(x))$. The homomorphism $\psi$ can be described similarly. It follows that $\phi$ and $\psi$ are inverse to each other.

Corollary 75.2. Let $F$ be a free group with free generators $\alpha_{1}, \ldots, \alpha_{n}$; let $N$ be the least normal subgroup of $F$ containing the element $x$ of $F$; let $G=F / N$. Let $p: F \rightarrow F /[F, F]$ be projection. Then $G /[G, G]$ is isomorphic to the quotient of $F /[F, F]$, which is free abelian with basis $p\left(\alpha_{1}\right), \ldots, p\left(\alpha_{n}\right)$, by the subgroup generated by $p(x)$.

Proof. Note that because $N$ is generated by $x$ and all its conjugates, the group $p(N)$ is generated by $p(x)$. The corollary then follows from the preceding theorem.

Theorem 75.3. If $X$ is the $n$-fold connected sum of tori, then $H_{1}(X)$ is a free abelian group of rank $2 n$.

Proof. In view of the preceding corollary, Theorem 74.3 implies that $H_{1}(X)$ is isomorphic to the quotient of the free abelian group $F^{\prime}$ on the set $\alpha_{1}, \beta_{1}, \ldots, \alpha_{n}, \beta_{n}$ by the subgroup generated by the element $\left[\alpha_{1}, \beta_{1}\right] \cdots\left[\alpha_{n}, \beta_{n}\right]$, where $[\alpha, \beta]=\alpha \beta \alpha^{-1} \beta^{-1}$ as usual. Because the group $F^{\prime}$ is abelian, this element equals the identity element.

Theorem 75.4. If $X$ is the $m$-fold connected sum of projective planes, then the torsion subgroup $T(X)$ of $H_{1}(X)$ has order 2 , and $H_{1}(X) / T(X)$ is a free abelian group of rank $m-1$.

Proof. In view of the preceding corollary, Theorem 74.4 implies that $H_{1}(X)$ is isomorphic to the quotient of the free abelian group $F^{\prime}$ on the set $\alpha_{1}, \ldots, \alpha_{m}$ by the
subgroup generated by $\left(\alpha_{1}\right)^{2} \cdots\left(\alpha_{m}\right)^{2}$. If we switch to additive notation (which is usual when dealing with abelian groups), this is the subgroup generated by the element $2\left(\alpha_{1}+\cdots+\alpha_{m}\right)$. Let us change bases in the group $F^{\prime}$. If we let $\beta=\alpha_{1}+\cdots+\alpha_{m}$, then the elements $\alpha_{1}, \ldots, \alpha_{m-1}, \beta$ form a basis for $F^{\prime}$; any element of $F^{\prime}$ can be written uniquely in terms of these elements. The group $H_{1}(X)$ is isomorphic to the quotient of the free abelian group on $\alpha_{1}, \ldots, \alpha_{m-1}, \beta$ by the subgroup generated by $2 \beta$. Said differently, $H_{1}(X)$ is isomorphic to the quotient of the $m$-fold cartesian product $\mathbb{Z} \times \cdots \times \mathbb{Z}$ by the subgroup $0 \times \cdots \times 0 \times 2 \mathbb{Z}$. The theorem follows.

Theorem 75.5. Let $T_{n}$ and $P_{m}$ denote the $n$-fold connected sum of tori and the $m$ fold connected sum of projective planes, respectively. Then the surfaces $S^{2} ; T_{1}, T_{2}$, $\ldots ; P_{1}, P_{2}, \ldots$ are topologically distinct.

## Exercises

1. Calculate $H_{1}\left(P^{2} \# T\right)$. Assuming that the list of compact surfaces given in Theorem 75.5 is a complete list, to which of these surfaces is $P^{2} \# T$ homeomorphic?
2. If $K$ is the Klein bottle, calculate $H_{1}(K)$ directly.
3. Let $X$ be the quotient space obtained from an 8 -sided polygonal region $P$ by pasting its edges together according to the labelling scheme $a c a d b c b^{-1} d$.

(a) Check that all vertices of $P$ are mapped to the same point of the quotient space $X$ by the pasting map.

(b) Calculate $H_{1}(X)$.

(c) Assuming $X$ is homeomorphic to one of the surfaces given in Theorem 75.5 (which it is), which surface is it?

*4. Let $X$ be the quotient space obtained from an 8-sided polygonal region $P$ by means of the labelling scheme $a b c d a d^{-1} c b^{-1}$. Let $\pi: P \rightarrow X$ be the quotient map.

(a) Show that $\pi$ does not map all the vertices of $P$ to the same point of $X$.

(b) Determine the space $A=\pi(\mathrm{Bd} P)$ and calculate its fundamental group.

(c) Calculate $\pi_{1}\left(X, x_{0}\right)$ and $H_{1}(X)$.

(d) Assuming $X$ is homeomorphic to one of the surfaces given in Theorem 75.5, which surface is it?

## §76 Cutting and Pasting

To prove the classification theorem, we need to use certain geometric arguments involving what are called "cut-and-paste" techniques. These techniques show how to take a space $X$ that is obtained by pasting together the edges of one or more polygonal
regions according to some labelling scheme and to represent $X$ by a different collection of polygonal regions and a different labelling scheme.

First, let us consider what it means to "cut apart" a polygonal region. Let $P$ be a polygonal region with successive vertices $p_{0}, \ldots, p_{n}=p_{0}$, as usual. Given $k$ with $1<k<n-1$, let us consider the polygonal regions $Q_{1}$, with successive vertices $p_{0}, p_{1}, \ldots, p_{k}, p_{0}$, and $Q_{2}$, with successive vertices $p_{0}, p_{k}, \ldots, p_{n}=p_{0}$. These regions have the edge $p_{0} p_{k}$ in common, and the region $P$ is their union.

Let us move $Q_{1}$ by a translation of $\mathbb{R}^{2}$ so as to obtain a polygonal region $Q_{1}^{\prime}$ that is disjoint from $Q_{2}$; then $Q_{1}^{\prime}$ has successive vertices $q_{0}, q_{1}, \ldots, q_{k}, q_{0}$, where $q_{i}$ is the image of $p_{i}$ under the translation. The regions $Q_{1}^{\prime}$ and $Q_{2}$ are said to have been obtained by cutting $\boldsymbol{P}$ apart along the line from $p_{0}$ to $p_{k}$. The region $P$ is homeomorphic to the quotient space of $Q_{1}^{\prime}$ and $Q_{2}$ obtained by pasting the edge of $Q_{1}^{\prime}$ going from $q_{0}$ to $q_{k}$ to the edge of $Q_{2}$ going from $p_{0}$ to $p_{k}$, by the positive linear map of one edge onto the other. See Figure 76.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-483.jpg?height=439&width=1069&top_left_y=1038&top_left_x=659)

Figure 76.1

Now let us consider how we can reverse this process. Suppose we are given two disjoint polygonal regions $Q_{1}^{\prime}$ with successive vertices $q_{0}, \ldots, q_{k}, q_{0}$, and $Q_{2}$, with successive vertices $p_{0}, p_{k}, \ldots, p_{n}=p_{0}$. And suppose we form a quotient space by pasting the edge of $Q_{1}^{\prime}$ from $q_{0}$ to $q_{k}$ onto the edge of $Q_{2}$ by $p_{0}$ to $p_{k}$, by the positive linear map of one edge onto the other. We wish to represent this space by a polygonal region $P$.

This task is accomplished as follows: The points of $Q_{2}$ lie on a circle and are arranged in counterclockwise fashion. Let us choose points $p_{1}, \ldots, p_{k-1}$ on this same circle in such a way that $p_{0}, p_{1}, \ldots, p_{k-1}, p_{k}$ are arranged in counterclockwise order, and let $Q_{1}$ be the polygonal region with these as successive vertices. There is a homeomorphism of $Q_{1}^{\prime}$ onto $Q_{1}$ that carries $q_{i}$ to $p_{i}$ for each $i$ and maps the edge $q_{0} q_{k}$ of $Q_{1}^{\prime}$ linearly onto the edge $p_{0} p_{k}$ of $Q_{2}$. Therefore, the quotient space in question is homeomorphic to the region $P$ that is the union of $Q_{1}$ and $Q_{2}$. We say that $P$ is obtained by pasting $Q_{1}^{\prime}$ and $Q_{2}$ together along the indicated edges. See Figure 76.2.

Now we ask the following question: If a polygonal region has a labelling scheme, what effect does cutting the region apart have on this labelling scheme? More pre-

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-484.jpg?height=449&width=1096&top_left_y=375&top_left_x=479)

Figure 76.2

cisely, suppose we have a collection of disjoint polygonal regions $P_{1}, \ldots, P_{m}$ and a labelling scheme for these regions, say $w_{1}, \ldots, w_{m}$, where $w_{i}$ is a labelling scheme for the edges of $P_{i}$. Suppose that $X$ is the quotient space obtained from this labelling scheme. If we cut $P_{1}$ apart along the line from $p_{0}$ to $p_{k}$, what happens? We obtain $m+1$ polygonal regions $Q_{1}^{\prime}, Q_{2}, P_{2}, \ldots, P_{m}$; to obtain the space $X$ from these regions, we need one additional edge pasting. We indicate the additional pasting that is required by introducing a new label that is to be assigned to the edges $q_{0} q_{k}$ and $p_{0} p_{k}$ that we introduced. Because the orientation from $p_{0}$ to $p_{k}$ is counterclockwise for $Q_{2}$, and the orientation from $q_{0}$ to $q_{k}$ is clockwise for $Q_{1}^{\prime}$, this label will have exponent +1 when it appears in the scheme for $Q_{2}$ and exponent -1 when it appears in the scheme for $Q_{1}^{\prime}$.

Let us be more specific. We can write the labelling scheme $w_{1}$ for $P_{1}$ in the form $w_{1}=y_{0} y_{1}$, where $y_{0}$ consists of the first $k$ terms of $w_{1}$ and $y_{1}$ consists of the remainder. Let $c$ be a label that does not appear in any of the schemes $w_{1}, \ldots, w_{m}$. Then give $Q_{1}^{\prime}$ the labelling scheme $y_{0} c^{-1}$, give $Q_{2}$ the labelling scheme $c y_{1}$, and for $i>1$ give the region $P_{i}$ its old scheme $w_{i}$.

It is immediate that the space $X$ can be obtained from the regions $Q_{1}^{\prime}, Q_{2}, P_{2}$, $\ldots, P_{m}$ by means of this labelling scheme. For the composite of quotient maps is a quotient map, so it does not matter whether we paste all the edges together at once, or instead paste the edge $p_{0} p_{k}$ to the edge $q_{0} q_{k}$ before pasting the others!

One can of course apply this procedure in reverse. If $X$ is represented by a labelling scheme for the regions $Q_{1}^{\prime}, Q_{2}, P_{2}, \ldots, P_{m}$ and if the labelling scheme indicates that an edge of the first is to be pasted to an edge of the second (and no other edge is to be pasted to these), we can actually carry out the pasting so as to represent $X$ by a labelling scheme for the $m$ regions $P_{1}, \ldots, P_{m}$.

We state this fact formally as a theorem:

Theorem 76.1. Suppose $X$ is the space obtained by pasting the edges of $m$ polygonal
regions together according to the labelling scheme

$$
\begin{equation*}
y_{0} y_{1}, w_{2}, \ldots, w_{m} \tag{*}
\end{equation*}
$$

Let $c$ be a label not appearing in this scheme. If both $y_{0}$ and $y_{1}$ have length at least two, then $X$ can also be obtained by pasting the edges of $m+1$ polygonal regions together according to the scheme

$$
\begin{equation*}
y_{0} c^{-1}, c y_{1}, w_{2}, \ldots, w_{m} . \tag{**}
\end{equation*}
$$

Conversely, if $X$ is the space obtained from $m+1$ polygonal regions by means of the scheme $(* *)$, it can also be obtained from $m$ polygonal regions by means of the scheme (*), providing that $c$ does not appear in scheme $(*)$.

## Elementary operations on schemes

We now list a number of elementary operations that can be performed on a labelling scheme $w_{1}, \ldots, w_{m}$ without affecting the resulting quotient space $X$. The first two arise from the theorem just stated.

(i) Cut. One can replace the scheme $w_{1}=y_{0} y_{1}$ by the scheme $y_{0} c^{-1}$ and $c y_{1}$, provided $c$ does not appear elsewhere in the total scheme and $y_{0}$ and $y_{1}$ have length at least two.

(ii) Paste. One can replace the scheme $y_{0} c^{-1}$ and $c y_{1}$ by the scheme $y_{0} y_{1}$, provided $c$ does not appear elsewhere in the total scheme.

(iii) Relabel. One can replace all occurrences of any given label by some other label that does not appear elsewhere in the scheme. Similarly, one can change the sign of the exponent of all occurrences of a given label $a$; this amounts to reversing the orientations of all the edges labelled " $a$ ". Neither of these alterations affects the pasting map.

(iv) Permute. One can replace any one of the schemes $w_{i}$ by a cyclic permutation of $w_{i}$. Specifically, if $w_{i}=y_{0} y_{1}$, we can replace $w_{i}$ by $y_{1} y_{0}$. This amount to renumbering the vertices of the polygonal region $P_{i}$ so as to begin with a different vertex; it does not affect the resulting quotient space.

(v) Flip. One can replace the scheme

$$
w_{i}=\left(a_{i_{1}}\right)^{\epsilon_{1}} \cdots\left(a_{i_{n}}\right)^{\epsilon_{n}}
$$

by its formal inverse

$$
w_{i}^{-1}=\left(a_{i_{n}}\right)^{-\epsilon_{n}} \cdots\left(a_{i_{1}}\right)^{-\epsilon_{1}} .
$$

This amounts simply to "flipping the polygonal region $P_{i}$ over.". The order of the vertices is reversed, and so is the orientation of each edge. The quotient space $X$ is not affected.

(vi) Cancel. One can replace the scheme $w_{i}=y_{0} a a^{-1} y_{1}$ by the scheme $y_{0} y_{1}$, provided $a$ does not appear elsewhere in the total scheme and both $y_{0}$ and $y_{1}$ have length at least two.

This last result follows from the three-step argument indicated in Figure 76.3, only one step of which is new. Letting $b$ and $c$ be labels that do not appear elsewhere in the total scheme, one first replaces $y_{0} a a^{-1} y_{1}$ by the scheme $y_{0} a b$ and $b^{-1} a^{-1} y_{1}$, using the cutting operation (i). Then one combines the edges labelled $a$ and $b$ in each polygonal region into a single edge, with a new label. This is the step that is new. The result is the scheme $y_{0} c$ and $c^{-1} y_{1}$, which one can replace by the single scheme $y_{0} y_{1}$, using the pasting operation (ii).

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-486.jpg?height=747&width=1110&top_left_y=748&top_left_x=464)

Figure 76.3

(vii) Uncancel. This is the reverse of operation (vi). It replaces the scheme $y_{0} y_{1}$ by the scheme $y_{0} a a^{-1} y_{1}$, where $a$ is a label that does not appear elsewhere in the total scheme. We shall not actually have occasion to use this operation.

Definition. We define two labelling schemes for collections of polygonal regions to be equivalent if one can be obtained from the other by a sequence of elementary scheme operations. Since each elementary operation has as its inverse another such operation, this is an equivalence relation.

EXAMPLE 1. The Klein bottle $K$ is the space obtained from the labelling scheme $a b a^{-1} b$. In the exercises of $\S 74$, you were asked to show that $K$ is homeomorphic to the 2 -fold projective plane $P^{2} \# P^{2}$. The geometric argument suggested there in fact consists of
the following elementary operations:

$$
\begin{array}{rlrl}
a b a^{-1} b & \longrightarrow a b c^{-1} \text { and } c a^{-1} b & & \text { by cutting } \\
& \longrightarrow c^{-1} a b \text { and } b^{-1} a c^{-1} & & \text { by permuting the first } \\
& \text { and flipping the second } \\
& \longrightarrow c^{-1} a a c^{-1} & & \text { by pasting } \\
& \longrightarrow a a c c & & \text { by permuting and relabelling. }
\end{array}
$$

## Exercises

1. Consider the quotient space $X$ obtained from two polygonal regions by means of the labelling scheme $w_{1}=a c b c^{-1}$ and $w_{2}=c d b a^{-1} d$.

(a) If one pastes these regions together along the edges labelled " $a$," one can represent $X$ as the quotient space of a single 7 -sided region $P$. What is a labelling scheme for $P$ ? What sequence of elementary operations is involved in obtaining this scheme?

(b) Repeat (a), pasting along the edges labelled " $b$ ".

(c) Explain why one cannot paste along the edges labelled " $c$ " to obtain the scheme $a c b d b a^{-1} d$ as a way of representing $X$.

2. Consider the space $X$ obtained from two polygonal regions by means of the labelling scheme $w_{1}=a b c c$ and $w_{2}=c^{-1} c^{-1} a b$. The following sequence of elementary operations:

$$
\begin{aligned}
& a b c c \text { and } c^{-1} c^{-1} a b \longrightarrow c c a b \text { and } b^{-1} a^{-1} c c \text { by permuting } \\
& \text { and flipping } \\
& \longrightarrow c c a a^{-1} c c \quad \text { by pasting } \\
& \longrightarrow c c c c \quad \text { by cancelling }
\end{aligned}
$$

indicates that $X$ is homeomorphic to the four-fold dunce cap. The sequence of operations

$$
\begin{aligned}
a b c c \text { and } c^{-1} c^{-1} a b & \longrightarrow a b c c^{-1} a b & & \text { by pasting } \\
& \longrightarrow a b a b & & \text { by cancelling }
\end{aligned}
$$

indicates that $X$ is homeomorphic to $P^{2}$. But these two spaces are not homeomorphic. Which (if either) argument is correct?

## §77 The Classification Theorem

We prove in this section the geometric part of our classification theorem for surfaces. We show that every space obtained by pasting the edges of a polygonal region together
in pairs is homeomorphic either to $S^{2}$, to the $n$-fold torus $T_{n}$, or to the $m$-fold projective plane $P_{m}$. Later we discuss the problem of showing that every compact surface can be obtained in this way.

Suppose $w_{1}, \ldots, w_{k}$ is a labelling scheme for the polygonal regions $P_{1}, \ldots, P_{k}$. If each label appears exactly twice in this scheme, we call it a proper labelling scheme. Note the following important fact:

If one applies any elementary operation to a proper scheme, one obtains another proper scheme.

Definition. Let $w$ be a proper labelling scheme for a single polygonal region. We say that $w$ is of torus type if each label in it appears once with exponent +1 and once with exponent -1 . Otherwise, we say $w$ is of projective type.

We begin by considering a scheme $w$ of projective type. We will show that $w$ is equivalent to a scheme (of the same length) in which all labels having the same exponent are paired and appear at the beginning of the scheme. That is, $w$ is equivalent to a scheme of the form

$$
\left(a_{1} a_{1}\right)\left(a_{2} a_{2}\right) \cdots\left(a_{k} a_{k}\right) w_{1},
$$

where $w_{1}$ is of torus type or is empty.

Because $w$ is of projective type, there is at least one label, say $a$, such that both occurrences of $a$ in the scheme $w$ have the same exponent. Therefore, we can assume that $w$ has the form

$$
w=y_{0} a y_{1} a y_{2},
$$

where some of the $y_{i}$ may be empty. We shall insert brackets in this expression for visual convenience, writing it in the form

$$
w=\left[y_{0}\right] a\left[y_{1}\right] a\left[y_{2}\right] .
$$

We have the following result:

Lemma 77.1. Let $w$ be a proper scheme of the form

$$
w=\left[y_{0}\right] a\left[y_{1}\right] a\left[y_{2}\right],
$$

where some of the $y_{i}$ may be empty. Then one has the equivalence

$$
w \sim a a\left[y_{0} y_{1}^{-1} y_{2}\right]
$$

where $y_{1}^{-1}$ denotes the formal inverse of $y_{1}$.

Proof. Step 1. We first consider the case where $y_{0}$ is empty. We show that

$$
a\left[y_{1}\right] a\left[y_{2}\right] \sim a a\left[y_{1}^{-1} y_{2}\right] .
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-489.jpg?height=312&width=1038&top_left_y=376&top_left_x=677)

Figure 77.1

If $y_{1}$ is empty, this result is immediate, while if $y_{2}$ is empty, it follows from flipping, permuting, and relabelling. If neither is empty, we apply the cutting and pasting argument indicated in Figure 77.1, followed by a relabelling. We leave it to you to write down the sequence of elementary operations involved.

Step 2. Now we consider the general case. Let $w=\left[y_{0}\right] a\left[y_{1}\right] a\left[y_{2}\right]$, where $y_{0}$ is not empty. If both $y_{1}$ and $y_{2}$ are empty, the lemma follows by permuting. Otherwise, we apply the cutting and pasting argument indicated in Figure 77.2 to show that

$$
w \sim b\left[y_{2}\right] b\left[y_{1} y_{0}^{-1}\right]
$$

It follows that

$$
\begin{aligned}
w & \sim b b\left[y_{2}^{-1} y_{1} y_{0}^{-1}\right] & & \text { by Step } 1 \\
& \sim\left[y_{0} y_{1}^{-1} y_{2}\right] b^{-1} b^{-1} & & \text { by flipping }
\end{aligned}
$$

$$
\sim a a\left[y_{0} y_{1}^{-1} y_{2}\right] \quad \text { by permuting and relabelling. }
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-489.jpg?height=260&width=1078&top_left_y=1610&top_left_x=658)

Figure 77.2

Corollary 77.2. If $w$ is a scheme of projective type, then $w$ is equivalent to a scheme of the same length having the form

$$
\left(a_{1} a_{1}\right)\left(a_{2} a_{2}\right) \cdots\left(a_{k} a_{k}\right) w_{1}
$$

where $k \geq 1$ and $w_{1}$ is either empty or of torus type.

Proof. The scheme $w$ can be written in the form

$$
w=\left[y_{0}\right] a\left[y_{1}\right] a\left[y_{2}\right]
$$

then the preceding lemma implies that $w$ is equivalent to a scheme of the form $w^{\prime}=$ $a a w_{1}$ that has the same length as $w$. If $w_{1}$ is of torus type, we are finished; otherwise, we can write $w^{\prime}$ in the form

$$
w^{\prime}=a a\left[z_{0}\right] b\left[z_{1}\right] b\left[z_{2}\right]=\left[a a z_{0}\right] b\left[z_{1}\right] b\left[z_{2}\right] .
$$

Applying the preceding lemma again, we conclude that $w^{\prime}$ is equivalent to a scheme $w^{\prime \prime}$ of the form

$$
w^{\prime \prime}=b b\left[a a z_{0} z_{1}^{-1} z_{2}\right]=b b a a w_{2}
$$

where $w^{\prime \prime}$ has the same length as $w$. If $w_{2}$ is of torus type, we are finished; otherwise, we continue the argument similarly.

It follows from the preceding corollary that if $w$ is a proper labelling scheme for a polygonal region, then either (1) $w$ is of torus type, or (2) $w$ is equivalent to a scheme of the form $\left(a_{1} a_{1}\right) \ldots\left(a_{k} a_{k}\right) w_{1}$, where $w_{1}$ is of torus type, or (3) $w$ is equivalent to a scheme of the form $\left(a_{1} a_{1}\right) \ldots\left(a_{k} a_{k}\right)$. In case (3), we are finished, for such a scheme represents a connected sum of projective planes. So let us consider cases (1) and (2).

At this point, we note that if $w$ is a scheme of length greater than four of the form indicated in case (1) or case (2), and if $w$ contains two adjacent terms having the same label but opposite exponents, then the cancelling operation may be applied to reduce $w$ to a shorter scheme that is also of the form indicated in cases (1), (2), or (3). Therefore, we can reduce $w$ either to a scheme of length four, or to a scheme that does not contain two such adjacent terms.

Schemes of length four are easy to deal with, as we shall see later, so let us assume that $w$ does not contain two adjacent terms having the same label but opposite exponents. In that case, we show that $w$ is equivalent to a scheme $w^{\prime}$, of the same length as $w$, having the form

$$
\begin{array}{ll}
w^{\prime}=a b a^{-1} b^{-1} w^{\prime \prime} & \text { in case (1) or } \\
w^{\prime}=\left(a_{1} a_{1}\right) \cdots\left(a_{k} a_{k}\right) a b a^{-1} b^{-1} w^{\prime \prime} & \text { in case }(2),
\end{array}
$$

where $w^{\prime \prime}$ is of torus type or is empty. This is the substance of the following lemma:

Lemma 77.3. Let $w$ be a proper scheme of the form $w=w_{0} w_{1}$, where $w_{1}$ is a scheme of torus type that does not contain two adjacent terms having the same label. Then $w$ is equivalent to a scheme of the form $w_{0} w_{2}$, where $w_{2}$ has the same length as $w_{1}$ and has the form

$$
w_{2}=a b a^{-1} b^{-1} w_{3},
$$

where $w_{3}$ is of torus type or is empty.

Proof. This is the most elaborate proof of this section; three cuttings and pastings are involved. We show first that, switching labels and exponents if necessary, $w$ can be written in the form

$$
\begin{equation*}
w=w_{0}\left[y_{1}\right] a\left[y_{1}\right] b\left[y_{3}\right] a^{-1}\left[y_{4}\right] b^{-1}\left[y_{5}\right], \tag{*}
\end{equation*}
$$

where some of the $y_{i}$ may be empty.

Among the labels appearing in $w_{1}$, let $a$ be one whose two occurrences (with opposite exponents of course) are as close together as possible. These occurrences are nonadjacent, by hypothesis. Switching exponents if necessary, we can assume that the term $a$ occurs first and the term $a^{-1}$ occurs second. Let $b$ be any label appearing between $a$ and $a^{-1}$; we can assume its exponent is +1 . Now the term $b^{-1}$ appears in $w_{1}$, but cannot occur between $a$ and $a^{-1}$ because these two are as close together as possible. If $b^{-1}$ appears following $a^{-1}$, we are finished. If it appears preceding $a$, then all we need to do is to switch exponents on the $b$ terms, and then switch the labels $a$ and $b$, to obtain a scheme of the desired form.

So let us assume that $w$ has the form $(*)$.

First cutting and pasting. We show that $w$ is equivalent to the scheme

$$
w^{\prime}=w_{0} a\left[y_{2}\right] b\left[y_{3}\right] a^{-1}\left[y_{1} y_{4}\right] b^{-1}\left[y_{5}\right] .
$$

To prove this result, we rewrite $w$ in the form

$$
w=w_{0}\left[y_{1}\right] a\left[y_{2} b y_{3}\right] a^{-1}\left[y_{4} b^{-1} y_{5}\right] .
$$

We then apply the cutting and pasting argument indicated in Figure 77.3 to conclude that

$$
\begin{aligned}
w & \sim w_{0} c\left[y_{2} b y_{3}\right] c^{-1}\left[y_{1} y_{4} b^{-1} y_{5}\right] \\
& \sim w_{0} a\left[y_{2}\right] b\left[y_{3}\right] a^{-1}\left[y_{1} y_{4}\right] b^{-1}\left[y_{5}\right],
\end{aligned}
$$

by relabelling. Note that the cut at $c$ can be made because both the resulting polygons have at least three sides.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-491.jpg?height=283&width=1086&top_left_y=1751&top_left_x=656)

Figure 77.3

Second cutting and pasting. Given

$$
w^{\prime}=w_{0} a\left[y_{2}\right] b\left[y_{3}\right] a^{-1}\left[y_{1} y_{4}\right] b^{-1}\left[y_{5}\right],
$$

we show that $w^{\prime}$ is equivalent to the scheme

$$
w^{\prime \prime}=w_{0} a\left[y_{1} y_{4} y_{3}\right] b a^{-1} b^{-1}\left[y_{2} y_{5}\right] .
$$

If all the schemes $y_{1}, y_{4}, y_{5}$, and $w_{0}$ are empty, then the argument is easy, since in that case

$$
\begin{aligned}
w^{\prime} & =a\left[y_{2}\right] b\left[y_{3}\right] a^{-1} b^{-1}, & \\
& \sim b\left[y_{3}\right] a^{-1} b^{-1} a\left[y_{2}\right] & \text { by permuting } \\
& \sim a\left[y_{3}\right] b a^{-1} b^{-1}\left[y_{2}\right] & \text { by relabelling } \\
& =w^{\prime \prime} . &
\end{aligned}
$$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-492.jpg?height=478&width=1086&top_left_y=876&top_left_x=478)

Figure 77.4

Otherwise, we apply the argument indicated in Figure 77.4 to conclude that

$$
\begin{aligned}
w^{\prime} & =w_{0} a\left[y_{2}\right] b\left[y_{3}\right] a^{-1}\left[y_{1} y_{4}\right] b^{-1}\left[y_{5}\right] \\
& \sim w_{0} c\left[y_{1} y_{4} y_{3}\right] a^{-1} c^{-1} a\left[y_{2} y_{5}\right] \\
& \sim w_{0} a\left[y_{1} y_{4} y_{3}\right] b a^{-1} b^{-1}\left[y_{2} y_{5}\right],
\end{aligned}
$$

by relabelling.

Third cutting and pasting. We complete the proof. Given

$$
w^{\prime \prime}=w_{0} a\left[y_{1} y_{4} y_{3}\right] b a^{-1} b^{-1}\left[y_{2} y_{5}\right],
$$

we show that $w^{\prime \prime}$ is equivalent to the scheme

$$
w^{\prime \prime \prime}=w_{0} a b a^{-1} b^{-1}\left[y_{1} y_{4} y_{3} y_{2} y_{5}\right] .
$$

If the schemes $w_{0}, y_{5}$, and $y_{2}$ are empty, the argument is easy, since in that case

$$
\begin{aligned}
& w^{\prime \prime}=a\left[y_{1} y_{4} y_{3}\right] b a^{-1} b^{-1} \\
& \sim b a^{-1} b^{-1} a\left[y_{1} y_{4} y_{3}\right] \quad \text { by permuting } \\
& \sim a b a^{-1} b^{-1}\left[y_{1} y_{4} y_{3}\right] \quad \text { by relabelling } \\
& =w^{\prime \prime \prime} \text {. }
\end{aligned}
$$

Otherwise, we apply the argument indicated in Figure 77.5 to conclude that

$$
\begin{aligned}
w^{\prime \prime} & =w_{0} a\left[y_{1} y_{4} y_{3}\right] b a^{-1} b^{-1}\left[y_{2} y_{5}\right] \\
& \sim w_{0} c a^{-1} c^{-1} a\left[y_{1} y_{4} y_{3} y_{2} y_{5}\right] \\
& \sim w_{0} a b a^{-1} b^{-1}\left[y_{1} y_{4} y_{3} y_{2} y_{5}\right],
\end{aligned}
$$

by relabelling, as desired.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-493.jpg?height=558&width=1107&top_left_y=862&top_left_x=643)

Figure 77.5

The final step of our classification procedure involves showing that a connected sum of projective planes and tori is equivalent to a connected sum of projective planes alone.

Lemma 77.4. Let $w$ be a proper scheme of the form

$$
w=w_{0}(c c)\left(a b a^{-1} b^{-1}\right) w_{1} .
$$

Then $w$ is equivalent to the scheme

$$
w^{\prime}=w_{0}(a a b b c c) w_{1} .
$$

Proof. Recall Lemma 77.1, which states that for proper schemes we have

$$
\begin{equation*}
\left[y_{0}\right] a\left[y_{1}\right] a\left[y_{2}\right] \sim a a\left[y_{0} y_{1}^{-1} y_{2}\right] . \tag{*}
\end{equation*}
$$

We proceed as follows:

$$
\begin{aligned}
w & \sim(c c)\left(a b a^{-1} b^{-1}\right) w_{1} w_{0} & & \text { by permuting } \\
& =c c[a b][b a]^{-1}\left[w_{1} w_{0}\right] & & \\
& \sim[a b] c[b a] c\left[w_{1} w_{0}\right] & & \text { by }(*) \text { read backwards } \\
& =[a] b[c] b\left[a c w_{1} w_{0}\right] & & \text { by }(*) \\
& \sim b b\left[a c^{-1} a c w_{1} w_{0}\right] & & \\
& =[b b] a[c]^{-1} a\left[c w_{1} w_{0}\right] & & \text { by }(*) \\
& \sim a a\left[b b c c w_{1} w_{0}\right] & & \text { by permuting. }
\end{aligned}
$$

Theorem 77.5 (The classification theorem). Let $X$ be the quotient space obtained from a polygonal region in the plane by pasting its edges together in pairs. Then $X$ is homeomorphic either to $S^{2}$, to the $n$-fold torus $T_{n}$, or to the $m$-fold projective plane $P_{m}$.

Proof. Let $w$ be the labelling scheme by which one forms the space $X$ from the polygonal region $P$. Then $w$ is a proper scheme of length least 4 . We show that $w$ is equivalent to one of the following schemes:

(1) $a a^{-1} b b^{-1}$,

(2) $a b a b$,

(3) $\left(a_{1} a_{1}\right)\left(a_{2} a_{2}\right) \cdots\left(a_{m} a_{m}\right) \quad$ with $m \geq 2$,

(4) $\left(a_{1} b_{1} a_{1}^{-1} b_{1}^{-1}\right)\left(a_{2} b_{2} a_{2}^{-1} b_{2}^{-1}\right) \cdots\left(a_{n} b_{n} a_{n}^{-1} b_{n}^{-1}\right) \quad$ with $n \geq 1$.

The first scheme gives rise to the space $S^{2}$, and the second, to the space $P^{2}$, as we noted in Examples 2 and 4 of $\S 74$. The third leads to the space $P_{m}$ and the fourth to the space $T_{n}$.

Step 1. Let $w$ be a proper scheme of torus type. We show that $w$ is equivalent either to scheme (1) or to a scheme of type (4).

It $w$ has length four, then it can be written in one of the forms

$$
a a^{-1} b b^{-1} \quad \text { or } \quad a b a^{-1} b^{-1} \text {. }
$$

The first is of type (1) and the second of type (4).

We proceed by induction on the length of $w$. Assume $w$ has length greater than four. If $w$ is equivalent to a shorter scheme of torus type, then the induction hypothesis applies. Otherwise, we know that $w$ contains no pair of adjacent terms having the same label. We apply Lemma 77.3 (with $w_{0}$ empty) to conclude that $w$ is equivalent to a scheme having the same length as $w$, of the form

$$
a b a^{-1} b^{-1} w_{3},
$$

where $w_{3}$ is of torus type. Note that $w_{3}$ is not empty because $w$ has length greater than four. Again, $w_{3}$ cannot contain two adjacent terms having the same label, since
$w$ is not equivalent to a shorter scheme of torus type. Applying the lemma again, with $w_{0}=a b a^{-1} b^{-1}$, we conclude that $w$ is equivalent to a scheme of the form

$$
\left(a b a^{-1} b^{-1}\right)\left(c d c^{-1} d^{-1}\right) w_{4}
$$

where $w_{4}$ is empty or of torus type. If $w_{4}$ is empty, we are finished; otherwise we apply the lemma again. Continue similarly.

Step 2. Now let $w$ be a proper scheme of projective type. We show that $w$ is equivalent either to scheme (2) or to a scheme of type (3).

If $w$ has length four, Corollary 77.2 implies that $w$ is equivalent to one of the schemes $a a b b$ or $a a b^{-1} b$. The first is of type (3). The second can be written in the form $a a y_{1}^{-1} y_{2}$, with $y_{1}=y_{2}=b$; then Lemma 77.1 implies that it is equivalent to the scheme $a y_{1} a y_{2}=a b a b$, which is of type (2).

We proceed by induction on the length of $w$. Assume $w$ has length greater than four. Corollary 77.2 tells us that $w$ is equivalent to a scheme of the form

$$
w^{\prime}=\left(a_{1} a_{1}\right) \cdots\left(a_{k} a_{k}\right) w_{1},
$$

where $k \geq 1$ and $w_{1}$ is of torus type or empty. If $w_{1}$ is empty, we are finished. If $w_{1}$ has two adjacent terms having the same label, then $w^{\prime}$ is equivalent to a shorter scheme of projective type and the induction hypothesis applies. Otherwise, Lemma 77.3 tells us that $w^{\prime}$ is equivalent to a scheme of the form

$$
w^{\prime \prime}=\left(a_{1} a_{1}\right) \cdots\left(a_{k} a_{k}\right) a b a^{-1} b^{-1} w_{2},
$$

where $w_{2}$ is either empty or of torus type. Then we apply Lemma 77.4 to conclude that $w^{\prime \prime}$ is equivalent to the scheme

$$
\left(a_{1} a_{1}\right) \cdots\left(a_{k} a_{k}\right) a a b b w_{2} .
$$

We continue similarly. Eventually we reach a scheme of type (3).

## Exercises

1. Let $X$ be a space obtained by pasting the edges of a polygonal region together in pairs.

(a) Show that $X$ is homeomorphic to exactly one of the spaces in the following list: $S^{2}, P^{2}, K, T_{n}, T_{n} \# P^{2}, T_{n} \# K$, where $K$ is the Klein bottle and $n \geq 1$.

(b) Show that $X$ is homeomorphic to exactly one of the spaces in the following list: $S^{2}, T_{n}, P^{2}, K_{m}, P^{2} \# K_{m}$, where $K_{m}$ is the $m$-fold connected sum of $K$ with itself and $m \geq 1$.

2. (a) Write down the sequence of elementary operations required to carry out the arguments indicated in Figures 77.1 and 77.2.

(b) Write down the sequence of elementary operations required to carry out the arguments indicated in Figures 77.3, 77.4, and 77.5.

3. The proof of the classification theorem provides an algorithm for taking a proper labelling scheme for a polygonal region and reducing it to one of the four standard forms indicated in the theorem. The appropriate equivalences are the following:

(i) $\left[y_{0}\right] a\left[y_{1}\right] a\left[y_{2}\right] \sim a a\left[y_{0} y_{1}^{-1} y_{2}\right]$.

(ii) $\left[y_{0}\right] a a^{-1}\left[y_{1}\right] \sim\left[y_{0} y_{1}\right]$ if $y_{0} y_{1}$ has length at least 4 .

(iii) $w_{0}\left[y_{1}\right] a\left[y_{2}\right] b\left[y_{3}\right] a^{-1}\left[y_{4}\right] b^{-1}\left[y_{5}\right] \sim w_{0} a b a^{-1} b^{-1}\left[y_{1} y_{4} y_{3} y_{2} y_{5}\right]$.

(iv) $w_{0}(c c)\left(a b a^{-1} b^{-1}\right) w_{1} \sim w_{0} a a b b c c w_{1}$.

Using this algorithm, reduce each of the following schemes to one of the standard forms.

(a) $a b a c b^{-1} c^{-1}$.

(b) $a b c a^{-1} c b$.

(c) $a b b c a^{-1} d d c^{-1}$.

(d) $a b c d a^{-1} b^{-1} c^{-1} d^{-1}$.

(e) $a b c d a^{-1} c^{-1} b^{-1} d^{-1}$.

(f) $a a b c d c^{-1} b^{-1} d^{-1}$.

(g) $a b c d a b d c$.

(h) abcdabcd.

4. Let $w$ be a proper labelling scheme for a 10-sided polygonal region. If $w$ is of projective type, which of the list of spaces in Theorem 77.5 can it represent? What if $w$ is of torus type?

## §78 Constructing Compact Surfaces

To complete our classification of the compact surfaces, we must show that every compact connected surface can be obtained by pasting together in pairs the edges of a polygonal region. We shall actually prove something slightly weaker than this, for we shall assume that the surface in question has what is called a triangulation. We define this notion as follows:

Definition. Let $X$ be a compact Hausdorff space. A curved triangle in $X$ is a subspace $A$ of $X$ and a homeomorphism $h: T \rightarrow A$, where $T$ is a closed triangular region in the plane. If $e$ is an edge of $T$, then $h(e)$ is is said to be an edge of $A$; if $v$ is a vertex of $T$, then $h(v)$ is said to be a vertex of $A$. A triangulation of $X$ is a collection of curved triangles $A_{1}, \ldots, A_{n}$ in $X$ whose union is $X$ such that for $i \neq j$, the intersection $A_{i} \cap A_{j}$ is either empty, or a vertex of both $A_{i}$ and $A_{j}$, or an edge of both. Furthermore, if $h_{i}: T_{i} \rightarrow A_{i}$ is the homeomorphism associated with $A_{i}$, we require that when $A_{i} \cap A_{j}$ is an edge $e$ of both, then the map $h_{j}^{-1} h_{i}$ defines a linear homeomorphism of the edge $h_{i}^{-1}(e)$ of $T_{i}$ with the edge $h_{j}^{-1}(e)$ of $T_{j}$. If $X$ has a triangulation, it is said to be triangulable.

It is a basic theorem that every compact surface is triangulable. The proof is long but not exceedingly difficult. (See $[\mathrm{A}-\mathrm{S}]$ or $[\mathrm{D}-\mathrm{M}]$.)

Theorem 78.1. If $X$ is a compact triangulable surface, then $X$ is homeomorphic to the quotient space obtained from a collection of disjoint triangular regions in the plane by pasting their edges together in pairs.

Proof. Let $A_{1}, \ldots, A_{n}$ be a triangulation of $X$, with corresponding homeomorphisms $h_{i}: T_{i} \rightarrow A_{i}$. We assume the triangles $T_{i}$ are disjoint; then the maps $h_{i}$ combine to define a map $h: E=T_{1} \cup \cdots \cup T_{n} \rightarrow X$ that is automatically a quotient map. ( $E$ is compact and $X$ is Hausdorff.) Furthermore, because the map $h_{j}^{-1} \circ h_{i}$ is linear whenever $A_{i}$ and $A_{j}$ intersect in an edge, $h$ pastes the edges of $T_{i}$ and $T_{j}$ together by a linear homeomorphism.

We have two things to prove. First, we must show that for each edge $e$ of a triangle $A_{i}$, there is exactly one other triangle $A_{j}$ such that $A_{i} \cap A_{j}=e$. This will show that the quotient map $h$ pastes the edges of the triangles $T_{i}$ together in pairs.

The second is a bit less obvious. We must show that if the intersection $A_{i} \cap A_{j}$ equals a vertex $v$ of each, then there is a sequence of triangles having $v$ as a vertex, beginning with $A_{i}$ and ending with $A_{j}$, such that the intersection of each triangle of the sequence with its successor equals an edge of each. See Figure 78.1.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-497.jpg?height=430&width=622&top_left_y=1256&top_left_x=885)

Figure 78.1

If this were not the case, one might have a situation such as that pictured in Figure 78.2. Here, one cannot specify the quotient map $h$ merely by specifying how the edges of the triangles $T_{i}$ are to be pasted together, but one must also indicate how the vertices are to be identified when that identification is not forced by the pasting of edges.

Step 1. Let us tackle the second problem first. We show that because the space $X$ is a surface, a situation such as that indicated in Figure 78.2 cannot occur.

Given $v$, let us define two triangles $A_{i}$ and $A_{j}$ having $v$ as a vertex to be equivalent if there is a sequence of triangles having $v$ as a vertex, beginning with $A_{i}$ and ending with $A_{j}$, such that the intersection of each triangle with its successor is an edge of each. If there is more than one equivalence class, let $B$ be the union of the triangles in one

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-498.jpg?height=469&width=680&top_left_y=371&top_left_x=681)

Figure 78.2

class and let $C$ be the union of the others. The sets $B$ and $C$ intersect in $v$ alone because no triangle in $B$ has an edge in common with a triangle in $C$. We conclude that for every sufficiently small neighborhood $W$ of $v$ in $X$, the space $W-v$ is nonconnected.

On the other hand, if $X$ is a surface, then $v$ has a neighborhood homeomorphic to an open 2-ball. In this case, $v$ has arbitrarily small neighborhoods $W$ such that $W-v$ is connected.

Step 2. Now we tackle the first question. This is a bit more work. First, we show that, given an edge $e$ of the triangle $A_{i}$, there is at least one additional triangle $A_{j}$ having $e$ as an edge. This is a consequence of the following result:

If $X$ is a triangular region in the plane and if $x$ is a point interior to one of the edges of $X$, then $x$ does not have a neighborhood in $X$ homeomorphic to an open 2-ball.

To prove this fact, we note that $x$ has arbitrarily small neighborhoods $W$ for which $W-x$ is simply connected. Indeed, if $W$ is the $\epsilon$-neighborhood of $x$ in $X$, for $\epsilon$ small, then it is easy to see that $W-x$ is contractible to a point. See Figure 78.3.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-498.jpg?height=344&width=741&top_left_y=1654&top_left_x=645)

Figure 78.3

On the other hand, suppose there is a neighborhood $U$ of $x$ that is homeomorphic to an open ball in $\mathbb{R}^{2}$, with the homeomorphism carrying $x$ to $\mathbf{0}$. We show that $x$ does not have arbitrarily small neighborhoods $W$ such that $W-x$ is simply connected.

Indeed, let $B$ be the open unit ball in $\mathbb{R}^{2}$ centered at the origin, and suppose $V$ is
any neighborhood of $\mathbf{0}$ that is contained in $B$. Choose $\epsilon$ so that the open ball $B_{\epsilon}$ of radius $\epsilon$ centered at $\mathbf{0}$ lies in $V$, and consider the inclusion mappings

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-499.jpg?height=195&width=519&top_left_y=488&top_left_x=945)

The inclusion $i$ is homotopic to the homeomorphism $h(x)=x / \epsilon$, so it induces an isomorphism of fundamental groups. Therefore, $k_{*}$ is surjective; it follows that $V-\mathbf{0}$ cannot be simply connected. See Figure 78.4.

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-499.jpg?height=408&width=402&top_left_y=856&top_left_x=998)

Figure 78.4

Step 3. Now we show that given an edge $e$ of the triangle $A_{i}$, there is no more than one additional triangle $A_{j}$ having $e$ as an edge. This is a consequence of the following result:

Let $X$ be the union of $k$ triangles in $\mathbb{R}^{3}$, each pair of which intersect in the common edge e. Let $x$ be an interior point of $e$. If $k \geq 3$, then $x$ does not have a neighborhood in $X$ homeomorphic to an open 2-ball.

We show that there is no neighborhood $W$ of $x$ in $X$ such that $W-x$ has abelian fundamental group. It follows that no neighborhood of $x$ is homeomorphic to an open 2-ball.

To begin, we show that if $A$ is the union of all the edges of the triangles of $X$ that are different from $e$, then the fundamental group of $A$ is not abelian. The space $A$ is the union of a collection of $k$ arcs, each pair of which intersect in their end points. If $B$ is the union of three of the arcs that make up $A$, then there is a retraction $r$ of $A$ onto $B$, obtained by mapping each of the arcs not in $B$ homeomorphically onto one of the arcs in $B$, keeping the end points fixed. Then $r_{*}$ is an epimorphism. Since the fundamental group of $B$ is not abelian (by Example 1 of $\S 70$ or Example 3 of $\S 58$ ), neither is the fundamental group of $A$.

It follows that the fundamental group of $X-x$ is not abelian, for it is easy to see that $A$ is a deformation retract of $X-x$. See Figure 78.5.

Now we prove our result. For convenience, assume $x$ is the origin in $\mathbb{R}^{3}$. If $W$ is an arbitrary neighborhood of $\mathbf{0}$, we can find a "shrinking map" $f(x)=\epsilon x$ that carries $X$

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-500.jpg?height=519&width=547&top_left_y=368&top_left_x=745)

Figure 78.5

into $W$. The space $X_{\epsilon}=f(X)$ is a copy of $X$ lying inside $W$. Consider the inclusions

![](https://cdn.mathpix.com/cropped/2024_03_09_120282c019557ec98d3dg-500.jpg?height=194&width=535&top_left_y=1088&top_left_x=754)

The inclusion $i$ is homotopic to the homeomorphism $h(x)=x / \epsilon$, so it induces an isomorphism of fundamental groups. It follows that $k_{*}$ is surjective, so the fundamental group of $W-\mathbf{0}$ cannot be abelian.

Theorem 78.2. If $X$ is a compact connected triangulable surface, then $X$ is homeomorphic to a space obtained from a polygonal region in the plane by pasting the edges together in pairs.

Proof. It follows from the preceding theorem that there is a collection $T_{1}, \ldots, T_{n}$ of triangular regions in the plane, and orientations and a labelling of the edges of these regions, where each label appears exactly twice in the total labelling scheme, such that $X$ is homeomorphic to the quotient space obtained from these regions by means of this labelling scheme.

We apply the pasting operation of $\S 76$. If two triangular regions have edges bearing the same label, we can (after flipping one of the regions if necessary) paste the regions together along these two edges. The result is to replace the two triangular regions by a single four-sided polygonal region, whose edges still bear orientations and labels. We continue similarly. As long as we have two regions having edges bearing the same label, the process can be continued.

Eventually one reaches the situation where either one has a single polygonal region, in which case the theorem is proved, or one has several polygonal regions, no two of which have edges bearing the same label. In such a case, the space formed by carrying out the indicated pasting of edges is not connected; in fact, each of the regions
gives rise to a component of this space. Since the space $X$ is connected, this situation cannot occur.

## Exercises

1. What space is indicated by each of the following labelling schemes for a collection of four triangular regions?

(a) $a b c$, dae, bef, $c d f$.

(b) $a b c, c b a, d e f, d f e^{-1}$.

2. Let $H^{2}$ be the subspace of $\mathbb{R}^{2}$ consisting of all points $\left(x_{1}, x_{2}\right)$ with $x_{2} \geq 0$. A 2manifold with boundary (or surface with boundary) is a Hausdorff space $X$ with a countable basis such that each point $x$ of $X$ has a neighborhood homeomorphic with an open set of $\mathbb{R}^{2}$ or $H^{2}$. The boundary of $X$ (denoted $\partial X$ ) consists of those points $x$ such that $x$ has no neighborhood homeomorphic with an open set of $\mathbb{R}^{2}$.

(a) Show that no point of $H^{2}$ of the form $\left(x_{1}, 0\right)$ has a neighborhood (in $H^{2}$ ) that is homeomorphic to an open set of $\mathbb{R}^{2}$.

(b) Show that $x \in \partial X$ if and only if there is a homeomorphism $h$ mapping a neighborhood of $x$ onto an open set of $H^{2}$ such that $h(x) \in \mathbb{R} \times 0$.

(c) Show that $\partial X$ is a 1 -manifold.

3. Show that the closed unit ball in $\mathbb{R}^{2}$ is a 2-manifold with boundary.
4. Let $X$ be a 2-manifold; let $U_{1}, \ldots, U_{k}$ be a collection of disjoint open sets in $X$; and suppose that for each $i$, there is a homeomorphism $h_{i}$ of the open unit ball $B^{2}$ with $U_{i}$. Let $\epsilon=1 / 2$ and let $B_{\epsilon}$ be the open ball of radius $\epsilon$. Show that the space $Y=X-\bigcup h_{i}\left(B_{\epsilon}\right)$ is a 2-manifold with boundary, and that $\partial Y$ has $k$ components. The space $Y$ is called " $X$-with- $k$-holes."
5. Prove the following:

Theorem. Given a compact connected triangulable 2-manifold $Y$ with boundary, such that $\partial Y$ has $k$ components, then $Y$ is homeomorphic to $X$-with- $k$-holes, where $X$ is either $S^{2}$ or the $n$-fold torus $T_{n}$ or the $m$-fold projective plane $P_{m}$.

[Hint: Each component of $\partial Y$ is homeomorphic to a circle.]

## Bibliography

[A] L. V. Ahlfors. Complex Analysis, 3rd edition. McGraw-Hill Book Company, New York, 1979.

[A-S] L. V. Ahlfors and L. Sario. Riemann Surfaces. Princeton University Press, Princeton, N.J., 1960.

[C] P. J. Campbell. The origin of "Zorn's lemma". Historia Mathematica, 5:7789, 1978 .

[D-M] P. H. Doyle and D.A. Moran. A short proof that compact 2-manifolds can be triangulated. Inventiones Math., 5:160-162, 1968.

[D] J. Dugundji. Topology. Allyn and Bacon, Boston, 1966.

[F] M. Fuchs. A note on mapping cylinders. Michigan Mathematical Journal, 18:289-290, 1971.

[G-P] V. Guillemin and A. Pollack. Differential Topology. Prentice Hall, Inc., Englewood Cliffs, N.J., 1974.

[H] P. R. Halmos. Naive Set Theory. Van Nostrand Reinhold Co., New York, 1960.

[H-S] D. W. Hall and G. L. Spencer. Elementary Topology. John Wiley \& Sons, Inc., New York, 1955.

[H-W] W. Hurewicz and H. Wallman. Dimension Theory. Princeton University Press, Princeton, New Jersey, 1974.

[H-Y] J. G. Hocking and G. S. Young. Topology. Addison-Wesley Publishing Company, Inc., Reading, Mass., 1961.

[K] J. L. Kelley. General Topology. Springer-Verlag, New York, 1991.

[K-F] A. N. Kolmogorov and S. V. Fomin. Elements of the Theory of Functions and Functional Analysis, vol. 1. Graylock Press, Rochester, New York, 1957.

[M] W. S. Massey. Algebraic Topology: An Introduction. Springer-Verlag, New York, 1990.

[Mo] G. H. Moore. Zermelo's Axiom of Choice. Springer-Verlag, New York, 1982.

[Mu] J. R. Munkres. Elements of Algebraic Topology. Perseus Books, Reading, Mass., 1993.

[M-Z] D. Montgomery and L. Zippin. Topological Transformation Groups. Interscience Publishers, Inc., New York, 1955.

[RM] M. E. Rudin. The box product of countably many compact metric spaces. General Topology and Its Applications, 2:293-298, 1972.

[RW] W. Rudin. Real and Complex Analysis, 3rd edition. McGraw-Hill Book Company, New York, 1987.

[S-S] L. A. Steen and J. A. Seebach Jr. Counterexamples in Topology. Holt, Rinehart \& Winston, Inc., New York, 1970.

[Sm] R. M. Smullyan. The continuum hypothesis. In The Mathematical Sciences, A Collection of Essays. The M.I.T. Press, Cambridge, Mass., 1969.

[S] E. H. Spanier. Algebraic Topology. McGraw-Hill Book Company, New York, 1966.

[T] J. Thomas. A regular space, not completely regular. American Mathematical Monthly, 76:181-182, 1969.

[W] R. L. Wilder. Introduction to the Foundations of Mathematics. John Wiley and Sons, Inc., New York, 1965.

[Wd] S. Willard. General Topology. Addison-Wesley Publishing Company, Inc., Reading, Mass., 1970.

## Index

Page references followed by "f" indicate illustrated figures or photographs; followed by "t" indicates a table.

A

Absolute value, 299-302, 344

complex numbers, 344

defined, 299

functions, 299, 302

properties of, 302

Accuracy, 217

Addition, 28, 129, 134, 279, 404

Algebra, 3, 5, 8, 29, 32, 70, 78, 103, 121, 174, 240, $292,307-308,318,321,347,349-351,418$, $444,447-449,477$

Algebraic functions, 104

Arcs, 306, 375, 385-388, 390-394, 396-398, 428, 496 Area, 352, 354-355

Argument, 5, 26, 44-45, 68, 72, 80, 84, 129, 146, 150 $154,162,172,194,200,252,324-325,384$ $386,390,410,431,446-447,474,483-484$, 486-490

Arithmetic, 2

Array, 48

Average, 173

Axes, 77, 270, 362, 369

Axis, 11, 22, 67, 166, 222, 335, 358, 369-371, 397, $400,432,455-456$

B

Base, 57, 148, 326-331, 356, 359, 361, 367, 369, $399-400,436,456,477$

Bearing, 497

C

Calculus, 13, 100-101, 104, 108, 127, 145-146, $151-152,170,172-173,180,187,219,346$ defined, 101, 104, 108, 219

limits, 127

Carrying, 14, 144, 220, 323, 327, 329, 447, 495, 497

Center, 335, 430, 432, 434-435, 453, 468

Circles, 22, 67, 76, 336, 369, 430-434, 438, 441, 453, $455,458,473$

center, 430, 432, 434, 453

defined, 432-433, 438, 453, 455

radius, $430,432,434,453$

Closed interval, 18, 82, 91, 145, 152-153, 158, 161, $170-172,175-176,181,205,217-218,220$, 237, 270, 317, 333

Closed intervals, 158, 162, 176, 386

Coefficients, 49, 70, 311, 318, 349-350, 352

Combinations, 9

Complement, 8-9, 75, 81, 91, 96-97, 99, 150, 158 $164,168-169,293,373,391,393$

Complex numbers, 143, 183, 334, 344, 349, 459

Complex plane, 183, 334, 401

Composition of functions, 412

Conjugates, 415-417, 420, 427, 478 defined, 427

Constant, 49, 105, 140, 158, 178, 239, 269, 319, $323-324,327,329,342-343,345,352,360$, 363-364, 366-367, 374, 377-378, 400, $423-426,432-433,452,457,463-464,466$

Continuity, 100-102, 104, 106-109, 114, 127-128, 130, 132-133, 135, 145, 154-155, 161, 165, 167, $170,173-174,188,208,215,238,249,274$ 284-285, 295-296, 301, 335, 339, 445, 464

Continuous function, 100, 102, 106-108, 110, 129, $145,165,173,205,209-211,213,217$, 220-221, 224, 237-239, 248, 257, 266, 268, $272,279,287,291,298-299,302,317,352$, 378

Convergence, 129-130, 132-133, 169, 279-291

Coordinates, 14, 28, 57, 61, 130-131, 196-197, 352, 405
Cosine, 109, 333

Counting, 38

Cubes, 147, 311-312

D

Days, 176

Decimals, 264

Degree, 49, 217, 349-350, 362-363, 402

Degrees, 363

Derivatives, 145, 278

second, 145

Difference, 8, 30, 56-57, 114, 199, 298-300, 322, 399

function, 56-57, 298-300, 322

real numbers, 30

Difference quotient 300

Difference quotients, 298-299

Differentiable function, 270, 298-299, 301

Distance, 22, 117, 173, 244, 272, 368

Distributive law, 9

Divisors, 420

Domain, 14-15, 17, 19, 50-52, 100-101, 105-106, 108, $158,319,330,372,377,379,381,389,426$ 435

defined, 14-15, 50-51, 101, 105-106, 108, 158, 319,426

determining, 14

relations, 19

## E

Empty set, 4-5, 10, 38-39, 77, 146, 177, 182, 293, $313,409,412,414$

Equality, 2, 12, 17-19, 98-99, 117, 247, 303

Equations, 4, 51, 54-55, 87, 99, 107, 136, 138 204-205, 270, 301, 307, 322, 326, 334-335, 347, 358-359, 369-370

polynomial, 307

rational, 205

Equivalence, 19-23, 26, 70, 72, 135, 137, 143 157-158, 161, 235, 269, 318, 320, 359-362, $397,444-449,453,456,460-461,463$, $469-470,474-475,483,485,494$

defined, 20, 23, 72, 135, 137, 158, 235, 269, 320, $445-446,448,453,456,463$

Error, 328

Experiment, 38

Experimentation, 390

Exponents, $33,471,487-488$ rational, 33

F

Factors, 85, 108, 408, 449 defined, 85, 108

Family of functions, 116

Fibonacci numbers, 54

formula, 54

recursive definition, 54

Finite sequence, 408, 468

First coordinate, 11, 13, 19, 52, 57-58, 136, 143, 153, 333, 337

First quadrant, 43

Fixed points, 318, 344-345, 347, 469

Formulas, 33, 45

defined, 45

Fractions, 29

multiplying, 29

Frequency, 19

Functions, 13-17, 34-36, 38, 42, 47, 49-50, 52, 59, 70, $73-74,76,78,80,82,84-86,88,90,92,94$, $96,98,100-112,114-116,118,120,122$, 124-130, 132-134, 136, 138-140, 142, 144 $145,169,185,188,192,205,209,211,213$, 215-217, 219-220, 223-224, 237, 239, 246-247, 249, 256-257, 261, 264-267, 270 , $272,274,276,278-283,286-288,291,292$ $295,297-299,302,317,333,350,399,412$, 500 algebraic, 49, 103-104, 133, 223, 286, 399, 500 constant, 49, 105, 140, 239

cube, 126

defined, 14-16, 34-36, 42, 47, 50, 80, 82, 85, 96 $101,104-106,108-111,115-116,118$, 122, 125-126, 129, 136, 140, 144, 211, 213, 215, 217, 219, 223-224, 237, 239, 257, 261, 264-266, 272, 276, 280, 283, 286, 298-299

difference, 114, 298-299, 399

domain and range, 100

even, 13, 15, 34, 38, 49, 59, 74, 101, 125, 132, $139,188,224,264,274,292$

family of, 34-36, 59, 110-112, 114, 116, 215-216, 223, 256

identity, 102, 104, 109, 142, 144, 211, 239, 333 , 412

inverse, 16-17, 101-104, 107-108, 115, 134, 145, 317

linear, 70, 78, 144, 292, 302

maximum value, 145

minimum value, 283

notation, 14, 17, 34-35, 82, 94, 111-112, 264, 266 280

odd, 34

one-to-one, 16

piecewise, 302

polynomial, 49, 350

product, 13, 34-36, 42, 47, 49, 84-86, 88, 90, 98, $101,108,110-112,114-116,122$, 124-127, 132, 139-140, 192, 209, 213 $215,220,224,246,249,264,278,280$, 287-288, 298, 500

quotient, 129, 134, 136, 138-140, 142, 144, 239, 287

rational, $34,49,59,82,90,94,100,142,188,192$, 205, 209, 211, 264, 297

square, $17,88,104,120,122,132,270,272,276$ 279

square-root, 17, 104

sum, 220, 224, 256-257

transcendental, 49

trigonometric, 105, 109

Fundamental theorem of algebra, $318,349-351$

G

Geometric series, 219

defined, 219

infinite, 219

Geometry, 11, 134, 146, 223, 250, 307, 310, 366, 368

Graphs, 19, 192, 280, 301, 306, 323-324, 390-391, 393-394

Greater than, 60, 66, 72, 193, 208, 420, 487, 491-492

$\mathrm{H}$

Hemisphere, 353, 440

Horizontal line, 67, 302, 352

graph of, 302

Horizontal lines, 67

I

Identity, 2, 19, 37, 102, 104, 109, 141-142, 144, 161, 181, 211, 236, 239-240, 268, 285, 323 $325-327,330-331,333,336,342,344-346$ $349,356-357,359,361-363,367,379,381$ $383,385,400,403-406,408-409,411-419$, 428, 432-433, 447, 449, 456, 459-461, 477-478

defined, 104, 109, 144, 211, 236, 239, 285, 323, $326-327,342,357,367,383,385,404$, $411,413,432-433,456,477$

property, 161, 181, 239, 404, 406, 413-415, 417

Image, 14, 16-17, 44, 48, 52-53, 55, 70-71, 100-103, $105-108,115-116,134-136,138,143,148$, 152-154, 164, 174, 213, 249, 265, 270, 273, $279,284,305,321,326,332,334-335,350$
$352,356,364,366-367,377,389,399-401$, 406, 428-429, 432, 435-436, 446, 454, 463, 478,480

Independence, 307

Inequalities, 29, 32, 44, 171, 173, 267, 275-276

defined, 44, 275-276

linear, 29

Infinite, 36-37, 42-46, 48-63, 65, 68, 72, 73, 81, 109 $111,115,122-123,126,133,150,160-161$, 167, 176-179, 193, 196, 206-207, 210, 219-222, 257, 274, 302, 336, 342, 344, 358, 362-363, 381, 383-384, 387, 396-397 407-408, 417-418, 420, 428, 431-434, 436, $440,453,465-466$

geometric series, 219

sequences, 61-62, 65, 126, 193

series, 109, 122, 126, 133, 219-220, 302

Infinite sequence, 36, 44, 53-54, 61-62, 109, 206-207, 220

Infinity, 278

Initial point, 270, 319, 423, 469

Integers, 3, 9, 24, 27-31, 33, 35-39, 41-43, 45, 52, $60-61,65,68,83,94-95,144,177,189,198$, 204, 211, 213, 263, 274, 304, 312, 341-342, $350,353,369,381,387,441,448-449,457$, 459

multiplying, 29

Integrals, 318, 401

Interest, 9, 28, 63, 79, 97, 283, 347, 366, 402, 453 simple, 402

Intermediate value theorem, 145, 151-152, 154-155, 333

Intersection of sets, 4

Intervals, 79-80, 82-83, 85, 88, 99, 114, 147, 151-153, $158,162,164,176,188,195,201,217,221$ $225,242,280,303,311,324-325,333-334$, 386

Inverse, 16-17, 19, 27, 60, 101-104, 107-108, 115, 134-135, 143, 145, 156, 174, 268, 317, $323-324,326-328,330,332,334-335,342$, $352,359,361-362,365,377,379,403,408$, $418,421,427-429,457,478,482-483,485$

functions, $16-17,101-104,107-108,115,134,145$ 317

Inverse functions, 145

Irrational number, 147

Irrational numbers, 198

L

Length, 176, 217, 271-272, 386, 408-412, 414, 417, $471,482,485-487,491-493$

Limits, 98, 127, 237, 279

Line, 22, 24, 26-27, 31, 67, 73, 79, 82, 88, 90-91, $94-97,100,120,136,141,143,147$ 151-157, 159-162, 164, 170-171, 173, 175, $180,183,188,192,196,205-206,212,225$ 230, 236, 254, 264, 270, 273, 300-302, 307, $315,317-318,321,324,327,330,333-334$, $349,352,354,356,358,360,362$, 365-366 $377,395,397-398,401,425,436,465$, 468-469, 474, 480-481

horizontal, 67, 212, 302, 352

slope of, 300

tangent, 67

Line segments, 141, 160, 192, 212, 254, 301, 307, $330,362,465,469$

Linear combination, 70,78

Linear functions, 302

Lines, 22, 67, 141, 156, 299, 389-390

defined, 156, 299

parallel, 22

slope of, 299

Loops, 327-328, 331, 343, 359, 369, 387, 399, 424, $430-432,438,473$

Lower bound, 25, 27, 31, 33, 61, 89, 208

M

Mass, 500

Matrices, 144

defined, 144

identity, 144

Matrix, 144, 347-349, 377, 449

Maximum, 66-71, 100, 145, 161

Mean, 2-3, 10, 19-20, 23, 34, 38, 42, 69, 87, 115, 127 . $145,180,190,205,239,256-257,303,307$. $347,430,455,468$

defined, 10, 20, 23, 34, 42, 69, 115, 190, 239, 257, 303, 455 geometric, 307

Means, 2-3, 5, 22, 53, 68, 74, 131, 144, 155, 159, 171 $178,192,196,209,233,244,249-250,265$ 268, 274, 278, 284-286, 299, 303, 312, 321, $343,346,357,367,400,408,437,441,456$, $468,471-476,479-482,484,497$

Measures, 309, 363, 394

Midpoint, 436

Minimum, 174, 257, 283, 310, 368

Multiples, 448

Multiplication, 28, 129, 134, 144, 350, 353, 449 of integers, 353

N

Notation, 2, 4, 6-7, 10-11, 14, 17, 19-20, 23, 28, 30, $34-35,82-83,93-94,111-112,117,179,204$, $231,244,264,266,280,330,346,392,406$, $418,422,427,464,477,479$

interval, 11, 23, 82, 204, 264

limit, 10, 82, 93, 179, 266

set, 2 , 4, 6-7, 10-11, 14, 17, 19-20, 23, 28, 30 $34-35,82-83,93-94,111-112,117,179$ $204,231,244,264,266,280,330,392$ $406,418,422,464$

nth partial sum, 220

nth root, 156

defined, 156

Numbers, 2-3, 5-6, 11-15, 22-26, 28-31, 33-34, 36, 46 $48-49,53-54,59,61,69,80,94-95,101-102$ 104, 116-118, 125, 133, 141-143, 145, 149, $158,168,170,173-174,180,183,190,198$, 205-208, 210-211, 257-258, 263-264, 298-299, 311-312, 325, 334, 344, 347-349, $381,401,459,468$

composite, 15, 46, 141, 344

irrational, 34,198

positive, 2, 24, 29-31, 33-34, 36, 46, 49, 69, 94-95, $117,173,198,257-258,299,325$ 347-349, 459

prime, 459

rational, 30-31, 33-34, 46, 49, 59, 69, 94-95, $141-142,158,180,190,198,205-208$, 210-211, 264

real, 2-3, 5-6, 11-15, 22-26, 28-31, 33-34, 36 $48-49,53-54,61,69,94-95,101-102$, $104,116,118,133,143,145,149,168$, 170, 173-174, 180, 183, 205-206, 264, $312,334,347-349,468$

O

Open interval, 23, 80, 82, 88, 118, 131, 157, 188, 190 198, 204, 208, 220, 236, 252, 264, 315, 317, 430

Open intervals, 79-80, 82-83, 85, 114, 162, 188, 195, 225, 303, 311

Ordered pair, 11, 13, 35, 57-58, 74, 346

Ordered pairs, $11,35,57$

Origin, 22, 67, 130-131, 136, 141, 154-155, 211, 221, $242,251,277,335,352,354,356,369-370$, $374,379,394,432,435,453,465,495-496$, 499

symmetry, 22

## P

Parabola, 299

defined, 299

Paths, 270-272, 318-319, 321-326, 328-329, 331, 338 $340-344,360,370,382,385-387,395,397$, 424-426, 438, 446, 454, 461, 463-464, 466, 477

definition of, 323, 382, 424, 463, 477

Permutations, 414

Plane, 11, 22, 24, 26-27, 67, 76-77, 79, 88, 90-91, 96, $100-101,105,108,120,143,147,154,183$, 191, 196, 212, 270, 293, 307-309, 317-318, $321,333-336,352-355,358,361,365$, $368-369,371,372-376,378,380,382,384$, $386,388,390-394,396,398,400-402,430$, $435,440,453,468-469,471,474-476,483$, $485,491,493-495,497-498$

Point, 1, 3, 6, 9-11, 15, 21-22, 24, 28, 31, 39, 45, 48, $51,55,63-64,68,77,80,83,85,88,91$, $94-99,101-103,105,107-111,113-118,122$, 124, 127-128, 130-131, 134, 136-137, $140-144,146-150,152-163,165,167$, $170-172,174-186,188-196,198,200,202$ 204, 206-216, 221-226, 229-230, 233-234 236-238, 240, 241-242, 245-251, 253-255,
259-260, 262, 264-270, 272-273, 276, $278-280,282,284-286,289,293-294$, 296-297, 301, 303-313, 317-319, 321, 323 326-332, 334-336, 339-343, 345-350, 352, 354-359, 362-363, 365-366, 368-371, $373-375,380-382$, 384-395, 397-402 $423-424,426,428,430-440,443,445-448$, 450-451, 453, 456-457, 459-461, 463-465, 468-470, 473, 475, 477, 479, 487, 495-496 498

Points, 2, 14, 16-17, 22, 26, 37, 43, 48, 66-67, 69, 73, $83,88,90-91,93,95-100,106,116-117,119$, 121-123, 127-132, 137, 139, 141-144, 146-148, 150-160, 162-163, 170-172, 174, 176-180, 182, 185, 188-190, 192-193, 195-198, 202, 204, 206, 209, 212, 216, 222, $229,234-236,238,240,246,248,257,259$, 262-265, 267, 269, 274, 278-282, 289, 295, 297, 304-311, 313-315, 318, 320-321, 324-325, 328-331, 333, 344-349, 352-353, $355,361,367-369,373-376,378-379$, 382, 385-393, 395-398, 400, 424-425, 428, 439-440, 447, 449, 455, 457, 465, 468-469, $473,477,480,496,498$

Polygons, 488

Polynomial, 49, 307, 318, 349-352

Positive integers, 24, 27, 30-31, 35-39, 41-43, 45, 52 $60,65,68,83,94-95,177,189,198,213$, $274,449,459$

Positive numbers, 117

Power, 10, 13, 286, 355, 394

defined, 10, 286

Power series, 286

Powers, 417, 420-421

Product, 11, 13, 19, 30, 34-37, 41-43, 47-49, 54, 57, $62-63,84-88,90-91,98-99,101,108$ $110-116,121-127,131-132,139-141$, $148-150,156,160,165-167,179,189$, 191-196, 201-203, 209-210, 213, 215, 220 $224,226,228-229,232-234,238,246,249$ $251,255,258,263-264,268,273,278,280$, 287-289, 298, 312, 322-327, 335, 342-343, $364,367,371,382-383,385,404-405$, 407-411, 413-419, 424, 427-428, 431-434, $438,441,455,466,475,479,500$

Q

Quadrants, 353

Quotient, 29-30, 129, 134-144, 150, 161, 170, 184 197, 222, 239, 287, 300, 318, 327, 345, $352-353,368,371,381-382,384,400,402$ $407,418,420,427,433-436,438-441$, $456-457,461,468,470-475,478-482,484$, $491,494,497$

functions, $129,134,136,138-140,142,144,239$, 287

real numbers, $29-30,170,468$

Quotients, 30, 108, 127, 298-299

$\mathbf{R}$

Range, 14-17, 19, 36, 41, 44, 98, 100-101, 103, $105-106,148,236,321,435$ defined, 14-16, 36, 41, 44, 101, 105-106, 236 determining, 14

Rational numbers, 30-31, 46, 59, 94-95, 141-142, 158, 180, 190, 205-208, 211, 264 principle of, 30, 46, 206

Ray, 84, 89-91, 152, 159, 214

Rays, 83-84, 88-89, 151-152

Real numbers, 2-3, 5-6, 11-15, 22-26, 28-31, 33-34, $36,48,53-54,61,69,102,104,116,118$, $133,145,149,168,170,174,347,468$ defined, $6,11,14-15,23,30,34,36,53-54,69$, in calculus, 13 104, 116, 118

inequalities, 29

integers, 3, 24, 28-31, 33, 36, 61

irrational, 34

ordered pair, 11, 13

properties of, 22-23, 25, 28, 30-31, 33, 48, 145, 170, 174

rational, 30-31, 33-34, 69

real, 2-3, 5-6, 11-15, 22-26, 28-31, 33-34, 36, 48, $53-54,61,69,102,104,116,118,133$, $145,149,168,170,174,347,468$

Reciprocals, 134

Rectangle, 85, 134, 137-138, 339-340, 425 fundamental, $339-340$

Rectangles, 77, 84, 339-340, 343 similar, 84

Reflection, 363, 365

Relations, 2, 19-28, 71, 320, 420-421, 441

defined, 20, 23, 27, 320

domain and range of, 19

graphs of, 19

Remainder, 110, 127, 312, 376, 481

Rise, 21, 72, 153, 235-236, 286, 328-329, 356, 470 491,498

Roots, 49, 307, 349, 352

of the equation, 352

Run, 62, 76, 209, 360

S

Scalars, 308

Secant, 299

defined, 299

Second coordinate, 11, 57, 158, 353

Semicircle, 212

Sequences, 61-62, 65, 96, 116, 125-129, 149, 185-186, 187-189, 193, 204, 263, 269, 279, 295

converging, 128, 185-186, 188

defined, 96, 116, 125-126, 129, 189, 263, 269

finite, $62,149,185-186,187,204,279$

geometric, 96

infinite, 61-62, 65, 126, 193

limits of, 127, 279

Series, 109, 122, 126, 133, 219-220, 248, 286, 302 defined, 109, 122, 126, 219, 286 geometric, 219

Sets, $1-4,7-13,17-18,23-24,27,32,34-39,41-50$,

$55-57,59-63,65-72,73-76,78,80-86$,

$88-97,99-100,103,106-108,110-114,116$, 128-129, 131, 135-138, 141-142, 144, 146-152, 154, 156, 158-165, 167-172, 174-177, 179-186, 188-207, 209, 211-212, 215-216, 222-225, 229-231, 234-235, 238, 243-254, 256-260, 268, 274-277, 279, 281, 283-284, 286-287, 289, 293-297, 303-305, 310-312, 314-315, 332-333, 335, 338-340 $348,353,355,364-366,368,373,375-376$, $379,381-382,384-388,391-393,397,404$, $411,415,428,431,436,439,443,451,457$ $460,462-463,465-466,473,495,498$ empty, 4, 10-11, 17, 23, 37-39, 41, 44, 47-48, 55 $60,72,80-82,85,89,94,100,116$, 146-147, 168, 170-171, 176-177, 182, 196, 205, 256, 293-295, 297, 305, 411, 431

intersection, 4, 8-11, 32, 35, 61, 74, 76, 78, 80-82, $84,86,88-89,91-94,108,111-113,128$, 152, 163, 167-169, 176, 179-180, 182, 186, 192, 211-212, 224, 229-231, 234, 247-248, 268, 279, 294-295, 310, 353, 366, 376, 381, 388, 391, 393, 415, 431 $460,462,465$

union, 3-4, 8-10, 35-36, 41, 46-47, 57, 66, 70-72 $74-75,78,80,84,91-93,103,106-107$ 112, 131, 136-137, 141-142, 146-152, $158-162,165,169,172,175-176,182$ 191, 193, 197-198, 212, 216, 222, 225, $231,235,243,245,250,254,256$ 258-260, 277, 293-297, 304-305, 312, 314-315, 332-333, 335, 339, 348, 366, 368, 375-376, 381-382, 384-388, $391-393,397,428,431,436,439,451$ $457,460,463,465,473,495$

Sides, 77, 115, 270, 363, 488

Signs, 29

Sine, $109,155,158-159,236,302,313,333,377,389$ inverse, 377

Slope, 299-302, 324

Solutions, 187, 347

Spheres, 151

Square, 17, 31, 33, 88, 99, 104, 120-122, 132 153-154, 160, 171, 191, 226, 236, 254, 263 270-272, 276-277, 279, 309, 311, 434 $470-472,476$

Squares, $272,304,335,472$

Statements, $3,6-7,10,12,20,55,70,108,168,233$, 239, 246, 273

defined, $6,10,20,55,108,239$

Subset, 2-3, 7, 10, 13-15, 17, 19-20, 23, 25-27, 30-33, $39-46,48,50,52,55-58,60-61,64-72,74$, $76,81,84-97,100,102,107,109,116,119$, 122, 125-126, 128, 130-131, 135-137, 139-142, 144, 146-148, 150, 153-154, 156,
160-161, 164, 172-174, 176-177, 179, 185, 188-190, 192-193, 195-197, 201, 204, 206, 213, 216, 220-221, 223, 225-226, 231-232, $234,240,243-244,247-248,250,262-263$ 265, 269, 274-276, 278-280, 282-283, 288-290, 293, 297-298, 303, 308-311, 327 , $330,333-334,353,366,369,377-379$, 414-416, 431, 453, 463, 465

Subtraction, 29, 129, 134

Sum, 30, 53, 220, 224-225, 256-257, 311, 403-408, $410-411,413,420,473-474,478-479,487$, 490, 492

Sums, 108, 126-127, 220, 403-407, 410, 414, 421

Symbols, 2-3, 12-13, 20, 28, 31, 35, 418

Symmetry, 20-22, 157-158, 181, 391, 393, 462

T

Tangent, 67, 363, 369-370

Temperature, 355

Transformations, 453-459

Triangles, 493-494, 496

theorem, 493-494

Trigonometric functions, 105, 109

sine and cosine, 109

U

Union of sets, 3

Unit circle, 104, 221, 236, 375, 430-431, 434

defined, 104, 236

Upper bound, 25-27, 29-31, 64, 68-69, 72, 89, 151-153, 170-171, 175, 177, 179, 181, 202, 231, 263

V

Variables, 101, 284, 336, 401 functions, 101

Vectors, 78, 307-308, 346 defined, 308

linear combination of, 78

parallel, 308

unit, 346

Vertex, 307, 348, 392-393, 471, 482, 493-494

Vertical, 3, 24, 141, 148, 155, 158, 202, 280

Vertical line, 24

Vertical lines, 141

$\mathrm{X}$

x-axis, 11, 22, 222, 369-371, 397, 400, 432, 455-456 xy-plane, 335,358

$Y$

y-axis, 11, 67, 166, 369-371, 455-456

y-coordinate, 22, 165

Years, 4, 57, 63, 66, 73, 101, 209, 250, 372

Z

Z-axis, 335,358

Zero, 29, 38, 49, 70, 116, 125-126, 130, 132, 134, 160 $249,256,300-301,338,372,386,409,412$


[^0]:    †Analysts are apt to use the word "range" to denote what we have called the "image set" of $f$. They avoid giving the set $B$ a name.

[^1]:    ${ }^{\dagger}$ This section will be assumed in Chapters 5 and 14.

[^2]:    ${ }^{\dagger}$ This section will be used throughout Part II of the book. It also is referred to in a number of exercises of Part I.

[^3]:    ${ }^{\dagger}$ This section will be assumed in Part II of the book.

[^4]:    ${ }^{\dagger}$ This is a good example of how a word can be overused. We have already defined what we mean by a separation of a space; and we shall discuss the separation axioms shortly.

[^5]:    ${ }^{\dagger}$ Kelley $[\mathrm{K}]$ attributes this example to J. Dieudonné and A. P. Morse independently.

[^6]:    ${ }^{\dagger}$ Actually, any countable dense subset of $[0,1]$ will do, providing it contains the points 0 and 1.

[^7]:    ${ }^{\dagger}$ Surprisingly enough, there does exist a connected Hausdorff space that is countably infinite. See Example 75 of [S-S].

[^8]:    ${ }^{\dagger}$ This section will be assumed in $\S 62$. It is also used in a number of exercises.

[^9]:    ${ }^{\dagger}$ This section will be assumed when we study paracompactness in $\S 41$ and when we study dimension theory in $\S 50$.

[^10]:    ${ }^{\dagger}$ In this section, we use the Tietze extension theorem (§35).

[^11]:    ${ }^{\dagger}$ This result uses Theorem 54.6, and will be used only when we deal with winding numbers in $\S 65$.

